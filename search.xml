<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Atlas--与Hive集成</title>
      <link href="/2019/05/22/Atlas-%E4%B8%8EHive%E9%9B%86%E6%88%90/"/>
      <url>/2019/05/22/Atlas-%E4%B8%8EHive%E9%9B%86%E6%88%90/</url>
      <content type="html"><![CDATA[<p>　　<br>　　本篇博文，<strong>讲解与配置Atlas与Hive的集成</strong>，以及其中遇到的一些问题，然后把hive的元数据信息导入到atlas里面，我们就可以直观的去看。<br>这边文章主要在于集成hive，其中的比如一下安装hadoop，hive等，可以查看我之前的博客。该集成不涉及到元数据血缘关系，主要通过atlas自身的导入脚本离线导入元数据，<strong>血缘以及实时导入将在后面的博文中介绍</strong>。</p><h2 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h2><ol><li><p><strong>配置</strong>，Hive安装目录/conf/hive-site.xml 添加：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.post.hooks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.atlas.hive.hook.HiveHook<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置</strong>，Hive安装目录/conf/hive-env.sh 添加：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_AUX_JARS_PATH=$atlas编译好的安装目录/hook/hive</span><br></pre></td></tr></table></figure></li></ol><p><strong>例如我这里修改为</strong>：<br>export HIVE_AUX_JARS_PATH=/opt/dev/idea/apache-atlas-sources-2.0.0/distro/target/apache-atlas-2.0.0-bin/apache-atlas-2.0.0/hook/hive</p><a id="more"></a><h2 id="异常解决"><a href="#异常解决" class="headerlink" title="异常解决"></a>异常解决</h2><ul><li><strong>异常1</strong>、在我们配置完上面的内容后，如果在运行hive,可能就会报如下的异常：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span> show tables;</span><br><span class="line">FAILED: Hive Internal Error: java.lang.ExceptionInInitializerError(null)</span><br><span class="line">java.lang.ExceptionInInitializerError</span><br><span class="line">at java.lang.Class.forName0(Native Method)</span><br><span class="line">at java.lang.Class.forName(Class.java:348)</span><br><span class="line">at org.apache.atlas.hive.hook.HiveHook.initialize(HiveHook.java:72)</span><br><span class="line">at org.apache.atlas.hive.hook.HiveHook.&lt;init&gt;(HiveHook.java:41)</span><br><span class="line">at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">at java.lang.Class.newInstance(Class.java:442)</span><br><span class="line">at org.apache.hadoop.hive.ql.hooks.HookUtils.getHooks(HookUtils.java:61)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.getHooks(Driver.java:1685)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.getHooks(Driver.java:1669)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1941)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)</span><br><span class="line">at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">at org.apache.hadoop.util.RunJar.run(RunJar.java:239)</span><br><span class="line">at org.apache.hadoop.util.RunJar.main(RunJar.java:153)</span><br><span class="line">Caused by: java.lang.NullPointerException</span><br><span class="line">at org.apache.atlas.hook.AtlasHook.&lt;clinit&gt;(AtlasHook.java:81)</span><br><span class="line">... 28 more</span><br><span class="line"></span><br><span class="line"><span class="meta">hive&gt;</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>解决：</strong><br><strong>原因</strong>，hive缺少了相应的脚本atlas-application.properties、atlas-env.sh，需要做一个软连接<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /opt/dev/idea/apache-atlas-sources-2.0.0/distro/target/apache-atlas-2.0.0-bin/apache-atlas-2.0.0/conf/atlas-application.properties /opt/local/apache-hive-2.3.5-bin/conf/atlas-application.properties</span><br><span class="line">ln -s /opt/dev/idea/apache-atlas-sources-2.0.0/distro/target/apache-atlas-2.0.0-bin/apache-atlas-2.0.0/conf/atlas-env.sh /opt/local/apache-hive-2.3.5-bin/conf/atlas-env.sh</span><br></pre></td></tr></table></figure></p><p><img src="https://img.xiaoxiaomo.com/blog/img/atlas_hive_1.png" alt="apache atlas"><br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_hive_2.png" alt="apache atlas"> </p><ul><li><strong>异常2</strong>、运行导入hive元数据脚本import-hive.sh，异常<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">2019-05-22T17:55:06,328 INFO [main] org.apache.atlas.AtlasBaseClient - method=GET path=api/atlas/v2/entity/uniqueAttribute/type/ contentType=application/json; charset=UTF-8 accept=application/json status=404</span><br><span class="line">Exception in thread "main" java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.util.BeanUtil.okNameForSetter(Lcom/fasterxml/jackson/databind/introspect/AnnotatedMethod;)Ljava/lang/String;</span><br><span class="line">at com.fasterxml.jackson.module.jaxb.JaxbAnnotationIntrospector.findNameForDeserialization(JaxbAnnotationIntrospector.java:1004)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.findNameForDeserialization(AnnotationIntrospectorPair.java:749)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector._addSetterMethod(POJOPropertiesCollector.java:620)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector._addMethods(POJOPropertiesCollector.java:535)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.collectAll(POJOPropertiesCollector.java:309)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.getJsonValueAccessor(POJOPropertiesCollector.java:196)</span><br><span class="line">at com.fasterxml.jackson.databind.introspect.BasicBeanDescription.findJsonValueAccessor(BasicBeanDescription.java:252)</span><br><span class="line">at com.fasterxml.jackson.databind.ser.BasicSerializerFactory.findSerializerByAnnotations(BasicSerializerFactory.java:346)</span><br><span class="line">at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._createSerializer2(BeanSerializerFactory.java:216)</span><br><span class="line">at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.createSerializer(BeanSerializerFactory.java:165)</span><br><span class="line">at com.fasterxml.jackson.databind.SerializerProvider._createUntypedSerializer(SerializerProvider.java:1388)</span><br><span class="line">at com.fasterxml.jackson.databind.SerializerProvider._createAndCacheUntypedSerializer(SerializerProvider.java:1336)</span><br><span class="line">at com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:510)</span><br><span class="line">at com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:713)</span><br><span class="line">at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:308)</span><br><span class="line">at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1396)</span><br><span class="line">at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:913)</span><br><span class="line">at com.fasterxml.jackson.jaxrs.base.ProviderBase.writeTo(ProviderBase.java:648)</span><br><span class="line">at com.sun.jersey.api.client.RequestWriter.writeRequestEntity(RequestWriter.java:300)</span><br><span class="line">at com.sun.jersey.client.urlconnection.URLConnectionClientHandler._invoke(URLConnectionClientHandler.java:204)</span><br><span class="line">at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:147)</span><br><span class="line">at com.sun.jersey.api.client.filter.HTTPBasicAuthFilter.handle(HTTPBasicAuthFilter.java:81)</span><br><span class="line">at com.sun.jersey.api.client.Client.handle(Client.java:648)</span><br><span class="line">at com.sun.jersey.api.client.WebResource.handle(WebResource.java:670)</span><br><span class="line">at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)</span><br><span class="line">at com.sun.jersey.api.client.WebResource$Builder.method(WebResource.java:623)</span><br><span class="line">at org.apache.atlas.AtlasBaseClient.callAPIWithResource(AtlasBaseClient.java:382)</span><br><span class="line">at org.apache.atlas.AtlasBaseClient.callAPIWithResource(AtlasBaseClient.java:353)</span><br><span class="line">at org.apache.atlas.AtlasBaseClient.callAPI(AtlasBaseClient.java:229)</span><br><span class="line">at org.apache.atlas.AtlasClientV2.createEntity(AtlasClientV2.java:320)</span><br><span class="line">at org.apache.atlas.hive.bridge.HiveMetaStoreBridge.registerInstance(HiveMetaStoreBridge.java:450)</span><br><span class="line">at org.apache.atlas.hive.bridge.HiveMetaStoreBridge.registerDatabase(HiveMetaStoreBridge.java:402)</span><br><span class="line">at org.apache.atlas.hive.bridge.HiveMetaStoreBridge.importDatabases(HiveMetaStoreBridge.java:281)</span><br><span class="line">at org.apache.atlas.hive.bridge.HiveMetaStoreBridge.importHiveMetadata(HiveMetaStoreBridge.java:251)</span><br><span class="line">at org.apache.atlas.hive.bridge.HiveMetaStoreBridge.main(HiveMetaStoreBridge.java:168)</span><br><span class="line">Failed to import Hive Meta Data!!!</span><br></pre></td></tr></table></figure></li></ul><p><strong>解决：</strong><br>1。下载 <code>jackson-annotations-2.9.8.jar</code>, <code>jackson-core-2.9.8.jar</code>、 <code>jackson-databind-2.9.8.jar</code>,可以通过<a href="https://mvnrepository.com下载" target="_blank" rel="noopener">https://mvnrepository.com下载</a><br>2。然后把jar放入到 ${atlas_project}/distro/target/apache-atlas-2.0.0-bin/apache-atlas-2.0.0/hook/hive/atlas-hive-plugin-impl/下面<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_hive_3.png" alt="apache atlas&amp;hive"> </p><h2 id="运行导入hive元数据"><a href="#运行导入hive元数据" class="headerlink" title="运行导入hive元数据"></a>运行导入hive元数据</h2><ul><li><p>运行：bin/import-hive.sh 成功<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_hive_4.png" alt="apache atlas import-hive.sh"> </p></li><li><p><strong>浏览</strong><br>左边选框可以选择<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_hive_5.png" alt="apache atlas web"> </p></li></ul><ul><li>参考：</li></ul><ol><li><a href="https://blog.csdn.net/jeffiny/article/details/82841171" target="_blank" rel="noopener">https://blog.csdn.net/jeffiny/article/details/82841171</a></li><li><a href="https://blog.csdn.net/hhhh222222/article/details/77427769" target="_blank" rel="noopener">https://blog.csdn.net/hhhh222222/article/details/77427769</a></li><li><a href="https://issues.apache.org/jira/browse/ATLAS-3172?page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel&amp;focusedCommentId=16827794#comment-16827794" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/ATLAS-3172?page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel&amp;focusedCommentId=16827794#comment-16827794</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Atlas </tag>
            
            <tag> 数据治理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Atlas--编译启动</title>
      <link href="/2019/05/20/Atlas-%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/"/>
      <url>/2019/05/20/Atlas-%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/</url>
      <content type="html"><![CDATA[<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><ul><li>我下载的最新版apache atlas 2.0：<a href="https://atlas.apache.org/Downloads.html" target="_blank" rel="noopener">https://atlas.apache.org/Downloads.html</a></li><li>下载后解压，进入该目录，然后开始编译。</li><li>命令：<blockquote><p>mvn clean -DskipTests install (atlas使用外部hbase和solr服务)<br>mvn clean -DskipTests package -Pdist,embedded-hbase-solr (atlas使用自带的hbase和solr服务)</p></blockquote></li></ul><ol><li>我目前使用他自带的服务hbase、solr服务.命令：mvn clean -DskipTests package -Pdist,embedded-hbase-solr</li><li>这个过程有点长，主要是这里，如果使用自带的服务需要下载一个hbase,100多MB</li><li>如果不想等，可以自己手动下载然后放入下面提示的目录，即通过：<a href="http://archive.apache.org/dist/hbase/2.0.2/hbase-2.0.2-bin.tar.gz" target="_blank" rel="noopener">http://archive.apache.org/dist/hbase/2.0.2/hbase-2.0.2-bin.tar.gz</a>下载<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_build_1.png" alt="apache atlas"> <a id="more"></a></li><li>solr服务同理，如下比较耗时，可以手动下载<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_build_2.png" alt=""> </li><li><p>重新编译，成功<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_build_3.png" alt="apache atlas编译成功"><br><strong>注意</strong>：这种方式（自带hbase+solr）只用于开发环境，不要用于生产</p></li><li><p>编译完后有如下gz压缩包，可以发现已经被解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">txd:conf tangxuandong$ cd /opt/dev/idea/apache-atlas-sources-2.0.0/distro/target/</span><br><span class="line">txd:target tangxuandong$ ll</span><br><span class="line">total 4151232</span><br><span class="line">drwxr-xr-x   5 tangxuandong  wheel        160  5 20 18:17 META-INF</span><br><span class="line">drwxr-xr-x   4 tangxuandong  wheel        128  5 20 18:17 antrun</span><br><span class="line">drwxr-xr-x   4 tangxuandong  wheel        128  5 22 18:16 apache-atlas-2.0.0-bin</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel  699096451  5 20 18:20 apache-atlas-2.0.0-bin.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-falcon-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel    9211833  5 20 18:18 apache-atlas-2.0.0-falcon-hook.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-hbase-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel   11079551  5 20 18:18 apache-atlas-2.0.0-hbase-hook.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-hive-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel   16267168  5 20 18:18 apache-atlas-2.0.0-hive-hook.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-kafka-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel    9219793  5 20 18:18 apache-atlas-2.0.0-kafka-hook.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:19 apache-atlas-2.0.0-server</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel  594436213  5 20 18:19 apache-atlas-2.0.0-server.tar.gz</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel   11078022  5 20 18:21 apache-atlas-2.0.0-sources.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-sqoop-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel    9200673  5 20 18:18 apache-atlas-2.0.0-sqoop-hook.tar.gz</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:18 apache-atlas-2.0.0-storm-hook</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel   58914529  5 20 18:18 apache-atlas-2.0.0-storm-hook.tar.gz</span><br><span class="line">drwxr-xr-x   2 tangxuandong  wheel         64  5 20 18:18 archive-tmp</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel  678903752  5 20 18:18 atlas-distro-2.0.0.jar</span><br><span class="line">drwxr-xr-x  13 tangxuandong  wheel        416  5 20 18:17 bin</span><br><span class="line">drwxr-xr-x  11 tangxuandong  wheel        352  5 20 18:17 conf</span><br><span class="line">drwxr-xr-x  13 tangxuandong  wheel        416  5 20 18:17 hbase</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:16 hbase.temp</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:17 maven-archiver</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:16 maven-shared-archive-resources</span><br><span class="line">-rw-r--r--   1 tangxuandong  wheel       3833  5 20 18:16 rat.txt</span><br><span class="line">drwxr-xr-x  14 tangxuandong  wheel        448  5 20 18:17 solr</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:17 solr.temp</span><br><span class="line">drwxr-xr-x   3 tangxuandong  wheel         96  5 20 18:17 test-classes</span><br></pre></td></tr></table></figure></li></ol><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><ul><li>编译好后，进入$project_name/distro/target/apache-atlas-2.0.0-bin/apache-atlas-2.0.0目录</li><li><p>把这个压缩包apache-atlas-2.0.0-bin.tar.gz放入到其他地方，解压后运行也是可以的，<strong>同上面一样的</strong></p></li><li><p>修改配置文件,conf/atlas-env.sh</p></li></ul><ol><li><p>如果运行的本地hbase/solr需要配置（默认已经配置好了）<br>export MANAGE_LOCAL_HBASE=true<br>export MANAGE_LOCAL_SOLR=true</p></li><li><p>设置支持大量的元数据对象<br>如果你计划来存储大量的元数据对象,建议您使用值调整GC JVM的性能更好。 　　 　　<br>以下值是常见的服务器端选项:（参见官网）<br>export ATLAS_SERVER_OPTS=”-server -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+PrintTenuringDistribution -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=dumps/atlas_server.hprof -Xloggc:logs/gc-worker.log -verbose:gc -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1m -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCTimeStamps”</p></li><li><p>如果是mac os<br>配置<br>export ATLAS_SERVER_OPTS=”-Djava.awt.headless=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=”</p></li></ol><ul><li>运行服务：./bin/atlas_start.py （默认hbase/solr一起启动）<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_build_4.png" alt="apache atlas 启动服务"> </li></ul><h2 id="访问服务"><a href="#访问服务" class="headerlink" title="访问服务"></a>访问服务</h2><ul><li>访问服务，端口21000 <a href="http://localhost:21000/index.html" target="_blank" rel="noopener">http://localhost:21000/index.html</a><br>默认账号密码：admin/admin<br><img src="https://img.xiaoxiaomo.com/blog/img/atlas_build_5.png" alt="atlas 访问服务"> </li></ul><ul><li>参考：<br><a href="https://atlas.apache.org/InstallationSteps.html" target="_blank" rel="noopener">https://atlas.apache.org/InstallationSteps.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Atlas </tag>
            
            <tag> 数据治理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper--通过idea搭建源码阅读环境</title>
      <link href="/2019/04/10/Zookeeper-%E9%80%9A%E8%BF%87idea%E6%90%AD%E5%BB%BA%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/"/>
      <url>/2019/04/10/Zookeeper-%E9%80%9A%E8%BF%87idea%E6%90%AD%E5%BB%BA%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/</url>
      <content type="html"><![CDATA[<ul><li>因为有了之前的经验，前面已经讲过<a href="https://blog.xiaoxiaomo.com/2019/04/07/HBase-%E9%80%9A%E8%BF%87idea%E6%90%AD%E5%BB%BA%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/">HBase-通过idea搭建源码阅读环境</a>所以下面讲的比较简洁，很多配置类似。</li></ul><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>zookeeper 服务启动<br>启动服务的时候需要一个配置文件，在conf目录下修改zoo_sample.cfg为zoo.cfg</p><h2 id="配置QuorumPeerMain"><a href="#配置QuorumPeerMain" class="headerlink" title="配置QuorumPeerMain"></a>配置QuorumPeerMain</h2><ul><li>配置：<br>VM options：-Dlog4j.configuration=file:/opt/dev/idea/zookeeper/conf/log4j.properties<br>Program arguments：/opt/dev/idea/zookeeper/conf/zoo.cfg<br>启动类为：org.apache.zookeeper.server.quorum.QuorumPeerMain<br><img src="https://img.xiaoxiaomo.com/blog/img/zk_source_1.png" alt="QuorumPeerMain"></li></ul><a id="more"></a><h2 id="ZooKeeperServerMain配置"><a href="#ZooKeeperServerMain配置" class="headerlink" title="ZooKeeperServerMain配置"></a>ZooKeeperServerMain配置</h2><ul><li>当然如果是本地standalone模式，也可以直接用org.apache.zookeeper.server.ZooKeeperServerMain启动<br><img src="https://img.xiaoxiaomo.com/blog/img/zk_source_2.png" alt="ZooKeeperServerMain启动"><br><img src="https://img.xiaoxiaomo.com/blog/img/zk_source_3.png" alt="ZooKeeperServerMain启动"></li></ul><h2 id="zookeeper-客户端"><a href="#zookeeper-客户端" class="headerlink" title="zookeeper 客户端"></a>zookeeper 客户端</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/zk_source_4.png" alt="zookeeper 客户端配置"><br><img src="https://img.xiaoxiaomo.com/blog/img/zk_source_5.png" alt="zookeeper 客户端运行"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--HMaster的启动流程</title>
      <link href="/2019/04/08/HBase-HMaster%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
      <url>/2019/04/08/HBase-HMaster%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>　　本篇文章主要来看一看<code>HMaster的启动流程</code>，直接进入主题吧。<br>ps:这些文章都是从我先记录到我为知笔记然后有空了就写成博客的，mac的为知笔记图片保存不是很方便，这篇文章的图片通过截图过来的上传后发现有点模糊，只能将就看了。</p><h2 id="HMaster加载配置"><a href="#HMaster加载配置" class="headerlink" title="HMaster加载配置"></a>HMaster加载配置</h2><ul><li><code>org.apache.hadoop.hbase.master.HMaster</code> 调用类中的main方法</li><li>在main方法中主要做了</li></ul><ol><li>打印启动日志，</li><li>调用HMasterCommandLine对象doMain()方法<br>a). 日志打打印<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_1.png" alt="hbase source日志打打印"></li></ol><a id="more"></a><p>b). 调用HMasterCommandLine对象doMain()方法<br>HMasterCommandLine extends ServerCommandLine而HMasterCommandLine没有重写doMain()方法，即调用了o.a.h.h.u.ServerCommandLine接口中的doMain()方法<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_2.png" alt="hbase HMasterCommandLine"><br>doMain()方法，采用了Hadoop的ToolRunner机制</p><p>c). 先来看看，org.apache.hadoop.hbase.HBaseConfiguration的create()方法，从字面意思就知道是在创建配置文件<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_3.png" alt="hbase HBaseConfiguration的create"></p><p>d). 加载：core-default.xml,core-site.xml,hbase-default.xml,hbase-sute.xml<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_4.png" alt="hbase 加载配置"></p><ul><li><p>加载配置看完了之后，回退回来继续看<br><code>ToolRunner.run(HBaseConfiguration.create(), this, args);</code><br><strong>即:</strong><br>org.apache.hadoop.util.ToolRunner.run,<br><code>如下：</code><br>将conf和args封装成GenericOptionsParser对象parser, 根据parser获取toolArgs<br>返回tool.run(toolArgs);<br>tool.run(toolArgs)也即HMasterComandLine.run(toolArgs)<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_5.png" alt="hbase HMasterComandLine.run"></p></li><li><p>org.apache.hadoop.hbase.master.HMasterComandLine.run(toolArgs)，重点在下面的startMaster()私有方法<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_6.png" alt="hbase startMaster"></p></li><li><p>重点来看看：<code>org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster()</code><br>由于代码过长我就不截图了<br>从注释就知道会有两种模式：本地模式和分布式模式。<br>1）本地模式local，master,regionserver,ZK都在同一个JVM中;<br>2）分布式模式distributed，仅只会启动一个HMaster对象。<br>代码里面大部分就是做一些配置处理，zk地址端口等，重点关注</p></li></ul><ol><li>local本地模式：ZK启动MiniZooKeeperCluster.startup(zkDataPath);</li><li>local本地模式：hmser,regionserver启动LocalHBaseCluster.startup();</li><li>distributed分布式模式：HMaster启动，HMaster.start()。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">startMaster</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Configuration conf = getConf();</span><br><span class="line">    TraceUtil.initTracer(conf);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// If 'local', defer to LocalHBaseCluster instance.  Starts master</span></span><br><span class="line">      <span class="comment">// and regionserver both in the one JVM.</span></span><br><span class="line">      <span class="keyword">if</span> (LocalHBaseCluster.isLocal(conf)) &#123;</span><br><span class="line">        DefaultMetricsSystem.setMiniClusterMode(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">final</span> MiniZooKeeperCluster zooKeeperCluster = <span class="keyword">new</span> MiniZooKeeperCluster(conf);</span><br><span class="line">        File zkDataPath = <span class="keyword">new</span> File(conf.get(HConstants.ZOOKEEPER_DATA_DIR));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// find out the default client port</span></span><br><span class="line">        <span class="keyword">int</span> zkClientPort = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the zookeeper client port is specified in server quorum, use it.</span></span><br><span class="line">        String zkserver = conf.get(HConstants.ZOOKEEPER_QUORUM);</span><br><span class="line">        <span class="keyword">if</span> (zkserver != <span class="keyword">null</span>) &#123;</span><br><span class="line">          String[] zkservers = zkserver.split(<span class="string">","</span>);</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (zkservers.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// In local mode deployment, we have the master + a region server and zookeeper server</span></span><br><span class="line">            <span class="comment">// started in the same process. Therefore, we only support one zookeeper server.</span></span><br><span class="line">            String errorMsg = <span class="string">"Could not start ZK with "</span> + zkservers.length +</span><br><span class="line">                <span class="string">" ZK servers in local mode deployment. Aborting as clients (e.g. shell) will not "</span></span><br><span class="line">                + <span class="string">"be able to find this ZK quorum."</span>;</span><br><span class="line">              System.err.println(errorMsg);</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> IOException(errorMsg);</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          String[] parts = zkservers[<span class="number">0</span>].split(<span class="string">":"</span>);</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (parts.length == <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="comment">// the second part is the client port</span></span><br><span class="line">            zkClientPort = Integer.parseInt(parts [<span class="number">1</span>]);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// If the client port could not be find in server quorum conf, try another conf</span></span><br><span class="line">        <span class="keyword">if</span> (zkClientPort == <span class="number">0</span>) &#123;</span><br><span class="line">          zkClientPort = conf.getInt(HConstants.ZOOKEEPER_CLIENT_PORT, <span class="number">0</span>);</span><br><span class="line">          <span class="comment">// The client port has to be set by now; if not, throw exception.</span></span><br><span class="line">          <span class="keyword">if</span> (zkClientPort == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"No config value for "</span> + HConstants.ZOOKEEPER_CLIENT_PORT);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        zooKeeperCluster.setDefaultClientPort(zkClientPort);</span><br><span class="line">        <span class="comment">// set the ZK tick time if specified</span></span><br><span class="line">        <span class="keyword">int</span> zkTickTime = conf.getInt(HConstants.ZOOKEEPER_TICK_TIME, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (zkTickTime &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          zooKeeperCluster.setTickTime(zkTickTime);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// login the zookeeper server principal (if using security)</span></span><br><span class="line">        ZKUtil.loginServer(conf, HConstants.ZK_SERVER_KEYTAB_FILE,</span><br><span class="line">          HConstants.ZK_SERVER_KERBEROS_PRINCIPAL, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">int</span> localZKClusterSessionTimeout =</span><br><span class="line">          conf.getInt(HConstants.ZK_SESSION_TIMEOUT + <span class="string">".localHBaseCluster"</span>, <span class="number">10</span>*<span class="number">1000</span>);</span><br><span class="line">        conf.setInt(HConstants.ZK_SESSION_TIMEOUT, localZKClusterSessionTimeout);</span><br><span class="line">        LOG.info(<span class="string">"Starting a zookeeper cluster"</span>);</span><br><span class="line">        <span class="keyword">int</span> clientPort = zooKeeperCluster.startup(zkDataPath);</span><br><span class="line">        <span class="keyword">if</span> (clientPort != zkClientPort) &#123;</span><br><span class="line">          String errorMsg = <span class="string">"Could not start ZK at requested port of "</span> +</span><br><span class="line">            zkClientPort + <span class="string">".  ZK was started at port: "</span> + clientPort +</span><br><span class="line">            <span class="string">".  Aborting as clients (e.g. shell) will not be able to find "</span> +</span><br><span class="line">            <span class="string">"this ZK quorum."</span>;</span><br><span class="line">          System.err.println(errorMsg);</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(errorMsg);</span><br><span class="line">        &#125;</span><br><span class="line">        conf.set(HConstants.ZOOKEEPER_CLIENT_PORT, Integer.toString(clientPort));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Need to have the zk cluster shutdown when master is shutdown.</span></span><br><span class="line">        <span class="comment">// Run a subclass that does the zk cluster shutdown on its way out.</span></span><br><span class="line">        <span class="keyword">int</span> mastersCount = conf.getInt(<span class="string">"hbase.masters"</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> regionServersCount = conf.getInt(<span class="string">"hbase.regionservers"</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// Set start timeout to 5 minutes for cmd line start operations</span></span><br><span class="line">        conf.setIfUnset(<span class="string">"hbase.master.start.timeout.localHBaseCluster"</span>, <span class="string">"300000"</span>);</span><br><span class="line">        LOG.info(<span class="string">"Starting up instance of localHBaseCluster; master="</span> + mastersCount +</span><br><span class="line">          <span class="string">", regionserversCount="</span> + regionServersCount);</span><br><span class="line">        LocalHBaseCluster cluster = <span class="keyword">new</span> LocalHBaseCluster(conf, mastersCount, regionServersCount,</span><br><span class="line">          LocalHMaster.class, HRegionServer.class);</span><br><span class="line">        ((LocalHMaster)cluster.getMaster(<span class="number">0</span>)).setZKCluster(zooKeeperCluster);</span><br><span class="line">        cluster.startup();</span><br><span class="line">        waitOnMasterThreads(cluster);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logProcessInfo(getConf());</span><br><span class="line">        HMaster master = HMaster.constructMaster(masterClass, conf);</span><br><span class="line">        <span class="keyword">if</span> (master.isStopped()) &#123;</span><br><span class="line">          LOG.info(<span class="string">"Won't bring the Master up as a shutdown is requested"</span>);</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        master.start();</span><br><span class="line">        master.join();</span><br><span class="line">        <span class="keyword">if</span>(master.isAborted())</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"HMaster Aborted"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Master exiting"</span>, t);</span><br><span class="line">      <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="ZK启动"><a href="#ZK启动" class="headerlink" title="ZK启动"></a>ZK启动</h2><p>ZK启动MiniZooKeeperCluster.startup(zkDataPath);<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_7.png" alt="hbase ZK启动MiniZooKeeperCluster"></p><p>zk的启动，主要逻辑在org.apache.zookeeper.server.NIOServerCnxnFactory<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_8.png" alt="hbase NIOServerCnxnFactory"></p><p>local HBase的启动（Master,RegionServer）以线程的方式<br>初始化一个LocalHBaseCluster，<br>org.apache.hadoop.hbase.LocalHBaseCluster<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_9.png" alt="hbase LocalHBaseCluster"></p><p>org.apache.hadoop.hbase.LocalHBaseCluster 实例化，可以看到下面调用了addMaster()、addRegionServer()<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_10.png" alt="hbase LocalHBaseCluster"></p><h2 id="创建master线程"><a href="#创建master线程" class="headerlink" title="创建master线程"></a>创建master线程</h2><ul><li><p>addMaster(),调用<br>JVMClusterUtil.createMasterThread创建master线程<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_11.png" alt="hbase createMasterThread创建master线程"></p></li><li><p>创建master线程<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_12.png" alt="hbase 创建master线程"></p></li><li><p>hmc 即 org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster 对象<br>LocalHMaster extends HMaster<br>Master extends HRegionServer implements MasterServices<br>构造函数主要做了几件事情：1.初始化相关配置  2.初始化rpcServer 3.初始化zk监控类，下面看看一些具体的细节<br>1）在HRegionServer中会做初始化配置，检查<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_13.png" alt="hbase 在HRegionServer中会做初始化配置"></p></li></ul><p>2）在HRegionServer中创建MasterRpcService<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_14.png" alt="hbase 在HRegionServer中创建MasterRpcService"><br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_15.png" alt="hbase 在HRegionServer中创建MasterRpcService"></p><p>3）在HRegionServer中创建initializeFileSystem();<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_16.png" alt="hbase 在HRegionServer中创建initializeFileSystem"></p><p>4）在HRegionServer中初始化zk监控类，启动相关服务<br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_17.png" alt="hbase 在HRegionServer中初始化zk监控类"></p><h2 id="启动regionServer类似"><a href="#启动regionServer类似" class="headerlink" title="启动regionServer类似"></a>启动regionServer类似</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_18.png" alt="hbase 在HRegionServer中初始化zk监控类"><br><img src="https://img.xiaoxiaomo.com/blog/img/hmaster_source_19.png" alt="hbase 在HRegionServer中初始化zk监控类"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--通过idea搭建源码阅读环境</title>
      <link href="/2019/04/07/HBase-%E9%80%9A%E8%BF%87idea%E6%90%AD%E5%BB%BA%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/"/>
      <url>/2019/04/07/HBase-%E9%80%9A%E8%BF%87idea%E6%90%AD%E5%BB%BA%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/</url>
      <content type="html"><![CDATA[<p>　　该篇文章主要是，<strong>搭建一个HBase的源码阅读环境</strong>。主要是通过github下载源码，编译导入到开发环境idea中，然后启动相关服务，做DeBug调试来阅读相关源码。</p><h2 id="下载HBase源码"><a href="#下载HBase源码" class="headerlink" title="下载HBase源码"></a>下载HBase源码</h2><p>通过github下载相关源码(我下载到目录：<code>/opt/dev/idea/hbase</code> )</p><ul><li><strong>注意</strong>：默认我们克隆时，会把所有的历史commit信息也会克隆下载。<br>对于一个非常活跃的开源项目来说这些历史信息非常占用空间，下载时就会很慢。<br>我们可以在git clone 后面加一个<code>--depth 1</code>这样只克隆最新的一次提交（深度为1），就会快很多，如下：<blockquote><p>git clone <a href="https://github.com/apache/hbase.git" target="_blank" rel="noopener">https://github.com/apache/hbase.git</a>  –depth 1</p></blockquote></li></ul><a id="more"></a><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><ul><li>命令：mvn clean install -DskipTests<br><img src="https://img.xiaoxiaomo.com/blog/img/hbase_source_build.png" alt="hbase编译"></li></ul><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>这里启动服务主要是启动HBase单节点，HBase单节点只有一个HMaster线程，zookeeper以及HRegionServer都是以进程的形式存在，在后面的源码阅读中可以很好的发现。</p><h3 id="配置HBase服务"><a href="#配置HBase服务" class="headerlink" title="配置HBase服务"></a>配置HBase服务</h3><ul><li>在idea中添加一个配置（Configuration）- Application。</li><li><strong>主要配置</strong>（注意自己的的项目路径）：</li></ul><ol><li><code>Main Class</code>：org.apache.hadoop.hbase.master.HMaster</li><li><code>VM Options</code>：-Dlog4j.configuration=file:/opt/dev/idea/hbase/conf/log4j.properties</li><li><code>参数</code>：start</li><li><code>工作目录</code>：/opt/dev/idea/hbase </li></ol><ul><li>如图所示：<br><img src="https://img.xiaoxiaomo.com/blog/img/hbase_source_hmaster.png" alt="hbase启动hmaster"></li></ul><h3 id="配置HBase客户端"><a href="#配置HBase客户端" class="headerlink" title="配置HBase客户端"></a>配置HBase客户端</h3><ul><li>在idea中添加一个配置（Configuration）- Application。</li><li><strong>主要配置</strong>（注意自己的的项目路径）：</li></ul><ol><li><code>Main Class</code>：org.jruby.Main</li><li><code>VM Options</code>：-Dhbase.ruby.sources=/opt/dev/idea/hbase/hbase-shell/src/main/ruby -Dlog4j.configuration=file:/opt/dev/idea/hbase/conf/log4j.properties</li><li><code>参数</code>：/opt/dev/idea/hbase/bin/hirb.rb</li><li><code>工作目录</code>：/opt/dev/idea/hbase </li></ol><ul><li>如图所示：<br><img src="https://img.xiaoxiaomo.com/blog/img/hbase_source_shell.png" alt="hbase启动shell"></li></ul><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><ol><li><strong>hbase-common 下面的resource，修改下面几个配置</strong>，如下：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/tmp/hbase-$&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary directory on the local filesystem.</span><br><span class="line">            Change this setting to point to a location more permanent</span><br><span class="line">            than '/tmp', the usual resolve for java.io.tmpdir, as the</span><br><span class="line">            '/tmp' directory is cleared on machine restart.</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>txd<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Comma separated list of servers in the ZooKeeper ensemble</span><br><span class="line">            (This config. should have been named hbase.zookeeper.ensemble).</span><br><span class="line">            For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".</span><br><span class="line">            By default this is set to localhost for local and pseudo-distributed modes</span><br><span class="line">            of operation. For a fully-distributed setup, this should be set to a full</span><br><span class="line">            list of ZooKeeper ensemble servers. If HBASE_MANAGES_ZK is set in hbase-env.sh</span><br><span class="line">            this is the list of servers which hbase will start/stop ZooKeeper on as</span><br><span class="line">            part of cluster start/stop. Client-side, we will take this list of</span><br><span class="line">            ensemble members and put it together with the hbase.zookeeper.property.clientPort</span><br><span class="line">            config. and pass it into zookeeper constructor as the connectString</span><br><span class="line">            parameter.</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.defaults.for.version.skip<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Set to true to skip the 'hbase.defaults.for.version' check.</span><br><span class="line">    Setting this to true can be useful in contexts other than</span><br><span class="line">    the other side of a maven generation; i.e. running in an</span><br><span class="line">    IDE.  You'll want to set this boolean to true to avoid</span><br><span class="line">    seeing the RuntimeException complaint: "hbase-default.xml file</span><br><span class="line">    seems to be for and old version of HBase (\$&#123;hbase.version&#125;), this</span><br><span class="line">    version is X.X.X-SNAPSHOT"<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="启动服务-1"><a href="#启动服务-1" class="headerlink" title="启动服务"></a>启动服务</h3><ul><li>服务启动，debug等调试操作<br><img src="https://img.xiaoxiaomo.com/blog/img/hbase_source_debug.png" alt="hbase debug"></li></ul><h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><ol><li>通过zk查看</li></ol><ul><li>下载一个zookeeper，在<code>/etc/profile</code>或用户目录下配置好环境变量，如：<code>export ZK_HOME=/opt/local/zookeeper-3.4.12</code></li><li>就可以运行zk的客户端了，查看hbase信息如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">txd:Downloads tangxuandong$ cd /opt/local/zookeeper-3.4.12/</span><br><span class="line">txd:zookeeper-3.4.12 tangxuandong$ cd bin/</span><br><span class="line">txd:bin tangxuandong$ zkCli.sh </span><br><span class="line">Connecting to localhost:2181</span><br><span class="line">2019-04-09 19:00:16,993 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.12-e5259e437540f349646870ea94dc2658c4e44b3b, built on 03/27/2018 03:55 GMT</span><br><span class="line">2019-04-09 19:00:16,997 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=10.106.195.85</span><br><span class="line">2019-04-09 19:00:16,997 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_161</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/opt/local/zookeeper-3.4.12/bin/../build/classes:/opt/local/zookeeper-3.4.12/bin/../build/lib/*.jar:/opt/local/zookeeper-3.4.12/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/local/zookeeper-3.4.12/bin/../lib/slf4j-api-1.7.25.jar:/opt/local/zookeeper-3.4.12/bin/../lib/netty-3.10.6.Final.jar:/opt/local/zookeeper-3.4.12/bin/../lib/log4j-1.2.17.jar:/opt/local/zookeeper-3.4.12/bin/../lib/jline-0.9.94.jar:/opt/local/zookeeper-3.4.12/bin/../lib/audience-annotations-0.5.0.jar:/opt/local/zookeeper-3.4.12/bin/../zookeeper-3.4.12.jar:/opt/local/zookeeper-3.4.12/bin/../src/java/lib/*.jar:/opt/local/zookeeper-3.4.12/bin/../conf:.:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/Users/tangxuandong/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/var/folders/yx/g41l6w1n62bgm721hhlr6b1c0000gn/T/</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Mac OS X</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=x86_64</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=10.14.4</span><br><span class="line">2019-04-09 19:00:16,999 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=tangxuandong</span><br><span class="line">2019-04-09 19:00:17,000 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/Users/tangxuandong</span><br><span class="line">2019-04-09 19:00:17,000 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/opt/local/zookeeper-3.4.12/bin</span><br><span class="line">2019-04-09 19:00:17,001 [myid:] - INFO  [main:ZooKeeper@441] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@255316f2</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line">2019-04-09 19:00:17,028 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1028] - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">JLine support is enabled</span><br><span class="line">2019-04-09 19:00:17,094 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@878] - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session</span><br><span class="line">2019-04-09 19:00:17,104 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1302] - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x16a01a1936b0007, negotiated timeout = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[zookeeper, hbase]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] ls /hbase</span><br><span class="line">[meta-region-server, rs, splitWAL, backup-masters, table-lock, flush-table-proc, master-maintenance, online-snapshot, switch, master, running, draining, hbaseid, table]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2]</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>浏览器访问<br>访问：<a href="http://localhost:16010/" target="_blank" rel="noopener">http://localhost:16010/</a><br><img src="https://img.xiaoxiaomo.com/blog/img/hbase_source_brow.png" alt="hbase浏览器访问"></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>监控--jmxtrans+influxdb+Grafana</title>
      <link href="/2019/04/01/%E7%9B%91%E6%8E%A7-jmxtrans+influxdb+Grafana/"/>
      <url>/2019/04/01/%E7%9B%91%E6%8E%A7-jmxtrans+influxdb+Grafana/</url>
      <content type="html"><![CDATA[<p>　　这里主要梳理一下大数据常用的监控组件的组合使用，<strong><code>jmxtrans</code>+<code>influxdb</code>+<code>Grafana</code></strong>。jmxtrans用于收集服务的jmx信息（通过配置json文件），然后入库到influxDB。<br>　　通过配置Grafana，把influxDB里面的数据通过web展示出来。<br>　　我这里主要做一些简单的安装，然后<strong>以HBase为例做收集存储展示</strong>，<em>更多详细的内容，会在后面的内容分享</em>。</p><h2 id="influxDB安装"><a href="#influxDB安装" class="headerlink" title="influxDB安装"></a>influxDB安装</h2><ol><li><p>下载地址：<a href="https://portal.influxdata.com/downloads/#influxdb" target="_blank" rel="noopener">https://portal.influxdata.com/downloads/#influxdb</a></p><ul><li>我这里通过wget下载1.7.5的版本</li><li>wget <a href="https://dl.influxdata.com/influxdb/releases/influxdb-1.7.5.x86_64.rpm" target="_blank" rel="noopener">https://dl.influxdata.com/influxdb/releases/influxdb-1.7.5.x86_64.rpm</a> </li></ul></li><li><p>安装</p><ul><li>sudo yum localinstall influxdb-1.7.5.x86_64.rpm</li></ul></li><li><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 ~]# service influxdb start</span><br><span class="line">Starting influxdb...</span><br><span class="line">influxdb process was started [ OK ]</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><ol start="4"><li><p>配置文件</p><ul><li>默认配置文件：/etc/influxdb/influxdb.conf</li><li>默认日志文件：/var/log/influxdb/influxd.log</li><li>配置文件详解：<a href="https://www.cnblogs.com/guyeshanrenshiwoshifu/p/9188368.html" target="_blank" rel="noopener">https://www.cnblogs.com/guyeshanrenshiwoshifu/p/9188368.html</a></li><li>可以修改mete、data、wal-dir目录（<strong>注意修改的目录需要有influxdb用户的写入权限，我这里修改到app目录了</strong>），</li></ul></li><li><p>重要的目录</p><ul><li>服务启动后生成以下目录：<blockquote><p>data 存放最终存储的数据，文件以.tsm结尾<br>meta 存放数据库元数据<br>wal 存放预写日志文件<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana01.png" alt="influxdb 数据目录"></p></blockquote></li></ul></li><li><p>客户端操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 ~]# /usr/bin/influx</span><br><span class="line">Connected to http://localhost:8086 version 1.7.5</span><br><span class="line">InfluxDB shell version: 1.7.5</span><br><span class="line">Enter an InfluxQL query</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ol><p>6.1. 查看创建database<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; show databases;</span><br><span class="line">name: databases</span><br><span class="line">name</span><br><span class="line">----</span><br><span class="line">_internal</span><br><span class="line">&gt; </span><br><span class="line">&gt; </span><br><span class="line">&gt; create database hbaseJmx;</span><br><span class="line">&gt; show databases;</span><br><span class="line">name: databases</span><br><span class="line">name</span><br><span class="line">----</span><br><span class="line">_internal</span><br><span class="line">hbaseJmx</span><br></pre></td></tr></table></figure></p><p>6.2. 查看<code>measurements</code>，这个理解成表的概念<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;</span><br><span class="line">&gt; use hbaseJmx</span><br><span class="line">Using database hbaseJmx</span><br><span class="line">&gt; show measurements;</span><br></pre></td></tr></table></figure></p><h2 id="安装grafana"><a href="#安装grafana" class="headerlink" title="安装grafana"></a>安装grafana</h2><ol><li><p>下载安装<br>下载：<a href="https://grafana.com/grafana/download?platform=linux" target="_blank" rel="noopener">https://grafana.com/grafana/download?platform=linux</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">安装：yum localinstall grafana-5.4.2-1.x86_64.rpm</span><br></pre></td></tr></table></figure></li><li><p>重要配置及目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">配置文件：/etc/sysconfig/grafana-server</span><br><span class="line">环境变量文件：/etc/grafana/grafana.ini</span><br><span class="line"></span><br><span class="line">日志文件：/var/log/grafana/grafana.log</span><br></pre></td></tr></table></figure></li></ol><p>可以在 <code>/etc/sysconfig/grafana-server</code> 文件中修改日志目录，数据目录和其他一些环境变量。<br>数据库：<br>默认配置指定的数据库 sqlite3 在 <code>/var/lib/grafana/grafana.db</code></p><ol start="3"><li><p>启动grafana服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 ~]# service grafana-server start</span><br><span class="line">Starting Grafana Server: ... [确定]</span><br></pre></td></tr></table></figure><p> <img src="https://img.xiaoxiaomo.com/blog/img/jigrafana02.png" alt="grafana 数据目录"></p></li><li>插件安装（略）</li></ol><ul><li>插件网址 <a href="https://grafana.com/plugins?type=panel" target="_blank" rel="noopener">https://grafana.com/plugins?type=panel</a></li></ul><ol start="5"><li>访问</li></ol><ul><li>网页访问，<code>端口号3000，账号密码都是admin</code><br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana03.png" alt="grafana web"></li></ul><h2 id="安装jmxtrans"><a href="#安装jmxtrans" class="headerlink" title="安装jmxtrans"></a>安装jmxtrans</h2><ol><li><p>官网：<a href="http://www.jmxtrans.org/" target="_blank" rel="noopener">http://www.jmxtrans.org/</a></p><ul><li>下载地址：<a href="http://central.maven.org/maven2/org/jmxtrans/jmxtrans/" target="_blank" rel="noopener">http://central.maven.org/maven2/org/jmxtrans/jmxtrans/</a></li><li>我下载的jmxtrans-270.rpm</li></ul></li><li><p>安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 work]# yum localinstall jmxtrans-270.rpm</span><br></pre></td></tr></table></figure></li><li><p>配置文件</p></li></ol><ul><li>/etc/jmxtrans/wrapper.conf </li></ul><ol start="4"><li>启动<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 ~]# service jmxtrans start</span><br></pre></td></tr></table></figure></li></ol><h2 id="收集HBase-Jmx"><a href="#收集HBase-Jmx" class="headerlink" title="收集HBase Jmx"></a>收集HBase Jmx</h2><ul><li>配置一个Demo，即收集<code>HBase</code>里面的监控项，通过Jmxtrans写入到influxDB,然后通过grafana展示。</li></ul><ol><li><p>配置hbase，将<code>hbase-env.sh</code>中以下配置项的注释打开，打开后为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_JMX_BASE=&quot;-Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&quot;</span><br><span class="line">export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10101&quot;</span><br><span class="line">export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10102&quot;</span><br><span class="line">export HBASE_THRIFT_OPTS=&quot;$HBASE_THRIFT_OPTS $HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10103&quot;</span><br><span class="line">export HBASE_ZOOKEEPER_OPTS=&quot;$HBASE_ZOOKEEPER_OPTS $HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10104&quot;</span><br><span class="line">export HBASE_REST_OPTS=&quot;$HBASE_REST_OPTS $HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10105&quot;</span><br></pre></td></tr></table></figure><ul><li>我是使用cloudera manager中的hbase，所以配置hbase-env.sh在 服务环境高级配置代码段中配置（<strong>注意该配置无法识别$变量</strong>）<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana04.png" alt="grafana web"></li></ul></li><li><p>配置Jmxtrans</p><ul><li><p>Jmxtrans的json默认地址：/var/lib/jmxtrans/，我在/var/lib/jmxtrans/目录下创建hbaseJmx.json配置文件，内容如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"servers"</span>:[&#123;</span><br><span class="line">    <span class="attr">"port"</span>:<span class="string">"10101"</span>,</span><br><span class="line">    <span class="attr">"host"</span>:<span class="string">"10.xxx.IP地址"</span>,</span><br><span class="line">    <span class="attr">"queries"</span>:[&#123;</span><br><span class="line">    <span class="attr">"obj"</span>:<span class="string">"Hadoop:service=HBase,name=JvmMetrics"</span>,</span><br><span class="line">    <span class="attr">"attr"</span>:[<span class="string">"GcCount"</span>],</span><br><span class="line">    <span class="attr">"resultAlias"</span>:<span class="string">"GcCount"</span>,</span><br><span class="line">    <span class="attr">"outputWriters"</span>:[&#123;</span><br><span class="line">        <span class="attr">"@class"</span>:<span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line">        <span class="attr">"url"</span>:<span class="string">"http://localhost:8086/"</span>,</span><br><span class="line">        <span class="attr">"username"</span>:<span class="string">"admin"</span>,</span><br><span class="line">        <span class="attr">"password"</span>:<span class="string">"admin"</span>,</span><br><span class="line">        <span class="attr">"database"</span>:<span class="string">"hbaseJmx"</span></span><br><span class="line">     &#125;]</span><br><span class="line">    &#125;]</span><br><span class="line">  &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>注意：</strong>空格等字符，还有注意上面的服务都是使用自己的用户启动服务，日志、数据等目录需要有相应的权限<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana05.png" alt="grafana 数据目录"></p></li><li>重启Jmxtrans，在启动服务的时候也<strong>可以手动指定上</strong>面的配置文件。</li></ul></li><li><p>查看influxDB中的数据</p><ul><li><strong>注意：</strong>如果改数据库没有表或者数据，<code>请查看Jmxtrans的日志</code>，启动是否正常等。</li></ul></li></ol><ol start="4"><li>配置grafana<br> 4.1. 配置grafanad的database<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana06.png" alt="grafana 数据目录"><br> 4.2. 配置grafanad的dashboard<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana07.png" alt="grafana 数据目录"><br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana08.png" alt="grafana 数据目录"><br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana09.png" alt="grafana 数据目录"><br> 4.3. 查看图<br><img src="https://img.xiaoxiaomo.com/blog/img/jigrafana10.png" alt="grafana 数据目录"></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 监控 </tag>
            
            <tag> jmxtrans </tag>
            
            <tag> influxDB </tag>
            
            <tag> Grafana </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--ConcurrentHashMap笔记整理</title>
      <link href="/2019/03/15/Java-ConcurrentHashMap%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/"/>
      <url>/2019/03/15/Java-ConcurrentHashMap%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/</url>
      <content type="html"><![CDATA[<ul><li>讨论ConcurrentHashMap之前，我们首先了解一下<strong>java提供了那些不同层面上的线程安全的支持</strong>。了解一下大概的分类，然后在具体看ConcurrentHashMap的细节，<strong>分类如下</strong>：</li></ul><ol><li><strong>同步包装器</strong>（java.util.Collections工具类提供的包装方法），如Collections.synchronizedMap等，但是它们都是利用非常粗粒度的同步方式，在高并发情况下，性能比较低下。<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap01.png" alt="ConcurrentHashMap同步包装器"><a id="more"></a></li><li><strong>并发包提供的线程安全容器类</strong>，这个应该是大多数人的选择：<ul><li>各种并发容器，比如<code>ConcurrentHashMap</code>、<code>CopyOnWriteArrayList</code>。</li><li>各种线程安全队列（<code>Queue/Deque</code>），如<code>ArrayBlockingQueue</code>、<code>SynchronousQueue</code>。</li><li>各种有序容器的线程安全版本等。</li></ul></li></ol><h2 id="为什么需要使用ConcurrentHashMap？"><a href="#为什么需要使用ConcurrentHashMap？" class="headerlink" title="为什么需要使用ConcurrentHashMap？"></a>为什么需要使用ConcurrentHashMap？</h2><p><strong>a</strong>. <code>HashTable</code> 主要是效率低(之前的文章提到过)，因为它的实现基本就是<strong>将put、get、size等各种方法加上“synchronized”。</strong>简单来说，这就导致了所有并发操作都要竞争同一把锁，一个线程在进行同步操作时，其他线程只能等待，大大降低了并发操作的效率。<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap02.png" alt="HashTable源码"><br><strong>b</strong>. <code>Collections</code> 提供的同步包装器，只是利用输入Map构造了另一个同步版本，所有操作虽然不再声明成为synchronized方法，<strong>但是还是利用了“this”作为互斥的mutex，没有真正意义上的改进！</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap03.png" alt="Collections源码"></p><ul><li><strong>总结：上面两种方式只适合并发不太高的场景，所以需要使用ConcurrentHashMap，下面我们继续对ConcurrentHashMap进行探索。</strong></li></ul><h2 id="Java7中的ConcurrentHashMap"><a href="#Java7中的ConcurrentHashMap" class="headerlink" title="Java7中的ConcurrentHashMap"></a>Java7中的ConcurrentHashMap</h2><ul><li>在上一篇文章，在讲分段锁的时候提到过ConcurrentHashMap，主要也是在1.7中的实现，我们再来回顾一下。<br><code>ConcurrentHashMap</code><strong>主要使用分离锁（也叫分段锁，将内部进行分段（Segment）），内部存储结构是HashEntry数组+链表。</strong><br><em>HashEntry内部使用volatile的value字段来保证可见性，也利用了不可变对象的机制以改进利用Unsafe提供的底层能力。在进行并发操作的时候，只需要锁定相应段，这样就有效避免了类似Hashtable整体同步的问题，大大提高了性能。</em><br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap04.png" alt="Java7 HashEntry内部结构"></li></ul><p>在构造的时候，Segment的数量由所谓的concurrentcyLevel决定，默认是16，也可以在相应构造函数直接指定。注意，Java需要它是2的幂数值，如果输入是类似15这种非幂值，会被自动调整到16之类2的幂数值。<br><strong>下面看看java.util.concurrent.ConcurrentHashMap的源码：</strong></p><ol><li>get操作需要保证的是可见性，所以并没有什么同步逻辑。<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap05.png" alt="Java7 ConcurrentHashMap get源码"></li><li>而对于put操作，以Unsafe调用方式，直接获取相应的Segment，然后进行线程安全的put操作：<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap06.png" alt="Java7 ConcurrentHashMap put操作"><br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap07.png" alt="Java7 ConcurrentHashMap put源码"></li><li>上面的源码清晰的看出，在进行并发写操作时：<ul><li>ConcurrentHashMap会获取再入锁，以保证数据一致性，Segment本身就是基于ReentrantLock的扩展实现，所以，在并发修改期间，相应Segment是被锁定的。</li><li>在最初阶段，进行重复性的扫描，以确定相应key值是否已经在数组里面，进而决定是更新还是放置操作，你可以在代码里看到相应的注释。重复扫描、检测冲突是ConcurrentHashMap的常见技巧。</li><li>与HashMap扩容区别是它进行的不是整体的扩容，而是单独对Segment进行扩容。</li></ul></li></ol><ol start="4"><li>在上一篇文章中提到过它size方法的问题<br><em>如果不进行同步，简单的计算所有Segment的总值，可能会因为并发put，导致结果不准确，但是直接锁定所有Segment进行计算，就会变得非常昂贵。</em><br><strong>所以，size()的实现是通过重试机制（RETRIES_BEFORE_LOCK，指定重试次数2），来试图获得可靠值</strong>。如果没有监控到发生变化（通过对比Segment.modCount），就直接返回，否则获取锁进行操作。<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap08.png" alt="Java7 ConcurrentHashMap size源码"></li></ol><h2 id="Java8中，ConcurrentHashMap发生了哪些变化呢？"><a href="#Java8中，ConcurrentHashMap发生了哪些变化呢？" class="headerlink" title="Java8中，ConcurrentHashMap发生了哪些变化呢？"></a>Java8中，ConcurrentHashMap发生了哪些变化呢？</h2><ul><li><p>总体结构上，非常相似，同样是大的桶（bucket）数组+链表结构（bin）</p></li><li><p><strong>同步的粒度要更细致一些。</strong></p></li><li><p><em>其内部仍然有Segment定义，但仅仅是为了保证序列化时的兼容性而已，不再有任何结构上的用处。</em></p></li><li><p>因为不再使用Segment，初始化操作大大简化，<strong>修改为lazy-load形式，这样可以有效避免初始开销</strong>，解决了老版本很多人抱怨的这一点。</p></li><li><p>数据存储利用volatile来保证可见性。</p></li><li><p><strong>使用CAS等操作，在特定场景进行无锁并发操作。</strong></p></li><li><p><strong>使用Unsafe、LongAdder之类底层手段，进行极端情况的优化。</strong></p></li><li><p>先看看现在的数据存储内部实现，我们可以发现Key是final的，因为在生命周期中，一个条目的Key发生变化是不可能的；与此同时val，则声明为volatile，以保证可见性。<br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap09.png" alt="Java8 ConcurrentHashMap结构"></p></li></ul><ol><li><p><strong>直接看并发的put是如何实现的</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap10.png" alt="Java8 ConcurrentHashMap put源码"></p><p> 1.1. <strong>初始化操作实现在initTable里面，这是一个典型的CAS使用场景，利用volatile的sizeCtl作为互斥手段：如果发现竞争性的初始化，就spin在那里，等待条件恢复；否则利用CAS设置排他标志。如果成功则进行初始化；否则重试。</strong><br> <img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap11.png" alt="Java8 ConcurrentHashMap init源码"><br> 1.2. <strong>bin为空时</strong>，同样是没有必要锁定，也是以CAS操作去放置。<br> 1.3. <strong>在同步逻辑上，它使用的是synchronized，而不是通常建议的ReentrantLock之类，**</strong>这是为什么呢<strong>？现代JDK中，synchronized已经被不断优化，可以不再过分担心性能差异，另外，</strong>相比于ReentrantLock，它可以减少内存消耗，这是个非常大的优势。<strong><br> 与此同时，</strong>更多细节实现通过使用Unsafe进行了优化**，例如tabAt就是直接利用getObjectAcquire，避免间接调用的开销。<br> <img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap12.png" alt="Java8 ConcurrentHashMap tabAt源码"></p></li></ol><ol start="2"><li><strong>再来看看size的一些实现和改动</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/concurrenthashmap12.png" alt="Java8 ConcurrentHashMap size源码"><br><strong>虽然思路仍然和以前类似，都是分而治之的进行计数，然后求和处理，但实现却基于一个奇怪的CounterCell</strong>。 难道它的数值，就更加准确吗？数据一致性是怎么保证的？<br><strong>其实，对于CounterCell的操作，是基于java.util.concurrent.atomic.LongAdder进行的，是一种JVM利用空间换取更高效率的方法，利用了Striped64内部的复杂逻辑。这个东西非常小众，大多数情况下，建议还是使用AtomicLong，足以满足绝大部分应用的性能需求。</strong></li></ol><ul><li>(TODO:更多的细节还没写完，以后有时间的话再补充吧~)</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--线程安全与不安全&amp;同步异步和锁</title>
      <link href="/2019/03/13/Java-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E4%B8%8D%E5%AE%89%E5%85%A8&amp;%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E5%92%8C%E9%94%81/"/>
      <url>/2019/03/13/Java-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E4%B8%8D%E5%AE%89%E5%85%A8&amp;%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E5%92%8C%E9%94%81/</url>
      <content type="html"><![CDATA[<p><img src="https://img.xiaoxiaomo.com/blog/img/synchronized01.png" alt="线程"><br>　　<strong>线程不安全？</strong>首先看看线程的工作原理，jvm有一个main memory，而每个线程有自己的working memory，一个线程对一个变量进行操作时，都要在自己的working   memory里面建立一个copy，操作完之后再写入main memory。多个线程同时操作同一个变量(variable)，就可能会出现不可预知的结果，即线程不安全。</p><p>　　而用synchronized（同步）的关键是建立一个monitor，这个monitor可以是要修改的变量，也可以是其他你认为合适的object比如method，然后通过给这个monitor加锁来实现线程安全，每个线程在获得这个锁之后，要执行完 <strong>load到working memory -&gt; use&amp;assign -&gt; store到main memory的过程</strong>，才会释放它得到的锁。这样就实现了所谓的线程安全。<br>　　<strong>总结：synchronized 使一段代码同时只能有一个线程来操作，其实就是给对象加了锁，来实现线程安全。</strong></p><a id="more"></a><h2 id="一、-基本概念"><a href="#一、-基本概念" class="headerlink" title="一、 基本概念"></a>一、 基本概念</h2><p><strong>线程安全</strong>：当多个线程访问某一个类（对象或方法）时，这个类始终都能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。</p><p><strong>线程不安全</strong>：当多个线程对同一个对象中的同一个实例变量进行操作时会出现值被更改、值不同步的情况，进而影响程序的执行流程。</p><p><strong>同步</strong>：发送一个请求，等待返回，然后再发送下一个请求<br><strong>异步</strong>：发送一个请求，不等待返回，随时可以再发送下一个请求   </p><p><strong>阻塞</strong>：是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回。<br><strong>非阻塞</strong>：在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。</p><h2 id="二、同步与阻塞的区别"><a href="#二、同步与阻塞的区别" class="headerlink" title="二、同步与阻塞的区别"></a>二、同步与阻塞的区别</h2><p>阻塞有一个很明显的特征就是Blocking，有了这个特征才叫做阻塞。在java程序中的<strong>阻塞线程通常处于Blocking状态</strong>。</p><p>同步通常是指步骤需要一步步来完成，就按常规的代码一条条的执行下去。相对于阻塞状态，<strong>同步的线程应当处于Running状态</strong>。</p><p><strong>即</strong>：线程处于Blocking状态就差不多可以看成是休眠了，就是什么也没法做，只有等待信号将他唤醒而Running状态的线程是活跃的。在这种状态下可以去做很多的事情。</p><h2 id="三、什么会引发线程不安全？"><a href="#三、什么会引发线程不安全？" class="headerlink" title="三、什么会引发线程不安全？"></a>三、什么会引发线程不安全？</h2><ul><li>引发线程不安全必须满足三个条件：</li></ul><blockquote><ol><li>有共享变量</li><li>处在多线程环境下</li><li>共享变量有修改操作。</li></ol></blockquote><p><strong>即</strong>：若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。<br><strong>总结：线程安全问题都是由全局变量及静态变量引起的。</strong></p><h2 id="四、Java中常见的线程安全与不安全的集合？"><a href="#四、Java中常见的线程安全与不安全的集合？" class="headerlink" title="四、Java中常见的线程安全与不安全的集合？"></a>四、Java中常见的线程安全与不安全的集合？</h2><p><code>ArrayList</code>、<code>LinkedList</code> <strong>线程不安全</strong>，<code>Vector</code>        <strong>线程安全</strong></p><p><code>HashMap</code>                  <strong>线程不安全</strong>，<code>HashTable</code>   <strong>线程安全</strong> </p><p><code>StringBuilder</code>              <strong>线程不安全</strong>，<code>StringBuffer</code> <strong>线程安全</strong></p><h2 id="五、有哪些方法能解决线程不安全？"><a href="#五、有哪些方法能解决线程不安全？" class="headerlink" title="五、有哪些方法能解决线程不安全？"></a>五、有哪些方法能解决线程不安全？</h2><ul><li>所谓解决线程安全问题无非就是<strong>将操作原子化</strong>，<strong>原子化</strong>可以使用原子类，加sychronized，或者加lock，只要将操作原子化就能避免线程安全的问题。<strong>即解决线程不安全的方法</strong>：<blockquote><ol><li>使用局部变量：优先考虑能否不用共享，<strong>优先使用局部变量代替共享的全局变量</strong>。</li><li>使用原子类：只能用共享变量的时候优先使用原子类，诸如AtomicInteger等等。 <strong>没有原子类，可以自己创造自己的原子类。</strong></li><li>使用sychronized或锁：<strong>上面方法都不行，再考虑使用sychronized，lock之等等</strong>，别一上来就加sychronize，锁会有性能问题。</li></ol></blockquote></li></ul><p>5.1. 【使用局部变量（略）】<br>5.2. 【使用原子类】<br>volatile对于单个的共享变量的读/写具有原子性，但是像num++（<code>1.读取 2.加一 3.写入 三步组成</code>）这种复合操作，volatile无法保证其原子性。在并发环境下，如果不做任何同步处理，就会有线程安全问题。最直接的处理方式就是加锁。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(<span class="keyword">this</span>）&#123;</span><br><span class="line">    num++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>a</strong>. 但是使用这种独占锁机制来解决，<strong>是一种悲观的并发策略</strong>（<code>每次操作数据的时候都认为别的线程会参与竞争修改，所以悲观</code>）。这种直接加锁，同一刻只能有一个线程持有锁，那其他线程就会阻塞。线程的挂起恢复会带来很大的性能开销，尽管jvm对于非竞争性的锁的获取和释放做了很多优化，但是一旦有多个线程竞争锁，频繁的阻塞唤醒，还是会有很大的性能开销的。所以，使用synchronized或其他重量级锁来处理显然不够合理。<br><strong>b</strong>. <strong>针对num++这类复合类的操作，可以使用java并发包中的原子操作类原子操作类。相比锁机制，使用原子类更精巧轻量，性能开销更小</strong>。这属于<strong>乐观的解决方案</strong>(<code>非阻塞；认为别的线程不会参与竞争修改，所以乐观</code>)，也不加锁。如果操作成功了那最好；如果失败了，比如中途确有别的线程进入并修改了数据（依赖于冲突检测），也不会阻塞，可以采取一些补偿机制，一般的策略就是反复重试。很显然，这种思想相比简单粗暴利用锁来保证同步要合理的多。</p><pre><code>- **引发思考**    - `volatile为什么不能保证符合操作其原子性？`    - `针对num++这类复合类的操作，为什么能使用java并发包中的原子类？（提到的一般策略）原理是什么？`    - 【回答问题一】：    volatile是一种轻量级的同步机制，具有可见性，上面提到每个线程都有它自己私有内存(working memory)。**所谓可见性，是指当一条线程修改了共享变量的值，新值对于其他线程来说是可以立即得知的**。即：1`.当写一个volatile变量时，JMM会把该线程对应的私有内存中的变量强制刷新到主内存中去`；`2.这个写操作会导致其他线程中之前的缓存无效，感知到更改。num++`（1.读取 2.加一 3.写入 三步组成）在多线程环境下，有可能线程A将num读取到本地内存中，此时其他线程可能已经将num增大了很多，线程A依然对过期的num进行自加(A线程认为是最新的num)，重新写到主存中，最终导致了num的结果不合预期。因此volatile不适合符合操作。volatile详情以及另一个特性**禁止指令重排序优化**。参考：http://www.cnblogs.com/chengxiao/p/6528109.html    - 【回答问题二】：    **java并发包中的原子类其原子性操作的实现是基于CAS**（compare-and-swap）技术。CAS，表征的是一些列操作的集合，CAS算法是由硬件直接支持来保证原子性的。看一下`AtomicInteger`的源码：    ![原子类](https://img.xiaoxiaomo.com/blog/img/synchronized02.png)**我们可以看见volatile保证了可见性，有序性，而unsafe保证了原子性**（线程安全几个基本特征，可见性、原子性、有序性）。- 在jdk7中incrementAndGet源码：</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> current = get(); <span class="comment">//获取当前值</span></span><br><span class="line">        <span class="keyword">int</span> next = current + <span class="number">1</span>; <span class="comment">//对当前值+1</span></span><br><span class="line">        <span class="keyword">if</span> (compareAndSet(current, next)) <span class="comment">//调用compareAndSet传入当前值和更新后的值进行原子操作</span></span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">    &#125; <span class="comment">//重试</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>=&gt; 1.先获取当前的value值; 2.对value+1; 3.调用compareAndSet方法来来进行原子更新操作,底层细节即：先检查当前value是否等于current，<br>如果相等，则意味着value没被其他线程修改过，更新并返回true。如果不相等，compareAndSet则会返回false，然后循环继续尝试更新。<br>下面是jdk8类似功能的源码，其实类似<br><img src="https://img.xiaoxiaomo.com/blog/img/synchronized03.png" alt="jdk8类似功能的源码"></p><p><strong>CAS的ABA问题</strong>，著名的<code>ABA</code>问题，这是通常只在lock-free算法下暴露的问题。我前面说过CAS是在更新时比较前值，如果对方只是恰好相同，例如期间发生了 A -&gt; B -&gt; A的更新，仅仅判断数值是A，可能导致不合理的修改操作。针对这种情况，Java提供了AtomicStampedReference工具类，通过为引用建立类似版本号（stamp）的方式，来保证CAS的正确性，具体用法请参考:<a href="http://tutorials.jenkov.com/java-util-concurrent/atomicstampedreference.html。" target="_blank" rel="noopener">http://tutorials.jenkov.com/java-util-concurrent/atomicstampedreference.html。</a></p><p>参考：<a href="https://www.cnblogs.com/chengxiao/p/6789109.html" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6789109.html</a></p><p>5.3.  【使用sychronized或锁】</p><pre><code>- `有三种方式：分别是同步代码块 、同步方法和锁机制(Lock)`(1) 同步方法：给多线程访问的成员方法加上synchronized修饰符![同步方法](https://img.xiaoxiaomo.com/blog/img/synchronized04.png)(2) 同步的代码块：![同步的代码块](https://img.xiaoxiaomo.com/blog/img/synchronized05.png)(3) 锁机制(Lock)Java提供的同步代码块的另一种机制，比synchronized关键字更强大也更加灵活。**这种机制基于Lock接口及其实现类（例如：ReentrantLock）**它比synchronized关键字好的地方：1、`提供了更多的功能。tryLock()方法的实现，这个方法试图获取锁，如果锁已经被其他线程占用，它将返回false并继续往下执行代码。`2、`Lock接口允许分离读和写操作，允许多个线程读和只有一个写线程。`3、`具有更好的性能`![锁机制(Lock)](https://img.xiaoxiaomo.com/blog/img/synchronized06.png)参考：https://blog.csdn.net/qq_39396275/article/details/74937110</code></pre><h2 id="六、Synchronized和ReentrantLock有什么区别？"><a href="#六、Synchronized和ReentrantLock有什么区别？" class="headerlink" title="六、Synchronized和ReentrantLock有什么区别？"></a>六、Synchronized和ReentrantLock有什么区别？</h2><ol><li><p><strong>Synchronized</strong>，是Java内建的同步机制，所以也有人称其为Intrinsic Locking，它提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他试图获取的线程只能等待或者阻塞在那里。<br>在Java 5以前，synchronized是仅有的同步手段，在代码中， synchronized可以用来修饰方法，也可以使用在特定的代码块儿上，本质上synchronized方法等同于把方法全部语句用synchronized块包起来。</p></li><li><p><strong>ReentrantLock</strong>，通常翻译为再入锁，是Java 5提供的锁实现，它的语义和synchronized基本相同。再入锁通过代码直接调用lock()方法获取，代码书写也更加灵活。与此同时，<code>ReentrantLock提供了很多实用的方法，能够实现很多synchronized无法做到的细节控制，比如可以控制fairness，也就是公平性，或者利用定义条件等</code>。<strong>注意</strong>：<strong>编码必须要明确调用unlock()方法释放，不然就会一直持有该锁</strong>。</p></li></ol><ul><li><strong>synchronized和ReentrantLock的性能不能一概而论，早期版本synchronized在很多场景下性能相差较大，在后续版本进行了较多改进，在低竞争场景中表现可能优于ReentrantLock。</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/synchronized07.png" alt="ReentrantLock"></li></ul><h2 id="七、synchronized底层如何实现？什么是锁的升级、降级？"><a href="#七、synchronized底层如何实现？什么是锁的升级、降级？" class="headerlink" title="七、synchronized底层如何实现？什么是锁的升级、降级？"></a>七、synchronized底层如何实现？什么是锁的升级、降级？</h2><ol><li><p>synchronized代码块是由一对儿monitorenter/monitorexit指令实现的，Monitor对象是同步的基本实现单元。</p></li><li><p>在Java 6之前，Monitor的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。</p></li><li><p>现代的（Oracle）JDK中，JVM对此进行了大刀阔斧地改进，提供了三种不同的Monitor实现，也就是常说的三种不同的锁，大大改进了其性能：<br><code>偏斜锁（Biased Locking）、轻量级锁、重量级锁。</code><br><code>锁的升级、降级：就是JVM优化synchronized运行的机制，当JVM检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。</code></p></li><li><p><strong>当没有竞争出现时，默认会使用偏斜锁</strong>。JVM会利用CAS操作（compare and swap），在对象头上的Mark Word部分设置线程ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。这样做的假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。</p></li><li><p><strong>如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM就需要撤销（revoke）偏斜锁，并切换到轻量级锁实现</strong>。轻量级锁依赖CAS操作Mark Word来试图获取锁，如果重试成功，就使用普通的轻量级锁；<strong>否则，进一步升级为重量级锁</strong>。</p></li></ol><ul><li><strong>有的观点认为Java不会进行锁降级。实际上，锁降级确实是会发生的，当JVM进入安全点（SafePoint）的时候，会检查是否有闲置的Monitor，然后试图进行降级。</strong></li></ul><h2 id="八、锁的分类（名词的解释）"><a href="#八、锁的分类（名词的解释）" class="headerlink" title="八、锁的分类（名词的解释）"></a>八、锁的分类（名词的解释）</h2><blockquote><p>乐观锁/悲观锁<br>独享锁/共享锁<br>互斥锁/读写锁<br>可重入锁<br>公平锁/非公平锁<br>分段锁<br>偏向锁/轻量级锁/重量级锁<br>自旋锁</p></blockquote><ol><li><p>乐观锁/悲观锁<br>这两个名词上面有提到，是一个概念或思想，主要是指看待并发同步的角度。下面再总结一下：<br><strong>乐观锁</strong>：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，在Java中java.util.concurrent.atomic包下面的原子类就是使用了乐观锁的一种实现方式CAS(Compare and Swap 比较并交换)实现的。<br><strong>悲观锁</strong>：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁(排他锁)，这样别人想拿这个数据就会阻塞直到它拿到锁，适合写操作非常多的场景。比如Java里面的synchronized关键字的实现就是悲观锁。</p></li><li><p>独享锁/共享锁<br><strong>独享锁</strong>：是指该锁一次只能被一个线程所持有。例如：ReentrantLock、Synchronized<br><strong>共享锁</strong>：是指该锁可被多个线程所持有。对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。<br><strong>独享锁与共享锁都是通过AQS来实现的，只是实现了不同的方法，来实现独享或者共享。</strong></p></li><li><p>互斥锁/读写锁<br>上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。<br><strong>互斥锁</strong>：在Java中的具体实现就是ReentrantLock。<br><strong>读写锁</strong>：在Java中的具体实现就是ReadWriteLock。</p></li><li><p>可重入锁<br><strong>可重入锁又名递归锁</strong>，<strong>是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁</strong>。synchronized和ReentrantLock都是可重入锁。<br>举个例子：<br>当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        method2();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>如果线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但问题是，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样线程A一直去尝试获取锁，就会造成死锁。</p><ol start="5"><li><p>公平锁/非公平锁<br><strong>公平锁</strong>：是指多个线程按照申请锁的顺序来获取锁。否则就是非公平锁。<br><code>ReetrantLock</code>，默认是非公平锁，可以设置为公平锁。非公平锁的优点在于吞吐量比公平锁大。<br><code>Synchronized</code>，非公平锁。</p></li><li><p>分段锁<br><strong>分段锁</strong>：也叫分离锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。<br>ConcurrentHashMap中的分段锁称为Segment（Segment继承了ReentrantLock），内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个。<br><strong>当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在哪一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。</strong><br><strong>注意</strong>：在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。<br><code>分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。</code></p></li><li><p>偏向锁/轻量级锁/重量级锁<br>这三种锁是指锁的状态，并且是针对Synchronized。上面已经提到（略）</p></li><li><p>自旋锁<br><strong>自旋锁</strong>（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。<br><img src="https://img.xiaoxiaomo.com/blog/img/synchronized08.png" alt="自旋锁"><br><strong>lock()方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。</strong><br><strong>自旋锁的缺点：</strong><br>8.1. 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。<br>8.2. 上面Java实现的自旋锁不是公平的，不公平的锁就会存在“线程饥饿”问题。<br><strong>自旋锁的优点：</strong><br><em><strong>自旋锁</strong>不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快</em><br><em><strong>非自旋锁</strong>在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。</em> （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）<br>自旋锁参考：<a href="https://blog.csdn.net/fuyuwei2015/article/details/83387536" target="_blank" rel="noopener">https://blog.csdn.net/fuyuwei2015/article/details/83387536</a><br>更多锁分类细节参考： <a href="https://www.cnblogs.com/hustzzl/p/9343797.html" target="_blank" rel="noopener">https://www.cnblogs.com/hustzzl/p/9343797.html</a></p></li></ol><h2 id="九、死锁，解决和避免"><a href="#九、死锁，解决和避免" class="headerlink" title="九、死锁，解决和避免"></a>九、死锁，解决和避免</h2><p><strong>死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/synchronized09.png" alt="死锁"><br>常见死锁的检测工具：<code>Jstack</code>、<code>JConsole</code><br><strong>避免</strong>：</p><ol><li>尽量避免使用多个锁，并且只有需要时才持有锁。</li><li>设计好锁的获取顺序，</li><li>超时放弃</li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--HashMap笔记整理</title>
      <link href="/2019/03/12/Java-HashMap%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/"/>
      <url>/2019/03/12/Java-HashMap%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/</url>
      <content type="html"><![CDATA[<h2 id="一、-Map整体结构"><a href="#一、-Map整体结构" class="headerlink" title="一、  Map整体结构"></a>一、  Map整体结构</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/hashmap01.png" alt="hashMap 解析"></p><ul><li>HashTable比较特别，作为类似Vector、Stack的早期集合相关类型，<strong>它是扩展了Dictionary类的，类结构上其他类明显不同，其他都扩展了AbstractMap。</strong></li><li>LinkedHashMap和TreeMap都可以保证某种顺序，但二者还是非常不同的。<ul><li>LinkedHashMap <strong>通常是遍历顺序符合插入顺序</strong>，它的实现是通过为条目（键值对）维护一个双向链表。</li><li>TreeMap <strong>整体顺序是由键的顺序关系决定的</strong>，通过Comparator或Comparable（自然顺序）来决定。<a id="more"></a></li></ul></li></ul><h2 id="二、-HashTable、HashMap、TreeMap都是最常见的一些Map实现-它们的简单区别？"><a href="#二、-HashTable、HashMap、TreeMap都是最常见的一些Map实现-它们的简单区别？" class="headerlink" title="二、 HashTable、HashMap、TreeMap都是最常见的一些Map实现,它们的简单区别？"></a>二、 HashTable、HashMap、TreeMap都是最常见的一些Map实现,它们的简单区别？</h2><ol><li>HashTable是早期Java类库提供的一个<code>哈希表</code>实现，本身是同步的，不支持null键和值，<strong>由于同步导致的性能开销</strong>，所以已经很少被推荐使用。</li><li>HashMap大致与HashTable一致，<strong>主要区别HashMap不是同步的，支持null键和值等</strong>。<strong>性能好</strong>，通常情况下，<strong>put、get可以达到常数时间的性能。</strong></li><li>TreeMap则是<strong>基于红黑树的一种提供顺序访问的Map，</strong><code>get、put、remove之类操作都是O（log(n)）的时间复杂度</code>，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断。</li></ol><h2 id="三、-HashMap内部的结构"><a href="#三、-HashMap内部的结构" class="headerlink" title="三、 HashMap内部的结构"></a>三、 HashMap内部的结构</h2><ul><li>HashMap内部的结构，它可以看作是数组（Node&lt;K,V&gt;[] table）和链表结合组成的复合结构，数组被分为一个个桶（bucket），<strong>通过哈希值决定了键值对在这个数组的寻址</strong>；<code>哈希值相同的键值对，则以链表形式存储，如果链表大小超过阈值（TREEIFY_THRESHOLD, 8），图中的链表就会被改造为树形结构。</code><br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap02.png" alt="HashMap内部的结构"></li></ul><h2 id="四、-哈希表"><a href="#四、-哈希表" class="headerlink" title="四、 哈希表"></a>四、 哈希表</h2><ol><li>数据结构的物理存储结构只有两种：<strong>顺序存储结构</strong>和<strong>链式存储结构</strong>（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中）。在数组中根据下标查找某个元素，一次定位就可以达到。</li><li><strong>同样哈希表如果不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，因为哈希表的主干就是数组。</strong></li><li>比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。<blockquote><p>存储位置 = f(关键字)</p></blockquote></li><li><p>这个函数f一般称为哈希函数(哈希算法)，哈希算法或散列函数可以将不定长的输入，通过散列算法转换成一个定长的输出，这个输出就是哈希值或散列值。这个函数的设计好坏会直接影响到哈希表的优劣。</p></li><li><p>如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的<code>哈希冲突</code>，也叫<code>哈希碰撞</code>。</p></li><li>好的哈希函数会尽可能地保证 <strong>计算简单</strong>和<strong>散列地址分布均匀</strong>。但是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。<br>解决hash碰撞的方法有很多例如：<strong>链地址法，开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再哈希法，建立公共溢出区</strong>。参考：<a href="https://blog.csdn.net/sinat_37906153/article/details/83004831" target="_blank" rel="noopener">https://blog.csdn.net/sinat_37906153/article/details/83004831</a><br>HashMap即：采用了链地址法，也就是数组+链表的方式。</li></ol><h2 id="五、HashMap中的哈希函数"><a href="#五、HashMap中的哈希函数" class="headerlink" title="五、HashMap中的哈希函数"></a>五、HashMap中的哈希函数</h2><ul><li><p>HashMap以jdk1.7  put为例：<br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap03.png" alt="HashMap以jdk1.7"></p></li><li><p>hash() 方法中使用扰动算法将 hashCode 的高位和低位混合起来：<strong>可以有效降低冲突概率。</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap04.png" alt="hashMap hash()"><br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap05.png" alt="hashMap 冲突"> </p></li><li><p><strong>注意</strong>：HashMap 的初始长度为 16，且每次扩容都必须以 2 的倍数（2^n）扩充。因为在 HashMap 中，采用按位与运算（&amp;）代替取模运算（&amp;），当 b = 2^n 时，a % b = a &amp; (b - 1) 。</p></li></ul><h2 id="六、为何HashMap的数组长度一定是2的次幂？"><a href="#六、为何HashMap的数组长度一定是2的次幂？" class="headerlink" title="六、为何HashMap的数组长度一定是2的次幂？"></a>六、为何HashMap的数组长度一定是2的次幂？</h2><ul><li>如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index</li><li>hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)。以及使地位更加散列。参考：<a href="https://www.cnblogs.com/chengxiao/p/6059914.html" target="_blank" rel="noopener">https://www.cnblogs.com/chengxiao/p/6059914.html</a></li></ul><h2 id="七、equals方法和hashCode方法，需要一起重写"><a href="#七、equals方法和hashCode方法，需要一起重写" class="headerlink" title="七、equals方法和hashCode方法，需要一起重写"></a>七、equals方法和hashCode方法，需要一起重写</h2><ol><li>equals(Object obj)方法用来判断两个对象是否“相同”，如果“相同”则返回true，否则返回false。</li><li>hashCode()方法返回一个int数，在Object类中的默认实现是“将该对象的内部地址转换成一个整数返回”。 </li><li><strong>重写equals但不重写hashCode,引发的问题</strong><ul><li>由于没有重写hashCode方法，所以put操作时，key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置 ，而通过key取出value的时候 key(hashcode2)–&gt;hash–&gt;indexFor–&gt;最终索引位置，由于hashcode1不等于hashcode2(默认返回内存地址转换后的整数)，导致没有定位到一个数组位置而返回逻辑上错误的值null（但也有可能碰巧定位到一个数组位置）。</li></ul></li><li><strong>重写hashCode但不重写equals,引发的问题</strong><ul><li>同理，在取值时，做equals比较的时候由于equals1方法不等于equals2方法（默认使用‘==’来判断）所以会返回false。</li></ul></li></ol><ul><li><strong>注意</strong>：如果对象已经存在集合中，再去修改hashcode值的相关信息,会导致内存泄露问题。参考：<a href="https://blog.csdn.net/fmwind/article/details/76460681" target="_blank" rel="noopener">https://blog.csdn.net/fmwind/article/details/76460681</a></li></ul><h2 id="八、JDK8中的HashMap"><a href="#八、JDK8中的HashMap" class="headerlink" title="八、JDK8中的HashMap"></a>八、JDK8中的HashMap</h2><ol><li><p><strong>一直到JDK7为止，HashMap的结构都是这么简单，基于一个数组以及多个链表的实现，hash值冲突的时候，就将对应节点以链表的形式存储。</strong></p></li><li><p>这样子的HashMap性能上就抱有一定疑问，如果说成百上千个节点在hash时发生碰撞，存储一个链表中，那么如果要查找其中一个节点，那就不可避免的花费O(N)的查找时间，这将是多么大的性能损失。这个问题终于在JDK8中得到了解决。再最坏的情况下，链表查找的时间复杂度为O(n)，而红黑树一直是O(logn)，这样会提高HashMap的效率。</p></li><li><p>JDK7中HashMap采用的是位桶+链表的方式，即我们常说的散列链表的方式，<strong>而JDK8中采用的是位桶+链表/红黑树的方式，也是非线程安全的。当某个位桶的链表的长度达到某个阀值的时候（默认8），这个链表就将转换成红黑树</strong>。红黑树：<a href="https://my.oschina.net/hosee/blog/618828" target="_blank" rel="noopener">https://my.oschina.net/hosee/blog/618828</a><br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap06.png" alt="JDK7中HashMap源码"></p></li><li><p>JDK8中Entry的名字变成了Node，原因是和红黑树的实现TreeNode相关联。transient Node&lt;K,V&gt;[] table;</p></li><li><p>当冲突节点数不小于8-1时，转换成红黑树。static final int TREEIFY_THRESHOLD = 8;</p></li><li><p>JDK8中的源码：<br><img src="https://img.xiaoxiaomo.com/blog/img/hashmap07.png" alt="JDK8中HashMap源码"></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kerberos-给CDH集群添加Kerberos认证</title>
      <link href="/2018/05/29/Kerberos-%E7%BB%99CDH%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0Kerberos%E8%AE%A4%E8%AF%81/"/>
      <url>/2018/05/29/Kerberos-%E7%BB%99CDH%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0Kerberos%E8%AE%A4%E8%AF%81/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul><li>近期网络曝出<strong>通过Hadoop Yarn资源管理系统未授权访问漏洞从外网进行攻击内部服务器并植入挖矿木马的行为和自动化脚本的产生</strong>。此次事件主要因Hadoop YARN 资源管理系统配置不当，导致可以未经授权进行访问，从而被攻击者恶意利用。攻击者无需认证即可通过REST API部署任务来执行任意指令，最终完全控制服务器。被攻击后的特征在Hadoop Yarn的管理页面可看到，是用dr.who创建了多个任务：<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos01.png" alt=""></li></ul><a id="more"></a><ul><li>内部修复建议其中一点，就是需要在集群中<strong>启动”Kerberos“认证</strong>，正式环境我已近启用了”Kerberos“，下面是测试环境的启用操作日志记录，整理后写下该博文：</li></ul><h2 id="安装Kerberos服务"><a href="#安装Kerberos服务" class="headerlink" title="安装Kerberos服务"></a>安装Kerberos服务</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>对于Kerberos的介绍这里就不多说了，直接进入主题吧，首先我们<strong>选择一台服务器安装Kerberos的核心服务master KDC</strong>，<strong>其他节点安装Kerberos client</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">主机名          角色</span><br><span class="line">fetch-master   master KDC</span><br><span class="line">fetch-slave1   Kerberos client</span><br><span class="line">fetch-slave2   Kerberos client</span><br><span class="line">fetch-slave3   Kerberos client</span><br><span class="line">fetch-slave4   Kerberos client</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h3 id="安装服务"><a href="#安装服务" class="headerlink" title="安装服务"></a>安装服务</h3><ul><li>我们选择fetch-master运行KDC，并在该主机上安装<code>krb5-server</code>,<code>krb-5libs</code>,<code>krb5-auth-dialog</code>,<code>krb5-workstation</code>。<br>命令：<code>yum install krb5-server krb5-libs krb5-auth-dialog krb5-workstation</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# yum install krb5-server krb5-libs krb5-auth-dialog krb5-workstation</span><br><span class="line">...</span><br><span class="line">Installed:</span><br><span class="line">  krb5-auth-dialog.x86_64 0:0.13-6.el6                                              krb5-workstation.x86_64 0:1.10.3-65.el6                                             </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  libkadm5.x86_64 0:1.10.3-65.el6                                                                                                                                        </span><br><span class="line"></span><br><span class="line">Dependency Updated:</span><br><span class="line">  krb5-devel.x86_64 0:1.10.3-65.el6                                                   krb5-libs.x86_64 0:1.10.3-65.el6                                                  </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure></li></ul><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><ol><li><p>修改配置文件，<strong>/etc/krb5.conf</strong>。<br>LOCAL.DOMAIN:是设定的realms，名字随意但注意后面相应的地方必须一致。修改日志目录，以及制定kdc、admin_server服务地址，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# vim /etc/krb5.conf</span><br><span class="line">[logging]</span><br><span class="line"> default = FILE:/app/log/krb5libs.log</span><br><span class="line"> kdc = FILE:/app/log/krb5kdc.log</span><br><span class="line"> admin_server = FILE:/app/log/kadmind.log</span><br><span class="line"></span><br><span class="line">[libdefaults]</span><br><span class="line"> default_realm = LOCAL.DOMAIN</span><br><span class="line"> dns_lookup_realm = false</span><br><span class="line"> dns_lookup_kdc = false</span><br><span class="line"> ticket_lifetime = 24h</span><br><span class="line"> renew_lifetime = 7d</span><br><span class="line"> forwardable = true</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line"> LOCAL.DOMAIN = &#123;</span><br><span class="line">  kdc = localhost</span><br><span class="line">  admin_server = localhost</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">[domain_realm]</span><br><span class="line">.local.domain = LOCAL.DOMAIN</span><br><span class="line">local.domain = LOCAL.DOMAIN</span><br></pre></td></tr></table></figure></li><li><p>修改配置文件，<strong>/var/Kerberos/krb5kdc/kadm5.acl</strong>。<br>匹配的用户和权限，下面就是默认以<a href="mailto:/admin@LOCAL.DOMAIN" target="_blank" rel="noopener">/admin@LOCAL.DOMAIN</a>结尾有所有权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# vim /var/Kerberos/krb5kdc/kadm5.acl</span><br><span class="line">*/admin@LOCAL.DOMAIN    *</span><br></pre></td></tr></table></figure></li><li><p>修改配置文件， <strong>/var/Kerberos/krb5kdc/kdc.conf</strong>。<br>master_key_type和supported_enctypes默认使用aes256-cts。JAVA使用aes256-cts验证方式需要安装额外的jar包，下载<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files</a>，下载解压后(local_policy.jar、US_export_policy.jar)放入$JAVA_HOME/jre/lib/security<br><strong>也可以不使用aes256-cts，即把aes256-cts去掉</strong>，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# vim /var/Kerberos/krb5kdc/kdc.conf</span><br><span class="line">[kdcdefaults]</span><br><span class="line"> kdc_ports = 88</span><br><span class="line"> kdc_tcp_ports = 88</span><br><span class="line"> </span><br><span class="line">[realms]</span><br><span class="line"> LOCAL.DOMAIN = &#123;</span><br><span class="line"><span class="meta">  #</span><span class="bash">master_key_type = aes256-cts</span></span><br><span class="line">  max_renewable_life= 7d 0h 0m 0s</span><br><span class="line">  acl_file = /var/Kerberos/krb5kdc/kadm5.acl</span><br><span class="line">  dict_file = /app/share/dict/words</span><br><span class="line">  admin_keytab = /var/Kerberos/krb5kdc/kadm5.keytab</span><br><span class="line">  supported_enctypes = aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="创建-初始化Kerberos"><a href="#创建-初始化Kerberos" class="headerlink" title="创建/初始化Kerberos"></a>创建/初始化Kerberos</h3><ol><li><p><strong>创建/初始化Kerberos数据库</strong>，kdb5_util create -s –r LOCAL.DOMAIN ，并设置密码。</p><ul><li>[-s]表示生成stash file，并在其中存储master server key（krb5kdc）；</li><li>[-r]来指定一个realm name，当krb5.conf中定义了多个realm时才是必要的。</li><li>保存路径为/var/Kerberos/krb5kdc 如果需要重建数据库，将该目录下的principal相关的文件删除即可<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# kdb5_util create –r LOCAL.DOMAIN -s</span><br><span class="line">Loading random data</span><br><span class="line">Initializing database '/var/Kerberos/krb5kdc/principal' for realm 'LOCAL.DOMAIN',</span><br><span class="line">master key name 'K/M@LOCAL.DOMAIN'</span><br><span class="line">You will be prompted for the database Master Password.</span><br><span class="line">It is important that you NOT FORGET this password.</span><br><span class="line">Enter KDC database master key: </span><br><span class="line">Re-enter KDC database master key to verify: </span><br><span class="line">kdb5_util: Unable to find requested database type while creating database '/var/Kerberos/krb5kdc/principal'</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>创建Kerberos的管理账号</strong>，并设置密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# kadmin.local </span><br><span class="line">Authenticating as principal root/admin@LOCAL.DOMAIN with password.</span><br><span class="line">kadmin.local:  add</span><br><span class="line">add_policy     add_principal  addpol         addprinc       </span><br><span class="line">kadmin.local:  addprinc admin/admin@LOCAL.DOMAIN</span><br><span class="line">WARNING: no policy specified for admin/admin@LOCAL.DOMAIN; defaulting to no policy</span><br><span class="line">Enter password for principal "admin/admin@LOCAL.DOMAIN": </span><br><span class="line">Re-enter password for principal "admin/admin@LOCAL.DOMAIN": </span><br><span class="line">Principal "admin/admin@LOCAL.DOMAIN" created.</span><br><span class="line">kadmin.local:  </span><br><span class="line">kadmin.local:  exit</span><br></pre></td></tr></table></figure></li></ol><h3 id="启动服务和测试"><a href="#启动服务和测试" class="headerlink" title="启动服务和测试"></a>启动服务和测试</h3><ol><li><p><strong>添加到开机启动，并启动服务krb5kdc和kadmin</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# chkconfig krb5kdc on</span><br><span class="line">[root@fetch-master ~]# chkconfig kadmin on</span><br><span class="line">[root@fetch-master ~]# service krb5kdc start</span><br><span class="line">正在启动 Kerberos 5 KDC：                                  [确定]</span><br><span class="line">[root@fetch-master ~]# service kadmin start</span><br><span class="line">正在启动 Kerberos 5 Admin Server：                         [确定]</span><br></pre></td></tr></table></figure></li><li><p>测试服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-master ~]# kinit admin/admin@LOCAL.DOMAIN</span><br><span class="line">Password for admin/admin@LOCAL.DOMAIN: </span><br><span class="line">[root@fetch-master ~]# klist</span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: admin/admin@LOCAL.DOMAIN</span><br><span class="line"></span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">05/28/18 15:20:04  05/29/18 15:20:04  krbtgt/LOCAL.DOMAIN@LOCAL.DOMAIN</span><br><span class="line">renew until 06/04/18 15:20:04</span><br></pre></td></tr></table></figure></li></ol><h2 id="安装Kerberos客户端"><a href="#安装Kerberos客户端" class="headerlink" title="安装Kerberos客户端"></a>安装Kerberos客户端</h2><ol><li><p><strong>给集群所有节点安装Kerberos客户端</strong>：<br>命令：<code>yum -y install krb5-workstation krb5-libs krb5-auth-dialog</code><br>（因为我测试环境，KDC与CM在同一节点我就不用在CM上安装了上面已近安装，如果没在同一节点记得CM也要安装这些）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave1 ~]#  yum -y install krb5-workstation krb5-libs krb5-auth-dialog</span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  krb5-workstation.x86_64 0:1.10.3-65.el6                                                                                                                                                      </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  libkadm5.x86_64 0:1.10.3-65.el6                                                                                                                                                              </span><br><span class="line"></span><br><span class="line">Updated:</span><br><span class="line">  krb5-libs.x86_64 0:1.10.3-65.el6                                                                                                                                                             </span><br><span class="line"></span><br><span class="line">Dependency Updated:</span><br><span class="line">  krb5-devel.x86_64 0:1.10.3-65.el6                                                                                                                                                            </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure></li><li><p>CM节点安装额外组件，<br>命令：<code>yum -y install openldap-clients</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@fetch-master ~]# yum -y install openldap-clients</span><br><span class="line"></span><br><span class="line">Running Transaction Test</span><br><span class="line">Transaction Test Succeeded</span><br><span class="line">Running Transaction</span><br><span class="line">  Updating   : openldap-2.4.40-16.el6.x86_64                                                                                                                                               1/3 </span><br><span class="line">  Installing : openldap-clients-2.4.40-16.el6.x86_64                                                                                                                                       2/3 </span><br><span class="line">  Cleanup    : openldap-2.4.23-31.el6.x86_64                                                                                                                                               3/3 </span><br><span class="line">  Verifying  : openldap-clients-2.4.40-16.el6.x86_64                                                                                                                                       1/3 </span><br><span class="line">  Verifying  : openldap-2.4.40-16.el6.x86_64                                                                                                                                               2/3 </span><br><span class="line">  Verifying  : openldap-2.4.23-31.el6.x86_64                                                                                                                                               3/3 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  openldap-clients.x86_64 0:2.4.40-16.el6                                                                                                                                                      </span><br><span class="line"></span><br><span class="line">Dependency Updated:</span><br><span class="line">  openldap.x86_64 0:2.4.40-16.el6                                                                                                                                                              </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure></li><li><p>拷贝配置文件，将KDC Server上的krb5.conf文件拷贝到所有Kerberos客户端(集群所有节点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#记得指定对的admin_server  、 default_domain</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#我上面都是localhost,所以需要修改为fectch-master</span></span></span><br><span class="line">scp -P 2222 /etc/krb5.conf fetch-slave1:/etc/</span><br><span class="line">scp -P 2222 /etc/krb5.conf fetch-slave2:/etc/</span><br><span class="line">scp -P 2222 /etc/krb5.conf fetch-slave3:/etc/</span><br><span class="line">scp -P 2222 /etc/krb5.conf fetch-slave4:/etc/</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li></ol><h2 id="CDH集群启用Kerberos"><a href="#CDH集群启用Kerberos" class="headerlink" title="CDH集群启用Kerberos"></a>CDH集群启用Kerberos</h2><ol><li><p>在KDC中给Cloudera Manager添加管理员账号,并设置密码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@fetch-master ~]# kadmin.local</span><br><span class="line">Authenticating as principal admin/admin@LOCAL.DOMAIN with password.</span><br><span class="line">kadmin.local:  add</span><br><span class="line">add_policy     add_principal  addpol         addprinc       </span><br><span class="line">kadmin.local:  addprinc cloudera-scm/admin@LOCAL.DOMAIN</span><br><span class="line">WARNING: no policy specified for cloudera-scm/admin@LOCAL.DOMAIN; defaulting to no policy</span><br><span class="line">Enter password for principal "cloudera-scm/admin@LOCAL.DOMAIN": </span><br><span class="line">Re-enter password for principal "cloudera-scm/admin@LOCAL.DOMAIN": </span><br><span class="line">Principal "cloudera-scm/admin@LOCAL.DOMAIN" created.</span><br><span class="line">kadmin.local:  exit</span><br></pre></td></tr></table></figure></li><li><p>CDH启用Kerberos<br>2.1. 进入Cloudera Manager的“管理”-&gt; “Security”界面-&gt;启用Kerberos<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos02.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos03.png" alt=""><br>2.2. 检查信息,勾选<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos04.png" alt=""><br>2.3. 配置KDC信息<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos05.png" alt=""><br>2.4. 不建议让Cloudera Manager来管理krb5.conf，点击“继续”<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos06.png" alt=""><br>2.5. 输入CM的Kerbers管理员账号<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos07.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos08.png" alt=""><br>2.6. Kerberos主体<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos09.png" alt=""><br>2.7. 重启集群<br><img src="https://img.xiaoxiaomo.com/blog/img/kerberos10.png" alt=""></p></li></ol><h2 id="测试-amp-操作"><a href="#测试-amp-操作" class="headerlink" title="测试&amp;操作"></a>测试&amp;操作</h2><ol><li><p>先开看几个命令：</p><blockquote><p>klist： 查看当前的认证用户<br>kinit： 进行验证<br>kadmin.local： 直接登录<br>addprinc： 添加用户，在kadmin.local下面<br>delprinc： 删除用户，在kadmin.local下面<br>modprinc： 修改用户，在kadmin.local下面<br>listprincs：列出用户，在kadmin.local下面<br>kinit –R：  更新ticket<br>kdestroy：  删除当前的认证的缓存</p></blockquote></li><li><p>示例1：登录到管理员账户: 如果在本机上，可以通过kadmin.local直接登录。其它机器的，先使用kinit进行验证。 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#登陆管理账户</span></span></span><br><span class="line">[root@fetch-master ~]# kadmin.local</span><br><span class="line">Authenticating as principal root/admin@LOCAL.DOMAIN with password.</span><br><span class="line">kadmin.local:  exit</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#查看当前的认证用户</span></span></span><br><span class="line">[root@fetch-master ~]# klist</span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: root@LOCAL.DOMAIN</span><br><span class="line"></span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">05/28/18 17:43:12  05/29/18 17:43:12  krbtgt/LOCAL.DOMAIN@LOCAL.DOMAIN</span><br><span class="line">renew until 06/04/18 17:43:1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#其他节点-通过kinit验证</span></span></span><br><span class="line">[root@fetch-slave1 hbase]# kinit admin/admin</span><br><span class="line">Password for admin/admin@LOCAL.DOMAIN: </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#其它节点-查看当前认证用户</span></span></span><br><span class="line">[root@fetch-slave1 hbase]# klist</span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: admin/admin@LOCAL.DOMAIN</span><br><span class="line"></span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">05/28/18 18:07:26  05/29/18 18:07:26  krbtgt/LOCAL.DOMAIN@LOCAL.DOMAIN</span><br><span class="line">renew until 06/04/18 18:07:26</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#如果不认证，会有如下异常:</span></span></span><br><span class="line">FATAL ipc.AbstractRpcClient: SASL authentication failed. The most likely cause is missing or invalid credentials. Consider 'kinit'.</span><br><span class="line">javax.security.sasl.SaslException: </span><br><span class="line">    GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</span><br></pre></td></tr></table></figure></li><li><p>示例2：销毁后就无法查看，重新认证后查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave2 ~]# kdestroy    ##销毁</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@fetch-slave2 ~]# klist</span><br><span class="line">klist: No credentials cache found (ticket cache FILE:/tmp/krb5cc_0)</span><br><span class="line">[root@fetch-slave2 ~]# hadoop fs -ls / ##销毁后就无法查看</span><br><span class="line">18/05/29 17:22:26 WARN security.UserGroupInformation: PriviledgedActionException as:root (auth:KERBEROS) cause:javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</span><br><span class="line">18/05/29 17:22:26 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</span><br><span class="line">18/05/29 17:22:26 WARN security.UserGroupInformation: PriviledgedActionException as:root (auth:KERBEROS) cause:java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</span><br><span class="line">ls: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]; Host Details : local host is: &quot;fetch-slave2/10.141.4.203&quot;; destination host is: &quot;fetch-master&quot;:8020; </span><br><span class="line">[root@fetch-slave2 ~]# kinit admin/admin  ##重新认证后，就能操作</span><br><span class="line">Password for admin/admin@LOCAL.DOMAIN: </span><br><span class="line">[root@fetch-slave2 ~]# hadoop fs -ls /</span><br><span class="line">Found 5 items</span><br><span class="line">drwxrwxrwx   - hdfs  supergroup          0 2017-06-22 16:39 /data</span><br><span class="line">drwx------   - hbase hbase               0 2018-05-28 17:08 /hbase</span><br><span class="line">drwxr-xr-x   - hdfs  supergroup          0 2017-01-16 18:03 /system</span><br><span class="line">drwxrwxrwt   - hdfs  supergroup          0 2018-01-09 11:06 /tmp</span><br><span class="line">drwxrwxrwx   - hdfs  supergroup          0 2018-05-28 18:38 /user</span><br></pre></td></tr></table></figure></li><li><p>示例3：运行hive，然后让他在Yarn上跑job<br>4.1. 直接使用admin凭证，会有如下异常，因为系统上没有admin用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Application application_1527494654301_0004 failed 2 times due to AM Container for appattempt_1527494654301_0004_000002 exited with exitCode: -1000</span><br><span class="line">For more detailed output, check application tracking page:http://fetch-master:8088/proxy/application_1527494654301_0004/Then, click on links to logs of each attempt.</span><br><span class="line">Diagnostics: Application application_1527494654301_0004 initialization failed (exitCode=255) with output: main : command provided 0</span><br><span class="line">main : run as user is admin</span><br><span class="line">main : requested yarn user is admin</span><br><span class="line">User admin not found</span><br><span class="line">Failing this attempt. Failing the application.</span><br></pre></td></tr></table></figure></li></ol><p>4.2. 运行任务，出现如下异常，用户id小于1000<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Application application_1527494654301_0003 failed 2 times due to AM Container for appattempt_1527494654301_0003_000002 exited with exitCode: -1000</span><br><span class="line">For more detailed output, check application tracking page:http://fetch-master:8088/proxy/application_1527494654301_0003/Then, click on links to logs of each attempt.</span><br><span class="line">Diagnostics: Application application_1527494654301_0003 initialization failed (exitCode=255) with output: main : command provided 0</span><br><span class="line">main : run as user is yarn</span><br><span class="line">main : requested yarn user is yarn</span><br><span class="line">Requested user yarn is not whitelisted and has id 488,which is below the minimum allowed 1000</span><br><span class="line">Failing this attempt. Failing the application.</span><br></pre></td></tr></table></figure></p><p>解决方法：<br>4.2.1. 修改一个用户的user id ：usermod -u <new-user-id> <user><br>4.2.2. 修改Clouder关于这个该项的设置 ：ARN -&gt; NodeManager -&gt; Security -&gt;  min.user.id改为0。</user></new-user-id></p><p>4.3. 使用yarn用户运行，出现用户被禁用的异常,需要在CM yarn服务页面，配置禁止的系统用户banned.users列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Application application_1527590116657_0001 failed 2 times due to AM Container for appattempt_1527590116657_0001_000002 exited with exitCode: -1000</span><br><span class="line">For more detailed output, check application tracking page:http://fetch-master:8088/proxy/application_1527590116657_0001/Then, click on links to logs of each attempt.</span><br><span class="line">Diagnostics: Application application_1527590116657_0001 initialization failed (exitCode=255) with output: main : command provided 0</span><br><span class="line">main : run as user is yarn</span><br><span class="line">main : requested yarn user is yarn</span><br><span class="line">Requested user yarn is banned</span><br><span class="line">Failing this attempt. Failing the application.</span><br></pre></td></tr></table></figure></p><p>4.4. 使用allowed.system.users允许的用户查询，例如hive,先添加一个用户,再运行，成功!<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">##添加用户</span><br><span class="line">[root@fetch-slave3 ~]# kadmin</span><br><span class="line">Authenticating as principal admin/admin@LOCAL.DOMAIN with password.</span><br><span class="line">Password for admin/admin@LOCAL.DOMAIN:</span><br><span class="line">kadmin:  addprinc hive/admin@LOCAL.DOMAIN</span><br><span class="line">WARNING: no policy specified for hive/admin@LOCAL.DOMAIN; defaulting to no policy</span><br><span class="line">Enter password for principal &quot;hive/admin@LOCAL.DOMAIN&quot;: </span><br><span class="line">Re-enter password for principal &quot;hive/admin@LOCAL.DOMAIN&quot;: </span><br><span class="line">Principal &quot;hive/admin@LOCAL.DOMAIN&quot; created.</span><br><span class="line">kadmin:  exit</span><br><span class="line"></span><br><span class="line">##然后再查询,运行成功</span><br><span class="line">[root@fetch-slave3 ~]# kinit hive/admin</span><br><span class="line">[root@fetch-slave3 ~]# hive</span><br><span class="line">##运行SQL,让它跑mapreduce</span><br><span class="line">hive&gt; select count(1) from test11;</span><br><span class="line">Query ID = root_20180529185252_84fdbaf2-6b3a-4470-b823-dda693865b54</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1527590116657_0002, Tracking URL = http://fetch-master:8088/proxy/application_1527590116657_0002/</span><br><span class="line">Kill Command = /opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop job  -kill job_1527590116657_0002</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span><br><span class="line">2018-05-29 18:52:48,536 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2018-05-29 18:52:58,874 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec</span><br><span class="line">2018-05-29 18:53:05,081 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.74 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 2 seconds 740 msec</span><br><span class="line">Ended Job = job_1527590116657_0002</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.74 sec   HDFS Read: 6800 HDFS Write: 3 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 2 seconds 740 msec</span><br><span class="line">OK</span><br><span class="line">18</span><br><span class="line">Time taken: 71.793 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure></p><p>4.5. <strong>使用普通用户运行job，这里以xuandongtang为例。</strong><br>4.5.1. 在Kerberos上创建该用户，然后kinit验证用户<br>4.5.2. 随后就可以运行(注：集群所有节点必须有该用户不然会报错User xuandongtang not found)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@fetch-slave3 ~]# kadmin</span><br><span class="line">Authenticating as principal lidongxiao/admin@LOCAL.DOMAIN with password.</span><br><span class="line">Password for lidongxiao/admin@LOCAL.DOMAIN: </span><br><span class="line">kadmin:  addprinc xuandongtang/admin@LOCAL.DOMAIN</span><br><span class="line">WARNING: no policy specified for xuandongtang/admin@LOCAL.DOMAIN; defaulting to no policy</span><br><span class="line">Enter password for principal &quot;xuandongtang/admin@LOCAL.DOMAIN&quot;: </span><br><span class="line">Re-enter password for principal &quot;xuandongtang/admin@LOCAL.DOMAIN&quot;: </span><br><span class="line">Principal &quot;xuandongtang/admin@LOCAL.DOMAIN&quot; created.</span><br><span class="line">kadmin:  exit</span><br><span class="line">[root@fetch-slave3 ~]# kinit xuandongtang/admin@LOCAL.DOMAIN</span><br><span class="line">Password for xuandongtang/admin@LOCAL.DOMAIN: </span><br><span class="line">##运行成功！</span><br><span class="line">[root@fetch-slave3 ~]# hive</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; select count(1) from test11;</span><br><span class="line">Query ID = root_20180530161717_62a841bc-6a27-45b7-9901-f97c7c8c3916</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1527590116657_0006, Tracking URL = http://fetch-master:8088/proxy/application_1527590116657_0006/</span><br><span class="line">Kill Command = /opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop job  -kill job_1527590116657_0006</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span><br><span class="line">2018-05-30 16:18:19,573 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2018-05-30 16:18:27,805 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.3 sec</span><br><span class="line">2018-05-30 16:18:37,097 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.79 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 2 seconds 790 msec</span><br><span class="line">Ended Job = job_1527590116657_0006</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.79 sec   HDFS Read: 6830 HDFS Write: 3 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 2 seconds 790 msec</span><br><span class="line">OK</span><br><span class="line">18</span><br><span class="line">Time taken: 71.835 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure></p><ul><li>参考：<br><a href="https://www.jianshu.com/p/f28467450859" target="_blank" rel="noopener">https://www.jianshu.com/p/f28467450859</a><br><a href="https://blog.csdn.net/lovebomei/article/details/79807484" target="_blank" rel="noopener">https://blog.csdn.net/lovebomei/article/details/79807484</a><br><a href="https://www.zybuluo.com/xtccc/note/177146" target="_blank" rel="noopener">https://www.zybuluo.com/xtccc/note/177146</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
            <tag> Kerberos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cloudera Manager--新版本中的警告</title>
      <link href="/2018/03/11/Cloudera-Manager-%E6%96%B0%E7%89%88%E6%9C%AC%E4%B8%AD%E7%9A%84%E8%AD%A6%E5%91%8A/"/>
      <url>/2018/03/11/Cloudera-Manager-%E6%96%B0%E7%89%88%E6%9C%AC%E4%B8%AD%E7%9A%84%E8%AD%A6%E5%91%8A/</url>
      <content type="html"><![CDATA[<h2 id="Cloudera-Manager-新版本中的警告"><a href="#Cloudera-Manager-新版本中的警告" class="headerlink" title="Cloudera Manager 新版本中的警告"></a>Cloudera Manager 新版本中的警告</h2><ul><li>异常信息如下：<br><a href="http://blog.xiaoxiaomo.com/2018/03/11/Cloudera-Manager-%E6%96%B0%E7%89%88%E6%9C%AC%E4%B8%AD%E7%9A%84%E8%AD%A6%E5%91%8A/">You are running Cloudera Manager in non-production mode, which uses an embedded PostgreSQL database. Switch to using a supported external database before moving into production.</a><br><img src="https://img.xiaoxiaomo.com/blog/img/20180312165429.jpg" alt=""></li></ul><a id="more"></a><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ol><li>在安装完rpm包后，启动cm,</li><li>然后在cm节点主机上（20）执行下面语句，fetch-loadtest-26(为数据库)，scm2（数据库） scm2（用户名） scm2（密码） 这个会写入到cm-server配置文件中 /etc/cloudera-scm-server/db.properties<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/share/cmf/schema/scm_prepare_database.sh mysql -h fetch-loadtest-26 -uhive -phive --scm-host fetch-loadtest-20 scm2 scm2 scm2</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog/img/20180312165430.jpg" alt=""></p><ol start="3"><li>停掉服务器，并重启cloudera-scm-server, 此时cloudera-scm-server-db就不需要启动了，会提示：CM is using external DB. Failed to start embedded DB service, giving up<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service cloudera-scm-server stop</span><br><span class="line">service cloudera-scm-server-db stop   </span><br><span class="line">service cloudera-scm-server start</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog/img/20180312165431.jpg" alt=""></p><ul><li>参考<br><a href="https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_installing_configuring_dbs.html" target="_blank" rel="noopener">https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_installing_configuring_dbs.html</a></li></ul><p>　　</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SparkException: Could not find CoarseGrainedScheduler or it has been stopped.</title>
      <link href="/2017/12/14/SparkException-Could-not-find-CoarseGrainedScheduler-or-it-has-been-stopped/"/>
      <url>/2017/12/14/SparkException-Could-not-find-CoarseGrainedScheduler-or-it-has-been-stopped/</url>
      <content type="html"><![CDATA[<h1 id="运行异常"><a href="#运行异常" class="headerlink" title="运行异常"></a>运行异常</h1><ul><li><strong>我在Python脚本中通过spark-submit提交运行多个任务</strong>（脚本中有多个spark SQL任务），<strong>任务正常运行完后报错</strong><br>ERROR netty.Inbox: Ignoring error<br>org.apache.spark.SparkException: Could not find CoarseGrainedScheduler or it has been stopped. </li></ul><a id="more"></a><ul><li>具体异常如下<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">17</span>/<span class="number">12</span>/<span class="number">14</span> <span class="number">11</span>:<span class="number">05</span>:<span class="number">26</span> ERROR netty.Inbox: Ignoring error</span><br><span class="line">org.apache.spark.SparkException: Could not find CoarseGrainedScheduler or it has been stopped.</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:<span class="number">163</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:<span class="number">133</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:<span class="number">192</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:<span class="number">516</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.reviveOffers(CoarseGrainedSchedulerBackend.scala:<span class="number">356</span>)</span><br><span class="line">        at org.apache.spark.scheduler.TaskSchedulerImpl.executorLost(TaskSchedulerImpl.scala:<span class="number">494</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.disableExecutor(CoarseGrainedSchedulerBackend.scala:<span class="number">301</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint$$anonfun$onDisconnected$<span class="number">1</span>.apply(YarnSchedulerBackend.scala:<span class="number">121</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint$$anonfun$onDisconnected$<span class="number">1</span>.apply(YarnSchedulerBackend.scala:<span class="number">120</span>)</span><br><span class="line">        at scala.Option.foreach(Option.scala:<span class="number">236</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint.onDisconnected(YarnSchedulerBackend.scala:<span class="number">120</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox$$anonfun$process$<span class="number">1</span>.apply$mcV$sp(Inbox.scala:<span class="number">142</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:<span class="number">204</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:<span class="number">100</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:<span class="number">217</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"><span class="number">17</span>/<span class="number">12</span>/<span class="number">14</span> <span class="number">11</span>:<span class="number">05</span>:<span class="number">26</span> ERROR netty.Inbox: Ignoring error</span><br><span class="line">org.apache.spark.SparkException: Could not find CoarseGrainedScheduler or it has been stopped.</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:<span class="number">163</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:<span class="number">133</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:<span class="number">192</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:<span class="number">516</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.reviveOffers(CoarseGrainedSchedulerBackend.scala:<span class="number">356</span>)</span><br><span class="line">        at org.apache.spark.scheduler.TaskSchedulerImpl.executorLost(TaskSchedulerImpl.scala:<span class="number">494</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.disableExecutor(CoarseGrainedSchedulerBackend.scala:<span class="number">301</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint$$anonfun$onDisconnected$<span class="number">1</span>.apply(YarnSchedulerBackend.scala:<span class="number">121</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint$$anonfun$onDisconnected$<span class="number">1</span>.apply(YarnSchedulerBackend.scala:<span class="number">120</span>)</span><br><span class="line">        at scala.Option.foreach(Option.scala:<span class="number">236</span>)</span><br><span class="line">        at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint.onDisconnected(YarnSchedulerBackend.scala:<span class="number">120</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox$$anonfun$process$<span class="number">1</span>.apply$mcV$sp(Inbox.scala:<span class="number">142</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:<span class="number">204</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:<span class="number">100</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:<span class="number">217</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@<span class="number">708</span>dfce7 rejected from java.util.concurrent.ThreadPoolExecutor@<span class="number">346</span>be0ef[Terminated, pool size = <span class="number">0</span>, active threads = <span class="number">0</span>, queued tasks = <span class="number">0</span>, completed tasks = <span class="number">224</span>]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:<span class="number">2048</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:<span class="number">821</span>)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:<span class="number">1372</span>)</span><br><span class="line">        at scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:<span class="number">122</span>)</span><br><span class="line">        at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:<span class="number">40</span>)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:<span class="number">248</span>)</span><br><span class="line">        at scala.concurrent.Promise$class.complete(Promise.scala:55)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:<span class="number">153</span>)</span><br><span class="line">        at scala.concurrent.Future$$anonfun$recover$<span class="number">1</span>.apply(Future.scala:<span class="number">324</span>)</span><br><span class="line">        at scala.concurrent.Future$$anonfun$recover$<span class="number">1</span>.apply(Future.scala:<span class="number">324</span>)</span><br><span class="line">        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:<span class="number">32</span>)</span><br><span class="line">        at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:<span class="number">293</span>)</span><br><span class="line">        at scala.concurrent.impl.ExecutionContextImpl$$anon$<span class="number">1</span>.execute(ExecutionContextImpl.scala:<span class="number">133</span>)</span><br><span class="line">        at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:<span class="number">40</span>)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:<span class="number">248</span>)</span><br><span class="line">        at scala.concurrent.Promise$class.complete(Promise.scala:55)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:<span class="number">153</span>)</span><br><span class="line">        at scala.concurrent.Future$$anonfun$map$<span class="number">1</span>.apply(Future.scala:<span class="number">235</span>)</span><br><span class="line">        at scala.concurrent.Future$$anonfun$map$<span class="number">1</span>.apply(Future.scala:<span class="number">235</span>)</span><br><span class="line">        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:<span class="number">32</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$<span class="number">1</span>.processBatch$<span class="number">1</span>(Future.scala:<span class="number">643</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$<span class="number">1</span>.apply$mcV$sp(Future.scala:<span class="number">658</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$<span class="number">1</span>.apply(Future.scala:<span class="number">635</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$<span class="number">1</span>.apply(Future.scala:<span class="number">635</span>)</span><br><span class="line">        at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:<span class="number">72</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$Batch.run(Future.scala:<span class="number">634</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$.scala$concurrent$Future$InternalCallbackExecutor$$unbatchedExecute(Future.scala:<span class="number">694</span>)</span><br><span class="line">        at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:<span class="number">685</span>)</span><br><span class="line">        at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:<span class="number">40</span>)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:<span class="number">248</span>)</span><br><span class="line">        at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:<span class="number">153</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$<span class="number">1</span>(NettyRpcEnv.scala:<span class="number">208</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$<span class="number">2</span>.apply(NettyRpcEnv.scala:<span class="number">230</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$<span class="number">2</span>.apply(NettyRpcEnv.scala:<span class="number">230</span>)</span><br><span class="line">        at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:<span class="number">71</span>)</span><br><span class="line">        at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:<span class="number">110</span>)</span><br><span class="line">        at org.apache.spark.network.client.TransportResponseHandler.channelUnregistered(TransportResponseHandler.java:<span class="number">124</span>)</span><br><span class="line">        at org.apache.spark.network.server.TransportChannelHandler.channelUnregistered(TransportChannelHandler.java:<span class="number">94</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">158</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">144</span>)</span><br><span class="line">        at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:<span class="number">53</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">158</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">144</span>)</span><br><span class="line">        at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:<span class="number">53</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">158</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">144</span>)</span><br><span class="line">        at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:<span class="number">53</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">158</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:<span class="number">144</span>)</span><br><span class="line">        at io.netty.channel.DefaultChannelPipeline.fireChannelUnregistered(DefaultChannelPipeline.java:<span class="number">739</span>)</span><br><span class="line">        at io.netty.channel.AbstractChannel$AbstractUnsafe$<span class="number">8</span>.run(AbstractChannel.java:<span class="number">659</span>)</span><br><span class="line">        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:<span class="number">328</span>)</span><br><span class="line">        at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:<span class="number">627</span>)</span><br><span class="line">        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:<span class="number">362</span>)</span><br></pre></td></tr></table></figure></li></ul><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><p><strong>设置：spark.dynamicAllocation.enabled=false</strong> </p><blockquote><ol><li>可以在提交任务的时候设置：spark-submit –conf spark.dynamicAllocation.enabled=false</li><li>也可以在代码中通过SparkConf设置：conf.set(“spark.dynamicAllocation.enabled”,”false”)</li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cloudera Manager--Yarn用户资源隔离配置</title>
      <link href="/2017/11/29/Cloudera-Manager-Yarn%E7%94%A8%E6%88%B7%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB%E9%85%8D%E7%BD%AE/"/>
      <url>/2017/11/29/Cloudera-Manager-Yarn%E7%94%A8%E6%88%B7%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　Yarn用户资源隔离配置，主要使用 <strong>Yarn动态资源池(dynamic resource pool)</strong> _ 对YARN应用程序进行资源和策略分配的池。(Impala资源也可以动态管理)_<br>动态资源池允许安排和分配用户访问特定池，用来执行YARN应用程序。<strong>如果一个池的资源未被使用，它可以被占用(preempted)并分配给其他池。否则，就根据各个池的权重来共享资源。访问控制列表(Access control lists (ACLs)) 对提交访问和管理访问进行限制。</strong></p><ul><li>下面主要以下几个步骤来实际的操作：<ol><li>资源隔离前：看看默认的组，以及为什么我们要去从新划分</li><li>规划用户组：举例本例中分配的组，以及我们线上环境一般怎么分配的</li><li>HDFS和Yarn设置：需要修改的一些配置</li><li>资源池设置：主要是资源池设置以及配置相应的规则</li><li>示例展示：截图说明一下修改后的一些运行效果</li></ol></li></ul><a id="more"></a><h1 id="资源隔离前"><a href="#资源隔离前" class="headerlink" title="资源隔离前"></a>资源隔离前</h1><ul><li>我弄了两张表，放入10G左右的数据，然后随便写了一个SQL在hive上运行(<strong>目的是消耗Yarn资源看看效果，以对比后面调整后的任务资源情况</strong>)</li></ul><ol><li>可以看到运行后占用了32cores,16G内存(每个map，reduce任务我设置的512MB内存，每个容器设置的1cores)</li><li>队列为：root.users.hue (后面说明为什么是这个队列)<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn99.png" alt=""></li></ol><h1 id="规划用户组"><a href="#规划用户组" class="headerlink" title="规划用户组"></a>规划用户组</h1><ul><li>我这里把用户组分为三种，便于后面测试对比。线上环境一般也是按照这个区划分，或者按照部门去划分。（在主节点创建下面用户）</li></ul><ol><li>超级用户组：root</li><li>开发者组：dev</li><li>业务分析组：query<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo.com ~]# groupadd dev</span><br><span class="line">[root@xiaoxiaomo.com ~]# groupadd query</span><br><span class="line">[root@xiaoxiaomo.com ~]# useradd -g dev dev1</span><br><span class="line">[root@xiaoxiaomo.com ~]# useradd -g dev dev2</span><br><span class="line">[root@xiaoxiaomo.com ~]# useradd -g query query1</span><br><span class="line">[root@xiaoxiaomo.com ~]# useradd -g query query2</span><br></pre></td></tr></table></figure></li></ol><ul><li>（我是用hue提交的SQL任务）所以hue中配置好相关的用户，如果还有sentry授权，配置相关组权限即可，这里简单的截图<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn103.png" alt=""><br>（可能大部分用户不一定都使用了hue和sentry，没使用的完全可以跳过这个可以在linux等客户端中提交）<br>sentry权限可参考：<a href="http://blog.xiaoxiaomo.com/2016/10/19/Sentry-%E9%80%9A%E8%BF%87Cloudera-Manager%E9%85%8D%E7%BD%AESentry/">http://blog.xiaoxiaomo.com/2016/10/19/Sentry-%E9%80%9A%E8%BF%87Cloudera-Manager%E9%85%8D%E7%BD%AESentry/</a></li></ul><h1 id="HDFS-设置"><a href="#HDFS-设置" class="headerlink" title="HDFS 设置"></a>HDFS 设置</h1><ol><li><strong>检查，HDFS权限检查是否开启，没有开启勾选即开启 (默认是开启的)</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/yarn102.png" alt=""></li></ol><h1 id="YARN-设置"><a href="#YARN-设置" class="headerlink" title="YARN 设置"></a>YARN 设置</h1><ol><li><p><strong>开启，资源管理器ACL并设置相应的管理ACL (Admin ACL)</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/yarn104.png" alt=""></p><blockquote><ol><li>yarn.acl.enable 默认值为true</li><li>yarn.admin.acl 默认值为*，默认表示任何人都可以提交，查看，和关闭应用程序。<br>2.1. 格式为 “以逗号分隔的用户列表＋空格＋以逗号分隔的用户组列表”，例如 “dev1,query1 dev,query”。<br>2.2. 如果只有组信息，需要在最前端加入一个空格，例如” dev,query”。<br>2.3. 至少将”yarn”加入到用户列表中。</li></ol></blockquote></li><li><p><strong>关闭，未声明资源池的自动生成 (默认是开启的)</strong><br><code>yarn.scheduler.fair.allow-undeclared-pools</code> ，不然会自动创建资源池<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn100.png" alt=""></p></li><li><p><strong>取消，使用默认队列时的 Fair Scheduler 用户（默认是选中）</strong><br><code>yarn.scheduler.fair.user-as-default-queue</code>，不然用户提交任务时不指定特定的队列，就使用以用户命名的queue。<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn101.png" alt=""></p></li></ol><h1 id="资源池设置"><a href="#资源池设置" class="headerlink" title="资源池设置"></a>资源池设置</h1><ol><li><p>进入动态资源池配置页面<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn105.png" alt=""></p></li><li><p>可以看到默认有两个资源池（default,users）<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn106.png" alt=""></p></li><li><p>点击<code>Create Resource Pool</code>可以创建资源池，添加相关属性，配置策略，修改提交/管理控制<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn107.png" alt=""><br>比如下面我们就限制了dev资源池只能是dev组提交任务<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn115.png" alt=""><br>（<strong>注意</strong>：还有一点很重要就是勾选<code>Parent Pool</code>，不然配置root.[primary group].[username]规则就无法获得root.dev.dev1队列）</p></li><li><p>重点看一下放置规则，<strong>只有配置合理的规则才能很好的使用我们的资源池</strong>，从上到下的优先级(默认下面三种)<br> 4.1. 最优先运行时指定的那一个资源池，没有就创建<br> 4.2. 第二个规则使用<code>root.[pool name].[username]</code>，规则[pool name]默认为users，所以最开始我们看到的队列就是root.users.hue(我是用hue用户运行的)，比如：<br> <img src="https://img.xiaoxiaomo.com/blog/img/yarn110.png" alt=""><br> 4.3. 最后一个，root.default，下面已经有中文说明了<br> <img src="https://img.xiaoxiaomo.com/blog/img/yarn109.png" alt=""></p></li><li><p><strong>设置我们自己的资源池，并配置规则库</strong><br>现在我们就要求dev组的用户使用dev资源池，query组的使用query的资源池<br> 5.1. 资源池配置（删掉之前的users资源池，添加需要的并配置权重），例如<br> <img src="https://img.xiaoxiaomo.com/blog/img/yarn111.png" alt=""><br> 5.2. 配置规则库，如下，其中root.[primary group].[username]只要我们上面的资源池中配置好对应的用户组的资源池即可<br> <img src="https://img.xiaoxiaomo.com/blog/img/yarn112.png" alt=""><br> fair-scheduler.xml文件</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">allocations</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">"root"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>drf<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aclSubmitApps</span>&gt;</span> <span class="tag">&lt;/<span class="name">aclSubmitApps</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">aclAdministerApps</span>&gt;</span>*<span class="tag">&lt;/<span class="name">aclAdministerApps</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">"default"</span> <span class="attr">type</span>=<span class="string">"parent"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>drf<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclSubmitApps</span>&gt;</span>*<span class="tag">&lt;/<span class="name">aclSubmitApps</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclAdministerApps</span>&gt;</span>*<span class="tag">&lt;/<span class="name">aclAdministerApps</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">"dev"</span> <span class="attr">type</span>=<span class="string">"parent"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>3.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>drf<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclSubmitApps</span>&gt;</span> dev<span class="tag">&lt;/<span class="name">aclSubmitApps</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclAdministerApps</span>&gt;</span>*<span class="tag">&lt;/<span class="name">aclAdministerApps</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">"query"</span> <span class="attr">type</span>=<span class="string">"parent"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>4.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>drf<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclSubmitApps</span>&gt;</span> query<span class="tag">&lt;/<span class="name">aclSubmitApps</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">aclAdministerApps</span>&gt;</span>*<span class="tag">&lt;/<span class="name">aclAdministerApps</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">defaultQueueSchedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">defaultQueueSchedulingPolicy</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"specified"</span> <span class="attr">create</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"nestedUserQueue"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"primaryGroup"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"nestedUserQueue"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"default"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">"default"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="示例展示"><a href="#示例展示" class="headerlink" title="示例展示"></a>示例展示</h1><ol><li><p>我们通过上面创建的dev1，dev2，query1，query2用户运行任务，可以看到下面的<strong>队列分配情况</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/yarn113.png" alt=""></p></li><li><p>我在linux上创建了一个test用户，通过job ID无法kill job。通过hue登陆也能明显看到下图标记中没有kill按钮<br>（应为test创建时组为test，而该组和用户没在yarn.admin.acl中配置）<br><img src="https://img.xiaoxiaomo.com/blog/img/yarn114.png" alt=""></p></li></ol><ul><li><p><strong>附录规则库说明</strong><br>  ▪ specified at run time - 使用 root.[pool name],其中pool name是运行时指定的池的名称。<br>  ▪ root.users.[username] - 使用父池root.users，以提交应用程序的用户名在该吃中创建以用户名为池名的子池。<br>  ▪ root.default - 使用root.default池<br>  ▪ root.[pool name] - 这里的pool name是你在Pool Name中指定的池名。<br>  ▪ root.[primary group] - 使用与用户提交应用程序的主组相匹配的池。<br>  ▪ root.[secondary group] - 使用与提交应用程序的用户的次组相匹配的池。<br>  ▪ root.[username] - 使用与提交应用程序的用户的名称相匹配的池。<br>  ▪ root.[primary group].[username] - 父池匹配提交程序用户的主组，然后根据用户名创建子池。<br>  ▪ root.[secondary group].[username] - 父池匹配提交程序用户的次组，然后根据用户名创建子池。</p></li><li><p><strong>参考</strong>：<br><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=5505362" target="_blank" rel="noopener">http://cwiki.apachecn.org/pages/viewpage.action?pageId=5505362</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive--Hive元数据HDFS路径异常</title>
      <link href="/2017/11/29/Hive-Hive%E5%85%83%E6%95%B0%E6%8D%AEHDFS%E8%B7%AF%E5%BE%84%E5%BC%82%E5%B8%B8/"/>
      <url>/2017/11/29/Hive-Hive%E5%85%83%E6%95%B0%E6%8D%AEHDFS%E8%B7%AF%E5%BE%84%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<h1 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h1><ul><li>在hue上面跑hive语句时，出现如下异常：<br><img src="https://img.xiaoxiaomo.com/blog/img/hive02.png" alt=""><a id="more"></a><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Error executing statement:</span><br><span class="line">org.apache.hive.service.cli.HiveSQLException: Error <span class="keyword">while</span> compiling statement: FAILED: </span><br><span class="line">SemanticException Unable to determine <span class="keyword">if</span> hdfs:<span class="comment">//fetch-loadTest-20:8020/user/hive/warehouse/feature.db/t_usercode_email_split is encrypted: </span></span><br><span class="line">java.lang.IllegalArgumentException: </span><br><span class="line">Wrong FS: hdfs:<span class="comment">//fetch-loadTest-20:8020/user/hive/warehouse/feature.db/t_usercode_email_split, expected: hdfs://nameservice1</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><ol><li>从日志上看是说，hdfs的路劲有问题，<strong>指定说可能应该是hdfs://nameservice1</strong></li><li>hive中日志也是报同样错误</li><li><strong>昨天好像修改过HDFS的NameNode为HA</strong>，问题大概确定，需要去修改Hive FSRoot</li></ol><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><ul><li>有两个方法，<strong>第一个通过bin/metatool修改</strong>，<strong>第二个方法去mysql中修改hive的元数据</strong></li></ul><ol><li><p><strong>通过bin/metatool修改</strong><br><code>bin/metatool -updateLocation &lt;new-loc&gt; &lt;old-loc&gt;</code><br><img src="https://img.xiaoxiaomo.com/blog/img/hive03.png" alt=""><br>居然没效果，查了资料可以通过下面的方案去解决<br><a href="https://discuss.pivotal.io/hc/en-us/articles/222679027-Failed-initializing-database-with-Access-denied-when-accessing-the-Hive-metatool-" target="_blank" rel="noopener">https://discuss.pivotal.io/hc/en-us/articles/222679027-Failed-initializing-database-with-Access-denied-when-accessing-the-Hive-metatool-</a></p></li><li><p><strong>通过修改MySQL的元数据</strong></p><blockquote><p>hive的元数据在哪儿？即mysql中，怎么修改？还不确认是那几张表，然后通过一篇文章确认为DBS、SDS两张表<br>查看表信息<br><img src="https://img.xiaoxiaomo.com/blog/img/hive01.png" alt=""><br>修改<br><img src="https://img.xiaoxiaomo.com/blog/img/hive04.png" alt=""></p></blockquote></li></ol><ul><li>参考：<a href="https://www.iyunv.com/thread-192158-1-1.html" target="_blank" rel="noopener">https://www.iyunv.com/thread-192158-1-1.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cloudera Manager--升级Kafka</title>
      <link href="/2017/11/22/Cloudera-Manager-%E5%8D%87%E7%BA%A7Kafka/"/>
      <url>/2017/11/22/Cloudera-Manager-%E5%8D%87%E7%BA%A7Kafka/</url>
      <content type="html"><![CDATA[<p>　　之前使用的kafka版本<em>0.10.0.0</em>，因为一个项目用到了<code>kafka streaming流计算</code>中最新的API，要求从<em>0.10.0.0-&gt;0.11.0.0</em>，所以不得不去进行升级。<br><strong>其实总的流程和Cloudera Manager中安装kafka差不多，记录下来，方便以后查询</strong>（只要是在Cloudera Manager中升级Kafka流程是一样的）。</p><h1 id="检查-Kafka-CSD"><a href="#检查-Kafka-CSD" class="headerlink" title="检查 Kafka CSD"></a>检查 Kafka CSD</h1><ol><li><p>查看<code>cloudera manager server服务所在节点</code>的csd是否最新（节点上csd默认地址：<em>/opt/cloudera/csd/</em>）<br>否就去<a href="http://archive.cloudera.com/csds/kafka/" target="_blank" rel="noopener">http://archive.cloudera.com/csds/kafka/</a>下载最新的jar。</p><a id="more"></a><p><img src="https://img.xiaoxiaomo.com/blog/img/cloudera100.png" alt=""> </p></li><li><p>如果一致跳过下面的步骤<br> 2.1. 勾选“启用本地描述符存储库”<br> 进入cm管理界面，管理 =&gt; 设置 =&gt; 自定义服务描述 =&gt; 本地描述符存储路径，勾选“启用本地描述符存储库”<br> <img src="https://img.xiaoxiaomo.com/blog/img/cloudera101.png" alt=""><br> 2.2. 上传CSD文件到本地描述符存储库路径<br> 下载CSD文件（目前为<a href="http://archive.cloudera.com/csds/kafka/" target="_blank" rel="noopener">KAFKA-1.2.0.jar</a>）上传到本地描述符存储库路径（默认：/opt/cloudera/csd/）</p></li></ol><h1 id="升级parcel包"><a href="#升级parcel包" class="headerlink" title="升级parcel包"></a>升级parcel包</h1><ol><li><strong>下载kafka parcel包</strong><br>下载地址:<a href="http://archive.cloudera.com/kafka/parcels" target="_blank" rel="noopener">http://archive.cloudera.com/kafka/parcels</a>（CentOS6.x选择el6版本）</li></ol><ol start="2"><li><p><strong>上传下载的parcel包到CM安装的机器</strong>上的<em>/opt/cloudera/parcel-repo</em>目录<br>（总共需要2个：KAFKA-3.0.0-1.3.0.0.p0.40-el6.parcel、 KAFKA-3.0.0-1.3.0.0.p0.40-el6.parcel.sha1）<br>（在相应目录的manifest.json文件中，我们可以看到kafak的版本）<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera102.png" alt=""> </p></li><li><p>到CM parcel页面，<strong>点击检查新的parcel包</strong>（刷新不出时多点击几次并稍加等待）<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera103.png" alt=""></p></li><li><p><strong>出现Hash file is not found或未找到哈希文件错误时</strong>，需要去<em>/opt/cloudera/parcel-repo</em>将parcel.sha1修改为parcel.sha<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera104.png" alt=""></p></li><li><p>再次回到页面点击检查新parcel（刷不成功多点击几次），错误消失，然后点击分配。<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera105.png" alt=""></p></li><li><p>激活parcel包<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera106.png" alt=""><br>选择“仅限活动状态”<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera107.png" alt=""></p></li><li><p>最后一步，逐个重启kafka服务就好了，升级成功<br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera108.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/cloudera109.png" alt=""></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--gcc/g++离线安装</title>
      <link href="/2017/11/21/Linux-gcc-g-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/"/>
      <url>/2017/11/21/Linux-gcc-g-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>　　由于线上服务器没办法访问外网，于是<strong>很多软件都没办法在线安装</strong>。<code>gcc/g++</code> 是我们在编译软件时经常需要的软件，<code>gcc/g++</code>依赖的包还有点多。<br>具体安装一般是在网上搜一下按照流程安装就行了，自己这两三年来感觉搜索安装了好几次！！！决定还是把这个小小的流程记录下来吧，以便下次方便。</p><h1 id="查看并下载对应版本"><a href="#查看并下载对应版本" class="headerlink" title="查看并下载对应版本"></a>查看并下载对应版本</h1><ul><li><strong>常见异常</strong>：<code>configure: error: no accepttable C compiler found in $PATH</code> 就是缺少gcc导致，如下图编译安装python时发现缺少gcc：<br><img src="https://img.xiaoxiaomo.com/blog/img/linux-gcc01.png" alt="linux-gcc"> </li></ul><a id="more"></a><ol><li><p>查看服务器的内核版本，操作系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo.blog ~]$ uname -a</span><br><span class="line">Linux xiaoxiaomo.blog 2.6.32-431.el6.x86_64 #1 ... x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line"></span><br><span class="line">[root@xiaoxiaomo.blog ~]$ cat /etc/redhat-release</span><br><span class="line">CentOS release 6.5 (Final)</span><br></pre></td></tr></table></figure></li><li><p>从上面可以看见是<code>CentOS6.5 x86_64</code>，去官网下载软件<br>centos软件下载：<a href="http://vault.centos.org/6.5/os/x86_64/Packages/" target="_blank" rel="noopener">http://vault.centos.org/6.5/os/x86_64/Packages/</a><br><img src="https://img.xiaoxiaomo.com/blog/img/linux-gcc02.png" alt="linux-gcc"> </p></li></ol><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ul><li>通过<code>rpm -ivh</code>安装<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh ppl-0.10.2-11.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh cloog-ppl-0.15.7-1.2.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh mpfr-2.4.1-6.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh cpp-4.4.7-4.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh kernel-headers-2.6.32-431.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh glibc-headers-2.12-1.132.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh glibc-devel-2.12-1.132.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh libstdc++-devel-4.4.7-4.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh gcc-4.4.7-4.el6.x86_64.rpm</span><br><span class="line">[root@xiaoxiaomo.blog gcc]# rpm -ivh gcc-c++-4.4.7-4.el6.x86_64.rpm</span><br></pre></td></tr></table></figure></li></ul><h1 id="校验"><a href="#校验" class="headerlink" title="校验"></a>校验</h1><ul><li>查看是否成功，如下输出就成功了<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo.blog gcc]# gcc</span><br><span class="line">gcc: 没有输入文件</span><br></pre></td></tr></table></figure></li></ul><h1 id="有时候还会出现如下异常"><a href="#有时候还会出现如下异常" class="headerlink" title="有时候还会出现如下异常"></a>有时候还会出现如下异常</h1><ul><li>异常，安装时有如下异常提示，可以通过<code>--nodeps --force</code>忽略依赖包<br><img src="https://img.xiaoxiaomo.com/blog/img/linux-gcc03.png" alt="linux-gcc"> </li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--用户密码设置</title>
      <link href="/2017/11/21/Cassandra-%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E8%AE%BE%E7%BD%AE/"/>
      <url>/2017/11/21/Cassandra-%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　<strong>Cassandra 用户名密码设置</strong>，我使用的cassandra版本为3.11.1。本篇博客不仅仅演示Cassandra 用户密码的设置，还包括Cassandra 用户的一些更新删除的操作。下面一起来看看：</p><h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><ol><li><p><strong>默认cassandra是不需要账号密码的</strong>，授权信息默认如下配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">authenticator: AllowAllAuthenticator</span><br><span class="line">authorizer: AllowAllAuthorizer</span><br></pre></td></tr></table></figure></li><li><p>修改<code>conf/cassandra.yaml</code>配置文件，<strong>然后重启</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">authenticator: PasswordAuthenticator</span><br><span class="line">authorizer: CassandraAuthorizer</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><ul><li>如下<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra24.png" alt="cassandra 授权"></li></ul><h1 id="查看Cassandra权限"><a href="#查看Cassandra权限" class="headerlink" title="查看Cassandra权限"></a>查看Cassandra权限</h1><ul><li>权限管理这块数据保存在<code>keyspace</code>里面，主要有四张表<code>resource_role_permissons_index</code>、<code>role_permissions</code>、<code>role_permissions</code>、<code>roles</code>，表不多我们可以查看一下<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cassandra@cqlsh&gt; desc keyspace system_auth</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> KEYSPACE system_auth <span class="keyword">WITH</span> </span><br><span class="line">    <span class="keyword">replication</span> = &#123;<span class="string">'class'</span>: <span class="string">'SimpleStrategy'</span>, <span class="string">'replication_factor'</span>: <span class="string">'1'</span>&#125;  <span class="keyword">AND</span> durable_writes = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> system_auth.resource_role_permissons_index (</span><br><span class="line">    <span class="keyword">resource</span> <span class="built_in">text</span>,</span><br><span class="line">    <span class="keyword">role</span> <span class="built_in">text</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">resource</span>, <span class="keyword">role</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> system_auth.role_permissions (</span><br><span class="line">    <span class="keyword">role</span> <span class="built_in">text</span>,</span><br><span class="line">    <span class="keyword">resource</span> <span class="built_in">text</span>,</span><br><span class="line">    permissions <span class="keyword">set</span>&lt;<span class="built_in">text</span>&gt;,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">role</span>, <span class="keyword">resource</span>)</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> system_auth.role_members (</span><br><span class="line">    <span class="keyword">role</span> <span class="built_in">text</span>,</span><br><span class="line">    <span class="keyword">member</span> <span class="built_in">text</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">role</span>, <span class="keyword">member</span>)</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> system_auth.roles (</span><br><span class="line">    <span class="keyword">role</span> <span class="built_in">text</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">    can_login <span class="built_in">boolean</span>,</span><br><span class="line">    is_superuser <span class="built_in">boolean</span>,</span><br><span class="line">    member_of <span class="keyword">set</span>&lt;<span class="built_in">text</span>&gt;,</span><br><span class="line">    salted_hash <span class="built_in">text</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li></ul><h1 id="使用默认账号密码"><a href="#使用默认账号密码" class="headerlink" title="使用默认账号密码"></a>使用默认账号密码</h1><ul><li>使用默认账号密码登录<code>cqlsh -ucassandra -p cassandra</code><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cassandra@cqlsh&gt; use system_auth;</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from resource_role_permissons_index;</span><br><span class="line"></span><br><span class="line"> resource | role</span><br><span class="line"><span class="comment">----------+------</span></span><br><span class="line"></span><br><span class="line">(0 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from role_permissions;</span><br><span class="line"></span><br><span class="line"> role | resource | permissions</span><br><span class="line"><span class="comment">------+----------+-------------</span></span><br><span class="line"></span><br><span class="line">(0 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from role_permissions;</span><br><span class="line"></span><br><span class="line"> role | resource | permissions</span><br><span class="line"><span class="comment">------+----------+-------------</span></span><br><span class="line"></span><br><span class="line">(0 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from roles;</span><br><span class="line"></span><br><span class="line"> role      | can_login | is_superuser | member_of | salted_hash</span><br><span class="line"><span class="comment">-----------+-----------+--------------+-----------+-------------------------------</span></span><br><span class="line"> cassandra |      True |         True |      null | $2a$10...RhFCCKQwT6wNyucgANW</span><br><span class="line"></span><br><span class="line">(1 rows)</span><br></pre></td></tr></table></figure></li></ul><h1 id="用户相关操作"><a href="#用户相关操作" class="headerlink" title="用户相关操作"></a>用户相关操作</h1><ol><li><p>创建账号并设置密码授权为超级用户，例如设置账号为xiaoxiaomo,密码为blog<br>（SUPERUSER超级用户，NOSUPERUSER普通用户）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cassandra@cqlsh:system_auth&gt; create user xiaoxiaomo with password 'blog' superuser;</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from resource_role_permissons_index;</span><br><span class="line"></span><br><span class="line"> resource         | role</span><br><span class="line"><span class="comment">------------------+-----------</span></span><br><span class="line"> roles/xiaoxiaomo | cassandra</span><br><span class="line"></span><br><span class="line">(1 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from role_permissions;</span><br><span class="line"></span><br><span class="line"> role      | resource         | permissions</span><br><span class="line"><span class="comment">-----------+------------------+--------------------------------</span></span><br><span class="line"> cassandra | roles/xiaoxiaomo | &#123;'ALTER', 'AUTHORIZE', 'DROP'&#125;</span><br><span class="line"></span><br><span class="line">(1 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from role_permissions;</span><br><span class="line"></span><br><span class="line"> role      | resource         | permissions</span><br><span class="line"><span class="comment">-----------+------------------+--------------------------------</span></span><br><span class="line"> cassandra | roles/xiaoxiaomo | &#123;'ALTER', 'AUTHORIZE', 'DROP'&#125;</span><br><span class="line"></span><br><span class="line">(1 rows)</span><br><span class="line">cassandra@cqlsh:system_auth&gt; select * from roles;</span><br><span class="line"></span><br><span class="line"> role       | can_login | is_superuser | member_of | salted_hash</span><br><span class="line"><span class="comment">------------+-----------+--------------+-----------+-------------------------------</span></span><br><span class="line"> xiaoxiaomo |      True |         True |      null | $2a$10$C....sUJwqElvJ9UZe0YXSdu</span><br><span class="line">  cassandra |      True |         True |      null | $2a$10$K....wNyucgANW</span><br><span class="line"></span><br><span class="line">(2 rows)</span><br></pre></td></tr></table></figure></li><li><p>删除默认账号</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cassandra@cqlsh:system_auth&gt; drop user cassandra;</span><br></pre></td></tr></table></figure></li><li><p>修改用户信息（密码或者身份）<br>（下面修改cassandra用户密码为cassandra1,身份修改为普通用户）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[cassandra@xiaoxiaomo.blog apache-cassandra-3.11.1]$ ./bin/cqlsh -uxiaoxiaomo -pblog</span><br><span class="line">Connected to XXOCluster at 127.0.0.1:9042.</span><br><span class="line">[cqlsh 5.0.1 | Cassandra 3.11.1 | CQL spec 3.4.4 | Native protocol v4]</span><br><span class="line"><span class="keyword">Use</span> <span class="keyword">HELP</span> <span class="keyword">for</span> help.</span><br><span class="line">xiaoxiaomo@cqlsh&gt; <span class="keyword">alter</span> <span class="keyword">user</span> cassandra <span class="keyword">with</span> <span class="keyword">password</span> <span class="string">'cassandra1'</span> nosuperuser;</span><br><span class="line">xiaoxiaomo@cqlsh&gt; quit;</span><br><span class="line"></span><br><span class="line">[cassandra@xiaoxiaomo.blog apache-cassandra-3.11.1]$ ./bin/cqlsh -ucassandra -pcassandra1;</span><br><span class="line">Connected to XXOCluster at 127.0.0.1:9042.</span><br><span class="line">[cqlsh 5.0.1 | Cassandra 3.11.1 | CQL spec 3.4.4 | Native protocol v4]</span><br><span class="line"><span class="keyword">Use</span> <span class="keyword">HELP</span> <span class="keyword">for</span> help.</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>普通用户智能查看，不能创建修改删除<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cassandra@cqlsh&gt; create keyspace test2</span><br><span class="line">   ... WITH REPLICATION = &#123;'class': 'SimpleStrategy','replication_factor':1&#125;;</span><br><span class="line">Unauthorized: Error from server: code=2100 [Unauthorized] message="User cassandra has no <span class="keyword">CREATE</span> permission <span class="keyword">on</span> &lt;all keyspaces&gt; <span class="keyword">or</span> <span class="keyword">any</span> <span class="keyword">of</span> its parents<span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">cassandra@cqlsh&gt; alter keyspace testspace</span></span><br><span class="line"><span class="string">   ... with replication=&#123;'class': 'SimpleStrategy', 'replication_factor':2&#125;;</span></span><br><span class="line"><span class="string">Unauthorized: Error from server: code=2100 [Unauthorized] message="</span><span class="keyword">User</span> cassandra has <span class="keyword">no</span> <span class="keyword">ALTER</span> permission <span class="keyword">on</span> &lt;keyspace testspace&gt; <span class="keyword">or</span> <span class="keyword">any</span> <span class="keyword">of</span> its parents<span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">cassandra@cqlsh&gt; drop keyspace testspace;</span></span><br><span class="line"><span class="string">Unauthorized: Error from server: code=2100 [Unauthorized] message="</span><span class="keyword">User</span> cassandra has <span class="keyword">no</span> <span class="keyword">DROP</span> permission <span class="keyword">on</span> &lt;keyspace testspace&gt; <span class="keyword">or</span> <span class="keyword">any</span> <span class="keyword">of</span> its parents<span class="string">"</span></span><br><span class="line"><span class="string">cassandra@cqlsh&gt;</span></span><br></pre></td></tr></table></figure></p></blockquote><ul><li>参考：<br><a href="https://www.cnblogs.com/zzd-zxj/p/6062768.html" target="_blank" rel="noopener">https://www.cnblogs.com/zzd-zxj/p/6062768.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--Java API</title>
      <link href="/2017/11/16/Cassandra-Java-API/"/>
      <url>/2017/11/16/Cassandra-Java-API/</url>
      <content type="html"><![CDATA[<p>　　前面已经说了一种访问<code>Cassandra</code>的一种方式CQL，本篇博客还讲解一下其他的方式访问，主要是以Java API的方式，当然它是支持很多语言的，看看下图就知道了：<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra20.png" alt=""><br><a id="more"></a></p><h2 id="Java-API"><a href="#Java-API" class="headerlink" title="Java API"></a>Java API</h2><ul><li>Cassandra 的Java API官网给出了如下几种，都是一些公司写的开源客户端，我们这里主要看一下datastax的<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra21.png" alt="Cassandra Java API"> </li></ul><h2 id="直接看代码吧"><a href="#直接看代码吧" class="headerlink" title="直接看代码吧"></a>直接看代码吧</h2><ul><li><p>访问前修改一下<code>cassandra.yaml</code>配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start_rpc: true</span><br><span class="line">rpc_address: 0.0.0.0</span><br><span class="line">broadcast_rpc_address: 1.2.3.4</span><br></pre></td></tr></table></figure></li><li><p>下面的代码来源于：<a href="https://github.com/jbisso/cassandra-samples" target="_blank" rel="noopener">https://github.com/jbisso/cassandra-samples</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.datastax.driver.core.Cluster;</span><br><span class="line"><span class="keyword">import</span> com.datastax.driver.core.Metadata;</span><br><span class="line"><span class="keyword">import</span> com.datastax.driver.core.ResultSet;</span><br><span class="line"><span class="keyword">import</span> com.datastax.driver.core.Row;</span><br><span class="line"><span class="keyword">import</span> com.datastax.driver.core.Session;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A simple client application that illustrates connecting to</span></span><br><span class="line"><span class="comment"> * a Cassandra cluster. retrieving metadata, creating a schema,</span></span><br><span class="line"><span class="comment"> * loading data into it, and then querying it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleClient</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Session session;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SimpleClient</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Connects to the specified node.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> node a host name or IP address of the node in the cluster</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">        Cluster cluster = Cluster.builder()</span><br><span class="line">                .addContactPoint(node)</span><br><span class="line"><span class="comment">//                .withCredentials("xiaoxiaomo", "blog")</span></span><br><span class="line">                .build();</span><br><span class="line">        Metadata metadata = cluster.getMetadata();</span><br><span class="line">        System.out.printf(<span class="string">"Connected to cluster: %s\n"</span>,</span><br><span class="line">                metadata.getClusterName());</span><br><span class="line">        session = cluster.connect();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(String[] nodes,<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        Cluster cluster = Cluster.builder()</span><br><span class="line">                .addContactPoints(nodes)</span><br><span class="line">                .withPort(port)</span><br><span class="line">                .withCredentials(<span class="string">"xiaoxiaomo"</span>, <span class="string">"blog"</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        Metadata metadata = cluster.getMetadata();</span><br><span class="line">        System.out.printf(<span class="string">"Connected to cluster: %s\n"</span>,</span><br><span class="line">                metadata.getClusterName());</span><br><span class="line">        session = cluster.connect();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Creates the simplex keyspace and two tables, songs and playlists.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createSchema</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"CREATE KEYSPACE IF NOT EXISTS simplex  WITH replication "</span> +</span><br><span class="line">                        <span class="string">"= &#123;'class':'SimpleStrategy', 'replication_factor':3&#125;;"</span>);</span><br><span class="line">        <span class="comment">// create songs and playlist tables</span></span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"CREATE TABLE IF NOT EXISTS simplex.songs ("</span> +</span><br><span class="line">                        <span class="string">"id uuid PRIMARY KEY,"</span> +</span><br><span class="line">                        <span class="string">"title text,"</span> +</span><br><span class="line">                        <span class="string">"album text,"</span> +</span><br><span class="line">                        <span class="string">"artist text,"</span> +</span><br><span class="line">                        <span class="string">"tags set&lt;text&gt;,"</span> +</span><br><span class="line">                        <span class="string">"data blob"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"CREATE TABLE IF NOT EXISTS  simplex.playlists ("</span> +</span><br><span class="line">                        <span class="string">"id uuid,"</span> +</span><br><span class="line">                        <span class="string">"title text,"</span> +</span><br><span class="line">                        <span class="string">"album text, "</span> +</span><br><span class="line">                        <span class="string">"artist text,"</span> +</span><br><span class="line">                        <span class="string">"song_id uuid,"</span> +</span><br><span class="line">                        <span class="string">"PRIMARY KEY (id, title, album, artist)"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        System.out.println(<span class="string">"Simplex keyspace and schema created."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Loads some data into the schema so that we can query the tables.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">loadData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// insert data in the tables</span></span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.songs (id, title, album, artist, tags) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"756716f7-2e54-4715-9f00-91dcbea6cf50,"</span> +</span><br><span class="line">                        <span class="string">"'La Petite Tonkinoise',"</span> +</span><br><span class="line">                        <span class="string">"'Bye Bye Blackbird',"</span> +</span><br><span class="line">                        <span class="string">"'Joséphine Baker',"</span> +</span><br><span class="line">                        <span class="string">"&#123;'jazz', '2013'&#125;)"</span> +</span><br><span class="line">                        <span class="string">";"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.songs (id, title, album, artist, tags) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"f6071e72-48ec-4fcb-bf3e-379c8a696488,"</span> +</span><br><span class="line">                        <span class="string">"'Die Mösch',"</span> +</span><br><span class="line">                        <span class="string">"'In Gold',"</span> +</span><br><span class="line">                        <span class="string">"'Willi Ostermann',"</span> +</span><br><span class="line">                        <span class="string">"&#123;'kölsch', '1996', 'birds'&#125;"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.songs (id, title, album, artist, tags) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"fbdf82ed-0063-4796-9c7c-a3d4f47b4b25,"</span> +</span><br><span class="line">                        <span class="string">"'Memo From Turner',"</span> +</span><br><span class="line">                        <span class="string">"'Performance',"</span> +</span><br><span class="line">                        <span class="string">"'Mick Jager',"</span> +</span><br><span class="line">                        <span class="string">"&#123;'soundtrack', '1991'&#125;"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.playlists (id, song_id, title, album, artist) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"2cc9ccb7-6221-4ccb-8387-f22b6a1b354d,"</span> +</span><br><span class="line">                        <span class="string">"756716f7-2e54-4715-9f00-91dcbea6cf50,"</span> +</span><br><span class="line">                        <span class="string">"'La Petite Tonkinoise',"</span> +</span><br><span class="line">                        <span class="string">"'Bye Bye Blackbird',"</span> +</span><br><span class="line">                        <span class="string">"'Joséphine Baker'"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.playlists (id, song_id, title, album, artist) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"2cc9ccb7-6221-4ccb-8387-f22b6a1b354d,"</span> +</span><br><span class="line">                        <span class="string">"f6071e72-48ec-4fcb-bf3e-379c8a696488,"</span> +</span><br><span class="line">                        <span class="string">"'Die Mösch',"</span> +</span><br><span class="line">                        <span class="string">"'In Gold',"</span> +</span><br><span class="line">                        <span class="string">"'Willi Ostermann'"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"INSERT INTO simplex.playlists (id, song_id, title, album, artist) "</span> +</span><br><span class="line">                        <span class="string">"VALUES ("</span> +</span><br><span class="line">                        <span class="string">"3fd2bedf-a8c8-455a-a462-0cd3a4353c54,"</span> +</span><br><span class="line">                        <span class="string">"fbdf82ed-0063-4796-9c7c-a3d4f47b4b25,"</span> +</span><br><span class="line">                        <span class="string">"'Memo From Turner',"</span> +</span><br><span class="line">                        <span class="string">"'Performance',"</span> +</span><br><span class="line">                        <span class="string">"'Mick Jager'"</span> +</span><br><span class="line">                        <span class="string">");"</span>);</span><br><span class="line">        System.out.println(<span class="string">"Data loaded."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Queries the songs and playlists tables for data.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">querySchema</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ResultSet results = session.execute(</span><br><span class="line">                <span class="string">"SELECT * FROM simplex.playlists "</span> +</span><br><span class="line">                        <span class="string">"WHERE id = 2cc9ccb7-6221-4ccb-8387-f22b6a1b354d;"</span>);</span><br><span class="line">        System.out.println(</span><br><span class="line">                String.format(<span class="string">"%-30s\t%-20s\t%-20s\n%s"</span>, <span class="string">"title"</span>, <span class="string">"album"</span>, <span class="string">"artist"</span>,</span><br><span class="line">                <span class="string">"-------------+------------------+---------------"</span>));</span><br><span class="line">        <span class="keyword">for</span> (Row row : results) &#123;</span><br><span class="line">            System.out.println(</span><br><span class="line">                    String.format(<span class="string">"%-30s\t%-20s\t%-20s"</span>, </span><br><span class="line">                    row.getString(<span class="string">"title"</span>),</span><br><span class="line">                    row.getString(<span class="string">"album"</span>), </span><br><span class="line">                    row.getString(<span class="string">"artist"</span>)));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println();</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Updates the songs table with a new song and then queries the table</span></span><br><span class="line"><span class="comment">     * to retrieve data.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateSchema</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        session.execute(</span><br><span class="line">                <span class="string">"UPDATE simplex.songs "</span> +</span><br><span class="line">                        <span class="string">"SET tags = tags + &#123; 'entre-deux-guerres' &#125; "</span> +</span><br><span class="line">                        <span class="string">"WHERE id = 756716f7-2e54-4715-9f00-91dcbea6cf50;"</span>);</span><br><span class="line">      </span><br><span class="line">        ResultSet results = session.execute(</span><br><span class="line">                <span class="string">"SELECT * FROM simplex.songs "</span> +</span><br><span class="line">                        <span class="string">"WHERE id = 756716f7-2e54-4715-9f00-91dcbea6cf50;"</span>);</span><br><span class="line">      </span><br><span class="line">        System.out.println(</span><br><span class="line">                String.format(<span class="string">"%-30s\t%-20s\t%-20s%-30s\n%s"</span>, </span><br><span class="line">                <span class="string">"title"</span>, <span class="string">"album"</span>, <span class="string">"artist"</span>, <span class="string">"tags"</span>, </span><br><span class="line">                <span class="string">"--------------------------+-----------------+-----------------+-------"</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (Row row : results) &#123;</span><br><span class="line">            System.out.println(</span><br><span class="line">                    String.format(<span class="string">"%-30s\t%-20s\t%-20s"</span>, </span><br><span class="line">                    row.getString(<span class="string">"title"</span>),</span><br><span class="line">                    row.getString(<span class="string">"album"</span>), </span><br><span class="line">                    row.getString(<span class="string">"artist"</span>), </span><br><span class="line">                    row.getSet(<span class="string">"tags"</span>, String.class)));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Drops the specified schema.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyspace the keyspace to drop (and all of its data)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dropSchema</span><span class="params">(String keyspace)</span> </span>&#123;</span><br><span class="line">        getSession().execute(<span class="string">"DROP KEYSPACE "</span> + keyspace);</span><br><span class="line">        System.out.println(<span class="string">"Finished dropping "</span> + keyspace + <span class="string">" keyspace."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Returns the current session.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the current session to execute statements on</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Session <span class="title">getSession</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.session;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// used by the workaround method in the BoundStatementsclient child class.</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setSession</span><span class="params">(Session session)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.session = session;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Shuts down the session and its cluster.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        session.close();</span><br><span class="line">        session.getCluster().close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Creates  simple client application that illustrates connecting to</span></span><br><span class="line"><span class="comment">     * a Cassandra cluster. retrieving metadata, creating a schema,</span></span><br><span class="line"><span class="comment">     * loading data into it, and then querying it.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args ignored</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SimpleClient client = <span class="keyword">new</span> SimpleClient();</span><br><span class="line">        client.connect(<span class="string">"10.141.5.27"</span>);</span><br><span class="line">        client.createSchema();</span><br><span class="line">        client.loadData();</span><br><span class="line">        client.querySchema();</span><br><span class="line">        client.updateSchema();</span><br><span class="line">        client.dropSchema(<span class="string">"simplex"</span>);</span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--CQL</title>
      <link href="/2017/11/16/Cassandra-CQL/"/>
      <url>/2017/11/16/Cassandra-CQL/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲Cassandra的基本操作，主要是通过<code>cqlsh</code>客户端命令。这个也是我们常用的基本操作，后面再会讲解一下通过java api的方式操作Cassandra。<br>下面让我们一起来熟悉吧！</p><h1 id="启动cqlsh"><a href="#启动cqlsh" class="headerlink" title="启动cqlsh"></a>启动cqlsh</h1><ul><li><p><code>启动cqlsh</code>，如果rpc_address不是设置为0.0.0.0，直接输入cqlsh是会拒绝连接的<br><em>Connection error: (‘Unable to connect to any servers’, {‘127.0.0.1’: error(111, “Tried connecting to [(‘127.0.0.1’, 9042)]. Last error: Connection refused”)})</em></p></li><li><p>需要指定ip，具体操作如下图（我们上篇博客设置为节点的ip）<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra09.jpg" alt=""></p></li></ul><a id="more"></a><h1 id="Keyspace键空间操作"><a href="#Keyspace键空间操作" class="headerlink" title="Keyspace键空间操作"></a>Keyspace键空间操作</h1><h2 id="查看所有keyspace"><a href="#查看所有keyspace" class="headerlink" title="查看所有keyspace"></a>查看所有keyspace</h2><ul><li>命令：<code>describe keyspaces 或者 desc keyspaces</code>;<br>系统默认了五个键空间：system_traces  system_schema  system_auth  system  system_distributed<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra06.jpg" alt="系统默认表"></li></ul><h2 id="查看某个keyspace"><a href="#查看某个keyspace" class="headerlink" title="查看某个keyspace"></a>查看某个keyspace</h2><ul><li>命令：<code>describe keyspace keyspacesName 或者 desc keyspace keyspacesName</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra07.jpg" alt="查看某个keyspace"></li></ul><h2 id="创建keyspace"><a href="#创建keyspace" class="headerlink" title="创建keyspace"></a>创建keyspace</h2><ul><li><p>注意：cassandra关键字不区分大小写</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cqlsh&gt; CREATE KEYSPACE IF NOT EXISTS testSpace                 </span><br><span class="line">   ... WITH REPLICATION = &#123;&apos;class&apos;: &apos;SimpleStrategy&apos;,&apos;replication_factor&apos;:1&#125;;</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog/img/cassandra10.png" alt="创建一个自己的keyspace"></p></li></ul><h2 id="修改删除keyspace"><a href="#修改删除keyspace" class="headerlink" title="修改删除keyspace"></a>修改删除keyspace</h2><ul><li>命令：<code>alter keyspace keyspaceName with replication ...</code></li><li><p>删除：<code>drop keyspace keyspaceName</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cqlsh&gt; alter keyspace testspace </span><br><span class="line">    ... with replication=&#123;&apos;class&apos;: &apos;SimpleStrategy&apos;, &apos;replication_factor&apos;:2&#125;;</span><br><span class="line">cqlsh&gt; drop keyspace testspace;</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog/img/cassandra11.png" alt="修改删除keyspace"></p></li></ul><h1 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h1><h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><ul><li><p>注意：table必须定义一个PRIMARY KEY。一个PRIMARY KEY可以由一个或多个columns组成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cqlsh&gt; use testSpace;</span><br><span class="line">cqlsh:testspace&gt; create table table1(   </span><br><span class="line">             ... id int primary key,</span><br><span class="line">             ... name text</span><br><span class="line">             ... );</span><br><span class="line">             </span><br><span class="line">## 也可以写出</span><br><span class="line">cqlsh&gt; use testSpace;</span><br><span class="line">cqlsh:testspace&gt; create table table1(   </span><br><span class="line">             ... id int ,</span><br><span class="line">             ... name text ,</span><br><span class="line">             ... primary key(id) ,</span><br><span class="line">             ... );</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog/img/cassandra12.png" alt=""></p></li></ul><h2 id="查看表结构"><a href="#查看表结构" class="headerlink" title="查看表结构"></a>查看表结构</h2><ul><li>desc或者describe都行：<code>desc table tableName</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra13.png" alt=""></li></ul><h2 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h2><ol><li><p>修改表的属性：<code>ALTER TABLE &lt;tableName&gt; WITH Properties;</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra14.png" alt=""></p></li><li><p>增加表的列：<code>ALTER TABLE &lt;tableName&gt; ADD columnName columnType;</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra15.png" alt=""></p></li><li><p>增加表的列：<code>ALTER TABLE &lt;tableName&gt; DROP columnName;</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra16.png" alt=""></p></li></ol><h2 id="插入表数据"><a href="#插入表数据" class="headerlink" title="插入表数据"></a>插入表数据</h2><ul><li>和sql语句相同：<code>insert into table(column,...) values(value,...)</code><br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra17.png" alt=""></li></ul><h2 id="删除表数据"><a href="#删除表数据" class="headerlink" title="删除表数据"></a>删除表数据</h2><ul><li>命令：<code>delete from table where ...</code>，必须要有where，例如<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from table1 where id = 1;</span><br></pre></td></tr></table></figure></li></ul><h2 id="清空表数据："><a href="#清空表数据：" class="headerlink" title="清空表数据："></a>清空表数据：</h2><ul><li>命令：<code>TRUNCATE table</code>,RUNCATE语句将会完全删除所有table的数据<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra18.png" alt=""></li></ul><h1 id="index索引"><a href="#index索引" class="headerlink" title="index索引"></a>index索引</h1><h1 id="function"><a href="#function" class="headerlink" title="function"></a>function</h1><h1 id="type"><a href="#type" class="headerlink" title="type"></a>type</h1>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--配置文件讲解</title>
      <link href="/2017/11/16/Cassandra-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AE%B2%E8%A7%A3/"/>
      <url>/2017/11/16/Cassandra-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AE%B2%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲Cassandra的配置文件，主要是说的<code>cassandra.yaml</code>里面的一些配置项。这里会把主要的都列出来，以供参考，后续有新的东西也会持续补充更新。</p><h2 id="Cassandra配置文件"><a href="#Cassandra配置文件" class="headerlink" title="Cassandra配置文件"></a>Cassandra配置文件</h2><ol><li>在0.7版本之前,cassandra的配置文件是<code>conf/storage-conf.xml</code>文件。0.7之后是<code>conf/cassandra.yaml</code>文件</li><li>可以通过-Dcassandra.conf指定需要加载的配置文件，例如：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">-Dcassandra.config=alternate-cassandra.yaml</span><br><span class="line">-Dcassandra.config=http://www.example.com/remote-cassandra.yaml</span><br><span class="line">-Dcassandra.config=file:///home/me/external-local-cassandra.yaml</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><h2 id="集群相关"><a href="#集群相关" class="headerlink" title="集群相关"></a>集群相关</h2><ol><li><p><code>cluster_name</code><br> 集群名称：同一集群该值相同，默认：Test Cluster</p></li><li><p><code>initial_token</code>(Token值，表示了一致性哈希环中的位置)<br> 默认为空，系统自动生成。为空还表示使用virtual nodes，删除了节点之后它会自动均衡数据，不要你手动处理。 </p></li><li><p><code>auto_bootstrap</code> 　　<br> 第一次启动的时候，是否在加入Cassandra集群时从其他服务器获取属于本服务器的数据。如果当前Cassandra服务器不在seed配置选项中，并且是第一次启动，将从Cassandra集群中其他服务器获取属于本服务器的数据。 　</p></li></ol><h2 id="种子地址"><a href="#种子地址" class="headerlink" title="种子地址"></a>种子地址</h2><ul><li><code>seed_provider</code><br>  通过该参数设置种子地址，以用来发现子节点<ul><li>class_name (默认: org.apache.cassandra.locator.SimpleSeedProvider)，可以自定义</li><li>seeds (默认: 127.0.0.1)<br>  gossip用来引导新节点加入集群中去，多数据中心的集群，最好每个数据中心都包含一个种子节点（容错，推荐超过一个种子节点）。<br>  否则，gossip在引导一个新节点时不得不和另外一个数据中心通信了。不推荐把每个节点都当成种子节点(大概每个数据中心三个种子节点)。<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra19.png" alt=""></li></ul></li></ul><h2 id="权限相关"><a href="#权限相关" class="headerlink" title="权限相关"></a>权限相关</h2><ol><li><p>authenticator 用户授权，选项：<br> 1.1. AllowAllAuthenticator：（默认值）不需要密码，具备所有的权限<br> 1.2. SimpleAuthenticator：需要账号密码（用户/密码在passwd.properties文件中定义）</p></li><li><p>authority 校验权限<br> 验证该用户是否具备操作某一个Column Family的权限，这是安全认证的第一步。Cassandra中定义了一系列验证用户权限的策略，可以选择的项为： 　　<br> 2.1. AllowAllAuthority：（默认值），用户具备所有的权限<br> 2.2. SimpleAuthority：需要校验（用户/权限在access.properties文件中定义）</p></li><li><p>role_manager: CassandraRoleManager</p></li><li>roles_validity_in_ms: 2000</li><li>permissions_validity_in_ms: 2000</li><li>credentials_validity_in_ms: 2000</li></ol><h2 id="数据分区策略"><a href="#数据分区策略" class="headerlink" title="数据分区策略"></a>数据分区策略</h2><ul><li>partitioner：数据分区的策略（集群中所有节点该配置相同） 　　<ol><li>org.apache.cassandra.dht.RandomPartitioner 　　</li><li>org.apache.cassandra.dht.ByteOrderedPartitioner 　　</li><li>org.apache.cassandra.dht.OrderPreservingPartitioner 　　</li><li>org.apache.cassandra.dht.CollatingOrderPreservingPartitioner 　</li></ol></li></ul><h2 id="数据目录"><a href="#数据目录" class="headerlink" title="数据目录"></a>数据目录</h2><ol><li><p>data_file_directories：SSTable数据文件存储位置<br>（默认：$CASSANDRA_HOME/data/data）下面示例多个的写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_file_directories:</span><br><span class="line">    - /data1/cassandra/data</span><br><span class="line">    - /data2/cassandra/data</span><br><span class="line">    - /data3/cassandra/data</span><br></pre></td></tr></table></figure></li><li><p>commitlog_directory：日志文件目录<br>（默认：$CASSANDRA_HOME/data/commitlog），最好和SSTable文件目录分不同磁盘　</p></li><li><p>saved_caches_directory：数据缓存目录<br>（默认：$CASSANDRA_HOME/data/saved_caches）这个目录是table key和row缓存存放的地方</p></li></ol><h2 id="commit-log文件"><a href="#commit-log文件" class="headerlink" title="commit log文件"></a>commit log文件</h2><ol><li><p>commitlog_sync：commitlog同步方式<br> 2.1. periodic：周期同步commitlog，每一次有数据更新都将操作commitlog。 　　<br> 2.2. batch   ：批量同步commitlog</p></li><li><p>commitlog_sync_period_in_ms 　　<br> 周期记录commitlog时，刷新commitlog文件的时间间隔。这个选项只有在commitlog_sync= periodic时才能设置。 　　</p></li><li><p>commitlog_sync_batch_window_in_ms 　　<br> 批量记录commitlog时，批量操作缓存的时间间隔。这个选项只有在commitlog_sync= batch时才能设置。 　　</p></li><li><p>commitlog_segment_size_in_mb: 32</p></li></ol><h2 id="数据文件访问"><a href="#数据文件访问" class="headerlink" title="数据文件访问"></a>数据文件访问</h2><ul><li>disk_access_mode：Cassandra访问SSTable文件中的Data文件和Index文件时是否使用虚拟内存映射的形式。<ol><li>auto 　　自动选择合适的文件访问形式，如果是64位系统，则为mmap形式，否则为standard形式。 　　</li><li>mmap 　　访问SSTable文件中的Data文件和Index文件时，都采用虚拟内存映射的形式。 　　</li><li>mmap_index_only 　　访问SSTable文件中的Index文件时采用虚拟内存映射的形式。 　　</li><li>standard 　　访问SSTable文件中的Data文件和Index文件时，都不采用虚拟内存映射的形式。使用虚拟内存映射的形式访问文件能够加快对文件的读写速度，但是这是以消耗而外的内存作为代价的。所以要根据实际内存大小与文件大小来选择合适的文件访问方式。 　　</li></ol></li></ul><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><ol><li><p><code>concurrent_reads</code> 　　<br> (默认: 32)并发读取的线程数，这个选项设置得越大，Cassandra在进行读取操作时可以使用的线程数就越多。推荐的配置为：CPU的个数*2。 　　</p></li><li><p><code>concurrent_writes</code> 　　<br> (默认: 32)并发写入的线程数，这个选项设置得越大，Cassandra在进行写入操作时可以使用的线程数就越多。 　　</p></li><li><p><code>concurrent_counter_writes</code><br> (默认: 32)注计数器在自增之前写当前读的值，然后写回调。推荐值是(16x处理器数量)</p></li><li><p><code>concurrent_batchlog_writes</code><br> (默认: 32)并发批量写日志的限制，类似于concurrent_writes</p></li><li><p><code>concurrent_materialized_view_writes</code><br> (默认: 32) 比并发读或者并发写更少的并发物化视图的写，因为物化视图写中包含了一个读取。</p></li></ol><h2 id="地址端口通信"><a href="#地址端口通信" class="headerlink" title="地址端口通信"></a>地址端口通信</h2><ol><li><p><code>storage_port</code>： 服务器与服务器通信端口　　</p></li><li><p><code>listen_address</code>： 服务器与服务器通信地址(默认：localhost)，也可以设置<code>listen_interface</code>，不需要同时设置</p></li><li><p><code>rpc_address</code>： 服务器对外通信地址(默认使用主机名)　</p></li><li><p><code>rpc_port</code>： 服务器对外通信端口　　</p></li><li><p><code>rpc_keepalive</code>： rpc连接是否一直保持。 　</p></li><li><p><code>rpc_timeout_in_ms</code>： rpc超时限制</p></li><li><code>rpc_min_threads</code>:  16</li><li><p><code>rpc_max_threads</code>:  2048</p></li><li><p><code>thrift_framed_transport_size_in_mb</code> ：使用Thrift Frame每次传递的数据大小。如果该选项为0，则禁用Thrift Frame。 　　</p></li><li><code>thrift_max_message_length_in_mb</code>  ：使用Thrift传递的数据最大值。 　　</li></ol><h2 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h2><ol><li><p><code>compaction_throughput_mb_per_sec</code><br> (默认: 16) compaction指定的总吞吐量的阀值。你插入速度越快，越需要在规定时间内更快的压缩速度。推荐的值是16到32的写吞吐量(单位：Mb/s)。<br>设为0，表示禁用compaction throttling。</p></li><li><p><code>compaction_large_partition_warning_threshold_mb</code><br> (默认: 100) 在压缩分区大于设定值时记录警告。</p></li><li><p><code>snapshot_before_compaction</code>：在执行数据压缩操作前<br> 是否对需要压缩的SSTable文件做数据快照(snapshot)，默认：false。 　　　　</p></li><li><p><code>in_memory_compaction_limit_in_mb</code>：在Cassandra执行数据压缩时<br> 如果某一个key对应的数据的大小超过了in_memory_compaction_limit_in_mb的限制，将采用延后压缩的机制进行压缩，避免使用过多的内存。 　　</p></li><li><p><code>column_index_size_in_kb</code>：SSTable数据文件对应索引的数据大小间隔。如果这个值越小，在Column索引中找到相应的值速度就越快，但是会消耗更多的内存与磁盘空间。 </p></li><li><p><code>index_interval</code> 　　<br> SSTable文件中的Index文件对应内存索引的数据大小间隔。如果这个值越小，在内存索引中找到相应的值速度就越快，但是会消耗更多的内存。 　　</p></li></ol><h2 id="memtable设置"><a href="#memtable设置" class="headerlink" title="memtable设置"></a>memtable设置</h2><ol><li><code>memtable_heap_space_in_mb</code><br> (默认: 1/4 堆大小)<br> 设置在堆内存里分配的memtables的大小。Cassandra使用这个和memtable_offheap_space_in_mb的值总和来决定何时自动刷新memtables。</li><li><p><code>memtable_offheap_space_in_mb</code><br> (默认: 1/4堆大小)<br> 设置在堆外内存里分配的memtables大小。Cassandra使用这个和memtable_heap_space_in_mb的值总和来决定何时自动刷新memtable</p></li><li><p><code>memtable_flush_writers</code> 　　<br> memtable中的数据写入到磁盘成为SSTable文件的并发数, 这个选项的默认配置为data_file_directories中指定的目录的个数。 　　</p></li><li><code>sliced_buffer_size_in_kb</code>：进行范围读取操作时，读取SSTable文件使用的缓存大小。 </li></ol><h2 id="策略相关"><a href="#策略相关" class="headerlink" title="策略相关"></a>策略相关</h2><ol><li><p><code>commit_failure_policy</code>：(默认: stop)提交磁盘故障策略</p><ul><li>die：关闭gossip和Thrift，然后杀掉JVM进程，这样节点就可以被替换。</li><li>stop：关闭gossip和Thrift，使节点实际上死亡了，但是可以使用JMX检查。</li><li>stop_commit：关闭commit log，让写聚集，但继续提供读服务(就像Cassandra 2.0.5之前的版本)。</li><li>ignore：忽略致命错误，并让批失败。</li></ul></li><li><p><code>disk_optimization_strategy</code>：(默认: ssd)优化磁盘读取策略可以设置成固态硬盘或者旋转的。</p></li><li><p><code>disk_failure_policy</code>：(默认: stop)设置Cassandra如何响应磁盘故障。建议设置成stop或者best_effort。</p><ul><li>die：关闭gossip和Thrift，然后对于任何系统错误或者仅仅是SSTable错误，都杀掉JVM进程，这样节点就可以被替换。</li><li>stop_paranoid：关闭gossip和Thrift，即使仅仅是SSTable错误。</li><li>stop：关闭gossip和Thrift，让节点实际上死亡了，但是可以使用JVX检查。</li><li>best_effort：停止使用故障磁盘，然后基于剩余可用的SSTables来响应请求。这意味着你会在一致性级别为1的基础上看到过时的数据。</li><li>ignore：忽略致命错误，并允许请求失败；所有文件系统错误都会被记录，但是忽略。在Cassandra 1.2版本之前是这种情况</li></ul></li><li><p>endpoint_snitch：网络选择策略，选项：<br> 4.1. SimpleSnitch（默认）<br> 用于单数据中心部署或者公共云中的单个区域。不识别数据中心或者机架信息。它视策略顺序为接近，当忽略读修复时可以提高缓存局部性。<br> 4.2. GossipingPropertyFileSnitch<br> 建议生产使用。本地节点机架和数据中心定义在cassandra-rackdc.properties文件里，通过八卦协议传播到其他节点。<br> 为了便于从PropertyFileSnitch移植，它也使用cassandra-topology.properties，如果存在的话。<br> 4.3. PropertyFileSnitch<br> 决定于机架和数据中心的距离，这是明确的在cassandratopology.properties文件里配置的。<br> 4.4. 更多参考：<a href="http://blog.csdn.net/qq_32523587/article/details/53982900" target="_blank" rel="noopener">http://blog.csdn.net/qq_32523587/article/details/53982900</a></p></li><li><p>dynamic_snitch：是否启用动态的节点选择策略，相关的其他选项为：<br> 2.1. dynamic_snitch_update_interval_in_ms:<br> 2.2. dynamic_snitch_reset_interval_in_ms:<br> 2.3. dynamic_snitch_badness_threshold:</p></li><li><p>request_scheduler：资源调度分配策略 ，选项： 　　<br> 3.1. org.apache.cassandra.scheduler.NoScheduler，所有的请求分配的计算资源都是均等的（默认）。 　　<br> 3.2. org.apache.cassandra.scheduler.RoundRobinScheduler，对不同的Keyspace分配不同的计算资源（多租户的情况下适合）。 　　</p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--搭建单节点和集群</title>
      <link href="/2017/11/16/Cassandra-%E6%90%AD%E5%BB%BA%E5%8D%95%E8%8A%82%E7%82%B9%E5%92%8C%E9%9B%86%E7%BE%A4/"/>
      <url>/2017/11/16/Cassandra-%E6%90%AD%E5%BB%BA%E5%8D%95%E8%8A%82%E7%82%B9%E5%92%8C%E9%9B%86%E7%BE%A4/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲一下Cassandra的搭建，单节点和集群。都是一些操作和注意事项，没有什么难点，按照下面一步一步操作就行。该系列博客使用的目前最新的版本cassandra-3.11.1。</p><h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><ol><li>下载jdk1.8（Cassandra 3.0 and later require Java 8u40 or later.）：<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></li><li>下载Cassandar：<br><a href="http://www.apache.org/dyn/closer.lua/cassandra/3.11.1/apache-cassandra-3.11.1-bin.tar.gz" target="_blank" rel="noopener">http://www.apache.org/dyn/closer.lua/cassandra/3.11.1/apache-cassandra-3.11.1-bin.tar.gz</a></li></ol><a id="more"></a><h1 id="单节点安装"><a href="#单节点安装" class="headerlink" title="单节点安装"></a>单节点安装</h1><h2 id="安装JDK1-8"><a href="#安装JDK1-8" class="headerlink" title="安装JDK1.8"></a>安装JDK1.8</h2><ul><li>因为机器中已经安装了jdk1.7，现在还需要一个jdk1.8，所以打算重新使用一个cassandra用户，然后配置该用户环境变量为1.8<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo data]# tar -zxvf apache-cassandra-3.11.1-bin.tar.gz</span><br><span class="line">[root@xiaoxiaomo data]# ll</span><br><span class="line">total 17</span><br><span class="line">drwxr-xr-x  8 root root 4096 Nov  9 11:20 apache-cassandra-3.11.1</span><br><span class="line">[root@xiaoxiaomo data]# useradd cassandra ##添加用户</span><br><span class="line">[root@xiaoxiaomo data]# passwd cassandra</span><br></pre></td></tr></table></figure></li></ul><h2 id="上传解压"><a href="#上传解压" class="headerlink" title="上传解压"></a>上传解压</h2><ul><li>我们这里上传到/data目录，然后解压<code>tar -zxvf apache-cassandra-3.11.1-bin.tar.gz</code> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo data]# tar -zxvf apache-cassandra-3.11.1-bin.tar.gz</span><br><span class="line">[root@xiaoxiaomo data]# ll</span><br><span class="line">total 17</span><br><span class="line">drwxr-xr-x  8 root root 4096 Nov  9 11:20 apache-cassandra-3.11.1</span><br><span class="line">[root@xiaoxiaomo data]# chown -R cassandra:cassandra apache-cassandra-3.11.1</span><br><span class="line">[root@xiaoxiaomo data]# ll</span><br><span class="line">total 17</span><br><span class="line">drwxr-xr-x  8 cassandra cassandra 4096 Nov  9 11:27 apache-cassandra-3.11.1</span><br></pre></td></tr></table></figure></li></ul><h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><ul><li>切换到cassandra用户，加入java环境变量到~/.bashrc<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo data]# su cassandra</span><br><span class="line">[cassandra@xiaoxiaomo ~]$ vim ~/.bashrc  ##修改用户环境变量如下</span><br><span class="line"><span class="meta">#</span> .bashrc</span><br><span class="line"><span class="meta">#</span> Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">    . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line">export JAVA_HOME=/data/jdk1.8.0_151</span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[cassandra@xiaoxiaomo ~]$ source ~/.bashrc</span><br></pre></td></tr></table></figure></li></ul><h2 id="启动cassandra"><a href="#启动cassandra" class="headerlink" title="启动cassandra"></a>启动cassandra</h2><ul><li><p>通过<code>bin/cassandra</code>启动cassandra服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[cassandra@xiaoxiaomo apache-cassandra-3.11.1]$ ./bin/cassandra -f ##前台启动</span><br><span class="line">[cassandra@xiaoxiaomo apache-cassandra-3.11.1]$ ./bin/cassandra    ##后台启动</span><br></pre></td></tr></table></figure></li><li><p>启动日志<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra00.jpg" alt="cassandra启动日志"></p></li><li>集群节点状态，通过cassandra提供的<code>nodetool</code>命令<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra02.jpg" alt="cassandra节点状态"></li></ul><h2 id="配置cql运行环境"><a href="#配置cql运行环境" class="headerlink" title="配置cql运行环境"></a>配置cql运行环境</h2><ol><li><p>如果要运行cqlsh，<strong>需要python2.7即以上版本</strong><br>下载python(我下载的是2.7.14):<a href="https://www.python.org/ftp/python/" target="_blank" rel="noopener">https://www.python.org/ftp/python/</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[cassandra@xiaoxiaomo data]$ exit   ## 退回到root用户</span><br><span class="line">[root@xiaoxiaomo data]# tar -zxvf Python-2.7.14.tgz</span><br><span class="line">[root@xiaoxiaomo data]# cd Python-2.7.14</span><br><span class="line">[root@xiaoxiaomo Python-2.7.14]# ./configure --prefix=/usr/local/python2.7.14</span><br><span class="line">[root@xiaoxiaomo Python-2.7.14]#  make &amp;&amp; make install</span><br></pre></td></tr></table></figure></li><li><p><strong>配置python环境变量</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo Python-2.7.14]# ll /usr/local/python2.7.14/bin/</span><br><span class="line">total 6164</span><br><span class="line">-rwxr-xr-x 1 root root     115 Nov  9 14:43 2to3</span><br><span class="line">-rwxr-xr-x 1 root root     113 Nov  9 14:43 idle</span><br><span class="line">-rwxr-xr-x 1 root root      98 Nov  9 14:43 pydoc</span><br><span class="line">lrwxrwxrwx 1 root root       7 Nov  9 14:43 python -&gt; python2</span><br><span class="line">lrwxrwxrwx 1 root root       9 Nov  9 14:43 python2 -&gt; python2.7</span><br><span class="line">-rwxr-xr-x 1 root root 6273931 Nov  9 14:43 python2.7</span><br><span class="line">-rwxr-xr-x 1 root root    1701 Nov  9 14:43 python2.7-config</span><br><span class="line">lrwxrwxrwx 1 root root      16 Nov  9 14:43 python2-config -&gt; python2.7-config</span><br><span class="line">lrwxrwxrwx 1 root root      14 Nov  9 14:43 python-config -&gt; python2-config</span><br><span class="line">-rwxr-xr-x 1 root root   18561 Nov  9 14:43 smtpd.py</span><br><span class="line">[root@xiaoxiaomo Python-2.7.14]# su cassandra</span><br><span class="line">[cassandra@xiaoxiaomo Python-2.7.14]$ vim ~/.bashrc</span><br><span class="line">[cassandra@xiaoxiaomo apache-cassandra-3.11.1]$ cat ~/.bashrc </span><br><span class="line"><span class="meta">#</span> .bashrc</span><br><span class="line">​</span><br><span class="line"><span class="meta">#</span> Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">    . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line">​</span><br><span class="line">export JAVA_HOME=/data/jdk1.8.0_151</span><br><span class="line">export CASSANDRA_HOME=/data/apache-cassandra-3.11.1</span><br><span class="line">PATH=$JAVA_HOME/bin:$CASSANDRA_HOME/bin:/usr/local/python2.7.14/bin:$PATH</span><br><span class="line">[cassandra@xiaoxiaomo ~]$ source ~/.bashrc</span><br></pre></td></tr></table></figure></li></ol><h2 id="运行-cqlsh"><a href="#运行-cqlsh" class="headerlink" title="运行 cqlsh"></a>运行 cqlsh</h2><ul><li><code>cqlsh</code>，cassandra内置的交互命令，可以通过该命令操作cassandra<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[cassandra@xiaoxiaomo apache-cassandra-3.11.1]$ ./bin/cqlsh</span><br><span class="line">Connected to Test Cluster at 127.0.0.1:9042.</span><br><span class="line">[cqlsh 5.0.1 | Cassandra 3.11.1 | CQL spec 3.4.4 | Native protocol v4]</span><br><span class="line">Use HELP for help.</span><br><span class="line"><span class="meta">cqlsh&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h1><ol><li>如上步骤，在其他节点上创建用户，安装jdk、Cassandra、python</li><li>统一集群的名字</li><li>为每个节点分配一个IP</li><li>确定种子节点，不需要配置全部节点</li><li>如果是多数据中心，为每个数据中心和机架确定命名约定</li><li><p>操作<br> 6.1. 配置cassandra.yaml，cluster_name集群名称|-seeds种子节点IP|listen_address和rpc_address指定为节点IP<br> 6.2. 如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cluster_name: 'XXOCluster'</span><br><span class="line">seed_provider:</span><br><span class="line">    # Addresses of hosts that are deemed contact points. </span><br><span class="line">    # Cassandra nodes use this list of hosts to find each other and learn</span><br><span class="line">    # the topology of the ring.  You must change this if you are running</span><br><span class="line">    # multiple nodes!</span><br><span class="line">    - class_name: org.apache.cassandra.locator.SimpleSeedProvider</span><br><span class="line">      parameters:</span><br><span class="line">          # seeds is actually a comma-delimited list of addresses.</span><br><span class="line">          # Ex: "&lt;ip1&gt;,&lt;ip2&gt;,&lt;ip3&gt;"</span><br><span class="line">          - seeds: "10.141.5.27"</span><br><span class="line">listen_address: 10.141.5.27</span><br><span class="line">rpc_address: 10.141.5.27</span><br></pre></td></tr></table></figure><p> 6.3. 启动节点，优先启动种子节点，能看到其他节点和种子节点的一些通信<br> <img src="https://img.xiaoxiaomo.com/blog/img/cassandra03.jpg" alt=""><br> 6.4. 查看节点机群状态<br> <img src="https://img.xiaoxiaomo.com/blog/img/cassandra04.jpg" alt=""></p></li></ol><h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><ol><li><p><strong>备注</strong>： <strong>无法添加用户</strong>，运行：<code>useradd cassandra</code>，提示：<code>useradd: cannot open /etc/passwd</code><br>（线上环境：一般限制了某些文件的改动，此时我们需要修改一下文件属性）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>##查看文件属性</span><br><span class="line">[root@xiaoxiaomo data]# lsattr /etc/passwd</span><br><span class="line">----i--------e- /etc/group</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>##修改文件属性</span><br><span class="line">[root@xiaoxiaomo data]# chattr -i /etc/passwd</span><br><span class="line">[root@xiaoxiaomo data]# chattr -i /etc/group</span><br><span class="line">[root@xiaoxiaomo data]# chattr -i /etc/shadow</span><br><span class="line">[root@xiaoxiaomo data]# chattr -i /etc/gshadow</span><br></pre></td></tr></table></figure></li><li><p>参考：<br><a href="http://cassandra.apache.org/doc/latest/getting_started/installing.html" target="_blank" rel="noopener">http://cassandra.apache.org/doc/latest/getting_started/installing.html</a></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cassandra--概述与相关介绍</title>
      <link href="/2017/11/15/Cassandra-%E6%A6%82%E8%BF%B0%E4%B8%8E%E7%9B%B8%E5%85%B3%E4%BB%8B%E7%BB%8D/"/>
      <url>/2017/11/15/Cassandra-%E6%A6%82%E8%BF%B0%E4%B8%8E%E7%9B%B8%E5%85%B3%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p>　　<code>Apache Cassandra</code><strong>是一套开源分布式NoSQL数据库系统</strong>，Facebook于2008开源，目前最新版本<a href="http://cassandra.apache.org/download/" target="_blank" rel="noopener">3.11.1</a>。<strong>架构设计主要由亚马逊的Dynamo与Google 的BigTable两部分组成</strong>。</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><ul><li><a href="http://cassandra.apache.org/" target="_blank" rel="noopener">Apache Cassandra </a><strong>是一个高可靠的大规模分布式存储系统。高度可伸缩的、高可用性、分布式的结构化key-value存储方案</strong>。在CAP理论中Cassandra主要是AP（可用性和分区容错性），<strong>分区容错性基于一致性哈希环（Consistent Hash Ring）算法实现的</strong>。<br>更多CAP相关内容可参考：<a href="http://blog.javachen.com/2014/05/30/note-about-brewers-cap-theorem.html" target="_blank" rel="noopener">http://blog.javachen.com/2014/05/30/note-about-brewers-cap-theorem.html</a><a id="more"></a><img src="https://img.xiaoxiaomo.com/blog/img/cassandra-cpa.gif" alt="Cassandra cpa"> </li></ul><h1 id="Cassandra相关概念"><a href="#Cassandra相关概念" class="headerlink" title="Cassandra相关概念"></a>Cassandra相关概念</h1><ul><li><strong>Cassandra 每个节点都是独立的，都可以接受读取和写入请求</strong><blockquote><p>Cluster：逻辑上的概念，其实就是多个节点Node（无中心），可以跨数据中心。<br>DataCenter ：数据中心，可以理解为是一个机房，包含多个Rack<br>Rack ： 机架，机架上包含多个节点Node<br>Node ： 节点，可以理解为机器<br>提交日志 ： 提交日志，是Cassandra中的崩溃恢复机制。每个写操作都写入提交日志。<br>Mem-表 ： mem-表，内存中的的数据结构。提交日志后，数据将被写入mem表。有时，对于单列族，将有多个mem表。<br>SSTable ： 它是一个磁盘文件，当其内容达到阈值时，数据从mem表中刷到磁盘。</p></blockquote></li></ul><h1 id="键空间KeySpace"><a href="#键空间KeySpace" class="headerlink" title="键空间KeySpace"></a>键空间KeySpace</h1><ul><li>keyspace类是于SQL的数据库database，但也有些不同，<strong>cassandra它还定义了数据的复制策略(副本放置策略和所需副本的数量)</strong>。<br>创建keysace的时候可以指定两个属性：replication和durable_writes<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> KEYSPACE keyspaceName <span class="keyword">WITH</span> <span class="keyword">replication</span> = &#123;<span class="string">'class'</span>: <span class="string">'SimpleStrategy'</span>,<span class="string">'replication_factor'</span>:<span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">create</span> KEYSPACE keyspaceName <span class="keyword">WITH</span> <span class="keyword">replication</span>=&#123;<span class="string">'class'</span>: <span class="string">'NetworkTopologyStrategy'</span>,<span class="string">'datacenter1'</span>:<span class="number">2</span>&#125; </span><br><span class="line">    ... <span class="keyword">AND</span> DURABLE_WRITES = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure></li></ul><h1 id="Replication-副本"><a href="#Replication-副本" class="headerlink" title="Replication 副本"></a>Replication 副本</h1><p><code>Replication：副本位置策略与副本的数量</code>，<strong>即存储数据到多个节点来保证可靠性和出错容忍性</strong></p><h2 id="副本数量"><a href="#副本数量" class="headerlink" title="副本数量"></a>副本数量</h2><p><strong>也叫副本因子，这个就是决定有多少份副本</strong>，比如如果设置为1，则表示每一行只有一个副本，所有的副本地位都是相等的（和kafka类似）。</p><h2 id="副本放置策略"><a href="#副本放置策略" class="headerlink" title="副本放置策略"></a>副本放置策略</h2><p>表示该keyspace的副本如何放置在集群中，keyspace有两种策略：<code>SimpleStrategy</code>和<code>NetworkTopologyStrategy</code></p><ol><li><p><strong>SimpleStrategy 简单策略</strong><br>默认副本放置策略，该模式下需要指定复制策略和副本因子,如下面指定2份副本:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> KEYSPACE demodb <span class="keyword">WITH</span> <span class="keyword">replication</span> = &#123;<span class="string">'class'</span>: <span class="string">'SimpleStrategy'</span>, <span class="string">'replication_factor'</span>: <span class="number">2</span>&#125;;</span><br></pre></td></tr></table></figure></li><li><p><strong>NetworkTopologyStrategy 网络拓扑策略</strong><br>这种策略用于当你知道节点如何在数据中心(Data Center)分组的情况或者你希望部署集群横跨多个数据中心，此时你必须指定每个数据中心要多少个副本。在这种情况下，副本放置策略由数据中心自己决定<br>创建代码如下:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> KEYSPACE demodb <span class="keyword">WITH</span> <span class="keyword">REPLICATION</span> = &#123; <span class="string">'class'</span> : <span class="string">'NetworkTopologyStrategy'</span>, <span class="string">'dc1'</span> :<span class="number">3</span> &#125;;</span><br></pre></td></tr></table></figure></li></ol><h1 id="列族（Column-Families）"><a href="#列族（Column-Families）" class="headerlink" title="列族（Column Families）"></a>列族（Column Families）</h1><ul><li>列族是列的容器</li><li>Cassandra 数据模型包括列、行、列族和间空间 (keyspace)<br><img src="https://img.xiaoxiaomo.com/blog/img/cassandra35.gif" alt="列族（Column Families）"> </li></ul><ol><li><p><strong>列</strong>：Cassandra 数据模型中最基本的单元，每一个列包括一个名称、一个值和一个时间戳。<br>（例如 name=”zhangsan”，暂忽略时间戳）。</p></li><li><p><strong>行</strong>：用一个名称标记的列的集合，可以把这个列名称叫做行键（rowKey）<br>（例如 “rowName”-&gt;{id=”34”,name=”zhangsan”,age=”25”}）<br>cassandra节点中，存储了每一行数据，按照行键排序，更具这种排序，我们就可以通过切片查询</p></li><li><p><strong>列族</strong>：用一个名称标记的行的集合<br>（例如 famliyName-&gt;{“rowName1”-&gt;{id=16,name=”zs”},”rowName1”-&gt;{id=17,name=”ls”）</p></li></ol><ul><li>参考：<br><a href="https://www.ibm.com/developerworks/cn/opensource/os-apache-cassandra/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-apache-cassandra/index.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cassandra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战七上线运行</title>
      <link href="/2017/09/08/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%83%E4%B8%8A%E7%BA%BF%E8%BF%90%E8%A1%8C/"/>
      <url>/2017/09/08/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%83%E4%B8%8A%E7%BA%BF%E8%BF%90%E8%A1%8C/</url>
      <content type="html"><![CDATA[<p>　　本篇文章就是该系列的最后一篇文章了，<strong>来的有点晚</strong>。本来计划这篇文章是和之前的几篇文章一起发布的，由于那个周末两天时间连续写了好几篇写的有点累了（也比较晚了）最后这篇还没写完，所以就只发布了前面的六篇。<br>主要说一下线上部署的事儿，以及说一下最后的一些改动和优化吧。</p><h2 id="最后的小BUG"><a href="#最后的小BUG" class="headerlink" title="最后的小BUG"></a>最后的小BUG</h2><ul><li>这个是一个什么问题呢？就是<strong>一个官网所说的登陆失败的问题</strong>，当然他们早已更新，只是我们的二次开发是基于8月1号左右的所以我们的static模块还是之前的代码。<ul><li>就导致苹果内置的浏览器，还有其他版本的google浏览器无法登陆。</li><li>为啥快上线了才发现呢？因为我自己开发测试都没事儿，使用的google版本56.0.2924.87 (64-bit)</li><li><strong>这个只需要把最新的static模块代码下载下来替换即可解决</strong><a id="more"></a><img src="https://img.xiaoxiaomo.com/blog/img/owl100.jpg" alt="owl commits"></li></ul></li></ul><h2 id="样式的小改动"><a href="#样式的小改动" class="headerlink" title="样式的小改动"></a>样式的小改动</h2><ol><li><p>虽然owl的css，js做了一下压缩，logo做了一些加密在里面，但想改动还是可以的<br><img src="https://img.xiaoxiaomo.com/blog/img/owl98.jpg" alt="owl 架构图"></p></li><li><p>可以通过google浏览器还原css如下，js同样也是很清楚了（<strong>需要改代码，就拷贝下面格式好的代码修改即可</strong>）<br><img src="https://img.xiaoxiaomo.com/blog/img/owl97.jpg" alt="owl 架构图"></p></li></ol><h2 id="最后的优化"><a href="#最后的优化" class="headerlink" title="最后的优化"></a>最后的优化</h2><ul><li><p><strong>原由</strong>：如果认真看过<a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%BA%94%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/">实战五二次开发</a>就会发现一个可以优化的点</p><ul><li>用户下面的进程是不定的，所以后面想保存一个总值是有误差的，最后解决是保存了pid级别的metric信息<br><img src="https://img.xiaoxiaomo.com/blog/img/owl94.jpg" alt="owl 架构图"></li><li>虽然问题是解决了，也能正常运行，就是导致<code>metrics</code>数量有点大，作为一个监控系统是我们不想看到的（IO是很珍贵的资源！）</li></ul></li><li><p><strong>优化改造</strong></p><ol><li>目的（最优结果）就是保存用户维度的数据，不保存所有进程级别的数据</li><li>为什么我们要去保存进程级别的数据？因为有进程差异情况</li><li>那为什么保存进程级别的数据就没有差异的情况了呢？因为我们的metric就是进程级别的，在<code>agent.go</code>里面可以看出，他是把上一次的数据metrics记录了下来，如果查询不到上一次的记录，该流程下面就不会被执行，即差异的结果就会被过滤。</li><li><strong>我们要保存用户级别的数据，那就把这个差异的结果去掉（自己做缓存保存上一次的结果，然后做减法不就行了）</strong></li></ol></li><li><p><strong>具体实现</strong></p><ol><li><p><strong>一个线程安全的Map，用来做缓存保存上一次的结果。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">var pidDataHis =  newThreadSafeMap()<span class="comment">//pid 上一次的历史数据,KEY:PID+唯一NAME值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程安全的map</span></span><br><span class="line">type threadSafeMap struct &#123;</span><br><span class="line">sync.RWMutex</span><br><span class="line">Map map[string]uint64</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">func <span class="title">newThreadSafeMap</span><span class="params">()</span> *threadSafeMap </span>&#123;</span><br><span class="line">tsMap := <span class="keyword">new</span>(threadSafeMap)</span><br><span class="line">tsMap.Map = make(map[string]uint64)</span><br><span class="line"><span class="keyword">return</span> tsMap</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (tsMap *threadSafeMap) read(key string) (uint64,bool) &#123;</span><br><span class="line">tsMap.RLock()</span><br><span class="line">value , ok := tsMap.Map[key]</span><br><span class="line">tsMap.RUnlock()</span><br><span class="line"><span class="keyword">return</span> value,ok</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (tsMap *threadSafeMap) write(key string, value uint64) &#123;</span><br><span class="line">tsMap.Lock()</span><br><span class="line">tsMap.Map[key] = value</span><br><span class="line">tsMap.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>提供一个方法，该方法就获取该时间和上一次时间值的差值</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pid + uuid：组成Map 的 key ，保证唯一性</span></span><br><span class="line"><span class="comment">// currValue：当前值</span></span><br><span class="line"><span class="function">func <span class="title">GetDValue</span><span class="params">( pid string,  uuid string, currValue uint64 )</span> <span class="params">(uint64,bool)</span> </span>&#123;</span><br><span class="line">history, ok := pidDataHis.read(pid+uuid)</span><br><span class="line">pidDataHis.write(pid+uuid, currValue)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="keyword">return</span> currValue - history , ok</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span> , <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>我们在处理值得时候就可以直接获取差值就行（调用上面的方法）</strong></p></li><li><p>然后就把结果放入到openTSDB了，但是DataType写什么呢？<strong>我们已经处理成一个结果了，最终的数据只需要：结果值/Cycle就行，但是并没有我们需要的。只有三种</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/owl93.jpg" alt="DataType"></p></li><li><p><strong>我们就增加一种DataType呗，取名为<code>REDUCE</code></strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="string">"REDUCE"</span>, <span class="string">"reduce"</span>:</span><br><span class="line">    tsd.Value = tsd.Value  / <span class="keyword">float64</span>(tsd.Cycle)</span><br></pre></td></tr></table></figure></li><li><p>增加了DataType，<strong>MySQL里面也得对应修改一下</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE `metric`</span><br><span class="line">  CHANGE COLUMN `dt` `dt` ENUM(&apos;GAUGE&apos;,&apos;DERIVE&apos;,&apos;COUNTER&apos;,&apos;REDUCE&apos;) NOT NULL COLLATE &apos;utf8_unicode_ci&apos; AFTER `name`;</span><br><span class="line">SET FOREIGN_KEY_CHECKS = 1;</span><br></pre></td></tr></table></figure></li></ol></li></ul><h2 id="数据初始化（清除数据）"><a href="#数据初始化（清除数据）" class="headerlink" title="数据初始化（清除数据）"></a>数据初始化（清除数据）</h2><ul><li>在自己测试的时候，或者线上的环境由于之前的问题，然后进行了改动，留了太多无效的metric。</li><li>个人有点强迫症，打算清掉之前的数据，步骤就是清除MySQ和HBase的数据。</li></ul><ol><li><p>清除MySQ数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use owl</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; source /usr/local/src/owl/scripts/db_schema/owl.sql;</span><br><span class="line">####插入默认管理员用户</span><br><span class="line">mysql&gt; INSERT INTO `user` (username, password, role, phone, mail, weixin, status) VALUES (&apos;admin&apos;, &apos;21232f297a57a5a743894a0e4a801fc3&apos;, &apos;1&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;1&apos;);</span><br><span class="line"></span><br><span class="line">#####记得添加我们新增的DataType</span><br><span class="line">ALTER TABLE `metric`</span><br><span class="line">  CHANGE COLUMN `dt` `dt` ENUM(&apos;GAUGE&apos;,&apos;DERIVE&apos;,&apos;COUNTER&apos;,&apos;REDUCE&apos;) NOT NULL COLLATE &apos;utf8_unicode_ci&apos; AFTER `name`;</span><br><span class="line">SET FOREIGN_KEY_CHECKS = 1;</span><br></pre></td></tr></table></figure></li><li><p>清除HBase数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">### 就是删了，重建</span><br><span class="line">disable &apos;tsdb-uid&apos;</span><br><span class="line">disable &apos;tsdb&apos;</span><br><span class="line">disable &apos;tsdb-tree&apos;</span><br><span class="line">disable &apos;tsdb-meta&apos;</span><br><span class="line"></span><br><span class="line">drop &apos;tsdb-uid&apos;</span><br><span class="line">drop &apos;tsdb&apos;</span><br><span class="line">drop &apos;tsdb-tree&apos;</span><br><span class="line">drop &apos;tsdb-meta&apos;</span><br><span class="line"></span><br><span class="line">create &apos;tsdb-uid&apos;,</span><br><span class="line">  &#123;NAME =&gt; &apos;id&apos;, COMPRESSION =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;&#125;,</span><br><span class="line">  &#123;NAME =&gt; &apos;name&apos;, COMPRESSION =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;&#125;</span><br><span class="line">create &apos;tsdb&apos;,</span><br><span class="line">  &#123;NAME =&gt; &apos;t&apos;, VERSIONS =&gt; 1, COMPRESSION =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;&#125;</span><br><span class="line">create &apos;tsdb-tree&apos;,</span><br><span class="line">  &#123;NAME =&gt; &apos;t&apos;, VERSIONS =&gt; 1, COMPRESSION =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;&#125;</span><br><span class="line">create &apos;tsdb-meta&apos;,</span><br><span class="line">  &#123;NAME =&gt; &apos;name&apos;, COMPRESSION =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>注意</strong><br>如果openTSDB还在运行，owl等服务还在写入数据的时候去做数据清理（删表等操作），<strong>会报如下错误</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">18</span>:<span class="number">20</span>:<span class="number">42.819</span> ERROR [CompactionQueue.call] - Failed to read a row to re-compact</span><br><span class="line">org.hbase.async.TableNotFoundException: <span class="string">"tsdb"</span></span><br><span class="line">        at org.hbase.async.HBaseClient$<span class="number">7</span>.call(HBaseClient.java:<span class="number">2315</span>) ~[asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.hbase.async.HBaseClient$<span class="number">7</span>.call(HBaseClient.java:<span class="number">2312</span>) ~[asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at com.stumbleupon.async.Deferred.doCall(Deferred.java:<span class="number">1278</span>) [async-<span class="number">1.4</span>.0.jar:na]</span><br><span class="line">        at com.stumbleupon.async.Deferred.runCallbacks(Deferred.java:<span class="number">1257</span>) [async-<span class="number">1.4</span>.0.jar:na]</span><br><span class="line">        at com.stumbleupon.async.Deferred.callback(Deferred.java:<span class="number">1005</span>) [async-<span class="number">1.4</span>.0.jar:na]</span><br><span class="line">        at org.hbase.async.HBaseRpc.callback(HBaseRpc.java:<span class="number">698</span>) [asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.hbase.async.RegionClient.decode(RegionClient.java:<span class="number">1509</span>) [asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.hbase.async.RegionClient.decode(RegionClient.java:<span class="number">88</span>) [asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:<span class="number">500</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:<span class="number">435</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.hbase.async.RegionClient.handleUpstream(RegionClient.java:<span class="number">1206</span>) [asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.SimpleChannelHandler.messageReceived(SimpleChannelHandler.java:<span class="number">142</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:<span class="number">88</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.handler.timeout.IdleStateAwareChannelHandler.handleUpstream(IdleStateAwareChannelHandler.java:<span class="number">36</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.handler.timeout.IdleStateHandler.messageReceived(IdleStateHandler.java:<span class="number">294</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">559</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.hbase.async.HBaseClient$RegionClientPipeline.sendUpstream(HBaseClient.java:<span class="number">3108</span>) [asynchbase-<span class="number">1.7</span>.0.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">268</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">255</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:<span class="number">88</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:<span class="number">108</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:<span class="number">318</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:<span class="number">89</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:<span class="number">178</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:<span class="number">108</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at org.jboss.netty.util.internal.DeadLockProofWorker$<span class="number">1</span>.run(DeadLockProofWorker.java:<span class="number">42</span>) [netty-<span class="number">3.9</span>.4.Final.jar:na]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>) [na:<span class="number">1.8</span>.0_141]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>) [na:<span class="number">1.8</span>.0_141]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">748</span>) [na:<span class="number">1.8</span>.0_141]</span><br></pre></td></tr></table></figure></li></ol><ul><li>所以我们在做数据清楚的时候最好关掉服务，如果不想关掉服务记得做完初始化操作后回来重启一下openTSDB(有可能你获取不到数据了,因为<code>HBaseClient: Lost connection with the .META. region</code>)<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2017-09-07 18:25:37,220 INFO  [AsyncHBase I/O Worker #13] HBaseClient: Closing idle connection to HBase region server: [id: 0xe8cfafdd, /10.134.81.55:34726 =&gt; /10.134.81.48:16020]</span><br><span class="line">2017-09-07 18:25:37,220 INFO  [AsyncHBase I/O Worker #13] HBaseClient: Channel [id: 0xe8cfafdd, /10.134.81.55:34726 =&gt; /10.134.81.48:16020] is disconnecting: [id: 0xe8cfafdd, /10.134.81.55:34726 =&gt; /10.134.81.48:16020] CLOSE</span><br><span class="line">2017-09-07 18:25:55,720 INFO  [AsyncHBase I/O Worker #17] HBaseClient: Closing idle connection to HBase region server: [id: 0x33948b1b, /10.134.81.55:39507 =&gt; /10.134.81.52:16020]</span><br><span class="line">2017-09-07 18:25:55,720 INFO  [AsyncHBase I/O Worker #17] HBaseClient: Channel [id: 0x33948b1b, /10.134.81.55:39507 =&gt; /10.134.81.52:16020] is disconnecting: [id: 0x33948b1b, /10.134.81.55:39507 =&gt; /10.134.81.52:16020] CLOSE</span><br><span class="line">2017-09-07 18:25:55,721 INFO  [AsyncHBase I/O Worker #17] HBaseClient: Lost connection with the .META. region</span><br></pre></td></tr></table></figure></li></ul><h2 id="上线部署"><a href="#上线部署" class="headerlink" title="上线部署"></a>上线部署</h2><ol><li><p><strong>上线的规划</strong>，<strong>因为线上机器目前大约200台，当时每台机器的metrics约13万（当然后面优化后约1000），单个repeater写入：200*13万=2000多万呢</strong></p></li><li><p>所以单节点肯定是不行的，通过之前的结构图以及阅读代码后理解下图红圈的都<strong>可以做成集群的模式</strong></p><ul><li><img src="https://img.xiaoxiaomo.com/blog/img/owl99.jpg" alt="owl 架构图"></li><li>api也是可以多节点，owl作者说后面补上auto_build_index只需一台设置为true</li><li>部署方式一对一（同一机器同时部署他们）<code>openTSDB/repeater/inspector/api</code></li><li>考虑到后期还有更多的metric收集，以及节点的增加，<code>openTSDB/repeater/inspector/api</code>在6台服务器上都部署</li><li>HBase使用的之前的集群（10多个节点）</li></ul></li><li><p><strong>配置文件</strong>（<code>openTSDB/repeater/inspector/api</code>指定为127.0.0.1，<code>agent</code>自定义配置分发）</p><ul><li>openTSDB 6个节点的配置文件都一样，只需设置<code>tsd.storage.hbase.zk_quorum</code></li><li><p>repeater repeater.conf，opentsdb_addr指定为本服务器的opentsdb</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">backend=opentsdb</span><br><span class="line">tcp_bind=0.0.0.0:10040</span><br><span class="line"></span><br><span class="line">opentsdb_addr=127.0.0.1:4242</span><br><span class="line">repeater_addr=</span><br><span class="line"></span><br><span class="line">max_packet_size=4096</span><br><span class="line">buffer_size=1048576</span><br></pre></td></tr></table></figure></li><li><p>inspector inspector.conf 指定controller地址，本地的openTSDB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">controller_addr=10.xx.xx.xx:10050</span><br><span class="line"></span><br><span class="line">max_packet_size=40960</span><br><span class="line">max_task_buffer=4096</span><br><span class="line">max_result_buffer=4096</span><br><span class="line">worker_count=5</span><br><span class="line"></span><br><span class="line">tsdb_addr=127.0.0.1:4242</span><br><span class="line">tsdb_timeout=30</span><br></pre></td></tr></table></figure></li><li><p>api api.conf 指定MySQL地址，本地的openTSDB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">http_bind=0.0.0.0:10060</span><br><span class="line"></span><br><span class="line">mysql_addr=10.xx.xx.xx:3306</span><br><span class="line">mysql_user=user</span><br><span class="line">mysql_dbname=owl</span><br><span class="line">mysql_password=pass</span><br><span class="line">mysql_max_conn=20</span><br><span class="line">mysql_max_idle_conn=5</span><br><span class="line"></span><br><span class="line">secret_key=b690dfddeb13156b6b88xxxxxxxxxxxxx3df1d285576e843c8zzzzzzzzzzzzz</span><br><span class="line"></span><br><span class="line">opentsdb_addr=127.0.0.1:4242</span><br><span class="line">opentsdb_timeout=10</span><br><span class="line"></span><br><span class="line">auto_build_metric_tag_index=false|true【自己注意配置】</span><br><span class="line">auto_build_interval=10</span><br></pre></td></tr></table></figure></li><li><p>agent agent.conf，opentsdb_addr指定为需要分发到的opentsdb服务器地址，cfc地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tcp_bind=127.0.0.1:10010</span><br><span class="line"></span><br><span class="line">cfc_addr=10.xx.xx.xx:10020</span><br><span class="line">repeater_addr=10.xx.zz.yy:10040</span><br><span class="line"></span><br><span class="line">buffer_size=1000000</span><br><span class="line">max_packet_size=4096</span><br><span class="line">update_pid_len=86400</span><br><span class="line">network_card=bond0</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>日志级别的配置</strong>，按照需求设置吧，我们调通后设置的为4</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#日志设置</span><br><span class="line">#Emergency    -&gt; 0</span><br><span class="line">#Alert        -&gt; 1</span><br><span class="line">#Critical     -&gt; 2</span><br><span class="line">#Error        -&gt; 3</span><br><span class="line">#Warning      -&gt; 4</span><br><span class="line">#Notice       -&gt; 5</span><br><span class="line">#Info         -&gt; 6</span><br><span class="line">#Debug        -&gt; 7</span><br></pre></td></tr></table></figure></li><li><p>因为api我们也设置了6个实例，所以在<strong>nginx那边就要做一下反向代理</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/owl96.jpg" alt="nginx 反向代理"></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
            <tag> OpenTSDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战六插件开发</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E5%85%AD%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E5%85%AD%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/</url>
      <content type="html"><![CDATA[<p>　　该篇博客主要讲解：</p><ol><li>开发owl插件的思路</li><li>开发一个Hadoop的owl插件的思路</li><li>Hadoop owl插件的具体实现</li></ol><h2 id="监控系统实战七插件开发"><a href="#监控系统实战七插件开发" class="headerlink" title="监控系统实战七插件开发"></a>监控系统实战七插件开发</h2><a id="more"></a><h3 id="开发owl插件的思路"><a href="#开发owl插件的思路" class="headerlink" title="开发owl插件的思路"></a>开发owl插件的思路</h3><ol><li><p>写插件之前，先看一看owl里面已有的插件代码，看明白了就可以写自己的插件了<br> <img src="https://img.xiaoxiaomo.com/blog/img/owl41.jpg" alt="owl插件"></p></li><li><p>下面以check_mysql为例，看看源码：</p><ul><li><p>main.go 主要就是组装参数，然后调用<code>FetchData</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">app := cli.NewApp()</span><br><span class="line">app.Name = <span class="string">"check_mysql"</span></span><br><span class="line">app.Version = <span class="string">"0.1"</span></span><br><span class="line">app.Usage = <span class="string">"mysql performance metric collector"</span></span><br><span class="line">app.Authors = []cli.Author&#123;</span><br><span class="line">cli.Author&#123;</span><br><span class="line">Name:  <span class="string">"yingsong"</span>,</span><br><span class="line">Email: <span class="string">"wyingsong@163.com"</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line">app.Copyright = <span class="string">"2011 (c) TalkingData.com"</span></span><br><span class="line">app.Flags = []cli.Flag&#123;</span><br><span class="line">cli.StringFlag&#123;</span><br><span class="line">Name:        <span class="string">"host"</span>,</span><br><span class="line">Value:       <span class="string">"127.0.0.1"</span>,</span><br><span class="line">Usage:       <span class="string">"Connect to host."</span>,</span><br><span class="line">EnvVar:      <span class="string">"mysql_host"</span>,</span><br><span class="line">Destination: &amp;host,</span><br><span class="line">&#125;,</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125;</span><br><span class="line">app.Action = FetchData</span><br><span class="line">app.Run(os.Args)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>mysql.go 就是组装Metric信息<br><img src="https://img.xiaoxiaomo.com/blog/img/owl39.jpg" alt="mysql插件"></p></li><li>key.go 就是定义具体的实体类型</li></ul></li><li><p>看完代码后，大概知道怎么写了，然后运行起来看看效果</p></li></ol><ul><li><p>插件怎么运行？</p><ul><li>进入插件目录然后<code>go build</code>，会出来一个可执行的文件，然后放入到指定目录(agent执行文件同级的plugins/目录下)就okay.<br><img src="https://img.xiaoxiaomo.com/blog/img/owl42.jpg" alt="插件存放位置"></li></ul></li><li><p>具体的调用和插件metrics的输出在agent task.go里面<br> <img src="https://img.xiaoxiaomo.com/blog/img/owl40.jpg" alt=""></p></li></ul><h3 id="Hadoop插件的思路"><a href="#Hadoop插件的思路" class="headerlink" title="Hadoop插件的思路"></a>Hadoop插件的思路</h3><h4 id="常见的Hadoop监控平台"><a href="#常见的Hadoop监控平台" class="headerlink" title="常见的Hadoop监控平台"></a>常见的Hadoop监控平台</h4><ul><li>常见的发行版<code>CDH</code>，监控管理平台<code>cloudera manager</code>，或则Ganglia等。就展示了各种信息（内存，cpu…）</li><li><strong>所以Hadoop平台的信息，肯定是可以采集的</strong>。我们要做的就是和它一样，<code>做一个属于自己的cloudera manager</code><br><img src="https://img.xiaoxiaomo.com/blog/img/owl47.jpg" alt=""></li></ul><h4 id="收集的方式"><a href="#收集的方式" class="headerlink" title="收集的方式"></a>收集的方式</h4><ul><li>怎么收集hadoop平台的metrics信息？有两种方式</li></ul><ol><li><p>通过实现接口方式，然后重写<code>putMetrics</code>等方法，就像源码中的FileSink,Ganglia等</p><ul><li>下图示例是写入文件，我们要做的就是写入到opentsdb里面就行</li><li><img src="https://img.xiaoxiaomo.com/blog/img/owl48.jpg" alt=""></li><li>写完后打包成jar，放到hadoop平台。然后修改metrics2配置文件</li><li><img src="https://img.xiaoxiaomo.com/blog/img/owl49.jpg" alt=""></li></ul></li><li><p>通过jmx信息收集平台信息</p><ul><li>一般地址是<strong><a href="http://ip:port/jmx" target="_blank" rel="noopener">http://ip:port/jmx</a></strong>，比如NameNode服务jmx信息：</li><li><img src="https://img.xiaoxiaomo.com/blog/img/owl50.jpg" alt=""></li></ul></li></ol><ul><li>上面两种方式选择哪一种？第一种方式直接写入到opentsdb但是还得去维护一下owl MySQL的元数据信息，第二种方式直接写插件收集就行，下面的示例选择的是第二中方式。</li></ul><h4 id="jmx数据的解析"><a href="#jmx数据的解析" class="headerlink" title="jmx数据的解析"></a>jmx数据的解析</h4><ol><li><p>我们可以看见jmx是一个超级大的json，仅仅DataNode就有40个items，而且每一个json不是那么有规律。<br><img src="https://img.xiaoxiaomo.com/blog/img/owl51.jpg" alt=""></p></li><li><p>我把全部json看了一遍，发现并不是所有都是我们需要的数据，像下面这种即使解析后放入到owl也是没有意义的，没法计算！<br><img src="https://img.xiaoxiaomo.com/blog/img/owl52.jpg" alt=""></p></li><li><p>我们只需要解析出我们想要的数据就行，就这样开发了一个自己的<code>cloudera manager</code><br><img src="https://img.xiaoxiaomo.com/blog/img/owl56.jpg" alt=""></p></li><li><p>于是可以通过定义一些模板的方式，去获取想要的数据。</p><ul><li>因为发现<code>modelerType</code>是唯一的，模板中我们就可以通过该值去json中匹配，然后解析对应的json</li><li>解析对应的json，我们也可以定义成一个实体出来，而且还可以在里面赛选需要的字段</li></ul></li><li><p>最终的数据是要转换成metrics结构的数据</p><ul><li>metrics name ：我们也需要定义出来一个通用的规则，方便统一管理和代码的编写</li><li>metrics type ：我们也要考虑到每一个字段统计的方式不同，的和字段绑定在一起，所以可以定义到上面json解析的字段实体中</li><li>metrics tags ：这个我们可以获取json中，jsonK以“tag.”开头的数据</li><li>metrics value：这个得考虑到hadoop平台中的一些单位的统一，有GB、MB、纳秒等</li></ul></li></ol><h3 id="具体的实现"><a href="#具体的实现" class="headerlink" title="具体的实现"></a>具体的实现</h3><h4 id="结构体的定义"><a href="#结构体的定义" class="headerlink" title="结构体的定义"></a>结构体的定义</h4><ol><li>结构肯定是一个map结构的（modelerType，json字段对应的实体）：map[string]interface{}</li><li>json字段对应的实体（json字段，metrics type）最终结构：map[string]map[string]string<br><img src="https://img.xiaoxiaomo.com/blog/img/owl53.jpg" alt=""></li><li>发现实体代码有点多copy麻烦，自己写了一个工具类生成的代码，<code>metrics type</code>在源码里面都有具体的类型可以参考。</li></ol><h4 id="http请求与json转换"><a href="#http请求与json转换" class="headerlink" title="http请求与json转换"></a>http请求与json转换</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// http get请求</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">httpGet</span><span class="params">(url <span class="keyword">string</span>)</span> <span class="params">(*simplejson.Json, error)</span></span> &#123;</span><br><span class="line">resp, err := http.Get(url)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">logs.Error(<span class="string">"http get请求异常"</span>,err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span> , err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> resp.Body.Close()</span><br><span class="line"><span class="keyword">return</span> simplejson.NewFromReader(resp.Body)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取beans</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getMap</span><span class="params">(url <span class="keyword">string</span>)</span> []<span class="title">map</span>[<span class="title">string</span>]<span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">json, err := httpGet(url)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">logs.Error(<span class="string">"获取beans失败"</span>,err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">beans, err := json.Get(<span class="string">"beans"</span>).Array()</span><br><span class="line">maps := <span class="built_in">make</span>([]<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;, <span class="built_in">len</span>(beans))</span><br><span class="line"><span class="keyword">for</span> i,_ := <span class="keyword">range</span> beans  &#123;</span><br><span class="line">mapInfo, err := json.Get(<span class="string">"beans"</span>).GetIndex(i).Map()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">logs.Error(<span class="string">"beans转map异常"</span>,err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">maps[i] = mapInfo</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> maps</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解析数据"><a href="#解析数据" class="headerlink" title="解析数据"></a>解析数据</h4><ul><li><p>通过定义的<code>modelerType</code>去匹配json的字段value</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strings.HasPrefix(maps[<span class="string">"modelerType"</span>].(<span class="keyword">string</span>),prefix)</span><br></pre></td></tr></table></figure></li><li><p>解析jmx tags</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    metrics: &#123;</span></span><br><span class="line"><span class="comment">        metric:prefix.map.k(排除tag开头的map.k)</span></span><br><span class="line"><span class="comment">        Value:map.v</span></span><br><span class="line"><span class="comment">        tags:&#123;tag开头的map.k,map.v,service:service&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 如果是Master,sub=AssignmentManger这种样式的我们就用tag.Context来作为metric前缀</span></span><br><span class="line"><span class="comment">// HBase的modelerType比较特殊</span></span><br><span class="line"><span class="keyword">if</span> strings.Contains(prefix,<span class="string">",sub="</span>) &#123;</span><br><span class="line">    prefix = maps[<span class="string">"tag.Context"</span>].(<span class="keyword">string</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取tags and 组装tags</span></span><br><span class="line">tags := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">for</span> k,v :=<span class="keyword">range</span> maps &#123;</span><br><span class="line">    <span class="keyword">if</span> strings.HasPrefix( k,<span class="string">"tag."</span> )  &amp;&amp; v != <span class="literal">nil</span> &#123;</span><br><span class="line">        tags[strings.ToLower(strings.TrimPrefix( k,<span class="string">"tag."</span> ))] = v.(<span class="keyword">string</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _,v := <span class="keyword">range</span> strings.Split(maps[<span class="string">"name"</span>].(<span class="keyword">string</span>),<span class="string">","</span>) &#123;</span><br><span class="line">    splits := strings.Split(v, <span class="string">":"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(splits) == <span class="number">2</span> &#123;</span><br><span class="line">        tags[strings.Split(splits[<span class="number">1</span>],<span class="string">"="</span>)[<span class="number">0</span>]]=strings.Split(splits[<span class="number">1</span>],<span class="string">"="</span>)[<span class="number">1</span>]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>组装metrics信息</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k,m :=<span class="keyword">range</span> fields &#123;</span><br><span class="line">    <span class="keyword">if</span> maps[k] != <span class="literal">nil</span> &#123;</span><br><span class="line">        data = <span class="built_in">append</span>(data, Metric&#123;</span><br><span class="line">            Metric:   prefix+<span class="string">"."</span>+k,</span><br><span class="line">            DataType: m,</span><br><span class="line">            Value:    conversionBytes(k,maps[k]),</span><br><span class="line">            Tags: tags,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="数据单位换算"><a href="#数据单位换算" class="headerlink" title="数据单位换算"></a>数据单位换算</h4><ul><li>大小转换为KB，时间转换为毫秒秒<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">conversionBytes</span><span class="params">( k <span class="keyword">string</span>, v <span class="keyword">interface</span>&#123;&#125; )</span> <span class="title">interface</span></span>&#123;&#125;&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MB</span></span><br><span class="line"><span class="keyword">if</span> strings.HasSuffix(k,<span class="string">"M"</span>) || strings.HasSuffix(k,<span class="string">"MB"</span>)&#123;</span><br><span class="line">vf, err := v.(json.Number).Float64()</span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &amp;&amp; vf &gt; <span class="number">0</span>&#123;</span><br><span class="line">v = vf*MB</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// GB</span></span><br><span class="line"><span class="keyword">if</span> strings.HasSuffix(k,<span class="string">"GB"</span>) &#123;</span><br><span class="line">vf, err := v.(json.Number).Float64()</span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &amp;&amp; vf &gt; <span class="number">0</span>&#123;</span><br><span class="line">v = vf*GB</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 纳秒</span></span><br><span class="line"><span class="keyword">if</span> strings.Contains(k,<span class="string">"NanosAvgTime"</span>)&#123;</span><br><span class="line">vf, err := v.(json.Number).Float64()</span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">v = vf/NANOS</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> v</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="参数的设置"><a href="#参数的设置" class="headerlink" title="参数的设置"></a>参数的设置</h4><ol><li>第一个参数就是url，即指定到具体的jmx信息</li><li>第二个参数service，就是服务的映射，你需要具体解析那些服务<br><img src="https://img.xiaoxiaomo.com/blog/img/owl54.jpg" alt=""></li><li>插件的配置<br><img src="https://img.xiaoxiaomo.com/blog/img/owl55.jpg" alt=""></li></ol><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><ul><li>看看效果吧！这就是我们自己的<strong>cloudera manager</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/owl43.jpg" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/owl44.jpg" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/owl45.jpg" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/owl46.jpg" alt=""></li></ul><ul><li>参考：<a href="https://www.datadoghq.com/blog/collecting-hadoop-metrics/" target="_blank" rel="noopener">https://www.datadoghq.com/blog/collecting-hadoop-metrics/</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> HBase </tag>
            
            <tag> Golang </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战五二次开发</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%BA%94%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%BA%94%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/</url>
      <content type="html"><![CDATA[<p>　　二次开发？ 当然就是<strong>修改源代码</strong>了。<br>　　为什么进行二次开发？ 当然就是<strong>有新需求</strong>了。</p><ul><li>需求的来由<blockquote><p>因为，我们做的是一个多租户的平台，需要实现用户资源的隔离。<br>在资源隔离这一块，选择了对yarn的改造，我们知道在yarn的这一块已经对cpu和内存进行了隔离，但是还没有网络IO和磁盘IO资源的隔离。<br>然后我们就想着在监控系统采集这一层，去采集到用户维度的磁盘IO和网络IO。<br>所以，采集用户维度的资源（网络，磁盘，内存，cpu），不仅仅有利于我们下一步对yarn的二次开发，而且也有益于我们更细维度的监控。</p></blockquote></li></ul><h2 id="监控系统实战六二次开发"><a href="#监控系统实战六二次开发" class="headerlink" title="监控系统实战六二次开发"></a>监控系统实战六二次开发</h2><a id="more"></a><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><h4 id="能不能直接获？"><a href="#能不能直接获？" class="headerlink" title="能不能直接获？"></a><strong>能不能直接获？</strong></h4><p>在linux里面有没有地方直接获取用户维度的信息（网络，磁盘，内存，cpu）？并没有！<br><code>top</code>行吗？来看一看，发现并没有网络和磁盘相关的数据<br><img src="https://img.xiaoxiaomo.com/blog/img/owl20.jpg" alt="top"><br><code>iostat</code>呢？发现也没有用户，直接能获取的这条路是走不通了。<br><img src="https://img.xiaoxiaomo.com/blog/img/owl21.jpg" alt="iostat"></p><h4 id="想一下其他的途径"><a href="#想一下其他的途径" class="headerlink" title="想一下其他的途径"></a><strong>想一下其他的途径</strong></h4><p>我们知道，在linux系统中我们这些东西（看到的所有东西）都是以文件的形式体现的，那在文件里是否有我们想要的数据呢？<br><code>ls /proc</code> 看一下，哈哈，感觉快找到我们想要的了。<br><img src="https://img.xiaoxiaomo.com/blog/img/owl22.jpg" alt="ls /proc"></p><h4 id="东西在这儿，怎么拿走？"><a href="#东西在这儿，怎么拿走？" class="headerlink" title="东西在这儿，怎么拿走？"></a><strong>东西在这儿，怎么拿走？</strong></h4><p>在<code>/proc</code>下面有好多东西，现在就去分析一下拿我们想要的就行了。<br>暂时别急，发现只有总的信息，还有一堆数字（进程号），暂时还没法区分用户！(直接拿不到想要的)</p><h4 id="通过进程获取"><a href="#通过进程获取" class="headerlink" title="通过进程获取"></a><strong>通过进程获取</strong></h4><p>直接拿不到用户的资源信息，那就只能通过进程然后汇总间接获取了！<br><code>ls /proc/1</code>看一下进程号为“1”的进程下面的信息，果然还是找到想要的了<br><img src="https://img.xiaoxiaomo.com/blog/img/owl23.jpg" alt="ls /proc/1"></p><h4 id="用户和进程关系的映射"><a href="#用户和进程关系的映射" class="headerlink" title="用户和进程关系的映射"></a><strong>用户和进程关系的映射</strong></h4><p>在进程下面算是能获取到资源了（网络，磁盘，内存，cpu），现在要做的就是让它与用户关联。<br><code>cat /proc/1/status</code>，在status找到了用户相关的信息，Uid,Gid<br><img src="https://img.xiaoxiaomo.com/blog/img/owl24.jpg" alt="/proc/1/status"></p><h4 id="优化用户和进程的映射"><a href="#优化用户和进程的映射" class="headerlink" title="优化用户和进程的映射"></a><strong>优化用户和进程的映射</strong></h4><ol><li><p><strong>通过上面的分析，现在直观的思路就是</strong>：</p><ul><li>在<code>/proc</code>下找到所有num(进程号)</li><li>然后通过进程下面的status文件找到用户/组ID</li><li>把用户ID，拿到<code>/etc/passwd</code>去获取用户名称</li><li>组ID，去<code>/etc/group</code>去获取组名称</li><li>然后再去，做用户/组合进程的映射</li></ul></li><li><p>这种方法能实现，但是<strong>过于复杂</strong>，<strong>性能差</strong></p></li><li><p><strong>我们换一种思路，先去获取用户，然后再通过用户去找进程，这种办法是不是更好呢?</strong></p><ul><li>最开始想通过<code>/run/user</code>来获取用户，发现并不全，最后通过<code>ps</code>获取用户<br><img src="https://img.xiaoxiaomo.com/blog/img/owl25.jpg" alt="ps -aux"></li><li><code>ps -o ruser=userForLongName -e|sort| uniq</code> ps 排序去重就获取到了所有用户<br><img src="https://img.xiaoxiaomo.com/blog/img/owl27.jpg" alt="ps -o ruser=userForLongName -e |sort| uniq"></li><li>然后通过<code>ps -u userName</code> 获取用户进程（这样关系就很清晰了）<br><img src="https://img.xiaoxiaomo.com/blog/img/owl28.jpg" alt="ps -u hadoop | awk &#39;{if(NR&gt;1){print $1}}&#39;"></li></ul></li><li><p>总结一下</p><ul><li>通过<code>ps命令</code>组装用户和进程的关系</li><li>遍历映射关系，去<code>/proc/&lt;pid&gt;/</code>取数据</li><li>保存数据</li></ul></li></ol><h3 id="具体代码实现"><a href="#具体代码实现" class="headerlink" title="具体代码实现"></a>具体代码实现</h3><h4 id="准备开始coding"><a href="#准备开始coding" class="headerlink" title="准备开始coding"></a>准备开始coding</h4><ul><li>在之前的博客，我们已近分析了owl的源码，应该是有个整体的了解，以及我们需要修改哪儿的代码也应该是有一个比较清晰的思路了，我们再来看看入口：<br><img src="https://img.xiaoxiaomo.com/blog/img/owl29.jpg" alt="owl二次开发程序入口"></li></ul><h4 id="获取用户与进程映射"><a href="#获取用户与进程映射" class="headerlink" title="获取用户与进程映射"></a>获取用户与进程映射</h4><ol><li><p>定义一个映射结构体</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用户属性</span></span><br><span class="line"><span class="keyword">type</span> UserAttr <span class="keyword">struct</span> &#123;</span><br><span class="line">Uid   <span class="keyword">string</span></span><br><span class="line">UName <span class="keyword">string</span></span><br><span class="line">Gid   <span class="keyword">string</span></span><br><span class="line">GName <span class="keyword">string</span></span><br><span class="line">Pid   []<span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>获取所有正在运行的用户</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取所有正在运行的用户</span></span><br><span class="line">getUserCommand, err := ExecCommand(<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"ps -o ruser=userForLongName -e |sort| uniq"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>通过用户名，获取用户信息（uid,gid,uName,gName）</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//通过用户名，获取用户信息（uid,gid,uName,gName）</span></span><br><span class="line">    idCommand, err := ExecCommand(<span class="string">"id"</span>, scannerUser.Text())</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>通过用户名获取用户所有进程ID</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用户所有进程ID</span></span><br><span class="line">    psCommand, err := ExecCommand(<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"ps -u userName | awk '&#123;if(NR&gt;1)&#123;print $1&#125;&#125;'"</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>获取用户信息以及用户所运行的进程关系，上面的代码整体后如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取用户信息以及用户所运行的进程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getUserAttr</span><span class="params">()</span> []<span class="title">UserAttr</span></span>&#123;</span><br><span class="line"><span class="comment">//获取所有正在运行的用户</span></span><br><span class="line">getUserCommand, err := ExecCommand(<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"ps -o ruser=userForLongName -e |sort| uniq"</span>)</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">userAttrs := <span class="built_in">make</span>([]UserAttr, <span class="number">0</span>)</span><br><span class="line">scannerUser := bufio.NewScanner(bytes.NewReader(getUserCommand))</span><br><span class="line"><span class="keyword">for</span> scannerUser.Scan() &#123;</span><br><span class="line"><span class="keyword">if</span> scannerUser.Text() != <span class="string">"userForLongName"</span> &#123;</span><br><span class="line"><span class="comment">//通过用户名，获取用户信息（uid,gid,uName,gName）</span></span><br><span class="line">idCommand, err := ExecCommand(<span class="string">"id"</span>, scannerUser.Text())</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">scannerId := bufio.NewScanner(bytes.NewReader(idCommand))</span><br><span class="line"><span class="keyword">for</span> scannerId.Scan() &#123;</span><br><span class="line"><span class="comment">//用户&amp;&amp;用户组信息</span></span><br><span class="line">f1 := strings.Split(scannerId.Text(), <span class="string">" "</span>)</span><br><span class="line">user := strings.Split(f1[<span class="number">0</span>], <span class="string">"="</span>)[<span class="number">1</span>] <span class="comment">//用户信息</span></span><br><span class="line">uidAndName := strings.Split(user, <span class="string">"("</span>)</span><br><span class="line"></span><br><span class="line">group := strings.Split(f1[<span class="number">1</span>], <span class="string">"="</span>)[<span class="number">1</span>] <span class="comment">//用户组信息</span></span><br><span class="line">gidAndName := strings.Split(group, <span class="string">"("</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//用户所有进程ID</span></span><br><span class="line">psCommand, err := ExecCommand(<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"ps -u "</span>+scannerUser.Text()+<span class="string">" | awk '&#123;if(NR&gt;1)&#123;print $1&#125;&#125;'"</span>)</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">scannerPs := bufio.NewScanner(bytes.NewReader(psCommand))</span><br><span class="line">pid := []<span class="keyword">string</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> scannerPs.Scan() &#123;</span><br><span class="line">pid = <span class="built_in">append</span>(pid, scannerPs.Text())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">userAttr := UserAttr&#123;</span><br><span class="line">Uid:   uidAndName[<span class="number">0</span>],</span><br><span class="line">UName: scannerUser.Text(),</span><br><span class="line">Gid:   gidAndName[<span class="number">0</span>],</span><br><span class="line">GName: strings.TrimSuffix(gidAndName[<span class="number">1</span>], <span class="string">")"</span>),</span><br><span class="line">Pid:   pid,</span><br><span class="line">&#125;</span><br><span class="line">userAttrs = <span class="built_in">append</span>(userAttrs, userAttr)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="遍历进程号组装数据"><a href="#遍历进程号组装数据" class="headerlink" title="遍历进程号组装数据"></a>遍历进程号组装数据</h4><blockquote><p>组装好用户和进程的关系后，下面就是遍历关系，获取进程下面的（网络，磁盘，内存，cpu）<br>这里就不一一举例收集上面四个了，以网络为例来说明</p></blockquote><ol><li><p>网络数据在那个文件？<br>这个得确认好，笔者最开始是收集<code>/proc/&lt;pid&gt;/net/snmp</code>下的tcp和udp等网络数据最后写完了发现不对！！<br>最后重写，收集<code>/proc/&lt;pid&gt;/net/dev</code>下的网卡流量信息，<code>cat /proc/1/net/dev</code>来看一看结构（网卡|接收|传输）：<br><img src="https://img.xiaoxiaomo.com/blog/img/owl30.jpg" alt="/proc/1/net/dev"></p></li><li><p>定义数据结构</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> NETPIDCountersStat <span class="keyword">struct</span> &#123;</span><br><span class="line">RBytes<span class="keyword">uint64</span> <span class="comment">// 表示收到的字节</span></span><br><span class="line">RPackets<span class="keyword">uint64</span><span class="comment">// 表示收到正确的包量</span></span><br><span class="line">RErrs<span class="keyword">uint64</span>  <span class="comment">// 表示收到错误的包量</span></span><br><span class="line">RDrop<span class="keyword">uint64</span>  <span class="comment">// 表示收到丢弃的包量</span></span><br><span class="line"></span><br><span class="line">TBytes<span class="keyword">uint64</span>  <span class="comment">// 表示发送的字节</span></span><br><span class="line">TPackets<span class="keyword">uint64</span>  <span class="comment">// 表示发送正确的包量</span></span><br><span class="line">TErrs<span class="keyword">uint64</span>  <span class="comment">// 表示发送错误的包量</span></span><br><span class="line">TDrop<span class="keyword">uint64</span>  <span class="comment">// 表示发送丢弃的包量</span></span><br><span class="line"></span><br><span class="line">UName<span class="keyword">string</span></span><br><span class="line">GName<span class="keyword">string</span></span><br><span class="line">NetCar<span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>解析dev文件组装数据</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NETPIDCounters</span><span class="params">(netCarName <span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">map</span>[<span class="keyword">string</span>]NETPIDCountersStat, error)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="keyword">for</span> _, pid := <span class="keyword">range</span> u.Pid &#123;</span><br><span class="line">        data, err := ioutil.ReadFile(<span class="string">"/proc/"</span> + pid + <span class="string">"/net/dev"</span>)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="comment">//打印异常但不停止程序 可能有些进程在获取到pid后获取信息时已经停止了</span></span><br><span class="line">            logs.Error(err.Error())</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        scanner := bufio.NewScanner(bytes.NewReader(data))</span><br><span class="line">        d := NETPIDCountersStat&#123;&#125;</span><br><span class="line">        <span class="comment">// 获取pid的具体io值</span></span><br><span class="line">        <span class="keyword">for</span> scanner.Scan() &#123;</span><br><span class="line">            f := strings.Split(scanner.Text(), <span class="string">": "</span>)</span><br><span class="line">            <span class="keyword">if</span>( <span class="built_in">len</span>(f) == <span class="number">2</span>  &amp;&amp; strings.TrimSpace(f[<span class="number">0</span>]) == netName) &#123;</span><br><span class="line">                <span class="keyword">if</span>( <span class="built_in">len</span>(f) == <span class="number">2</span>  &amp;&amp; strings.TrimSpace(f[<span class="number">0</span>]) == v)&#123;</span><br><span class="line">                    fields := strings.Fields(f[<span class="number">1</span>])<span class="comment">//网络流量 数据</span></span><br><span class="line">                    rBytes, err := strconv.ParseUint((fields[<span class="number">0</span>]), <span class="number">10</span>, <span class="number">64</span>)</span><br><span class="line">                    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                        <span class="keyword">return</span> ret, err</span><br><span class="line">                    &#125;</span><br><span class="line">                    d.RBytes = rBytes</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">//......</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> d == empty &#123;</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    d.UName = name</span><br><span class="line">                    d.GName = gName</span><br><span class="line">                    d.NetCar = v</span><br><span class="line">                    ret[v+pid] = d</span><br><span class="line">    </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>解析结构体数据，组装成<code>types.TimeSeriesData</code>数据</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用户级别的网络流量</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">netUserMetrics</span><span class="params">(netCarName <span class="keyword">string</span>)</span> []*<span class="title">types</span>.<span class="title">TimeSeriesData</span></span> &#123;</span><br><span class="line">cnt, err := netstat.NETPIDCounters(netCarName)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">ts := time.Now().Unix()</span><br><span class="line">metrics := []*types.TimeSeriesData&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, v := <span class="keyword">range</span> cnt &#123;</span><br><span class="line"><span class="keyword">if</span> NameNotAvalid(v.NetCar) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">metrics = <span class="built_in">append</span>(metrics,</span><br><span class="line">&amp;types.TimeSeriesData&#123;</span><br><span class="line">Metric:    <span class="string">"net.user.rbytes"</span>,</span><br><span class="line">Value:     <span class="keyword">float64</span>(v.RBytes),</span><br><span class="line">Cycle:     Cycle,</span><br><span class="line">Timestamp: ts,</span><br><span class="line">DataType:  <span class="string">"COUNTER"</span>,</span><br><span class="line">Tags:      <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;<span class="string">"user"</span>: v.UName, <span class="string">"group"</span>: v.GName, <span class="string">"iface"</span>: k&#125;,</span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ul><li>除了上面提到的最开始解析错文件，还遇到了一些问题</li></ul><ol><li><p><code>ps -aux |awk &#39;{if(NR&gt;1){print $1}}&#39; |sort| uniq</code> 想查找用户信息，结果显示不全<br><img src="https://img.xiaoxiaomo.com/blog/img/owl26.jpg" alt="ps -aux |awk &#39;{if(NR&gt;1){print $1}}&#39; |sort| uniq"><br>解决办法：<a href="http://www.linuxdiyf.com/linux/29239.html" target="_blank" rel="noopener">http://www.linuxdiyf.com/linux/29239.html</a></p></li><li><p>统计用户所有进程网络io后,然后想加和保存一个汇总的结果到数据库（当然很好的是数据量会小），结果引发了一系列问题</p><ul><li>这样汇总统计后，发现root用户的流量统计出来太吓人了<br><img src="https://img.xiaoxiaomo.com/blog/img/owl31.jpg" alt="root用户的流量"></li><li>直觉可能是自己单位换算有问题，或者是我之前的思路有问题？看了源码然后问了下作者发现没啥问题，单位都正常bytes。</li><li><strong>于是就把每一个进程的详细记录值打印出来</strong>，查看了一下没有问题，差值不明显，看不出来结果！<br><img src="https://img.xiaoxiaomo.com/blog/img/owl32.jpg" alt="log"></li><li>然后又统计了和上一秒的差值（上一秒root用户总值 -减去 当前root用户总值），卧槽，<strong>怎么还有负数</strong>！后来上面的文本往下看（<strong>每次进程数不一样</strong>，左边为168行即168个进程，右边170行即170个进程，绿色的30706那个进程左边就没有！）！！<br><img src="https://img.xiaoxiaomo.com/blog/img/owl33.jpg" alt="log"></li><li>最后想着求一下均值，也是没法解决这个问题，果断放弃了汇总后保存结果，只能分别保存每一个pid的信息了</li></ul></li><li><p>Golang的类型也是一个坑，注意一下类型转换还有类似于这种（uint|int）的区别。</p></li><li>线上环境网卡的问题，因为线上网络的吞吐量非常大通常使用网卡bond把多个物理网卡绑定为一个逻辑网卡，需要确定统计那个网卡<br><img src="https://img.xiaoxiaomo.com/blog/img/owl34.jpg" alt="网卡bond"></li></ol><h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><ol><li><p>模拟单例模式做了一个25s的缓存</p><ul><li>因为我们每一次都需要去调用获取用户与进程的关系，它们（网络，磁盘，内存，cpu）的数据组装是分开写的，所以每个Cycle(60s)时间内需要调用4次</li><li>然后自己就把获取进程信息那块代码做了一个缓存<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 模拟单例模式做了一个25s的缓存</span></span><br><span class="line"><span class="keyword">var</span> u []UserAttr</span><br><span class="line"><span class="keyword">var</span> currTime <span class="keyword">int64</span></span><br><span class="line"><span class="keyword">var</span> lock *sync.Mutex = &amp;sync.Mutex&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetUserPidInfo</span><span class="params">()</span> []<span class="title">UserAttr</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> u == <span class="literal">nil</span> || time.Now().Unix() - currTime &gt; <span class="number">25</span> &#123;</span><br><span class="line">lock.Lock()</span><br><span class="line"><span class="keyword">defer</span> lock.Unlock()</span><br><span class="line">u = getUserAttr()</span><br><span class="line">currTime = time.Now().Unix()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> u</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>多网卡灵活配置</p><ul><li>通过配置，传入需要统计的网卡名称（多个网卡以逗号分隔），如果不传会统计指定的默认网卡<br><img src="https://img.xiaoxiaomo.com/blog/img/owl35.jpg" alt="多网卡支持"></li></ul></li></ol><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p><img src="https://img.xiaoxiaomo.com/blog/img/owl36.jpg" alt="网络"><br><img src="https://img.xiaoxiaomo.com/blog/img/owl37.jpg" alt="磁盘"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战四认识OpenTSDB</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E5%9B%9B%E8%AE%A4%E8%AF%86OpenTSDB/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E5%9B%9B%E8%AE%A4%E8%AF%86OpenTSDB/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要简单介绍一下<code>OpenTSDB</code>，看完后应该可以了解到以下内容</p><ol><li><code>OpenTSDB</code>到底是个什么东西，还有那些类似的数据库</li><li><code>OpenTSDB</code>里面的一些结构，对应HBase来看一下</li><li>通过Java API调用OpenTSDB</li></ol><h2 id="OpenTSDB介绍"><a href="#OpenTSDB介绍" class="headerlink" title="OpenTSDB介绍"></a>OpenTSDB介绍</h2><h3 id="简单介绍一下"><a href="#简单介绍一下" class="headerlink" title="简单介绍一下"></a>简单介绍一下</h3><ul><li><code>OpenTSDB</code>：一个开源的基于HBase的分布式，可扩展的时间序列数据库。<ul><li>第一开源JAVA写的，</li><li>第二是基于HBase的，作者想和HBase社区保持一致性，作为HBase生态的一种补充</li><li>第三分布式可扩展的，当然就有集群了</li><li>第四它是一个时间序列数据库。</li></ul></li></ul><a id="more"></a><ul><li><code>时间序列数据库</code>：主要用来存储时间序列数据（数据格式里包含timestamp字段的数据），常常用来做监控预警数据的存储。</li><li><code>特点</code>：<ol><li>写多于读：95%-99%的操作都是写操作</li><li>顺序写：实时数据写入，多以追加的方式</li><li>很少更新：基本上不更新</li><li>区块删除：删除总是会删除一段时间的数据</li></ol></li></ul><p>参考：<a href="http://liubin.org/blog/2016/02/18/tsdb-intro/" target="_blank" rel="noopener">http://liubin.org/blog/2016/02/18/tsdb-intro/</a></p><h3 id="还有那些TSDB"><a href="#还有那些TSDB" class="headerlink" title="还有那些TSDB"></a>还有那些TSDB</h3><ul><li><p>InfluxDB</p><ul><li>现在名气比较大的，使用Golang写的，目前在TSDB排名第一</li><li>而且支持类SQL查询语言</li><li>数据类型丰富</li><li>事件数据全量存储</li><li>只是目前只有单节点了，集群要付费了</li></ul></li><li><p>Graphite</p><ul><li>创立于2006年，Python写的</li><li>提供了大量函数，画图强大</li><li>Google、GitHub、豆瓣、Instagram、Evernote和Uber都在用</li></ul></li><li><p>Beringei</p><ul><li>Facebook今年开源的TSDB</li></ul></li></ul><p>来看一下最新<a href="https://db-engines.com/en/ranking/time+series+dbms" target="_blank" rel="noopener">db-engines.com</a>排行统计：<br><img src="https://img.xiaoxiaomo.com/blog/img/owl57.jpg" alt=""></p><ul><li>了解更多时序数据库：<br><a href="http://www.uml.org.cn/sjjm/2016032210.asp?artid=17785" target="_blank" rel="noopener">http://www.uml.org.cn/sjjm/2016032210.asp?artid=17785</a><br><a href="http://liubin.org/blog/2016/02/25/tsdb-list-part-1/" target="_blank" rel="noopener">http://liubin.org/blog/2016/02/25/tsdb-list-part-1/</a></li></ul><h2 id="OpenTSDB的一些结构设计"><a href="#OpenTSDB的一些结构设计" class="headerlink" title="OpenTSDB的一些结构设计"></a>OpenTSDB的一些结构设计</h2><ul><li><p><strong>OpenTSDB里面的结构和概念</strong></p><ul><li>Metric：监控项，owl里面的一些监控指标，比如磁盘剩余量disk.free。</li><li>Tags：标签，由tagk和tagv组成，用来描述Metric，比如某台机器的磁盘剩余量tags定义hostname=主机名。</li><li>Value：metric的值，比如磁盘剩余量等于100GB。</li><li>Timestamp：时间戳，描述Value是什么时候的，比如是上午10点剩余磁盘容量为10GB。</li><li>Data Point：某个Metric在某个时间点的数值(Metric、Tags、Value、Timestamp)，即OpenTSDB保存的就是无数个Data Point。</li><li>示例：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">"metric"</span>: <span class="string">"disk.free"</span>,</span><br><span class="line"> <span class="attr">"value"</span>: <span class="number">10737418240.00</span>,</span><br><span class="line"> <span class="attr">"tags"</span>: &#123;</span><br><span class="line">     <span class="attr">"hostname"</span>: <span class="string">"xiaoxiaomo"</span>,</span><br><span class="line">     <span class="attr">"uuid"</span>: <span class="string">"da361bb0e20a45ee"</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>在hbase中现在有四张表<br><img src="https://img.xiaoxiaomo.com/blog/img/owl58.jpg" alt=""></p></li><li><p>看一看具体的数据</p><ul><li>tsdb-uid：其实就是保存的一些metric，tagk，tagv的一些映射关系</li><li>tsdb：保存具体的数据，看看该表的设计<br><img src="https://img.xiaoxiaomo.com/blog/img/owl59.jpg" alt=""></li></ul></li><li><p>看一看具体的设计（自己看图吧，画的挺好的，我就不再这儿浪费时间了）</p><ul><li><img src="https://img.xiaoxiaomo.com/blog/img/owl61.jpg" alt=""></li><li><img src="https://img.xiaoxiaomo.com/blog/img/owl60.png" alt=""></li></ul></li></ul><h2 id="API操作OpenTSDB"><a href="#API操作OpenTSDB" class="headerlink" title="API操作OpenTSDB"></a>API操作OpenTSDB</h2><ul><li>基于<a href="https://github.com/shifeng258/opentsdb-client" target="_blank" rel="noopener">https://github.com/shifeng258/opentsdb-client</a></li><li><p>写入数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">putData</span><span class="params">(String metric, <span class="keyword">long</span> timestamp, Long value, Map&lt;String, String&gt; tagMap)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    MetricBuilder builder = MetricBuilder.getInstance();</span><br><span class="line">    builder.</span><br><span class="line">            addMetric(metric).</span><br><span class="line">            setDataPoint(timestamp, value).</span><br><span class="line">            addTags(tagMap);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Response response = httpClient.pushMetrics(builder, ExpectResponse.SUMMARY);</span><br><span class="line">        <span class="keyword">return</span> response.isSuccess();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">"put data to opentsdb error: "</span>, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPutData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    OpentsdbClient client = <span class="keyword">new</span> OpentsdbClient(ConfigLoader.getProperty(<span class="string">"opentsdb.url"</span>));</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        tags.put(<span class="string">"hostname"</span>,<span class="string">"xiaoxiaomo"</span>);</span><br><span class="line">        client.putData(<span class="string">"disk.free"</span>, System.currentTimeMillis(), <span class="number">10737418240L</span>,tags);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>API下面的内容就省略了，请参考：<a href="https://my.oschina.net/HuQingmiao/blog/701145" target="_blank" rel="noopener">https://my.oschina.net/HuQingmiao/blog/701145</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OWL </tag>
            
            <tag> OpenTSDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战三源码阅读</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%89%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%89%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
      <content type="html"><![CDATA[<p>　　本篇博客，主要是带你看看具体的源码，<strong>从源码的解读理解一下OWL这个监控系统，以及为后面我们做<a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战五二次开发/">二次开发</a>和<a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战六插件开发/">插件开发</a>打下基础</strong>。OWL的一些介绍还可参考官方文档：OWL监控系统最佳实践.pdf</p><h2 id="OWL的介绍"><a href="#OWL的介绍" class="headerlink" title="OWL的介绍"></a>OWL的介绍</h2><p>　　来看看OWL监控系统最佳实践.pdf里面的一张结构图吧：<br><img src="https://img.xiaoxiaomo.com/blog/img/owl04.jpg" alt="访问OpenTSDB"></p><a id="more"></a><p>　　刚开始要去了解OWL这么多组件，容易看花眼，各种曲线箭头。</p><ul><li><strong>所以得把问题简单化，简单到我们分为三个部分</strong>：<ol><li>数据的采集（netcollect和agent）</li><li>数据的存储（TSDB和MySQL）</li><li>数据的查询（API和Controller）</li></ol></li></ul><ul><li><strong>然后就只剩下Repeater和CFC：</strong><ol><li>Repeater：接收监控采集的数据写到OpenTSDB</li><li>CFC：维护一些元数据(WEB界面交互数据)，然后保存在MySQL中，(主机状态、metric信息、插件列表)</li></ol></li></ul><ul><li><strong>哈哈！这样是不是更好理解一点呢？接着往下看具体源码吧</strong></li></ul><h2 id="一起来看看具体的源码"><a href="#一起来看看具体的源码" class="headerlink" title="一起来看看具体的源码"></a>一起来看看具体的源码</h2><h3 id="Agent数据的采集"><a href="#Agent数据的采集" class="headerlink" title="Agent数据的采集"></a>Agent数据的采集</h3><ol><li><p>首先看看agent的main.go，主要是做初始化，还有程序运行的一些入口<br><img src="https://img.xiaoxiaomo.com/blog/img/owl05.png" alt=""></p></li><li><p>看一个配置文件的获取<br><img src="https://img.xiaoxiaomo.com/blog/img/owl06.jpg" alt=""></p></li><li><p>agent.SendConfig2CFC()发送配置信息到cfc<br><img src="https://img.xiaoxiaomo.com/blog/img/owl07.jpg" alt=""><br>上面看到的<code>types.MessageType=types.MESS_POST_HOST_CONFIG</code>，具体代码可以在handle中看到</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> types.MESS_POST_HOST_CONFIG:</span><br><span class="line">host := &amp;types.Host&#123;&#125;</span><br><span class="line">err = host.Decode(data[<span class="number">1</span>:])</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">lg.Error(err.Error())</span><br><span class="line">sess.Close()</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> h := mydb.GetHost(host.ID); h == <span class="literal">nil</span> &#123; <span class="comment">//主机不存在</span></span><br><span class="line">err := mydb.CreateHost(host.ID, host.SN, host.IP, host.Hostname, host.AgentVersion)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">lg.Error(<span class="string">"create host error: %s"</span>, err.Error())</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">lg.Info(<span class="string">"create host:%v"</span>, host)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> h.IP != host.IP ||</span><br><span class="line">h.Hostname != host.Hostname ||</span><br><span class="line">h.AgentVersion != host.AgentVersion ||</span><br><span class="line">h.SN != host.SN &#123;</span><br><span class="line">lg.Info(<span class="string">"update host: %v-&gt;%v"</span>, h, host)</span><br><span class="line">mydb.UpdateHost(host)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>agent.GetPluginList() 获取插件<br><img src="https://img.xiaoxiaomo.com/blog/img/owl08.jpg" alt=""></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取需要执行的插件列表</span></span><br><span class="line"><span class="keyword">case</span> types.MESS_GET_HOST_PLUGIN_LIST:</span><br><span class="line">host := &amp;types.Host&#123;&#125;</span><br><span class="line">err = host.Decode(data[<span class="number">1</span>:])</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">sess.Send(types.Pack(types.MESS_GET_HOST_PLUGIN_LIST_RESP,</span><br><span class="line">&amp;types.GetPluginResp&#123;HostID: host.ID, Plugins: mydb.GetPlugins(host.ID)&#125;),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>agent.SendTSD2Repeater() 发送metrics信息<br><img src="https://img.xiaoxiaomo.com/blog/img/owl10.jpg" alt=""></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">       <span class="comment">//repeater 发送数据</span></span><br><span class="line">   <span class="keyword">case</span> types.MESS_POST_TSD:</span><br><span class="line">repeater.buffer &lt;- data[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">//cfc 同步metric 到MySQL</span></span><br><span class="line"><span class="keyword">case</span> types.MESS_POST_METRIC:</span><br><span class="line">cfg := types.MetricConfig&#123;&#125;</span><br><span class="line">err = cfg.Decode(data[<span class="number">1</span>:])</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">lg.Error(err.Error())</span><br><span class="line">sess.Close()</span><br><span class="line">&#125;</span><br><span class="line">host := mydb.GetHost(cfg.HostID)</span><br><span class="line"><span class="keyword">if</span> host == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这是去mysql里面查询metrics信息，如果不存在该metrics就创建</span></span><br><span class="line"><span class="comment">// 在“设备列表”中点击“metrics数”看见的metric名就是这儿保存的</span></span><br><span class="line"><span class="keyword">if</span> mydb.MetricIsExists(cfg.HostID, cfg.SeriesData.GetMetric()) &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err = mydb.CreateMetric(cfg.HostID, cfg.SeriesData); err != <span class="literal">nil</span> &#123;</span><br><span class="line">lg.Error(<span class="string">"create metric error %v"</span>, err.Error())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>agent.SendAgentAlive2Repeater() &amp; agent.SendHostAlive2CFC() 发送心跳报告</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(this *Agent)</span> <span class="title">SendAgentAlive2Repeater</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">this.SendChan &lt;- types.TimeSeriesData&#123;</span><br><span class="line">Metric:    <span class="string">"agent.alive"</span>,</span><br><span class="line">DataType:  <span class="string">"GAUGE"</span>,</span><br><span class="line">Value:     <span class="number">1</span>,</span><br><span class="line">Cycle:     <span class="number">30</span>,</span><br><span class="line">Timestamp: time.Now().Unix(),</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * <span class="number">30</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(this *Agent)</span> <span class="title">SendHostAlive2CFC</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">if</span> this.cfc.IsClosed() &#123;</span><br><span class="line">time.Sleep(time.Second * <span class="number">10</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">this.cfc.Send(types.Pack(types.MESS_POST_HOST_ALIVE, NewHostConfig()))</span><br><span class="line">time.Sleep(time.Minute * <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>agent.RunBuiltinMetric() 具体metrics采集（之后的二次开发也是修改这些代码）<br><img src="https://img.xiaoxiaomo.com/blog/img/owl09.png" alt=""></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 看一个简单的LoadMetrics 主要实现就是组装TimeSeriesData数据</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LoadMetrics</span><span class="params">(cycle <span class="keyword">int</span>, ch <span class="keyword">chan</span> types.TimeSeriesData)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, metric := <span class="keyword">range</span> loadMetrics(cycle) &#123;</span><br><span class="line"><span class="keyword">if</span> metric == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">ch &lt;- *metric</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">loadMetrics</span><span class="params">(cycle <span class="keyword">int</span>)</span> []*<span class="title">types</span>.<span class="title">TimeSeriesData</span></span> &#123;</span><br><span class="line">cnt, err := load.Avg()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">ts := time.Now().Unix()</span><br><span class="line">metrics := <span class="built_in">make</span>([]*types.TimeSeriesData, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">metrics[<span class="number">0</span>] = &amp;types.TimeSeriesData&#123;</span><br><span class="line">Metric:    <span class="string">"sys.load1"</span>,</span><br><span class="line">Value:     cnt.Load1,</span><br><span class="line">Cycle:     cycle,</span><br><span class="line">Timestamp: ts,</span><br><span class="line">DataType:  <span class="string">"GAUGE"</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">return</span> metrics</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ul><li>到这里我们agent的核心代码就看完了！</li></ul><h3 id="repeater核心代码"><a href="#repeater核心代码" class="headerlink" title="repeater核心代码"></a>repeater核心代码</h3><ol><li>main方法入口<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">go</span> repeater.Forward()</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog/img/owl11.jpg" alt="写入数据到opentsdb"><br><img src="https://img.xiaoxiaomo.com/blog/img/owl12.jpg" alt="opentsdb具体写逻辑"></p><h3 id="cfc核心代码"><a href="#cfc核心代码" class="headerlink" title="cfc核心代码"></a>cfc核心代码</h3><ol><li>main方法入口<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UpdatHostAive()</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog/img/owl13.jpg" alt="cfc"></p><h3 id="api核心代码"><a href="#api核心代码" class="headerlink" title="api核心代码"></a>api核心代码</h3><ol><li><p>有必要看看api模块main里面的初始化<br><img src="https://img.xiaoxiaomo.com/blog/img/owl14.jpg" alt="api main"></p></li><li><p>InitServer<br><img src="https://img.xiaoxiaomo.com/blog/img/owl15.jpg" alt="api InitServer"></p></li><li><p>我们可以直接调用api<br><img src="https://img.xiaoxiaomo.com/blog/img/owl16.jpg" alt="api InitServer"></p></li><li><p>api查询调用以及返回值，看一个query就够了</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">query := authorized.Group(<span class="string">"/query"</span>)</span><br><span class="line">&#123;</span><br><span class="line">query.GET(<span class="string">""</span>, data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog/img/owl17.jpg" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/owl18.jpg" alt=""></p><h3 id="剩下源码"><a href="#剩下源码" class="headerlink" title="剩下源码"></a>剩下源码</h3><ul><li>看完前面的源码，总体思路我想应该是有了。剩下的源码，你们就自己去阅读吧，后面的也都很简单，因为go语言本身就有阅读简单的特点。</li><li>运行起来看看具体的日志，更加容易理解<br><img src="https://img.xiaoxiaomo.com/blog/img/owl38.jpg" alt="owl log"></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战二搭建梳理</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%BA%8C%E6%90%AD%E5%BB%BA%E6%A2%B3%E7%90%86/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%BA%8C%E6%90%AD%E5%BB%BA%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>　　本篇博客不会讲具体的怎么搭建owl，而只是对一些遇到的问题进行梳理。因为已经有文档讲的非常清楚了，可以去github：<a href="https://github.com/TalkingData/owl" target="_blank" rel="noopener">https://github.com/TalkingData/owl</a> 上指定的QQ群里面获取（所以，如果参考QQ群上面的文档安装没有什么问题可跳过该篇博客）。</p><h2 id="整个环境搭建的梳理"><a href="#整个环境搭建的梳理" class="headerlink" title="整个环境搭建的梳理"></a>整个环境搭建的梳理</h2><ul><li>开始准备安装软件<ul><li>搭建OWL之前，需要安装<code>OpenTSDB</code>，<code>MySQL</code>、<code>HBase</code>、<code>Nginx</code>、<code>JDK</code>、<code>GO语言环境</code>。</li><li>安装HBase、MySQL、Nginx、JDK这些就不在这里介绍了，可以参考我之前的博客。</li><li>所以下面就介绍一下OpenTSDB、GO语言环境、OWL的搭建</li></ul></li></ul><a id="more"></a><h3 id="编译安装OpenTSDB"><a href="#编译安装OpenTSDB" class="headerlink" title="编译安装OpenTSDB"></a>编译安装OpenTSDB</h3><ul><li><strong>注意</strong>：安装OpenTSDB之前需要提前安装好HBase，因为在HBase中存了OpenTSDB的数据</li><li><strong>一、下载</strong>：<a href="https://github.com/OpenTSDB/opentsdb/releases" target="_blank" rel="noopener">https://github.com/OpenTSDB/opentsdb/releases</a></li><li><p><strong>二、解压</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# tar -zxvf /opt/opentsdb-2.3.0.tar.gz -C /data</span><br><span class="line">[root@xiaoxiaomo ~]# mv /data/opentsdb-2.3.0/ /data/opentsdb</span><br></pre></td></tr></table></figure></li><li><p><strong>三、编译</strong></p></li></ul><ol><li><p>创建一个<code>build</code>目录，复制<code>third_party</code>下面所有的文件到<code>build</code>目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# cd /data/opentsdb</span><br><span class="line">[root@xiaoxiaomo opentsdb]# mkdir build</span><br><span class="line">[root@xiaoxiaomo opentsdb]# cp -r third_party ./build</span><br><span class="line">[root@xiaoxiaomo opentsdb]# ./build.sh</span><br></pre></td></tr></table></figure></li><li><p>直接cd 到 $opentsdb目录下，执行build.sh文件编译会出现异常：</p><blockquote><p>异常：Error: Could not find or load main class javacc<br>解决：<a href="https://community.hortonworks.com/questions/82834/error-could-not-find-or-load-main-class-javacc.html" target="_blank" rel="noopener">https://community.hortonworks.com/questions/82834/error-could-not-find-or-load-main-class-javacc.html</a></p></blockquote></li><li><p>编译后会看到如下日志</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">INFO: Created user preferences directory.</span><br><span class="line">Compiling module tsd.QueryUi</span><br><span class="line">   Compiling 5 permutations</span><br><span class="line">      Compiling permutation 0...</span><br><span class="line">      Compiling permutation 1...</span><br><span class="line">      Compiling permutation 2...</span><br><span class="line">      Compiling permutation 3...</span><br><span class="line">      Compiling permutation 4...</span><br><span class="line">   Compile of permutations succeeded</span><br><span class="line">Linking into /data/opentsdb/build/gwt/queryui</span><br><span class="line">   Link succeeded</span><br><span class="line">   Compilation succeeded -- 70.492s</span><br><span class="line">/bin/mkdir -p staticroot</span><br><span class="line">cp ../src/tsd/static/favicon.ico ../src/tsd/static/opentsdb_header.jpg staticroot</span><br><span class="line">find -L staticroot -type l -exec rm &#123;&#125; \;</span><br><span class="line">p=`pwd`/gwt/queryui &amp;&amp; cd staticroot \</span><br><span class="line">  &amp;&amp; for i in $p/*; do ln -s -f "$i" || break; done</span><br><span class="line">find -L staticroot/gwt -type f | xargs touch</span><br><span class="line">make[1]: Leaving directory `/data/opentsdb/build'</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>四、初始化HBase表修改配置</strong></li></ul><ol><li><p>初始化HBase表，执行：<em>env COMPRESSION=NONE HBASE_HOME=/data/hbase ./src/create_table.sh</em><br><img src="https://img.xiaoxiaomo.com/blog/img/owl01.png" alt="初始化HBase表"></p></li><li><p>修改配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim opentsdb/src/opentsdb.conf</span></span><br><span class="line">   tsd.network.port = 4242</span><br><span class="line">   tsd.http.staticroot =/data/opentsdb/build/staticroot</span><br><span class="line">   tsd.http.cachedir = /tmp/tsd</span><br><span class="line">   tsd.core.auto_create_metrics = true</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>五、启动&amp;访问</strong></li></ul><ol><li><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# nohup opentsdb/build/tsdb tsd --config=opentsdb/src/opentsdb.conf 2&gt;&amp;1  &gt; a.log &amp; </span><br><span class="line">[root@xiaoxiaomo ~]# jps</span><br><span class="line">3771 TSDMain</span><br></pre></td></tr></table></figure></li><li><p>访问：<a href="http://ip:4242" target="_blank" rel="noopener">http://ip:4242</a><br><img src="https://img.xiaoxiaomo.com/blog/img/owl02.png" alt="访问OpenTSDB"></p></li></ol><h3 id="GO语言环境"><a href="#GO语言环境" class="headerlink" title="GO语言环境"></a>GO语言环境</h3><ul><li><strong>GO语言环境，这里主要是想说一下GOROOT和GOPATH，得配置好</strong>。<br>  1、作为一个对GO语言不是很了解，对其他语言很熟悉的就很容易忽视这一点，我就掉进这个里面过。直接下载下来安装包解压后，配了一个GO_HOME！！哈哈，傻了，后面pull下来owl代码后import找不到自己！<br>  2、<code>GOROOT</code>：简单理解就是go安装包目录<br>  3、<code>GOPATH</code>：简单理解就是一个工作区（你放项目的地方，包括你自己安装的Go包）。在这个目录下一般有<code>src、pak、bin</code>三个目录。<br>  4、<code>GOPATH</code>：你可以配置多个，Win下用分号分割/Linux用冒号分割，举个linux下变量配置例子：GOPATH=/data/data/ext:/data/data/work。pull下来的代码就可以放在/data/data/work/src/下面</li></ul><h3 id="OWL的搭建"><a href="#OWL的搭建" class="headerlink" title="OWL的搭建"></a>OWL的搭建</h3><ol><li>owl是有很多组件构成，所以得组逐个安装，由于该golang项目包由godep管理，在安装之前先安装godep：go get github.com/tools/godep，如果网络问题没法下载可参考：<a href="https://www.golangtc.com/download/package" target="_blank" rel="noopener">https://www.golangtc.com/download/package</a>手动下载</li><li>owl组件安装参考QQ群中的文档，文档上面看着内容有点多，其实主要做的都是重复的事情。下面以安装agent举个例子，来说明一下每一步都在做什么<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> ## 安装agent，在$GOPATH目录下就会有一个可执行文件</span><br><span class="line">[root@xiaoxiaomo owl]# godep go install owl/agent</span><br><span class="line">godep: WARNING: Godep workspaces (./Godeps/_workspace) are deprecated and support for them will be removed when go1.8 is released.</span><br><span class="line">godep: WARNING: Go version (go1.6) &amp; $GO15VENDOREXPERIMENT= wants to enable the vendor experiment, but disabling because a Godep workspace (Godeps/_workspace) exists</span><br><span class="line"></span><br><span class="line">## 创建一个目录（下面/etc/init.d/owl-agent文件中的执行文件路径，其实就是指向的该目录下的具体文件）</span><br><span class="line">[root@xiaoxiaomo owl]# mkdir -p /usr/local/owl-agent/conf </span><br><span class="line"></span><br><span class="line">## 复制第一步编译好的执行文件到第二步创建好的目录下</span><br><span class="line">[root@xiaoxiaomo owl]# cp $GOPATH/bin/agent /usr/local/owl-agent/ </span><br><span class="line"></span><br><span class="line">## 复制配置文件到第二步创建好的conf目录下</span><br><span class="line">[root@xiaoxiaomo owl]# cp conf/agent.conf /usr/local/owl-agent/conf</span><br><span class="line"></span><br><span class="line">## 复制启动文件到init.d目录下并添加执行权限，方便下面启动</span><br><span class="line">[root@xiaoxiaomo owl]# cp scripts/init/owl-agent.init /etc/init.d/owl-agent</span><br><span class="line">[root@xiaoxiaomo owl]# chmod +x /etc/init.d/owl-agent</span><br><span class="line"></span><br><span class="line">## 修改配置文件</span><br><span class="line">[root@xiaoxiaomo owl]# vim /usr/local/owl-agent/conf/agent.conf</span><br><span class="line"></span><br><span class="line">## 启动</span><br><span class="line">[root@xiaoxiaomo owl]# /etc/init.d/owl-agent start</span><br><span class="line">Starting owl-agent (via systemctl):                        [  确定  ]</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
            <tag> OpenTSDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OWL--监控系统实战一平台概述</title>
      <link href="/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%80%E5%B9%B3%E5%8F%B0%E6%A6%82%E8%BF%B0/"/>
      <url>/2017/08/28/OWL-%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B8%80%E5%B9%B3%E5%8F%B0%E6%A6%82%E8%BF%B0/</url>
      <content type="html"><![CDATA[<p>　　接下来的几篇博客是一个连续的部分，主要讲解<code>OWL监控系统实战与二次开发</code>，<a href="https://github.com/TalkingData/owl" target="_blank" rel="noopener">OWL</a>-是 <code>TalkingData</code> 推出的一款开源分布式监控系统。本篇是该系列的第一遍博客，将总体的介绍一下背景目的，好让读者有一个整体的概念：</p><blockquote><p>该系列博客所设计到的代码也会开源出来，后面会贴出github地址<br>所以，在实战五和六中有一部分是伪代码（用// …… 省略）</p></blockquote><h2 id="一、目录"><a href="#一、目录" class="headerlink" title="一、目录"></a>一、目录</h2><ol><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战一平台概述/">OWL–监控系统实战一平台概述,讲解背景目的以及监控平台概述</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战二搭建梳理/">OWL–监控系统实战二搭建梳理,整个环境搭建的梳理</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战三源码阅读/">OWL–监控系统实战三源码阅读,OWL的介绍，一起来看看具体的源码</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战四认识OpenTSDB/">OWL–监控系统实战四认识OpenTSDB,认识一下OpenTSDB</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战五二次开发/">OWL–监控系统实战五二次开发,Linux用户级别的Metrics收集</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/08/28/OWL-监控系统实战六插件开发/">OWL–监控系统实战六插件开发,插件收集Hadoop平台Metrics信息（做一个自己的Cloudera Manager）</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/09/08/OWL-监控系统实战七上线运行/">OWL–监控系统实战七上线运行,上线运行的事情，可以当作一个参考</a></li></ol><a id="more"></a><h2 id="二、背景以及目的"><a href="#二、背景以及目的" class="headerlink" title="二、背景以及目的"></a>二、背景以及目的</h2><p>　　最近有幸参与到公司的<code>数据服务平台</code>，负责开发数据服务平台的监控和运维这一块。为什么需要监控？简单来讲就是为了系统可控，实时数据一目了然，异常预警、准确定位。<br>　　<strong><a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener">宜人蜂巢 </a>于2013年由李善任先生（人称麦哥或Michael），在宜人贷内部组建团队并成功孵化的项目。通过8大维度:金融、电商、社交、保险、社保、行为、位置等约20种数据源，千余维度特征，亿级关系网络等，帮助企业做出更明智的信贷决策，以扩大公平和透明信贷的可用性。目前查询量超过6000万次，体验用户超过3000万，集群规模上千台，YARN集群每天调度近十万离线作业和实时任务；通过宜人蜂巢科技平台的促成的放款额已突破1200亿。</strong><a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener">宜人蜂巢是领先的，智能的、数据科学驱动的互联网风控科技平台，通过最领先科技与大数据的智能技术准确预测借款人的信用、偿还能力；并实别欺诈、助力贷后风险管理等；从而将公平的信用扩展到更多的人。</a></p><ol><li>下面简单介绍一下这个数据服务平台：<br><strong>数据服务平台，就是一个多租户容器化的一站式开发运维数据知识平台</strong>，包括了<code>权限控制</code>、<code>资源划分隔离</code>、<code>元数据管理</code>、<code>执行引擎（Spark\Flink\MR\HBase\等）</code>、<code>集群运维监控</code>等。</li><li>开发这个平台的目的是什么？<ul><li>提高业务分析师获取数据，以及分析效率</li><li>提高数据清洗/数据质量验证效率</li><li>解决集群运维监控的统一管理</li><li>支持不同场景下的计算需求等</li></ul></li></ol><h2 id="三、监控平台"><a href="#三、监控平台" class="headerlink" title="三、监控平台"></a>三、监控平台</h2><ol><li><p>本系列的主角终于登场了，<strong>监控运维平台</strong>！主要包括三个部分：<code>集群节点监控</code>、<code>集群服务监控</code>、<code>集群配置管理</code></p><ul><li><code>集群节点监控</code>：包括了CUP使用率，磁盘IO，网络IO，内存等指标，可按用户，分组汇总显示，时序查询</li><li><code>集群服务监控</code>：包括了HDFS、Yarn、HBase、Zookeeper、Spark等等（类是于Cloudera Manager监控的服务）</li><li><code>集群配置管理</code>：包括了服务的滚动重启，节点添加下线，预警等。</li></ul></li><li><p>本系列博主重点讲解，<code>集群节点监控</code>和<code>集群服务监控</code>。然后考虑到查询速度，数据存储，自定义开发等原因选择了OWL分布式开源监控软件，在它基础上做了一些扩展。</p></li><li>选择OWL主要是因为以它下几个<strong>特点</strong>：<ul><li>Go语言开发，部署简单，并发性好</li><li>自带web管理界面，能灵活的自定义图表</li><li>数据底层存储在HBase，查询效率高，加上已有的HBase集群</li><li>分布式，支持多机房 、开源</li><li>完善的预警系统(报警算法、报警渠道，邮件、微信、短信)</li><li>扩展性好，方便二次开发，支持插件开发</li></ul></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Golang </tag>
            
            <tag> 运维 </tag>
            
            <tag> OWL </tag>
            
            <tag> OpenTSDB </tag>
            
            <tag> Metrics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--快速搭建大数据开发环境</title>
      <link href="/2017/07/30/Hadoop-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"/>
      <url>/2017/07/30/Hadoop-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>　　最近自己电脑的磁盘坏了，导致数据也没了。安装好系统之后就是各种弄环境了，之前的博客也写过Hadoop环境搭建 <code>Hadoop</code>，<code>Hive</code>，<code>HBase</code>，<code>Kafka</code>，<code>Spark</code>，<code>MySQL</code>，<code>Redis</code>等等一系列的。<br>之前记录的目的也是为了方便自己吧，但整个流程下来还是的花费几个小时。从前面的博客找到从虚拟机的网络配置，下载软件上传在修改配置挺麻烦的。这里再次做个汇总，以后做这个过程或者升级就更加方便（<strong>主要便捷是后面会给出一个Virtual Box的包直接导入就有这些所有环境了</strong>）。</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>软件下载(可以通过该链接自己下载，同时我在附录中也提供了<a href="http://pan.baidu.com/s/1ge9cHiV" target="_blank" rel="noopener">百度云下载</a>地址)</li></ul><ol><li><a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="noopener">https://www.virtualbox.org/wiki/Downloads virtual box 使用了5.0.40版本</a></li><li><a href="http://vault.centos.org/6.5/isos/x86_64/" target="_blank" rel="noopener">http://vault.centos.org/6.5/isos/x86_64/ box 使用CentOS-6.5-x86_64-minimal.iso</a></li><li><a href="http://archive.apache.org/dist/hadoop/common/" target="_blank" rel="noopener">http://archive.apache.org/dist/hadoop/common 使用 hadoop-2.7.2</a></li><li><a href="http://archive.apache.org/dist/hbase/" target="_blank" rel="noopener">http://archive.apache.org/dist/hbase/ 使用 hbase-1.3.1-bin.tar.gz</a></li><li><a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/ 使用apache-hive-1.2.1-bin.tar.gz</a></li><li><a href="http://archive.apache.org/dist/kafka/" target="_blank" rel="noopener">http://archive.apache.org/dist/kafka/ 使用 kafka_2.11-0.11.0.0.tgz</a></li><li><a href="http://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">http://archive.apache.org/dist/zookeeper/ 使用 zookeeper-3.4.9.tar.gz</a></li><li><a href="http://archive.apache.org/dist/spark/" target="_blank" rel="noopener">http://archive.apache.org/dist/spark/ 使用 spark-2.0.0-bin-hadoop2.7.tgz</a></li><li><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html 使用 jdk-8u144-linux-x64.tar.gz</a></li><li><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">https://redis.io/download 使用 redis-3.0.6.tar.gz</a></li><li><a href="https://dev.mysql.com/downloads/mysql/5.5.html?os=31&amp;version=5.1" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.5.html?os=31&amp;version=5.1 使用 mysql-5.7.9-1.el6.x86_64.rpm-bundle.tar</a></li></ol><a id="more"></a><h2 id="安装linux"><a href="#安装linux" class="headerlink" title="安装linux"></a>安装linux</h2><ol><li>安装virtual box（略，这个没什么好说的，一直下一步就ok！）<br><img src="https://img.xiaoxiaomo.com/blog/img/hadoopstack1.png" alt="https://img.xiaoxiaomo.com/blog/img/hadoopstack1.png"></li><li>安装Linux虚拟机注意（选择第一个）<br><img src="https://img.xiaoxiaomo.com/blog/img/hadoopstack2.png" alt="https://img.xiaoxiaomo.com/blog/img/hadoopstack2.png"></li><li>添加虚拟机后网络配置</li></ol><ul><li>这个网络配置部分参考:<a href="http://blog.xiaoxiaomo.com/2016/11/11/VirtualBox-网络配置/">http://blog.xiaoxiaomo.com/2016/11/11/VirtualBox-网络配置/</a></li></ul><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>规划</li></ul><ol><li>创建一个data目录所有东西都放在那儿：<em>mkdir /data</em></li><li>再在data目录下创建一个data目录用来保存一些数据，比如hdfs,kafka等：<em>mkdir /data/data</em></li></ol><ul><li><p>上传软件<br><img src="https://img.xiaoxiaomo.com/blog/img/hadoopstack3.png" alt="https://img.xiaoxiaomo.com/blog/img/hadoopstack3.png"></p></li><li><p>准备</p></li></ul><ol><li><p>关闭防火墙：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# service iptables stop </span><br><span class="line">[root@xiaoxiaomo ~]# chkconfig --list | grep iptables</span><br></pre></td></tr></table></figure></li><li><p>修改主机名：修改</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# vi /etc/sysconfig/network</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 修改为：</span></span></span><br><span class="line">HOSTNAME=xiaoxiaomo</span><br></pre></td></tr></table></figure></li><li><p>绑定hosts Name：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# vi /etc/hosts</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 添加 </span></span></span><br><span class="line">192.168.56.102 xiaoxiaomo</span><br></pre></td></tr></table></figure></li><li><p>设置ssh：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# ssh-keygen -t rsa  #生成rsa格式的ssh私钥和公钥</span><br><span class="line">[root@xiaoxiaomo ~]# ssh-copy-id -i xiaoxiaomo #把公钥复制到对方节点(这里我复制到自己的主机xiaoxiaomo01上)</span><br><span class="line">[root@xiaoxiaomo ~]# ssh xiaoxiaomo01 #验证</span><br></pre></td></tr></table></figure></li><li><p>安装国内的yum镜像<br>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/02/11/Linux-Yum%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/">http://blog.xiaoxiaomo.com/2016/02/11/Linux-Yum%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</a></p></li><li>安装JDK <a href="http://blog.xiaoxiaomo.com/2016/01/22/Linux-软件安装之JDK/">参考，这里我们安装jdk1.8</a>：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#解压到/data &amp;&amp; 修改名称</span></span></span><br><span class="line">[root@xiaoxiaomo ~]# tar -zxvf /opt/jdk-8u144-linux-x64.tar.gz -C /data</span><br><span class="line">[root@xiaoxiaomo ~]# mv /data/jdk1.8.0_144/ /data/jdk</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#配置环境变量 </span></span></span><br><span class="line">[root@xiaoxiaomo ~]# vi /etc/profile</span><br><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export PATH=.:$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/">http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</a></p></blockquote><h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><ul><li><p>解压&amp;&amp;重命名&amp;&amp;配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# tar -zxvf /opt/hadoop-2.7.2.tar.gz -C /data/</span><br><span class="line">[root@xiaoxiaomo ~]# mv /data/hadoop-2.7.2/ /data/hadoop</span><br><span class="line">[root@xiaoxiaomo ~]# mkdir -p /data/data/hdfs/name ##需要创建一个目录不然启动会报错</span><br><span class="line">[root@xiaoxiaomo ~]# vim /etc/profile ##添加如下</span><br><span class="line">export HADOOP_HOME=/data/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 【**备注后面的环境变量就略了，参考附录中的环境变量**】</span></span></span><br></pre></td></tr></table></figure></li><li><p>配置</p></li></ul><ol><li><p>配置core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://xiaoxiaomo:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/data/hdfs/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 垃圾回收站</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;fs.trash.interval&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;1440&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置hadoop-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export HADOOP_LOG_DIR=/data/data/hdfs/logs</span><br></pre></td></tr></table></figure></li><li><p>配置hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/data/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/data/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/data/hdfs/namesecondary<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>xiaoxiaomo:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">        &lt;property&gt;</span></span><br><span class="line"><span class="comment">                &lt;name&gt;dfs.hosts&lt;/name&gt;</span></span><br><span class="line"><span class="comment">                &lt;value&gt;/data/hadoop/etc/hadoop/datanode-allow&lt;/value&gt;</span></span><br><span class="line"><span class="comment">        &lt;/property&gt;</span></span><br><span class="line"><span class="comment">        &lt;property&gt;</span></span><br><span class="line"><span class="comment">                &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span></span><br><span class="line"><span class="comment">                &lt;value&gt;/data/hadoop/etc/hadoop/datanode-deny&lt;/value&gt;</span></span><br><span class="line"><span class="comment">        &lt;/property&gt;</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置log4j.properties</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop.log.dir=/data/data/hdfs/logs</span><br></pre></td></tr></table></figure></li><li><p>配置log4j.properties</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:10020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:19888&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/history&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done_intermediate&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.map.log.level&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;DEBUG&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.reduce.log.level&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;DEBUG&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>配置slaves</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#localtion修改为</span></span></span><br><span class="line">xiaoxiaomo</span><br></pre></td></tr></table></figure></li><li><p>yarn-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export YARN_LOG_DIR=/data/data/hdfs/logs</span><br><span class="line">export YARN_ROOT_LOGGER=DEBUG,DRFA</span><br></pre></td></tr></table></figure></li><li><p>配置yarn-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;xiaoxiaomo&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:8031&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:8033&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li></ol><ul><li>启动测试<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 格式化数据目录</span></span></span><br><span class="line">[root@xiaoxiaomo ~]# hdfs namenode -format</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动hdfs</span></span></span><br><span class="line">[root@xiaoxiaomo ~]# start-dfs.sh ##访问：http://xiaoxiaomo:50070</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动yarn</span></span></span><br><span class="line">[root@xiaoxiaomo ~]# start-yarn.sh ##访问：http://xiaoxiaomo:8088</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/">http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</a></p></blockquote><h2 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# tar -zxvf /opt/zookeeper-3.4.9.tar.gz -C /data/</span><br><span class="line">[root@xiaoxiaomo ~]# mv /data/zookeeper-3.4.9/ /data/zookeeper</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量略</span></span></span><br><span class="line">[root@xiaoxiaomo ~]# vi /etc/profile ## 添加：export ZK_HOME=/data/zookeeper</span><br><span class="line">[root@xiaoxiaomo ~]# cd $ZK_HOME/conf</span><br><span class="line">[root@xiaoxiaomo conf]# mv zoo_sample.cfg zoo.cfg</span><br><span class="line">[root@xiaoxiaomo conf]# vi zoo.cfg ##修改：dataDir=/data/data/zookeeper</span><br><span class="line">[root@xiaoxiaomo conf]# vi log4j.properties  ##修改：zookeeper.log.dir=/data/data/zookeeper/logs</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#启动</span></span></span><br><span class="line">[root@xiaoxiaomo conf]# zkServer.sh start</span><br></pre></td></tr></table></figure><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</a></p></blockquote><h2 id="安装HBase"><a href="#安装HBase" class="headerlink" title="安装HBase"></a>安装HBase</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# tar -zxvf hbase-1.3.1-bin.tar.gz -C /data/</span><br><span class="line">[root@xiaoxiaomo ~]# mv /data/hbase-1.3.1/ /data/hbase</span><br></pre></td></tr></table></figure><ul><li>修改配置</li></ul><ol><li><p>vi $HBASE_HOME/conf/hbase-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export HBASE_LOG_DIR=/data/data/hbase/logs</span><br><span class="line">export HBASE_ROOT_LOGGER=INFO,DRFA</span><br></pre></td></tr></table></figure></li><li><p>vi $HBASE_HOME/conf/hbase-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/data/data/hbase/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://xiaoxiaomo:9000/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!--zk --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;xiaoxiaomo&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt; </span><br><span class="line">  &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/data/data/hbase/zk&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>vi $HBASE_HOME/conf/log4j.propertie</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase.log.dir=/data/data/hbase/logs ##修改为统一目录</span><br></pre></td></tr></table></figure></li><li><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 启动hbase</span><br><span class="line">[root@xiaoxiaomo ~]# start-hbase.sh</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/06/04/HBase-%E4%BC%AA%E5%88%86%E5%B8%83%E5%92%8C%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/">http://blog.xiaoxiaomo.com/2016/06/04/HBase-%E4%BC%AA%E5%88%86%E5%B8%83%E5%92%8C%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</a></p></blockquote><h2 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo opt]# rpm -qa|grep mysql #如有就卸载</span><br><span class="line">[root@xiaoxiaomo opt]# tar -xvf mysql-5.7.9-1.el6.x86_64.rpm-bundle.tar </span><br><span class="line">[root@xiaoxiaomo opt]# rpm -ivh mysql-community-common-5.7.9-1.el6.x86_64.rpm </span><br><span class="line">[root@xiaoxiaomo opt]# rpm -ivh mysql-community-libs-5.7.9-1.el6.x86_64.rpm </span><br><span class="line">[root@xiaoxiaomo opt]# rpm -ivh mysql-community-client-5.7.9-1.el6.x86_64.rpm </span><br><span class="line">[root@xiaoxiaomo opt]# yum install -y mysql-community-server-5.7.9-1.el6.x86_64.rpm </span><br><span class="line">[root@xiaoxiaomo opt]# mysqld --initialize #初始化</span><br><span class="line">[root@xiaoxiaomo opt]# cat /var/log/mysqld.log #可以获取初始密码</span><br><span class="line">[root@xiaoxiaomo opt]# chown -R mysql:mysql /var/lib/mysql #授权</span><br><span class="line">[root@xiaoxiaomo opt]# /etc/init.d/mysqld start #启动</span><br><span class="line">[root@xiaoxiaomo opt]# mysql -uroot -p #登录（通过默认的初始密码）</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#登录进去后要重设密码</span></span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> SET PASSWORD = PASSWORD(<span class="string">'root'</span>);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#mysql启动&amp;&amp;停止</span></span></span><br><span class="line">[root@xiaoxiaomo opt]# /etc/init.d/mysqld start ##启动服务</span><br><span class="line">[root@xiaoxiaomo opt]# service mysqld start ##启动服务</span><br><span class="line">[root@xiaoxiaomo opt]# /etc/init.d/mysqld stop ##启停止服务</span><br><span class="line">[root@xiaoxiaomo opt]# service mysqld stop ##停止服务</span><br></pre></td></tr></table></figure><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/02/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BMysql/">http://blog.xiaoxiaomo.com/2016/02/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BMysql/</a></p></blockquote><h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo opt]# tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /data/</span><br><span class="line">[root@xiaoxiaomo opt]# mv /data/apache-hive-1.2.1-bin/ /data/hive</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量略</span></span></span><br><span class="line">[root@xiaoxiaomo opt]# cd $HIVE_HOME</span><br><span class="line">[root@xiaoxiaomo hive]# cp conf/hive-env.sh.template conf/hive-env.sh</span><br><span class="line">[root@xiaoxiaomo hive]# cp conf/hive-default.xml.template conf/hive-site.xml</span><br></pre></td></tr></table></figure><ul><li>修改配置</li></ul><ol><li><p>hive-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo hive]# vim conf/hive-env.sh ##添加如下配置</span><br><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export HIVE_HOME=/data/hive</span><br><span class="line">export HADOOP_HOME=/data/hadoop</span><br></pre></td></tr></table></figure></li><li><p>hive-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo hive]# vim conf/hive-env.sh ##修改如下配置</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.querylog.location&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/data/data/hive/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/data/data/hive/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/data/data/hive/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 修改metadata为mysql --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">&lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>复制mysql驱动jar包到$HIVE_HOME/lib/目录下</p></li><li>启动。查看mysql数据库 ##[root@xiaoxiaomo hive]# hive</li></ol><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/05/27/Hive-%E6%A6%82%E8%BF%B0%E4%B8%8E%E4%BD%BF%E7%94%A8/">http://blog.xiaoxiaomo.com/2016/05/27/Hive-%E6%A6%82%E8%BF%B0%E4%B8%8E%E4%BD%BF%E7%94%A8/</a></p></blockquote><h2 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h2><ol><li><p>解压 &amp;&amp; 配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo opt]# tar -zxvf kafka_2.11-0.11.0.0.tgz -C /data</span><br><span class="line">[root@xiaoxiaomo opt]# mv /data/kafka_2.11-0.11.0.0/ /data/kafka</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量 &amp;&amp; 修改配置文件</span></span></span><br><span class="line">cd $KAFKA_HOME</span><br><span class="line">log.dirs=/data/data/kafka/logs</span><br><span class="line">zookeeper.connect=xiaoxiaomo:2181</span><br><span class="line">[root@xiaoxiaomo kafka]# mkdir -p /data/data/kafka/logs</span><br></pre></td></tr></table></figure></li><li><p>启动 &amp;&amp; 测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动</span></span></span><br><span class="line">[root@xiaoxiaomo kafka]# nohup /data/kafka/bin/kafka-server-start.sh /data/kafka/config/server.properties &gt;&gt;/data/data/kafka/logs/kafka-server.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 测试</span></span></span><br><span class="line">[root@xiaoxiaomo kafka]# bin/kafka-topics.sh --create --zookeeper xiaoxiaomo:2181 --replication-factor 1 --partitions 1  --topic hello</span><br><span class="line">[root@xiaoxiaomo kafka]# bin/kafka-topics.sh --describe --zookeeper xiaoxiaomo:2181   --topic hello</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/">http://blog.xiaoxiaomo.com/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/</a></p></blockquote><h2 id="安装Redis"><a href="#安装Redis" class="headerlink" title="安装Redis"></a>安装Redis</h2><ol><li><p>解压编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# yum -y install gcc #依赖于gcc</span><br><span class="line">[root@xiaoxiaomo ~]# tar -zxvf /opt/redis-3.0.6.tar.gz -C /data</span><br><span class="line">[root@xiaoxiaomo ~]# cd /data/redis-3.0.6/</span><br><span class="line">[root@xiaoxiaomo ~]# make PREFIX=/data/redis install　　　#安装到指定目录</span><br></pre></td></tr></table></figure></li><li><p>将redis做成服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###将redis_init_script复制到/etc/rc.d/init.d/同时改名为redis</span></span></span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# cp /opt/redis-3.0.6/utils/redis_init_script /etc/rc.d/init.d/redis</span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# vim /etc/rc.d/init.d/redis</span><br></pre></td></tr></table></figure></li><li><p>配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###修改下面4行</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="comment">#chkconfig: 2345 80 90   ##注意：这个在上面蓝色字体第二行</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> EXEC=/data/redis/bin/redis-server　　<span class="comment">##第七行</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> CLIEXEC=/data/redis/bin/redis-cli　　<span class="comment">##第八行</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="variable">$EXEC</span> <span class="variable">$CONF</span> &amp;　　　　<span class="comment">##第二十行</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量 &amp;&amp; 修改配置文件</span></span></span><br><span class="line">cd $REDIS_HOME</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##配置文件拷贝到/etc/redis/$&#123;REDISPORT&#125;.conf </span></span></span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# mkdir /etc/redis   </span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# cp /opt/redis-3.0.6/redis.conf /etc/redis/6379.conf</span><br></pre></td></tr></table></figure></li><li><p>注册服务 &amp;&amp; 启动 &amp;&amp; 停止</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 注册redis服务：</span></span></span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# vim /etc/redis/6379.conf</span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# service redis start ##启动</span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# service redis stop ##停止</span><br><span class="line">[root@xiaoxiaomo redis-3.0.6]# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; shutdown ##停止</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>参考：<br><a href="http://blog.xiaoxiaomo.com/2016/02/23/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BRedis/">http://blog.xiaoxiaomo.com/2016/02/23/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BRedis/</a><br><a href="http://blog.xiaoxiaomo.com/2016/04/28/Redis-%E9%9B%86%E7%BE%A4/">http://blog.xiaoxiaomo.com/2016/04/28/Redis-%E9%9B%86%E7%BE%A4/</a></p></blockquote><h2 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h2><ol><li><p>安装 &amp;&amp; 配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo opt]# tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz -C /data/</span><br><span class="line">[root@xiaoxiaomo opt]# mv /data/spark-2.0.0-bin-hadoop2.7/ /data/spark</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量</span></span></span><br><span class="line">[root@xiaoxiaomo conf]# cd $SPARK_HOME/conf</span><br><span class="line">[root@xiaoxiaomo conf]# mv spark-env.sh.template spark-env.sh</span><br><span class="line">[root@xiaoxiaomo conf]# mv slaves.template slaves</span><br><span class="line">[root@xiaoxiaomo conf]# vi spark-env.sh  </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 添加下面两项</span></span></span><br><span class="line">SPARK_MASTER_IP=xiaoxiaomo</span><br><span class="line">export JAVA_HOME=/data/jdk</span><br></pre></td></tr></table></figure></li><li><p>启动 &amp;&amp; 访问</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动</span></span></span><br><span class="line">[root@xiaoxiaomo conf]# $SPARK_HOME/sbin/start-master.sh </span><br><span class="line">[root@xiaoxiaomo conf]# $SPARK_HOME/sbin/start-slave.sh </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 访问</span></span></span><br><span class="line">http://xiaoxiaomo:8080/</span><br></pre></td></tr></table></figure></li></ol><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ol><li><p>环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/data/jdk</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/data/hadoop</span><br><span class="line">export HIVE_HOME=/data/hive</span><br><span class="line">export HBASE_HOME=/data/hbase</span><br><span class="line">export ZK_HOME=/data/zookeeper</span><br><span class="line">export KAFKA_HOME=/data/kafka</span><br><span class="line">export REDIS_HOME=/data/redis</span><br><span class="line">export SPARK_HOME=/data/spark</span><br><span class="line"></span><br><span class="line">export PATH=.:$JAVA_HOME/bin:$HADOOP_HOME/bin:$&#123;HADOOP_HOME&#125;/sbin:$HIVE_HOME/bin:$HBASE_HOME/bin:$ZK_HOME/bin:$KAFKA_HOME/bin:$REDIS_HOME/bin:$SPARK_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>软件下载(百度云下载地址)</p><blockquote><p><a href="http://blog.xiaoxiaomo.com/2017/07/30/Hadoop-快速搭建大数据开发环境/">本博客</a>所用到的所有软件（除了Virtual Box因为自己的电脑是linux系统直接就安装了没单独下再）<a href="http://pan.baidu.com/s/1ge9cHiV" target="_blank" rel="noopener">http://pan.baidu.com/s/1ge9cHiV</a></p></blockquote></li><li><p>搭建好的虚拟机下载，下载后直接导入就可以使用</p><blockquote><ol><li>本博客中讲到的所有环境已经搭建好的虚拟机下载(root密码123456)：<a href="http://pan.baidu.com/s/1slsd9iH" target="_blank" rel="noopener">http://pan.baidu.com/s/1slsd9iH</a></li><li>另外一个类似的已经搭建好的虚拟机下载(不同只是版本低一点root密码bd745127)：<a href="http://pan.baidu.com/s/1dFCKPED" target="_blank" rel="noopener">使用java1.7 + hadoop2.6 + hive0.14 + hbase0.98 + spark1.4.1 + kafka_2.11-0.8.2.2 + zk3.5.6 + redis3.0.6</a></li></ol></blockquote></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Kafka </tag>
            
            <tag> HBase </tag>
            
            <tag> Hive </tag>
            
            <tag> Spark </tag>
            
            <tag> Mysql </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--相关介绍</title>
      <link href="/2017/07/06/SparkStreaming-%E7%9B%B8%E5%85%B3%E4%BB%8B%E7%BB%8D/"/>
      <url>/2017/07/06/SparkStreaming-%E7%9B%B8%E5%85%B3%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p>　　我接着<a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从Spark组件来看Spark的执行流程"> 分享主题 </a>往下看，<a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从RDD的角度来看Spark内部原理/">上</a>两篇主要介绍了<a href="http://blog.xiaoxiaomo.com/tags/Spark/">Spark</a>，本篇文章主要介绍<code>Spark Streaming</code>相关概念，有如下内容：</p><ul><li>（介绍的比较基础哈，大神就可以跳过了，对<a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-一/"> Spark Streaming 相关的应用 </a>可以看之前的博客）</li></ul><ol><li><strong>Spark Streaming</strong> 在计算引擎中的位置</li><li><strong>Spark Streaming</strong> 的介绍</li><li><strong>Spark Streaming</strong> 处理的数据流</li><li><strong>Spark Streaming</strong> 相关概念</li></ol><a id="more"></a><h1 id="Spark-Streaming-在计算引擎中的位置"><a href="#Spark-Streaming-在计算引擎中的位置" class="headerlink" title="Spark Streaming 在计算引擎中的位置"></a>Spark Streaming 在计算引擎中的位置</h1><ul><li>在分布式计算中，大致分为了两类：离线批处理和实时流计算（还有一种中间状态<strong>近实时计算</strong>）</li></ul><ol><li><code>离线批处理</code>：以处理大批量数据为主，常常用于数据仓库中的ETL，<strong>对时效性相对要求不高</strong>（可以以分钟小时为单位）常见的框架有MapReduce、Spark job、FlinK DataSet；</li><li><code>实时流计算</code>：主要以小批量数据处理为主，<strong>对时效性相对要求高</strong>（以毫秒|秒为单位），最开始的Storm(JStorm)、最近火的Flink；</li><li><code>近实时计算</code>：还有一种在离线批处理和实时流计算中间的，就是该篇博客的主角了“<strong>Spark Streaming</strong>”，目前来讲它<strong>并非实时计算</strong>（Spark 2.2版本之后就很难讲了）。<br><img src="https://img.xiaoxiaomo.com/blog/img/SparkStreaming55.jpg" alt="Spark Streaming 在流式计算中的位置"></li></ol><h1 id="Spark-Streaming-的介绍"><a href="#Spark-Streaming-的介绍" class="headerlink" title="Spark Streaming 的介绍"></a>Spark Streaming 的介绍</h1><ul><li><code>Spark Streaming</code> ：<strong>基于Spark core的计算模型</strong>，Spark最开始只有Spark Core，之后的SQL\Streaming\MLib\Graphx 都是在Spark Core上面进行的扩展。</li><li>那相比其他流计算框架 Spark Streaming 所具备的一些优势是什么呢？具体可参考：<a href="http://www.csdn.net/article/2015-09-13/2825689" target="_blank" rel="noopener">http://www.csdn.net/article/2015-09-13/2825689</a>（PS：如果Flink普及之后，感觉Spark Streaming并没有太多优势）</li></ul><ol><li>能在故障报错与straggler的情况下迅速恢复状态；</li><li>更好的负载均衡与资源使用；</li><li>静态数据集与流数据的整合和可交互查询；</li><li>内置丰富高级算法处理库，可以很好的和SQL、机器学习、图处理结合，常说的在流上做机器学习，图处理等。</li></ol><ul><li><code>Spark Streaming</code> 整个计算流程大致描述就是：<strong>输入的数据通过Spark Streaming处理成一小批小批的数据</strong>，然后交给<code>Spark Engine</code>处理（<strong>Spark Engine 处理的数据封装就是RDD</strong>）<br><img src="https://img.xiaoxiaomo.com/blog/img/SparkStreaming57.png" alt="Spark Streaming 计算模型"></li></ul><h1 id="Spark-Streaming-处理的数据流"><a href="#Spark-Streaming-处理的数据流" class="headerlink" title="Spark Streaming 处理的数据流"></a>Spark Streaming 处理的数据流</h1><ul><li><code>Spark Streaming</code> <strong>支持从多种数据源获取数据</strong>，包括 <strong>Kafka</strong>、<strong>Flume</strong>、<strong>Twitter</strong>、<strong>ZeroMQ</strong>、<strong>Kinesis</strong> 以及<strong>TCP sockets</strong>，从数据源获取数据之后，可以使用诸如map、reduce、join和window等高级函数进行复杂算法的处理。</li><li>在我们开发的时候引入相应的jar就可以了，比如source端是kafka，spark streaming作为消费者消费kafka数据就需引入<code>spark-streaming-kafka_2.xx</code> <code>eg</code> : val kafkaMsg=KafkaUtils.createDirectStream(ssc, kafkaParams, fromOffsets, messageHandler)<br><img src="https://img.xiaoxiaomo.com/blog/img/SparkStreaming56.png" alt="Spark Streaming 处理的数据流图"></li></ul><h1 id="Spark-Streaming-相关概念"><a href="#Spark-Streaming-相关概念" class="headerlink" title="Spark Streaming 相关概念"></a>Spark Streaming 相关概念</h1><ul><li>上面提到 <code>Spark Streaming</code> <strong>是基于Spark core的计算模型，其实底层组件还是核心RDD，只不过在Streaming这边是对RDD做了一层封装叫做DStream</strong>。</li></ul><ol><li><code>RDD</code>：Spark最核心的概念(<a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从RDD的角度来看Spark内部原理/">RDD详细讲解参考</a>)</li><li><code>DStream</code>：对RDD的封装</li><li><code>DStreams(Discretized Streams)</code>：一系列连续数据流的抽象。</li><li><code>一系列</code>：指的就是一段时间间隔（时间窗口）</li><li><code>数据流</code>：数据指的就是RDD(分布式数据集)<br><img src="https://img.xiaoxiaomo.com/blog/img/SparkStreaming59.jpg" alt="Spark Streaming DStream 图解"></li></ol><ul><li>（我看网上介绍Streaming概念就是大篇文字描述，这样感觉概念讲的不够简洁明了，倒还扰乱了你的思路！我喜欢各种表现形式，图片文字代码）</li></ul><ol><li><p><code>理解一下时间窗口和间隔时间</code>，先看看代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">                .set(<span class="string">"spark.streaming.kafka.maxRatePerPartition"</span>, maxRatePerPartition) <span class="comment">//此处为每秒每个partition的条数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(timeWindow.toInt)) <span class="comment">//多少秒处理一次请求</span></span><br></pre></td></tr></table></figure></li><li><p><strong>时间窗口和间隔时间</strong>，因为streaming是处理小批量数据，把多少数据认为是一个批次呢？就是通过时间间隔来划分，让streaming job多久去处理一次（多久去消费一次数据）这段时间的相关计算可以理解成一个时间窗口。</p></li><li>怎么去设置相应的值，可参考：<a href="http://blog.xiaoxiaomo.com/2017/06/29/SparkStreaming-应用与实战-六/">Streaming 任务的划分</a><br><img src="https://img.xiaoxiaomo.com/blog/img/SparkStreaming58.png" alt="DStreams(Discretized Streams)"></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark--从RDD的角度来看Spark内部原理</title>
      <link href="/2017/07/05/Spark-%E4%BB%8ERDD%E7%9A%84%E8%A7%92%E5%BA%A6%E6%9D%A5%E7%9C%8BSpark%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/"/>
      <url>/2017/07/05/Spark-%E4%BB%8ERDD%E7%9A%84%E8%A7%92%E5%BA%A6%E6%9D%A5%E7%9C%8BSpark%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/</url>
      <content type="html"><![CDATA[<p>　　- 上篇博客主要讲了<a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从Spark组件来看Spark的执行流程/">Spark的执行流程</a>，看完后应该是对Spark有一个整体的了解，对Spark各个组件的工作流程都应该是有一个很清晰的认识了。<br>本篇博客，笔者主要是继续接着“<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener">宜人蜂巢内部分享</a>”，从RDD的角度来看Spark的内部原理，包括以下内容：</p><blockquote><ol><li>RDD为什么是Spark的核心概念</li><li>通过一个wordCount例子来看一看RDD</li><li>RDD的管理与操作（算子）</li><li>常见的RDD操作有哪些（包括RDD的分类）</li><li>RDD的依赖关系（DAG）</li><li>RDD依赖关系的划分（stage）</li></ol></blockquote><a id="more"></a><h1 id="RDD为什么是Spark的核心概念"><a href="#RDD为什么是Spark的核心概念" class="headerlink" title="RDD为什么是Spark的核心概念"></a>RDD为什么是Spark的核心概念</h1><ul><li><code>Spark建立在统一抽象的RDD之上</code>，使得Spark可以很容易扩展，比如 Spark Streaming、Spark SQL、Machine Learning、Graph都是在spark RDD上面进行的扩展（可以看见RDD的核心地位了吧）</li><li><strong>RDD是什么呢？理解一下概念</strong>：</li></ul><ol><li>RDD(Resilient Distributed Dataset)：弹性分布式数据集。</li><li>RDD是只读的，由多个partition组成</li><li>Partition分区，和Block数据块是一一对应的<br><img src="https://img.xiaoxiaomo.com/blog/img/spark15.jpg" alt="RDD 与 Partition、Block 的对应关系图"></li></ol><h1 id="通过一个wordCount例子来看一看RDD"><a href="#通过一个wordCount例子来看一看RDD" class="headerlink" title="通过一个wordCount例子来看一看RDD"></a>通过一个wordCount例子来看一看RDD</h1><ul><li>上面只是RDD的概念，下面举个wordCount的例子来说明一下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> file = sc.textFile(<span class="string">"hdfs://data/test.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data = file.flatMap(_.split(<span class="string">" "</span>)).map((_,<span class="number">1</span>)).reduceByKey(_ + _)</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog/img/spark13.jpg" alt="wordCount 例子，执行示意图"></p><ul><li>Spark 程序具体的流程图<br><img src="https://img.xiaoxiaomo.com/blog/img/spark06.jpg" alt="Spark 程序具体的流程图"></li></ul><ol><li>客户端提交任务，<strong>初始化sparkContext之后</strong>，sc.textFile(“hdfs://“)，去hdfs加载文件</li><li>加载的文件比如有300MB，在hdfs中就有3个block块，对应 RDD 里面的三个partition</li><li><code>加载的这个过程其实就是RDD的创建（MapPartitionsRDD）</code></li><li>数据被加载到不同的partition中，通过构建的stage（task set）然后提交到executor中去并行计算</li><li>计算完成后输出结果</li></ol><ul><li>在整个spark计算流程里面，RDD起到了一些什么作用？</li></ul><blockquote><p>作用当然大了！可以看出整个计算流程都是基于RDD在做计算,从数据加载，即RDD的创建,中途的计算（stage的划分，RDD的操作，shuffle）。到最后结果的输出，整个计算流程都是由RDD在贯穿</p></blockquote><blockquote><p>写博客其实挺累的，太耗时了</p></blockquote><blockquote><p>…</p></blockquote><blockquote><p>继续吧，既然已经开始…..</p></blockquote><h1 id="RDD的管理与操作（算子）"><a href="#RDD的管理与操作（算子）" class="headerlink" title="RDD的管理与操作（算子）"></a>RDD的管理与操作（算子）</h1><ul><li><strong>RDD管理</strong></li></ul><ol><li>RDD是一个分布式数据集，即数据分布存储在多台机器上。从上面也可以看到，每个RDD的数据都以Block的形式存储于多台机器上</li><li>在Spark任务运行时</li><li><strong>Driver 节点</strong>的BlockManagerMaster保存Block的元数据，并且管理RDD与Block的关系。</li><li><strong>Executor </strong>会启动一个BlockManagerSlave，管理Block数据并向BlockManagerMaster注册该Block</li><li>当RDD不再需要存储的时候，BlockManagerMaster将向BlockManagerSlave发送指令删除相应的Block。<br><img src="https://img.xiaoxiaomo.com/blog/img/spark08.jpg" alt="RDD管理"></li></ol><ul><li><p><strong>RDD操作</strong><br>RDD还提供了一组丰富的操作来操作这些数据，这种操作叫做算子。比如map、flatMap、filter、join、groupBy、reduceByKey等</p></li><li><p>RDD分类，分为创建算子、转换、缓存、执行</p></li></ul><ol><li><code>Transformation</code>：转换算子，这类转换并不触发提交作业，完成作业中间过程处理。</li><li><code>Action</code>：行动算子，这类算子会触发SparkContext提交Job作业。<br><img src="https://img.xiaoxiaomo.com/blog/img/spark09.jpg" alt="RDD操作"></li></ol><h1 id="常见的RDD操作有哪些（包括RDD的分类）"><a href="#常见的RDD操作有哪些（包括RDD的分类）" class="headerlink" title="常见的RDD操作有哪些（包括RDD的分类）"></a>常见的RDD操作有哪些（包括RDD的分类）</h1><ul><li><p>常见的算子，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog/img/spark10.jpg" alt="常见的算子"></p></li><li><p>具体的来看一下，例如map算子示例如下：<br><img src="https://img.xiaoxiaomo.com/blog/img/spark16.jpg" alt=""></p></li></ul><h1 id="RDD的依赖关系（DAG）"><a href="#RDD的依赖关系（DAG）" class="headerlink" title="RDD的依赖关系（DAG）"></a>RDD的依赖关系（DAG）</h1><ul><li>RDD的依赖关系有两种：窄依赖（narrow dependency）和宽依赖（wide dependency）。</li></ul><ol><li><code>窄依赖</code>：<strong>每一个parent RDD的Partition最多被子RDD的一个Partition使用</strong></li><li><code>宽依赖</code>：<strong>多个子RDD的Partition会依赖同一个parent RDD的Partition</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/spark11.jpg" alt="RDD的依赖关系--血统（左边窄依赖，右边宽依赖）"></li></ol><ul><li><strong>依赖的具体实现</strong>，以及怎么去知道是窄依赖还是宽依赖？</li></ul><ol><li><p><strong>所有的依赖</strong>都要实现trait <code>Dependency[T]</code></p><blockquote><p>abstract class Dependency[T] extends Serializable {<br>　　　　def rdd: RDD[T]<br>  }</p></blockquote></li><li><p><strong>窄依赖</strong>是有两种具体实现 <code>OneToOneDependency</code> 和 <code>RangeDependency</code></p><blockquote><p>abstract class NarrowDependency<a href="_rdd: RDD[T]">T</a> extends Dependency[T] {<br>　　　　def getParents(partitionId: Int): Seq[Int]<br>　　　　override def rdd: RDD[T] = _rdd<br>}</p><p>//OneToOneDependency<br>class OneToOneDependency<a href="rdd: RDD[T]" target="_blank" rel="noopener">T</a> extends NarrowDependency<a href="rdd">T</a> {<br>　　　　override def getParents(partitionId: Int) = List(partitionId)</p><p>//RangeDependency<br>class RangeDependency<a href="rdd: RDD[T], inStart: Int, outStart: Int, length: Int" target="_blank" rel="noopener">T</a> extends NarrowDependency<a href="rdd">T</a> {</p><p>　　override def getParents(partitionId: Int): List[Int] = {<br>　　　　if (partitionId &gt;= outStart &amp;&amp; partitionId &lt; outStart + length) {<br>　　　　　　List(partitionId - outStart + inStart)<br>　　　　} else {<br>　　　　　　Nil<br>　　　　}<br>　　}<br>}</p></blockquote></li><li><p><strong>宽依赖</strong>的实现只有一种：<code>ShuffleDependency</code></p><blockquote><p>class ShuffleDependency[K, V, C] extends Dependency[Product2[K, V]] { … }</p></blockquote></li><li><p><strong>窄依赖|宽依赖，可以通过dependencies方法来查看</strong>，以上面的wordCount为例，可以看到res4（reduceByKey）为宽依赖<br><img src="https://img.xiaoxiaomo.com/blog/img/spark14.jpg" alt="RDD依赖关系的划分（stage）"></p></li></ol><h1 id="RDD依赖关系的划分（stage）"><a href="#RDD依赖关系的划分（stage）" class="headerlink" title="RDD依赖关系的划分（stage）"></a>RDD依赖关系的划分（stage）</h1><ul><li><code>RDD依赖关系的划分</code>，RDD怎么被划分到一个stage里面？</li></ul><ol><li>就是<strong>通过窄依赖和宽依赖来划分stage的</strong></li><li>如果是窄依赖就他们放在一个Stage里面，<strong>遇到宽依赖就断开</strong>划分为另外一个stage</li><li>如上面的workCount例子，就划分为了两个stage，在reduceByKey的时候断开了</li><li>如下图，遇到groupByKey断开，为一个stage1，map、union为窄依赖遇到join断开划分为stage2，其余划分为stage3<br><img src="https://img.xiaoxiaomo.com/blog/img/spark12.jpg" alt="RDD依赖关系的划分（stage）"></li></ol><ul><li>参考：</li></ul><ol><li><a href="http://blog.csdn.net/wangxiaotongfan/article/details/51395769" target="_blank" rel="noopener">http://blog.csdn.net/wangxiaotongfan/article/details/51395769</a></li><li><a href="http://www.cnblogs.com/zlslch/p/5723403.html" target="_blank" rel="noopener">http://www.cnblogs.com/zlslch/p/5723403.html</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark--从Spark组件来看Spark的执行流程</title>
      <link href="/2017/07/05/Spark-%E4%BB%8ESpark%E7%BB%84%E4%BB%B6%E6%9D%A5%E7%9C%8BSpark%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
      <url>/2017/07/05/Spark-%E4%BB%8ESpark%E7%BB%84%E4%BB%B6%E6%9D%A5%E7%9C%8BSpark%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>　　上周在<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener"> 宜人蜂巢 </a>内部分享了 <code>spark</code> 、和 <code>spark streaming</code> 相关的主题，现在有些空闲时间，就整理了一下，放在博客上面。</p><ul><li>一篇博客描述不完整，即使讲完了也会显得很臃肿，所以会分为以下几篇博客来讲解：</li></ul><ol><li><a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从Spark组件来看Spark的执行流程/">Spark – Spark 相关介绍（如下）</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从Spark组件来看Spark的执行流程/">Spark – 从Spark组件来看Spark的执行流程（如下）</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/07/05/Spark-从RDD的角度来看Spark内部原理/">Spark – 从RDD的角度来看Spark内部原理</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/07/06/SparkStreaming-相关介绍/">Spark Streaming – 相关介绍</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-一/">Spark Streaming – 相关应用（这个之前的博客已经讲了）</a></li></ol><a id="more"></a><h1 id="Spark-相关介绍"><a href="#Spark-相关介绍" class="headerlink" title="Spark 相关介绍"></a>Spark 相关介绍</h1><ul><li>这个介绍就没有什么好讲的哈，即使读者自己没去研究过 spark，也多多少少有些了解了，毕竟很火嘛，直接发几张图片</li><li><p>Spark <a href="http://spark.apache.org/" target="_blank" rel="noopener">一站式大数据处理平台</a><br><img src="https://img.xiaoxiaomo.com/blog/img/spark03.png" alt="Spark 一站式大数据处理平台（图片来源于网络）"></p></li><li><p><strong>Spark vs Hadoop</strong></p></li></ul><ol><li>右箭头”→”就是表示,Hadoop 组件 与 Spark 组件的直观对比</li><li>双箭头，Yarn 与 Mesos 就是他们共存的，都可以使用yarn或者mesos作为调度器</li><li>虚线，Tachyon 主要用于Spark ，并且可以基于HDFS</li><li>至于常常讨论的 Spark 为什么比<a href="http://blog.xiaoxiaomo.com/2016/07/03/Hadoop-MapReduce详解/">MapReduce</a>快，主要是它们的计算模型很大不同，MapReduce落地磁盘比较多<br><img src="https://img.xiaoxiaomo.com/blog/img/spark04.png" alt="Spark vs Hadoop（图片来源:https://www.slideshare.net/SparkSummit/dev-ops-training）"></li></ol><ul><li><strong>Spark vs Flink</strong></li></ul><ol><li><code>Flink</code>也是后起之秀哈，势头猛的很，还有阿里的Blink在支撑，感觉流行起来是迟早的事情</li><li><code>流计算</code>这些 Flink 是要强一点，真正的流计算。不过前段时间的<a href="https://spark-summit.org/" target="_blank" rel="noopener"><code>Spark Summit 2017</code></a>大会也是说spark 2.2后重点会是流计算与深度学习</li><li><code>Spark SQL</code>或者<code>Hive on Spark</code> 相对与 Flink 也是有优势</li><li>总的来说与 Flink 里面的东西差不多，如果对 Spark 深入了解后对 Flink 的应用也是简单事情。</li></ol><h1 id="从Spark组件来看Spark的执行流程"><a href="#从Spark组件来看Spark的执行流程" class="headerlink" title="从Spark组件来看Spark的执行流程"></a>从Spark组件来看Spark的执行流程</h1><h2 id="Spark架构分布"><a href="#Spark架构分布" class="headerlink" title="Spark架构分布"></a>Spark架构分布</h2><ul><li><p>下面来看看<code>spark各个节点的分布图</code>，如下<br><img src="https://img.xiaoxiaomo.com/blog/img/spark00.jpg" alt="spark各个节点的分布图"></p></li><li><p><strong>Spark采用的是Master-Slave模型</strong>，从上面可以看出分为四个部分，Client、Driver、ClusterManager、Worker</p></li></ul><ol><li><code>client</code>：客户端进程，负责提交job到master</li><li><code>Driver</code>：运行Application，主要是做一些job的初始化工作，包括job的解析，DAG的构建和划分并提交和监控task</li><li><code>Cluster Manager</code>：在standalone模式中即为Master主节点，控制整个集群，监控worker，在YARN模式中为资源管理器ResourceManager</li><li><code>Worker</code>：负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver。<code>Executor</code>，即真正执行作业的地方，一个Executor可以执行一到多个<code>Task</code></li></ol><h2 id="Spark执行流程"><a href="#Spark执行流程" class="headerlink" title="Spark执行流程"></a>Spark执行流程</h2><p> <strong>再把图细画一下</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/spark01.jpg" alt="spark执行流程图，ps:不清楚可以点击放大了看"></p><ol><li>通过<code>SparkSubmit提交job后</code>，<code>Client就开始构建</code> spark context，即 application 的运行环境（使用本地的Client类的main函数来创建spark context并初始化它）</li><li><strong>yarn client</strong>提交任务，<code>Driver在客户端本地运行</code>；<strong>yarn cluster</strong>提交任务的时候，<code>Driver是运行在集群上</code></li><li><strong>SparkContext</strong>连接到<code>ClusterManager(Master)</code>，向资源管理器注册并申请运行Executor的资源（内核和内存）</li><li><code>**Master**根据SparkContext提出的申请</code>，根据worker的心跳报告，来决定到底在那个worker上启动executor</li><li><strong>Worker节点</strong>收到请求后会<code>启动executor</code></li><li><code>executor向SparkContext注册</code>，这样driver就知道哪些executor运行该应用</li><li>SparkContext<code>将Application代码发送给executor</code>（如果是standalone模式就是StandaloneExecutorBackend）</li><li><code>同时SparkContext解析Application代码</code>，<strong>构建DAG图，提交给DAGScheduler进行分解成stage，stage被发送到TaskScheduler</strong>。</li><li><code>TaskScheduler负责将Task分配到相应的worker</code>上，最后<strong>提交给executor执行</strong></li><li><strong>executor会建立Executor线程池</strong>，<code>开始执行Task</code>，并向SparkContext汇报,直到所有的task执行完成</li><li>所有Task完成后，<code>SparkContext向Master注销</code></li></ol><ul><li>参考资料</li></ul><ol><li><a href="http://www.jianshu.com/p/612ad0898fe2" target="_blank" rel="noopener">http://www.jianshu.com/p/612ad0898fe2</a></li><li><a href="http://www.cnblogs.com/shishanyuan/archive/2015/08/19/4721326.html" target="_blank" rel="noopener">http://www.cnblogs.com/shishanyuan/archive/2015/08/19/4721326.html</a></li><li><a href="http://blog.csdn.net/do_what_you_can_do/article/details/53128480" target="_blank" rel="noopener">http://blog.csdn.net/do_what_you_can_do/article/details/53128480</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(六)</title>
      <link href="/2017/06/29/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E5%85%AD/"/>
      <url>/2017/06/29/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E5%85%AD/</url>
      <content type="html"><![CDATA[<h1 id="管理Streaming任务"><a href="#管理Streaming任务" class="headerlink" title="管理Streaming任务"></a>管理Streaming任务</h1><p>　　- 这是目前<a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-一/"><code>Spark Streaming</code></a>系列博客的最后一篇文章了，该篇文章主要讲一下我自己对<code>Spark Streaming</code>任务的一些划分，还有一个<code>Spark Streaming</code>任务的邮件监控。</p><h2 id="Streaming-任务的划分"><a href="#Streaming-任务的划分" class="headerlink" title="Streaming 任务的划分"></a>Streaming 任务的划分</h2><a id="more"></a><ul><li>当<code>Spark Streaming</code>开发完成，测试完成之后，就发布上线了，<code>Spark Streaming</code>任务的划分，以及时间窗口调试多少这些都是更具业务划分的。</li></ul><ol><li>kafka 一个topic对应HBase里面的一张表</li><li>Kafka topic 里面的partition（3-5个不等）</li><li>Streaming job即Kafka消费者，消费一个或多个Kafka topic</li></ol><ul><li>那一个Streaming消费者到底去对应哪些topic呢？还有为什么这么划分，以及这样划分有什么好处呢？</li></ul><ol><li>因为kafka topic对应了业务中的具体HBase表，然后就通过监控HBase表插入流量来判断该表插入情况</li><li>对于HBase表数据的插入量划分了5种，插入量特别大、插入条数多每条数据量不大、每次插入数据量少数据大、比较均匀、插入少不频繁</li><li>对于插入量特别大，比如该表都占了插入总量的10%、20%的这种就独立出来一张表对应一个streaming消费者</li><li>插入条数多每条数据量不大，就是把插入比较频繁的可以放在一起，这时候可以调小<code>timeWindow</code></li><li>每次插入数据量少数据大，就是可以看见插入每次都是1000条，2000条，有些时间间隔，就可以调大<code>timeWindow</code>时间间隔，<code>maxRatePerPartition</code>设置大一点</li><li>比较均匀就好办了，很好设置参数</li><li>插入少不频繁，可以调大timeWindow到几秒，甚至太少，太不频繁可以继续调大</li><li>好处大家应该也看出来了吧，资源的合理利用，对streaming的优化，<code>timeWindow</code>、<code>maxRatePerPartition</code>对应不同表，增加和控制了并发量</li></ol><h2 id="Streaming-任务的监控"><a href="#Streaming-任务的监控" class="headerlink" title="Streaming 任务的监控"></a>Streaming 任务的监控</h2><ul><li><p>对于<code>Spark Streaming job</code>的监控，自带的<code>Streaming UI</code>能看到具体的一些流量，时间等信息，但是缺少了一个通知，于是简单的开发了一个。<br>在监控这一块也想了不少方案，比如监控pid，通过shell去监控，或者直接调用源码里面的方法，都尝试过，有的要么没达到预期的效果，要么有的不是很好维护开发成本高</p></li><li><p>最终选了一个比较简单的，但是又能达到一定效果的，通过py爬虫，到原始的streaming UI界面去获取到具体的信息，来监控，到达阈值就发送邮件，总体步骤如下：</p></li></ul><ol><li>通过job name在<code>yarn 8088界面/cluster/apps/RUNNING</code>找到<code>ApplicationMaster</code>URL地址</li><li>然后通过该地址到streaming界面监控具体Streaming job的<code>Scheduling Delay</code>、<code>Processing Time</code>值<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming38.png" alt="yarn 8088界面/cluster/apps/RUNNING"></li></ol><ul><li><p>具体代码<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming39.png" alt="Python 监控爬虫 邮件通知"></p></li><li><p>参考：<a href="http://www.th7.cn/Program/Python/201612/1035126.shtml" target="_blank" rel="noopener">http://www.th7.cn/Program/Python/201612/1035126.shtml</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(五)</title>
      <link href="/2017/06/29/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%BA%94/"/>
      <url>/2017/06/29/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%BA%94/</url>
      <content type="html"><![CDATA[<p>　　前期的一系列 <strong><strong><em>Spark Streaming相关博客</em></strong></strong> 其实还没写完，对于<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener">宜人蜂巢</a>这样一个多维度的实时数据抓取服务来讲，对性能的要求极高，需要更多的压测与性能检测。 <strong>还有一些优化和监控，一直没更新主要是因为还不够完善</strong>，但是最近也没时间来弄了。虽然不完善但是还是可以写写已经完成的，因为也有不少网友通过微信和邮件联系到了我，也讨论了一些问题，后续再继续跟进吧。</p><h1 id="Streaming-持续优化之HBase"><a href="#Streaming-持续优化之HBase" class="headerlink" title="Streaming 持续优化之HBase"></a>Streaming 持续优化之HBase</h1><a id="more"></a><h2 id="设置WALog"><a href="#设置WALog" class="headerlink" title="设置WALog"></a>设置WALog</h2><blockquote><p>put.setDurability(Durability.SKIP_WAL)/*<em> 跳过写WALog </em>/</p></blockquote><ul><li><p><strong>关闭WALog</strong>后写入能到20万，但是发现还是不是特别稳定，有时耗时还是比较长的，发现此阶段正在做Compaction!!!<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming31.png" alt="查看streaming统计,发现耗时不稳定"><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming32.png" alt="HBase界面统计信息"></p></li><li><p>HBase是一种Log-Structured Merge Tree架构模式，用户数据写入先写WAL，再写缓存，满足一定条件后缓存数据会执行flush操作真正落盘，形成一个数据文件HFile。随着数据写入不断增多，flush次数也会不断增多，进而HFile数据文件就会越来越多。然而，太多数据文件会导致数据查询IO次数增多，因此HBase尝试着不断对这些文件进行合并，<strong>这个合并过程称为Compaction</strong>。</p></li><li><p>Compaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，<strong>这个新生成的文件就会取代之前待合并的所有文件对外提供服务</strong>。<br>HBase根据合并规模将Compaction分为了两类：MinorCompaction和MajorCompaction</p><blockquote><p><code>Minor Compaction</code>是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。<br><code>Major Compaction</code>是指将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。另外，一般情况下，Major Compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。<br>更多Compaction信息参考：<a href="http://hbasefly.com/2016/07/13/hbase-compaction-1/" target="_blank" rel="noopener">http://hbasefly.com/2016/07/13/hbase-compaction-1/</a></p></blockquote></li></ul><h2 id="调整压缩"><a href="#调整压缩" class="headerlink" title="调整压缩"></a>调整压缩</h2><ul><li><p>通常生产环境会关闭自动major_compact(配置文件中hbase.hregion.majorcompaction设 为0)，选择一个晚上用户少的时间窗口手工major_compact</p><blockquote><p>手动：major_compact ‘testtable’<br>如果hbase更新不是太频繁，可以一个星期对所有表做一次 major_compact，这个可以在做完一次major_compact后，观看所有的storefile数量，如果storefile数量增加到 major_compact后的storefile的近二倍时，可以对所有表做一次major_compact，时间比较长，操作尽量避免高锋期。<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming33.png" alt="查看统计信息"></p></blockquote></li><li><p>Compact触发条件</p></li></ul><ol><li>memstore flush之后触发</li><li>客户端通过shell或者API触发</li><li>后台线程CompactionChecker定期触发<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming34.png" alt="查看统计信息"><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming35.png" alt="查看统计信息"><blockquote><p><strong>周期为</strong>：<code>Hbase.server.thread.wakefrequencyhbase.server.compactchecker.interval.multiplier</code>触发compaction，后面还有一些其他的条件也可以在源码里面看看<br><strong>条件的验证逻辑就是在这个时间范围</strong>：mcTime= 7-70.5天,7+7*0.5天=3.5-10.5;<br><strong>是否有文件修改具体逻辑可见RatioBasedCompactionPolicy#isMajorCompaction方法</strong>。 <a href="http://blog.csdn.net/c77_cn/article/details/38820379" target="_blank" rel="noopener">http://blog.csdn.net/c77_cn/article/details/38820379</a></p></blockquote></li></ol><h2 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h2><ul><li><p>通过上面的截图我们可以看到，该表只有一个region，写入数据都集中到了一台服务器，这个远远没有发挥出HBase集群的能力呀，手动拆分吧！<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming36.png" alt="通过hbase ui界面拆分Region"></p></li><li><p>拆分后<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming37.png" alt="Region拆分后"></p></li></ul><h2 id="待续"><a href="#待续" class="headerlink" title="待续"></a>待续</h2>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(四)</title>
      <link href="/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E5%9B%9B/"/>
      <url>/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E5%9B%9B/</url>
      <content type="html"><![CDATA[<p>　　对项目做压测与相关的优化，主要从内存(executor-memory和driver-memory)、num-executors、executor-cores，以及代码层面做一些测试和改造。</p><h1 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h1><ol><li><code>spark-submit –master yarn-client –conf spark.driver.memory=256m –class com.xiaoxiaomo.KafkaDataStream –num-executors 1 –executor-memory 256m –executor-cores 2 –conf spark.locality.wait=100ms hspark.jar 3 1000</code><br>Spark streaming 处理速度为3s一次，每次1000条<br>Kafka product 每秒1000条数据， 与上面spark consumer消费者恰好相等。结果：数据量大导致积压，这个过程中active Batches会越变越大.<a id="more"></a></li></ol><ul><li>调整Kafka product 每秒600条数据，存在积压，但已经不严重<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming17.png" alt="Kafka product 每秒600条数据，存在积压"></li><li>调整Kafka product 每秒500条数据，为消费者50%，测试结果显示正常，等待时间很稳定<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming18.png" alt="Kafka product 每秒500条数据，正常"></li></ul><p>但是。此时每秒吞吐量为500 显然不够</p><ol start="2"><li>通过调整间歇实际等，发现并没有变化<br><code>spark-submit –master yarn-client –conf spark.driver.memory=256m –class com.xiaoxiaomo.KafkaDataStream –num-executors 1 –executor-memory 256m –executor-cores 2 –conf spark.locality.wait=100ms hspark.jar 2 2000 Spark streaming 处理速度为2s一次，每次2000条</code><br>Kafka product 每秒500条数据，可以看见没有在指定时间内消费完数据，照成数据积压，并发下降了<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming19.png" alt="Kafka product 每秒500条数据，没有在指定时间内消费完"></li></ol><h1 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h1><ul><li>分析原因，发现大部分耗时都在处理数据这样一阶段，如下图所示<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming20.png" alt="Streaming 时间分析图"></li></ul><h1 id="调整参数"><a href="#调整参数" class="headerlink" title="调整参数"></a>调整参数</h1><ul><li><p>调整 executor-cores<br>–executor-cores 2 并发上升至700/s<br>–executor-cores 3 并发上升至750/s<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming21.png" alt="调整executor-cores后"></p></li><li><p>调整executor内存，并发没有增长，无效<br>–executor-memory 512m<br>–conf spark.yarn.executor.memoryOverhead=512</p></li><li><p>调整am内存，并发没有增长，无效<br>–am-memory 512m<br>–conf spark.yarn.am.memoryOverhead=512</p></li></ul><h1 id="代码调整"><a href="#代码调整" class="headerlink" title="代码调整"></a>代码调整</h1><ul><li><p>发现现在主要还是在处理数据的时候消耗时间一直没有减少，而处理数据查看后发现是一条一条的往hbase里面插入的，修改为批量插入，重新构建了json.性能猛增！！ 修改前的代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * 插入数据到 HBase</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * 参数( tableName ,  json ) )：</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * Json格式：</span></span><br><span class="line"><span class="comment">  *     &#123;</span></span><br><span class="line"><span class="comment">  *         "rowKey": "00000-0",</span></span><br><span class="line"><span class="comment">  *         "family:qualifier": "value",</span></span><br><span class="line"><span class="comment">  *         "family:qualifier": "value",</span></span><br><span class="line"><span class="comment">  *         ......</span></span><br><span class="line"><span class="comment">  *     &#125;</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * @param data</span></span><br><span class="line"><span class="comment">  * @return</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(data: (<span class="type">String</span>, <span class="type">String</span>)): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> t: <span class="type">HTable</span> = getTable(data._1) <span class="comment">//HTable</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> map: mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">JsonUtils</span>.json2Map(data._2)</span><br><span class="line">        <span class="keyword">val</span> rowKey: <span class="type">Array</span>[<span class="type">Byte</span>] = <span class="type">String</span>.valueOf(map.get(<span class="string">"rowKey"</span>)).getBytes <span class="comment">//rowKey</span></span><br><span class="line">        <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(rowKey)</span><br><span class="line">        <span class="keyword">for</span> ((k, v) &lt;- map) &#123;</span><br><span class="line">            <span class="keyword">val</span> keys: <span class="type">Array</span>[<span class="type">String</span>] = k.split(<span class="string">":"</span>)</span><br><span class="line">            <span class="keyword">if</span> (keys.length == <span class="number">2</span>)&#123;</span><br><span class="line">                put.addColumn(keys(<span class="number">0</span>).getBytes, keys(<span class="number">1</span>).getBytes, <span class="type">String</span>.valueOf(v).getBytes)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Try</span>(t.put(put)).getOrElse(t.close())</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">            e.printStackTrace()</span><br><span class="line">            <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改后的代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//数据操作</span></span><br><span class="line">messages.foreachRDD(rdd =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> offsetsList: <span class="type">Array</span>[<span class="type">OffsetRange</span>] = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">    <span class="comment">//data 处理</span></span><br><span class="line">    rdd.foreachPartition(partitionRecords =&gt; &#123;</span><br><span class="line">        <span class="comment">//TaskContext 上下文</span></span><br><span class="line">        <span class="keyword">val</span> offsetRange: <span class="type">OffsetRange</span> = offsetsList(<span class="type">TaskContext</span>.get.partitionId)</span><br><span class="line">        logger.debug(<span class="string">s"<span class="subst">$&#123;offsetRange.topic&#125;</span> <span class="subst">$&#123;offsetRange.partition&#125;</span> <span class="subst">$&#123;offsetRange.fromOffset&#125;</span> <span class="subst">$&#123;offsetRange.untilOffset&#125;</span>"</span>)</span><br><span class="line">        <span class="comment">//TopicAndPartition 主构造参数第一个是topic，第二个是Kafka partition id</span></span><br><span class="line">        <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(offsetRange.topic, offsetRange.partition)</span><br><span class="line">        <span class="keyword">val</span> either = kc.setConsumerOffsets(groupName, <span class="type">Map</span>((topicAndPartition, offsetRange.untilOffset))) <span class="comment">//是</span></span><br><span class="line">        <span class="keyword">if</span> (either.isLeft) &#123;</span><br><span class="line">            logger.info(<span class="string">s"Error updating the offset to Kafka cluster: <span class="subst">$&#123;either.left.get&#125;</span>"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/** 解析PartitionRecords数据 */</span></span><br><span class="line">        <span class="keyword">if</span> (offsetRange.topic != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">HBaseDao</span>.insert(offsetRange.topic, partitionRecords)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li><li><p>插入数据到 HBase</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * 插入数据到 HBase</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * 参数( tableName , [( tableName , json )] )：</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * Json格式：</span></span><br><span class="line"><span class="comment">  *     &#123;</span></span><br><span class="line"><span class="comment">  *         "r": "00000-0",</span></span><br><span class="line"><span class="comment">  *         "f": "family",</span></span><br><span class="line"><span class="comment">  *         "q": [</span></span><br><span class="line"><span class="comment">  *             "qualifier",</span></span><br><span class="line"><span class="comment">  *             "qualifier"</span></span><br><span class="line"><span class="comment">  *             ...</span></span><br><span class="line"><span class="comment">  *          ],</span></span><br><span class="line"><span class="comment">  *         "v": [</span></span><br><span class="line"><span class="comment">  *             "value",</span></span><br><span class="line"><span class="comment">  *             "value"</span></span><br><span class="line"><span class="comment">  *             ...</span></span><br><span class="line"><span class="comment">  *         ],</span></span><br><span class="line"><span class="comment">  *     &#125;</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * @return</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(tableName: <span class="type">String</span>, array: <span class="type">Iterator</span>[(<span class="type">String</span>, <span class="type">String</span>)]): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">/** 操作数据表 &amp;&amp; 操作索引表 */</span></span><br><span class="line">        <span class="keyword">val</span> t: <span class="type">HTable</span> = getTable(tableName) <span class="comment">//HTable</span></span><br><span class="line">        <span class="keyword">val</span> puts: util.<span class="type">ArrayList</span>[<span class="type">Put</span>] = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">Put</span>]()</span><br><span class="line">        <span class="comment">/** 遍历Json数组 */</span></span><br><span class="line">        array.foreach(json =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> jsonObj: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(json._2)</span><br><span class="line">            <span class="keyword">val</span> rowKey: <span class="type">Array</span>[<span class="type">Byte</span>] = jsonObj.getString(<span class="string">"r"</span>).getBytes</span><br><span class="line">            <span class="keyword">val</span> family: <span class="type">Array</span>[<span class="type">Byte</span>] = jsonObj.getString(<span class="string">"f"</span>).getBytes</span><br><span class="line">            <span class="keyword">val</span> qualifiers: <span class="type">JSONArray</span> = jsonObj.getJSONArray(<span class="string">"q"</span>)</span><br><span class="line">            <span class="keyword">val</span> values: <span class="type">JSONArray</span> = jsonObj.getJSONArray(<span class="string">"v"</span>)</span><br><span class="line">            <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(rowKey)</span><br><span class="line">            <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until qualifiers.size()) &#123;</span><br><span class="line">                put.addColumn(family, qualifiers.getString(i).getBytes, values.getString(i).getBytes)</span><br><span class="line">            &#125;</span><br><span class="line">            puts.add(put)</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="type">Try</span>(t.put(puts)).getOrElse(t.close())</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">            e.printStackTrace()</span><br><span class="line">            logger.error(<span class="string">s"insert <span class="subst">$&#123;tableName&#125;</span> error "</span>, e)</span><br><span class="line">            <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><ol><li>刚测试时给它相对很小的内存跑一跑<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> [root@xiaoxiaomo.com ~]# /opt/cloudera/parcels/CDH/bin/spark-submit \</span><br><span class="line">--master yarn-client --num-executors 1 \</span><br><span class="line">--driver-memory 256m --conf spark.yarn.driver.memoryOverhead=256 \</span><br><span class="line">--conf spark.yarn.am.memory=256m --conf spark.yarn.am.memoryOverhead=256  \</span><br><span class="line">--executor-memory 256m --conf spark.yarn.executor.memoryOverhead=256  \</span><br><span class="line">--executor-cores 1  \</span><br><span class="line">--class com.creditease.streaming.KafkaDataStream hspark-1.0.jar 1 3 30000</span><br></pre></td></tr></table></figure></li></ol><ul><li>五六万的插入没什么压力，但是到10万的时候，就有些卡顿了！！<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming22.png" alt="yarn 容器、cpu、内存大小"><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming23.png" alt="五六万的插入没什么压力"></li></ul><ol start="2"><li>当然是需要增大内存的，修改配置,都增加一倍<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> [root@xiaoxiaomo.com ~]# /opt/cloudera/parcels/CDH/bin/spark-submit \</span><br><span class="line">--master yarn-client --num-executors 2 \</span><br><span class="line">--driver-memory 512m --conf spark.yarn.driver.memoryOverhead=512 \</span><br><span class="line">--conf spark.yarn.am.memory=512m --conf spark.yarn.am.memoryOverhead=512 \</span><br><span class="line">--executor-memory 512m --conf spark.yarn.executor.memoryOverhead=512 \</span><br><span class="line">--executor-cores 1  \</span><br><span class="line">--class com.creditease.streaming.KafkaDataStream hspark-1.0.jar 1 3 30000</span><br></pre></td></tr></table></figure></li></ol><ul><li><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming24.png" alt="yarn 容器、cpu、内存大小"></li><li><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming25.png" alt="90000的插入没什么压力"></li></ul><ul><li>查看插入数据量，能看到修改后插入数据10万是没有什么压力的<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming28.png" alt="查看插入数据量，能看到修改后插入数据10万是没有什么压力的"></li></ul><ul><li><p>当我们再继续加大压力测试的时候，性能下降<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming29.png" alt="当我们再继续加大压力测试的时候，性能下降"></p></li><li><p>查看统计信息<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming30.png" alt="查看统计信息"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(三)</title>
      <link href="/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%B8%89/"/>
      <url>/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%B8%89/</url>
      <content type="html"><![CDATA[<p>　　<a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-一/">第一篇</a>介绍了项目背景，为什么需要对架构进行一些改造，以及为啥要引入SparkStreaming，<a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-二/">第二篇</a>就是一些具体的方法实现，<br><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-三/">第三篇</a>，该篇主要在代码运行起来的情况下来看一下任务的运行情况主要是streaming的监控界面，以及我们怎么去通过监控界面发现问题和解决问题。</p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><ul><li>官网中指出，spark中专门为SparkStreaming程序的监控设置了额外的途径，当使用StreamingContext时，在WEB UI中会出现一个”Streaming”的选项卡，<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming6.png" alt="WEB UI中的”Streaming”选项卡"></li></ul><a id="more"></a><ul><li>在此选项卡内，统计的内容展示如下：<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming7.png" alt="Streaming 状态图"></li></ul><p>Spark streaming 处理速度为3s一次，每次1000条<br>Kafka product 每秒1000条数据， 与上面spark consumer消费者恰好相等。结果：数据量大导致积压，这个过程中active Batches会越变越大</p><p>因为忽略了实际的Processing time<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming8.png" alt="Active Batches"><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming9.png" alt="Completed Batches"></p><p><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming10.png" alt="Streaming Batches对应的趋势图"><br>这其中包括接受的记录数量，每一个batch内处理的记录数，处理时间，以及总共消耗的时间。<br>在上述参数之中最重要的两个参数分别是Porcessing Time 以及 Scheduling Delay<br>Porcessing Time 用来统计每个batch内处理数据所消费的时间<br>Scheduling Delay 用来统计在等待被处理所消费的时间<br>如果PT比SD大，或者SD持续上升，这就表明此系统不能对产生的数据实时响应，换句话来说就是，出现了处理时延，每个batch time 内的处理速度小于数据的产生速度。<br>在这种情况下，读者需要想法减少数据的处理速度，即需要提升处理效率。</p><h2 id="问题发现"><a href="#问题发现" class="headerlink" title="问题发现"></a>问题发现</h2><p>在我做压测的时候， Spark streaming 处理速度为3s一次，每次1000条<br>Kafka product 每秒1000条数据， 与上面spark consumer消费者恰好相等。于是就会数据量大导致积压，这个过程中active Batches会越变越大<br>最后发现了一个问题 </p><p><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming11.png" alt="Streaming Batches对应的趋势图"></p><p>当压测峰值过后Input Size=0 events，时间任然不减，奇怪！ </p><p><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming12.png" alt="Streaming Batches一些异常情况图"></p><ul><li>查看摸个具体stage:<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming13.png" alt="Streaming 具体的stage信息"></li></ul><p>从图中, 我们可以看到Spark总共调度分发了两批次task set, 每个task set的处理(含序列化和压缩之类的工作)都不超过100毫秒,<br>那么该Stage何来消耗4s呢? 慢着, 貌似这两批次的task set分发的时间相隔得有点长啊, 隔了4秒左右. 为什么会隔这么就才调度一次呢?</p><p>此处要引入一个配置项”spark.locality.wait”, (默认等待3s)<br>它配置了本地化调度降级所需要的时间. 这里概要补充下Spark本地化调度的知识, Spark的task一般都会分发到它所需数据的那个节点, 这称之为”NODE_LOCAL”,<br>但在资源不足的情况下, 数据所在节点未必有资源处理task, 因此Spark在等待了” spark.locality.wait”所配置的时间长度后, 会退而求其次, 分发到数据所在节点的同一个机架的其它节点上, 这是”RACK_LOCAL”,<br>当然, 也有更惨的, 就是再等了一段” spark.locality.wait”的时间长度后, 干脆随便找一台机器去跑task, 这就是”ANY”策略了. </p><p><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming14.png" alt="Streaming 源码"></p><p>官网解释：How long to wait to launch a data-local task before giving up and launching it on a less-local node. The same wait will be used to step through multiple locality levels (process-local, node-local, rack-local and then any). It is also possible to customize the waiting time for each level by setting spark.locality.wait.node, etc. You should increase this setting if your tasks are long and see poor locality, but the default usually works well.<br>来源： <a href="https://github.com/apache/spark/blob/66636ef0b046e5d1f340c3b8153d7213fa9d19c7/docs/configuration.md" target="_blank" rel="noopener">https://github.com/apache/spark/blob/66636ef0b046e5d1f340c3b8153d7213fa9d19c7/docs/configuration.md</a></p><p>而从上例看到, 即使用最差的”ANY”策略进行调度, task set的处理也只是花了100毫秒, 因此, 没必要非得为了”NODE_LOCAL”策略的生效而去等待那么长的时间, 特别是在流计算这种场景上. 所以把” spark.locality.wait”果断调小, 从1秒到500毫秒, 最后干脆调到100毫秒算了.</p><p>spark-submit –master yarn-client –conf spark.driver.memory=256m –class com.KafkaDataStream –num-executors 1 –executor-memory 256m –executor-cores 2 –conf spark.locality.wait=100ms hspark-1.0.jar<br>调了之后的处理时间为0.7s:<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming15.png" alt="Streaming Completed Batches正常"></p><p>具体耗时如下<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming16.png" alt="Streaming 具体耗时信息图"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(二)</title>
      <link href="/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%BA%8C/"/>
      <url>/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%BA%8C/</url>
      <content type="html"><![CDATA[<h1 id="然后就开始写代码了"><a href="#然后就开始写代码了" class="headerlink" title="然后就开始写代码了"></a>然后就开始写代码了</h1><ul><li>总体思路就是:</li></ul><ol><li>put数据构造json数据，写入kafka；</li><li>spark streaming任务启动后首先去zookeeper中去读取offset,组装成fromOffsets；</li><li>spark streaming 获取到fromOffsets后通过KafkaUtils.createDirectStream去消费Kafka的数据；</li><li>读取kafka数据返回一个InputDStream的信息，foreachRDD遍历，同时记录读取到的offset到zk中；</li><li>写入数据到HBase<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming3.png" alt="详细一点的架构图"><a id="more"></a></li></ol><h1 id="初始化与配置加载"><a href="#初始化与配置加载" class="headerlink" title="初始化与配置加载"></a>初始化与配置加载</h1><ul><li>下面是一些接收参数，加载配置，获取配置中的topic，还有初始化配置，代码如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//接收参数</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">Array</span>(kafka_topic, timeWindow, maxRatePerPartition) = args</span><br><span class="line"></span><br><span class="line"><span class="comment">//加载配置</span></span><br><span class="line"><span class="keyword">val</span> prop: <span class="type">Properties</span> = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">prop.load(<span class="keyword">this</span>.getClass().getResourceAsStream(<span class="string">"/kafka.properties"</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> groupName = prop.getProperty(<span class="string">"group.id"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取配置文件中的topic</span></span><br><span class="line"><span class="keyword">val</span> kafkaTopics: <span class="type">String</span> = prop.getProperty(<span class="string">"kafka.topic."</span> + kafka_topic)</span><br><span class="line"><span class="keyword">if</span> (kafkaTopics == <span class="literal">null</span> || kafkaTopics.length &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">System</span>.err.println(<span class="string">"Usage: KafkaDataStream &lt;kafka_topic&gt; is number from kafka.properties"</span>)</span><br><span class="line">    <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> topics: <span class="type">Set</span>[<span class="type">String</span>] = kafkaTopics.split(<span class="string">","</span>).toSet</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> kafkaParams = scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">    <span class="string">"metadata.broker.list"</span> -&gt; prop.getProperty(<span class="string">"bootstrap.servers"</span>),</span><br><span class="line">    <span class="string">"group.id"</span> -&gt; groupName,</span><br><span class="line">    <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"largest"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> kc = <span class="keyword">new</span> <span class="type">KafkaCluster</span>(kafkaParams)</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化配置</span></span><br><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">        .setAppName(<span class="type">KafkaDataStream</span>.getClass.getSimpleName + topics.toString())</span><br><span class="line">        .set(<span class="string">"spark.yarn.am.memory"</span>, prop.getProperty(<span class="string">"am.memory"</span>))</span><br><span class="line">        .set(<span class="string">"spark.yarn.am.memoryOverhead"</span>, prop.getProperty(<span class="string">"am.memoryOverhead"</span>))</span><br><span class="line">        .set(<span class="string">"spark.yarn.executor.memoryOverhead"</span>, prop.getProperty(<span class="string">"executor.memoryOverhead"</span>))</span><br><span class="line">        .set(<span class="string">"spark.streaming.kafka.maxRatePerPartition"</span>, maxRatePerPartition) <span class="comment">//此处为每秒每个partition的条数</span></span><br><span class="line">        .set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br><span class="line">        .set(<span class="string">"spark.reducer.maxSizeInFlight"</span>, <span class="string">"1m"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(timeWindow.toInt)) <span class="comment">//多少秒处理一次请求</span></span><br></pre></td></tr></table></figure></li></ul><p><code>只是需要注意一下，这里的KafkaCluster，需要把源码拷贝过来，修改一下，因为里面有些方法是私有的。copy过来后改为public 即可。</code></p><h1 id="链接ZK"><a href="#链接ZK" class="headerlink" title="链接ZK"></a>链接ZK</h1><ul><li><strong>注意：这里的ZKStringSerializer，需要把源码拷贝过来，修改一下</strong><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//zk</span></span><br><span class="line"><span class="keyword">val</span> zkClient = <span class="keyword">new</span> <span class="type">ZkClient</span>(prop.getProperty(<span class="string">"zk.connect"</span>), <span class="type">Integer</span>.<span class="type">MAX_VALUE</span>, <span class="number">100000</span>, <span class="type">ZKStringSerializer</span>)</span><br><span class="line"><span class="keyword">val</span> messageHandler = (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; (mmd.topic, mmd.message())</span><br></pre></td></tr></table></figure></li></ul><h1 id="组装fromOffsets"><a href="#组装fromOffsets" class="headerlink" title="组装fromOffsets"></a>组装fromOffsets</h1><ul><li>组装fromOffsets，createDirectStream接收的是一个map的结构，所以可以支持多个topic的消费<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> fromOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = <span class="type">Map</span>() <span class="comment">//多个partition的offset</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//支持多个topic : Set[String]</span></span><br><span class="line">topics.foreach(topicName =&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//去brokers中获取partition数量，注意：新增partition后需要重启</span></span><br><span class="line">    <span class="keyword">val</span> children = zkClient.countChildren(<span class="type">ZkUtils</span>.getTopicPartitionsPath(topicName))</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until children) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//kafka consumer 中是否有该partition的消费记录，如果没有设置为0</span></span><br><span class="line">        <span class="keyword">val</span> tp = <span class="type">TopicAndPartition</span>(topicName, i)</span><br><span class="line">        <span class="keyword">val</span> path: <span class="type">String</span> = <span class="string">s"<span class="subst">$&#123;new ZKGroupTopicDirs(groupName, topicName).consumerOffsetDir&#125;</span>/<span class="subst">$i</span>"</span></span><br><span class="line">        <span class="keyword">if</span> (zkClient.exists(path)) &#123;</span><br><span class="line">            fromOffsets += (tp -&gt; zkClient.readData[<span class="type">String</span>](path).toLong)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            fromOffsets += (tp -&gt; <span class="number">0</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li></ul><h1 id="通过createDirectStream接受数据"><a href="#通过createDirectStream接受数据" class="headerlink" title="通过createDirectStream接受数据"></a>通过createDirectStream接受数据</h1><ul><li>使用KafkaUtils里面的createDirectStream方法去消费kafka数据，createDirectStream使用的是kafka简单的Consumer API，所以需要自己去管理offset,我们把offset写入到zk中，这样也方便了一些监控软件读取记录<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建Kafka持续读取流，通过zk中记录的offset</span></span><br><span class="line"><span class="keyword">val</span> messages: <span class="type">InputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] =</span><br><span class="line">    <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>, (<span class="type">String</span>, <span class="type">String</span>)](ssc, kafkaParams, fromOffsets, messageHandler)</span><br></pre></td></tr></table></figure></li></ul><h1 id="入库"><a href="#入库" class="headerlink" title="入库"></a>入库</h1><ul><li><p>入库HBase</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">//数据操作</span></span><br><span class="line">        messages.foreachRDD(rdd =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> offsetsList: <span class="type">Array</span>[<span class="type">OffsetRange</span>] = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line"></span><br><span class="line">            <span class="comment">//data 处理</span></span><br><span class="line">            rdd.foreachPartition(partitionRecords =&gt; &#123;</span><br><span class="line">                <span class="comment">//TaskContext 上下文</span></span><br><span class="line">                <span class="keyword">val</span> offsetRange: <span class="type">OffsetRange</span> = offsetsList(<span class="type">TaskContext</span>.get.partitionId)</span><br><span class="line">                logger.info(<span class="string">s"<span class="subst">$&#123;offsetRange.topic&#125;</span> <span class="subst">$&#123;offsetRange.partition&#125;</span> <span class="subst">$&#123;offsetRange.fromOffset&#125;</span> <span class="subst">$&#123;offsetRange.untilOffset&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">                partitionRecords.foreach(data =&gt; &#123;</span><br><span class="line">                    <span class="type">HBaseDao</span>.insert(data)</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                <span class="comment">//TopicAndPartition 主构造参数第一个是topic，第二个是Kafka partition id</span></span><br><span class="line">                <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(offsetRange.topic, offsetRange.partition)</span><br><span class="line">                <span class="keyword">val</span> either = kc.setConsumerOffsets(groupName, <span class="type">Map</span>((topicAndPartition, offsetRange.untilOffset))) <span class="comment">//是</span></span><br><span class="line">                <span class="keyword">if</span> (either.isLeft) &#123;</span><br><span class="line">                    logger.info(<span class="string">s"Error updating the offset to Kafka cluster: <span class="subst">$&#123;either.left.get&#125;</span>"</span>)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        &#125;)</span><br></pre></td></tr></table></figure></li><li><p><strong>插入数据到具体HBase数据库</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * 插入数据到 HBase</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * 参数( tableName ,  json ) )：</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * Json格式：</span></span><br><span class="line"><span class="comment">  *     &#123;</span></span><br><span class="line"><span class="comment">  *         "rowKey": "00000-0",</span></span><br><span class="line"><span class="comment">  *         "family:qualifier": "value",</span></span><br><span class="line"><span class="comment">  *         "family:qualifier": "value",</span></span><br><span class="line"><span class="comment">  *         ......</span></span><br><span class="line"><span class="comment">  *     &#125;</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * @param data</span></span><br><span class="line"><span class="comment">  * @return</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(data: (<span class="type">String</span>, <span class="type">String</span>)): <span class="type">Boolean</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> t: <span class="type">HTable</span> = getTable(data._1) <span class="comment">//HTable</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> map: mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">JsonUtils</span>.json2Map(data._2)</span><br><span class="line">        <span class="keyword">val</span> rowKey: <span class="type">Array</span>[<span class="type">Byte</span>] = <span class="type">String</span>.valueOf(map.get(<span class="string">"rowKey"</span>)).getBytes <span class="comment">//rowKey</span></span><br><span class="line">        <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(rowKey)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ((k, v) &lt;- map) &#123;</span><br><span class="line">            <span class="keyword">val</span> keys: <span class="type">Array</span>[<span class="type">String</span>] = k.split(<span class="string">":"</span>)</span><br><span class="line">            <span class="keyword">if</span> (keys.length == <span class="number">2</span>)&#123;</span><br><span class="line">                put.addColumn(keys(<span class="number">0</span>).getBytes, keys(<span class="number">1</span>).getBytes, <span class="type">String</span>.valueOf(v).getBytes)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">Try</span>(t.put(put)).getOrElse(t.close())</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">            e.printStackTrace()</span><br><span class="line">            <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="运行并查看结果"><a href="#运行并查看结果" class="headerlink" title="运行并查看结果"></a>运行并查看结果</h1><ul><li><strong>运行命令：</strong><br><code>/opt/cloudera/parcels/CDH/bin/spark-submit --master yarn-client --class com.xiaoxiaomo.streaming.KafkaDataStream hspark-1.0.jar 1 3 1000</code><br>运行后可以去spark UI中去查看相关运行情况，UI中具体细节见<a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-三/">下篇博客</a><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming4.png" alt="Streaming Statistics数据统计图"><br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming5.png" alt="Completed Batches"></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> HBase </tag>
            
            <tag> Spark </tag>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark Streaming--应用与实战(一)</title>
      <link href="/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%B8%80/"/>
      <url>/2017/06/10/SparkStreaming-%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98-%E4%B8%80/</url>
      <content type="html"><![CDATA[<p>　　接下来的几篇博客是一个连续的部分，主要分为了：</p><ol><li><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-一/">SparkStreaming-应用与实战(一),讲解背景与架构改造，以及为什么使用spark streaming</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-二/">SparkStreaming-应用与实战(二),通过代码实现具体细节，并运行项目</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-三/">SparkStreaming-应用与实战(三),对streaming监控的介绍以及解决实际问题</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/10/SparkStreaming-应用与实战-四/">SparkStreaming-应用与实战(四),对项目做压测与相关的优化</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/29/SparkStreaming-应用与实战-五/">SparkStreaming-应用与实战(五),Streaming优化之HBase</a></li><li><a href="http://blog.xiaoxiaomo.com/2017/06/29/SparkStreaming-应用与实战-六/">SparkStreaming-应用与实战(六),Streaming任务的管理及监控</a></li></ol><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><ul><li>笔者所在部门<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener"><code>宜人蜂巢</code></a> ，是由<strong>李善仁 宜人贷副总裁，宜人蜂巢负责人</strong> 2013年创建。<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener"><code>宜人蜂巢</code></a> 是做什么的？笔者在这里简单表述一下<a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener"><code>宜人蜂巢</code></a> – <strong>数据科学驱动的互联网风控解决方案，通过千万级爬虫并发技术、计算机视觉技术、机器学习技术等；实时数据采集源；鲜活信用分析特征提取；多维度特征下的欺诈行为交叉检测等一系列科技手段助力金融生态和谐健康发展。</strong></li><li>在大数据风控领域，数据是一切工作的根基。数据量的多少、维度的多少，抓取的速度、成功率都是评判数据质量、获取能力的重要条件。在经过用户授权的情况下，宜人蜂巢可以实现对“社交、电商、金融、信用、社保”五大维度的实时数据抓取。宜人蜂巢正在积极与银行、电商、电信运营商、保险公司以及社保基金等机构展开合作，进一步提高数据抓取的工作效率。</li><li><strong>所以在大量数据获取之后，对于底层的数据存储依赖也是相当高的，传统的数据库已经没法在支持，对底层数据服务架构的改造迫在眉睫。</strong></li></ul><a id="more"></a><h2 id="二、问题描述"><a href="#二、问题描述" class="headerlink" title="二、问题描述"></a>二、问题描述</h2><ul><li><a href="http://honeycomb.yirendai.com" target="_blank" rel="noopener"><code>宜人蜂巢</code></a>之前的数据数据服务主要是支撑爬虫服务的，“宜人蜂巢爬虫”抓取的数据通过大数据这边提供的SOA服务入库到HBase,架构大致如下：<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming1.png" alt="架构改造之前"></li></ul><p>以对于以上的架构存在一些问题，我们可以看见数据在Dubbox服务阶段处理后直接通过HBase API入库了HBase，中间并没做任何缓冲，要是HBase出现了问题整个集群都完蛋，没法写入数据，数据还丢失，HBase这边压力也相当大，针对这一点，对入库HBase这个阶段做了一些改造。</p><h2 id="三、架构改造"><a href="#三、架构改造" class="headerlink" title="三、架构改造"></a>三、架构改造</h2><p>改造后的架构，爬虫通过接口服务，入库到Kafka，Spark streaming去消费kafka的数据，入库到HBase.核心组件如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog/img/sparkstreaming2.png" alt="架构改造图"></p><ul><li>为什么不直接入库到HBase，这样做有什么好处？</li></ul><ol><li>缓解了HBase这边峰值的压力，并且流量可控</li><li>HBase集群出现问题或者挂掉，都不会照成数据丢失的问题</li><li>增加了吞吐量</li></ol><h2 id="四、-为什么选择Kafka和Spark-streaming"><a href="#四、-为什么选择Kafka和Spark-streaming" class="headerlink" title="四、 为什么选择Kafka和Spark streaming"></a>四、 为什么选择Kafka和Spark streaming</h2><ol><li>由于Kafka它简单的架构以及出色的吞吐量.</li><li>Kafka与Spark streaming也有专门的集成模块.</li><li>Spark的容错,以及现在技术相当的成熟.</li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> HBase </tag>
            
            <tag> Spark </tag>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Linux相关系列博客</title>
      <link href="/2017/06/07/Linux-Linux%E7%9B%B8%E5%85%B3%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2/"/>
      <url>/2017/06/07/Linux-Linux%E7%9B%B8%E5%85%B3%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h2 id="Linux相关系列博客导航"><a href="#Linux相关系列博客导航" class="headerlink" title="Linux相关系列博客导航"></a>Linux相关系列博客导航</h2><h3 id="一、基本操作"><a href="#一、基本操作" class="headerlink" title="一、基本操作"></a>一、基本操作</h3><ol><li><a href="http://blog.xiaoxiaomo.com/2016/01/18/Linux-用户和组管理/">http://blog.xiaoxiaomo.com/2016/01/18/Linux-用户和组管理/</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/14/Linux-基本配置修改/">http://blog.xiaoxiaomo.com/2016/02/14/Linux-基本配置修改/</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/01/27/Linux-文本管理类命令/">http://blog.xiaoxiaomo.com/2016/01/27/Linux-文本管理类命令/</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/01/28/Linux-压缩及归档/">http://blog.xiaoxiaomo.com/2016/01/28/Linux-压缩及归档</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/18/Linux-系统进程管理/">http://blog.xiaoxiaomo.com/2016/02/18/Linux-系统进程管理</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/16/Linux-跟文件系统/">http://blog.xiaoxiaomo.com/2016/02/16/Linux-跟文件系统</a></li></ol><h3 id="二、Linux-进阶"><a href="#二、Linux-进阶" class="headerlink" title="二、Linux 进阶"></a>二、Linux 进阶</h3><ol start="7"><li><a href="http://blog.xiaoxiaomo.com/2016/02/16/Linux-操作系统及常用命令/">http://blog.xiaoxiaomo.com/2016/02/16/Linux-操作系统及常用命令</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/28/Linux-常用VI-VIM命令/">http://blog.xiaoxiaomo.com/2016/02/28/Linux-常用VI-VIM命令</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/23/Linux-软件安装之Redis/">http://blog.xiaoxiaomo.com/2016/02/23/Linux-软件安装之Redis</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/17/Linux-grep和正则表达式/">http://blog.xiaoxiaomo.com/2016/03/17/Linux-grep和正则表达式</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/19/Linux-awk命令详解/">http://blog.xiaoxiaomo.com/2016/03/19/Linux-awk命令详解</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/11/Linux-Yum源码安装配置/">http://blog.xiaoxiaomo.com/2016/02/11/Linux-Yum源码安装配置</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/21/Linux-RPM软件包管理/">http://blog.xiaoxiaomo.com/2016/03/21/Linux-RPM软件包管理</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/29/Linux-磁盘管理及挂载/">http://blog.xiaoxiaomo.com/2016/02/29/Linux-磁盘管理及挂载</a></li></ol><h3 id="三、Linux-Shell"><a href="#三、Linux-Shell" class="headerlink" title="三、Linux Shell"></a>三、Linux Shell</h3><ol start="15"><li><a href="http://blog.xiaoxiaomo.com/2016/03/05/Linux-Shell编程入门/">http://blog.xiaoxiaomo.com/2016/03/05/Linux-Shell编程入门</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/06/Linux-Shell条件判断及算术运算/">http://blog.xiaoxiaomo.com/2016/03/06/Linux-Shell条件判断及算术运算</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/12/Linux-Shell循环结构/">http://blog.xiaoxiaomo.com/2016/03/12/Linux-Shell循环结构</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/03/13/Linux-Shell函数及进阶/">http://blog.xiaoxiaomo.com/2016/03/13/Linux-Shell函数及进阶</a></li></ol><h3 id="四、Linux-相关操作"><a href="#四、Linux-相关操作" class="headerlink" title="四、Linux 相关操作"></a>四、Linux 相关操作</h3><ol start="19"><li><a href="http://blog.xiaoxiaomo.com/2016/01/22/Linux-软件安装之JDK/">http://blog.xiaoxiaomo.com/2016/01/22/Linux-软件安装之JDK</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/22/Linux-软件安装之Mysql/">http://blog.xiaoxiaomo.com/2016/02/22/Linux-软件安装之Mysql</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/02/25/Linux-Mysql源码安装及配置/">http://blog.xiaoxiaomo.com/2016/02/25/Linux-Mysql源码安装及配置</a></li><li><a href="http://blog.xiaoxiaomo.com/2016/04/20/Linux-Maven和nexus私服搭建/">http://blog.xiaoxiaomo.com/2016/04/20/Linux-Maven和nexus私服搭建</a></li></ol>]]></content>
      
      <categories>
          
          <category> 导航 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--服务异常排查</title>
      <link href="/2017/03/29/HBase-%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/"/>
      <url>/2017/03/29/HBase-%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</url>
      <content type="html"><![CDATA[<h2 id="潜在的危机"><a href="#潜在的危机" class="headerlink" title="潜在的危机"></a>潜在的危机</h2><ul><li>就在某一天下午，刚去公司楼下逛了一圈，悠哉悠哉的回到自己的工位上，几个同事就找过来了。说HBase服务巨慢，立即调出日志，晕，全是插入请求超时的日志。立即调出HBase监控，发现HBase一些可疑的信息！<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #61, waiting for some tasks to finish. Expected max=0, tasksInProgress=5</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #54, waiting for some tasks to finish. Expected max=0, tasksInProgress=6</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #18, waiting for some tasks to finish. Expected max=0, tasksInProgress=5</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #62, waiting for some tasks to finish. Expected max=0, tasksInProgress=5</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #46, waiting for some tasks to finish. Expected max=0, tasksInProgress=5</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #70, waiting for some tasks to finish. Expected max=0, tasksInProgress=4</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #45, waiting for some tasks to finish. Expected max=0, tasksInProgress=6</span><br><span class="line">INFO org.apache.hadoop.hbase.client.AsyncProcess: #47, waiting for some tasks to finish. Expected max=0, tasksInProgress=15</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">INFO org.apache.hadoop.hbase.regionserver.wal.FSHLog: Slow sync cost: 204 ms, current pipeline: [DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-47fdd2fe-7722-47d9-9518-151b49a59fc7,DISK], DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-f55c19d9-5494-47d0-a97b-5d0d07fc8a95,DISK], DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-4413d571-cab8-4b5f-bc7f-9cf11d2ec2e8,DISK]]</span><br><span class="line">INFO org.apache.hadoop.hbase.regionserver.wal.FSHLog: Slow sync cost: 148 ms, current pipeline: [DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-47fdd2fe-7722-47d9-9518-151b49a59fc7,DISK], DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-f55c19d9-5494-47d0-a97b-5d0d07fc8a95,DISK], DatanodeInfoWithStorage[10.xx.xx.xx:50010,DS-4413d571-cab8-4b5f-bc7f-9cf11d2ec2e8,DISK]]</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h2 id="紧绷的神经"><a href="#紧绷的神经" class="headerlink" title="紧绷的神经"></a>紧绷的神经</h2><ul><li><p>看来情况有点严重！发现读写请求剧增，咨询情况，发现时有一个业务之前业务问题导致关键性数据不正常，在进行HBase大量读写操作更新数据！！！赶紧让他们停掉，缓一缓，看看具体原因，停掉后hbase正常了一下。一会儿，异常信息又来了！汗！！看来这个只是其中原因之一，但是上面第一个异常信息没有了，第二个警告减少。HBase服务正常（只是有大量警告）！！！<br><img src="https://img.xiaoxiaomo.com/blog/img/20170329225042.png" alt=""></p></li><li><p>这是什么原因呢？不是hbase的问题，hbase服务前面还有一层负载“edware 负载均衡 -&gt;waf -&gt;  nginx ”，中间还有一个HBase接口服务。然后发了封邮件给运维让他帮着排查一下是否与负载有关，当然这个希望不大，于是紧接着就检查HBase接口服务。</p></li><li>通过top命令查看服务，我插CPU直接到200%多了，内存也用完了，怎么突然占用这么多内存？大对象？？<br><img src="https://img.xiaoxiaomo.com/blog/img/20170329225043.png" alt=""></li></ul><h2 id="初尝甜果"><a href="#初尝甜果" class="headerlink" title="初尝甜果"></a>初尝甜果</h2><ol><li>查看JVM参数设置，也没啥问题，于是打印查看GC日志，希望能从中发现问题：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup java -server -Xms6144m -Xmx6144m  -XX:SurvivorRatio=<span class="number">2</span> -XX:PermSize=<span class="number">256</span>m -XX:MaxPermSize=<span class="number">256</span>m -XX:+UseG1GC  </span><br><span class="line">-XX:InitiatingHeapOccupancyPercent=<span class="number">50</span>  -XX:-UseSplitVerifier -XX:+PrintGCDateStamps -XX:+PrintGCDetails </span><br><span class="line">-Xloggc:/data/dubbox/hservice/logs/gc.<span class="built_in">log</span> -jar ./$JAR_NAME &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure></li></ol><ul><li>GC日志如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">2017-03-07T15:01:14.767+0800: 7.071: [GC pause (young), 0.0502650 secs]</span><br><span class="line">   [Parallel Time: 18.1 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 306.0M(306.0M)-&gt;0.0B(268.0M) Survivors: 0.0B-&gt;38.0M Heap: 307.0M(6144.0M)-&gt;38.8M(6144.0M)]</span><br><span class="line">2017-03-07T15:01:28.113+0800: 20.417: [GC pause (young), 0.0183790 secs]</span><br><span class="line">   [Parallel Time: 9.2 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 268.0M(268.0M)-&gt;0.0B(282.0M) Survivors: 38.0M-&gt;24.0M Heap: 306.8M(6144.0M)-&gt;24.8M(6144.0M)]</span><br><span class="line">2017-03-07T15:01:45.162+0800: 37.466: [GC pause (young), 0.0114490 secs]</span><br><span class="line">   [Parallel Time: 6.0 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 282.0M(282.0M)-&gt;0.0B(334.0M) Survivors: 24.0M-&gt;22.0M Heap: 306.8M(6144.0M)-&gt;22.3M(6144.0M)]</span><br><span class="line">2017-03-07T15:02:03.528+0800: 55.832: [GC pause (young), 0.0143630 secs]</span><br><span class="line">   [Parallel Time: 7.2 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 334.0M(334.0M)-&gt;0.0B(1986.0M) Survivors: 22.0M-&gt;28.0M Heap: 356.3M(6144.0M)-&gt;28.2M(6144.0M)]</span><br><span class="line">2017-03-07T15:02:23.174+0800: 75.478: [GC pause (young), 0.2785950 secs]</span><br><span class="line">   [Parallel Time: 268.8 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 212.0M(212.0M)-&gt;0.0B(242.0M) Survivors: 590.0M-&gt;64.0M Heap: 802.1M(6144.0M)-&gt;556.7M(6144.0M)]</span><br><span class="line">2017-03-07T15:02:28.132+0800: 80.435: [GC pause (young), 0.0534540 secs]</span><br><span class="line">   [Parallel Time: 50.9 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 220.0M(220.0M)-&gt;0.0B(354.0M) Survivors: 110.0M-&gt;116.0M Heap: 1038.4M(6144.0M)-&gt;887.4M(6144.0M)]</span><br><span class="line">2017-03-07T15:02:34.622+0800: 86.926: [GC pause (young), 0.0927160 secs]</span><br><span class="line">   [Parallel Time: 89.4 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 426.0M(426.0M)-&gt;0.0B(510.0M) Survivors: 200.0M-&gt;212.0M Heap: 1610.4M(6144.0M)-&gt;1311.4M(6144.0M)]</span><br><span class="line">2017-03-07T15:02:45.490+0800: 97.793: [GC pause (young), 0.1458780 secs]</span><br><span class="line">   [Parallel Time: 141.0 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 566.0M(566.0M)-&gt;0.0B(606.0M) Survivors: 316.0M-&gt;304.0M Heap: 2359.5M(6144.0M)-&gt;1943.5M(6144.0M)]</span><br><span class="line">/////几秒钟就上来了，停不下来了</span><br><span class="line">2017-03-07T15:03:01.747+0800: 114.050: [GC pause (young), 0.1641290 secs]</span><br><span class="line">   [Parallel Time: 157.9 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 700.0M(700.0M)-&gt;0.0B(760.0M) Survivors: 412.0M-&gt;408.0M Heap: 3441.2M(6144.0M)-&gt;2946.2M(6144.0M)]</span><br><span class="line">2017-03-07T15:03:15.536+0800: 127.840: [GC pause (young) (initial-mark), 0.1768610 secs]</span><br><span class="line">   [Parallel Time: 169.8 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 932.0M(932.0M)-&gt;0.0B(966.0M) Survivors: 432.0M-&gt;452.0M Heap: 4532.2M(6144.0M)-&gt;3837.2M(6144.0M)]</span><br><span class="line">2017-03-07T15:03:26.259+0800: 138.563: [GC pause (young) (initial-mark), 0.1677280 secs]</span><br><span class="line">   [Parallel Time: 160.8 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 654.0M(654.0M)-&gt;0.0B(532.0M) Survivors: 508.0M-&gt;438.0M Heap: 5016.6M(6144.0M)-&gt;4554.6M(6144.0M)]</span><br><span class="line">2017-03-07T15:03:44.313+0800: 156.616: [GC pause (young) (initial-mark) (to-space exhausted), 0.2589990 secs]</span><br><span class="line">   [Parallel Time: 234.0 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 200.0M(200.0M)-&gt;0.0B(244.0M) Survivors: 106.0M-&gt;62.0M Heap: 6007.4M(6144.0M)-&gt;5946.0M(6144.0M)]</span><br><span class="line">2017-03-07T15:03:45.374+0800: 157.678: [GC pause (young) (to-space exhausted), 1.7079930 secs]</span><br><span class="line">   [Parallel Time: 1572.6 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 196.0M(244.0M)-&gt;0.0B(306.0M) Survivors: 62.0M-&gt;0.0B Heap: 6142.0M(6144.0M)-&gt;6142.0M(6144.0M)]</span><br><span class="line">////这个内存增长的也太猛了，停不下来了</span><br><span class="line">2017-03-07T15:04:10.598+0800: 182.902: [GC pause (young) (to-space exhausted), 1.0087070 secs]</span><br><span class="line">   [Parallel Time: 905.9 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 204.0M(204.0M)-&gt;0.0B(258.0M) Survivors: 102.0M-&gt;48.0M Heap: 6038.3M(6144.0M)-&gt;6112.3M(6144.0M)]</span><br><span class="line">2017-03-07T15:04:11.725+0800: 184.029: [GC pause (young) (to-space exhausted), 0.6503080 secs]</span><br><span class="line">   [Parallel Time: 614.5 ms, GC Workers: 28]</span><br><span class="line">   [Eden: 28.0M(258.0M)-&gt;0.0B(306.0M) Survivors: 48.0M-&gt;0.0B Heap: 6140.3M(6144.0M)-&gt;6140.3M(6144.0M)]</span><br><span class="line">////下面彻底回收不了了</span><br><span class="line">2017-03-07T15:04:12.376+0800: 184.680: [GC pause (young), 0.0118450 secs]</span><br><span class="line">   [Parallel Time: 10.4 ms, GC Workers: 28]</span><br><span class="line">      [GC Worker Start (ms): Min: 184680.1, Avg: 184680.3, Max: 184680.6, Diff: 0.5]</span><br><span class="line">      [Ext Root Scanning (ms): Min: 1.1, Avg: 1.5, Max: 2.0, Diff: 0.9, Sum: 41.8]</span><br><span class="line">      [SATB Filtering (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]</span><br><span class="line">      [Update RS (ms): Min: 7.8, Avg: 8.2, Max: 8.5, Diff: 0.6, Sum: 228.5]</span><br><span class="line">         [Processed Buffers: Min: 3, Avg: 15.1, Max: 31, Diff: 28, Sum: 424]</span><br><span class="line">      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class="line">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class="line">      [Object Copy (ms): Min: 0.0, Avg: 0.1, Max: 0.3, Diff: 0.3, Sum: 2.2]</span><br><span class="line">      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.4, Diff: 0.4, Sum: 5.3]</span><br><span class="line">      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.9]</span><br><span class="line">      [GC Worker Total (ms): Min: 9.7, Avg: 10.0, Max: 10.2, Diff: 0.5, Sum: 278.8]</span><br><span class="line">      [GC Worker End (ms): Min: 184690.2, Avg: 184690.3, Max: 184690.4, Diff: 0.2]</span><br><span class="line">   [Code Root Fixup: 0.0 ms]</span><br><span class="line">   [Code Root Migration: 0.0 ms]</span><br><span class="line">   [Clear CT: 0.5 ms]</span><br><span class="line">   [Other: 0.9 ms]</span><br><span class="line">      [Choose CSet: 0.0 ms]</span><br><span class="line">      [Ref Proc: 0.7 ms]</span><br><span class="line">      [Ref Enq: 0.0 ms]</span><br><span class="line">      [Free CSet: 0.0 ms]</span><br><span class="line">   [Eden: 0.0B(306.0M)-&gt;0.0B(306.0M) Survivors: 0.0B-&gt;0.0B Heap: 6140.3M(6144.0M)-&gt;6140.3M(6144.0M)]</span><br><span class="line"> [Times: user=0.22 sys=0.00, real=0.01 secs]</span><br><span class="line">2017-03-07T15:04:12.389+0800: 184.693: [GC pause (young), 0.0034990 secs]</span><br><span class="line">   [Parallel Time: 2.2 ms, GC Workers: 28]</span><br><span class="line">      [GC Worker Start (ms): Min: 184692.9, Avg: 184693.0, Max: 184693.2, Diff: 0.3]</span><br><span class="line">      [Ext Root Scanning (ms): Min: 1.1, Avg: 1.4, Max: 1.6, Diff: 0.4, Sum: 38.7]</span><br><span class="line">      [SATB Filtering (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]</span><br><span class="line">      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class="line">         [Processed Buffers: Min: 0, Avg: 0.0, Max: 1, Diff: 1, Sum: 1]</span><br><span class="line">      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class="line">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class="line">      [Object Copy (ms): Min: 0.0, Avg: 0.1, Max: 0.3, Diff: 0.2, Sum: 2.2]</span><br><span class="line">      [Termination (ms): Min: 0.0, Avg: 0.3, Max: 0.5, Diff: 0.5, Sum: 7.4]</span><br><span class="line">      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.3]</span><br><span class="line">      [GC Worker Total (ms): Min: 1.6, Avg: 1.7, Max: 1.9, Diff: 0.2, Sum: 48.6]</span><br><span class="line">      [GC Worker End (ms): Min: 184694.8, Avg: 184694.8, Max: 184694.8, Diff: 0.0]</span><br><span class="line">   [Code Root Fixup: 0.0 ms]</span><br><span class="line">   [Code Root Migration: 0.0 ms]</span><br><span class="line">   [Clear CT: 0.4 ms]</span><br><span class="line">   [Other: 0.8 ms]</span><br><span class="line">      [Choose CSet: 0.0 ms]</span><br><span class="line">      [Ref Proc: 0.7 ms]</span><br><span class="line">      [Ref Enq: 0.0 ms]</span><br><span class="line">      [Free CSet: 0.0 ms]</span><br><span class="line">   [Eden: 0.0B(306.0M)-&gt;0.0B(306.0M) Survivors: 0.0B-&gt;0.0B Heap: 6140.3M(6144.0M)-&gt;6140.3M(6144.0M)]</span><br><span class="line"> [Times: user=0.05 sys=0.00, real=0.00 secs]</span><br><span class="line">2017-03-07T15:04:12.404+0800: 184.708: [Full GC</span><br></pre></td></tr></table></figure></li></ul><p>从上面GC日志，显然发现了问题，内存猛增，并且后面无法回收，同时运维邮件反馈和通过自己测试也排查掉了网络问题。现在总算有点眉目了，锁定异常到HBase接口服务，很可能就是大对象，还有可能一些锁等问题导致。</p><ol start="2"><li><p>通过<strong>jstack</strong>，观察线程状状态，看看锁是否被释放等</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# jps  ##查看PID</span><br><span class="line">110132 hservice.jar</span><br><span class="line">[root@xiaoxiaomo ~]# jstack 110132 &gt; jstack110132.log  ###日志中并没有什么锁信息</span><br></pre></td></tr></table></figure></li><li><p>通过<strong>jmap</strong>查看，但是不直观，只能去获取一下dump文件，然后下载到本地然后通过<a href="http://www.eclipse.org/mat/downloads.php" target="_blank" rel="noopener">dump分析工具分析</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo ~]# jmap 110132 &gt; jmap110132 .log</span><br><span class="line">[root@xiaoxiaomo ~]# jmap -dump:format=b,file=dump2.bin 110132</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>刚开始dump下来的文件太大了，差不多6G,笔记本总共内存才8g,dump文件没法打开，第二次弄了个小的，打开软件，运行<br><img src="https://img.xiaoxiaomo.com/blog/img/20170329225044.png" alt=""></p></li><li><p>就是这样一个dump分析工具<br><img src="https://img.xiaoxiaomo.com/blog/img/20170329225045.png" alt=""></p></li><li><p>左键点击饼图–&gt;Java Basics，Thread Details 就是我们比较熟悉的了<br><img src="https://img.xiaoxiaomo.com/blog/img/20170329225046.png" alt=""></p></li><li><p>我们主要看的是：Thread Overview and Stacks<br><img src="https://img.xiaoxiaomo.com/blog/img/20170325201212.png" alt=""></p><blockquote><p>我想到这儿，问提基本上就解决了一大半了吧，通过这里就能找到相应的表，然后找到接口调用方。</p></blockquote></li></ul><h2 id="水落石出"><a href="#水落石出" class="headerlink" title="水落石出"></a>水落石出</h2><ul><li>找到调用方，发现是他们当天正好写了一个监控HBase的程序发布到线上，监控的方法是通过scan，看是否请求正常！！！就是这个东东，scan的startKey是00,endKey是99，然而他们HBase表的rowke前缀就是数字，这不一下返回了大对象吗！！，然后暂时帮他们设置了一个固定的rowKey让他们换成了get,观察GC，正常！</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cloudera Manager--升级</title>
      <link href="/2017/03/26/Cloudera-Manager-%E5%8D%87%E7%BA%A7/"/>
      <url>/2017/03/26/Cloudera-Manager-%E5%8D%87%E7%BA%A7/</url>
      <content type="html"><![CDATA[<p>　　我想大家都已经很熟悉<a href="https://www.cloudera.com/" target="_blank" rel="noopener">Cloudera公司</a>的产品了，我也是从<a href="https://www.cloudera.com/downloads/manager/5-10-0.html" target="_blank" rel="noopener">CDH</a>以及CM 4.x使用到现在最新版本<a href="http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.10.0/" target="_blank" rel="noopener">CDH5.10.0</a>。不知道大家是否和我一样，喜欢去折腾一些新的版本，总感觉最新的发行版要好一些，有更多优化改进的地方，哈哈哈，当然这种只是片面想法，毕竟早期的版本还是比较稳定。</p><p>　　我们在升级CDH的时候，首先去升级的是Cloudera Manager,下面博客主要讲解的就是Cloudera Manager从5.5.1升级到5.9.1（其实升级的方法都是大同小异的，比如下面的方法升级5.5.1到5.10.0都是可以的亲自都升级过，只是下面的讲解截图是5.9.1）。</p><h2 id="下载上传配置"><a href="#下载上传配置" class="headerlink" title="下载上传配置"></a>下载上传配置</h2><ol><li>下载rpm包，<a href="http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/" target="_blank" rel="noopener">http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/</a><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100952.png" alt=""><a id="more"></a></li><li><p>上传到/var/www/html<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100953.png" alt=""></p></li><li><p>配置<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100954.png" alt=""><br>  [cloudera-manager]<br>  name = Cloudera Manager, Version 5.9.1<br>  baseurl = <a href="http://fetch-loadtest-20/cm5.9.1/" target="_blank" rel="noopener">http://fetch-loadtest-20/cm5.9.1/</a><br>  gpgcheck = 0</p></li></ol><h2 id="升级后重启"><a href="#升级后重启" class="headerlink" title="升级后重启"></a>升级后重启</h2><ul><li><p>升级 （所有agent都需要升级）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum clean all</span><br><span class="line">sudo yum upgrade cloudera-manager-server cloudera-manager-daemons cloudera-manager-server-db-2 cloudera-manager-agent</span><br></pre></td></tr></table></figure></li><li><p><img src="https://img.xiaoxiaomo.com/blog/img/20170326100955.png" alt=""></p></li><li><p>重启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo service cloudera-scm-server stop</span><br><span class="line">sudo service cloudera-scm-server-db stop</span><br><span class="line">sudo service cloudera-scm-server-db start</span><br><span class="line">sudo service cloudera-scm-server start</span><br></pre></td></tr></table></figure></li></ul><h2 id="登陆后配置"><a href="#登陆后配置" class="headerlink" title="登陆后配置"></a>登陆后配置</h2><ul><li><p>登陆7180界面配置信息<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100956.png" alt=""></p></li><li><p>选择是，点击继续<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100957.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100958.jpg" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100959.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100960.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100961.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100962.png" alt="">   </p></li><li><p>会重启一下cloudera manager<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100963.png" alt=""></p></li><li><p>重启客户端配置，升级完成<br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100964.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog/img/20170326100965.png" alt=""></p></li></ul><p>　　</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Some of the anomalies about kylin</title>
      <link href="/2017/03/11/Kylin-some-of-the-anomalies/"/>
      <url>/2017/03/11/Kylin-some-of-the-anomalies/</url>
      <content type="html"><![CDATA[<p>　　在做kylin的时候遇到了的一些问题，如果后面继续发现问题，会持续做更新……</p><ol><li>异常信息：可以发现是找不到hive-jdbc驱动包</li><li>kylin运行时Container内存不够</li><li>在kylin中执行SQL语句异常</li><li>kylin执行时找不到类</li></ol><a id="more"></a><h2 id="异常信息：可以发现是找不到hive-jdbc驱动包"><a href="#异常信息：可以发现是找不到hive-jdbc驱动包" class="headerlink" title="异常信息：可以发现是找不到hive-jdbc驱动包"></a>异常信息：可以发现是找不到hive-jdbc驱动包</h2><ul><li><code>Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.serde2.typeinfo.TypeInfo</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">2017-03-09 15:27:43,438 FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.NoClassDefFoundError: org/apache/hadoop/hive/serde2/typeinfo/TypeInfo</span><br><span class="line">at java.lang.Class.forName0(Native Method)</span><br><span class="line">at java.lang.Class.forName(Class.java:270)</span><br><span class="line">at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2138)</span><br><span class="line">at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2103)</span><br><span class="line">at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2197)</span><br><span class="line">at org.apache.hadoop.mapreduce.task.JobContextImpl.getInputFormatClass(JobContextImpl.java:184)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:749)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</span><br><span class="line">at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:415)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796)</span><br><span class="line">at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.serde2.typeinfo.TypeInfo</span><br><span class="line">at java.net.URLClassLoader$1.run(URLClassLoader.java:366)</span><br><span class="line">at java.net.URLClassLoader$1.run(URLClassLoader.java:355)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:354)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:425)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:358)</span><br><span class="line">... 13 more</span><br></pre></td></tr></table></figure></li></ul><p>知道问题是啥，但是不知道怎么解决，尴尬！因为把jive-jdbc放入到$KYLIN_HOME/bin没效果，不知道把jdbc驱动放到哪儿，google了一下<br><a href="http://www.07net01.com/2016/02/1292650.html" target="_blank" rel="noopener">hhttp://www.07net01.com/2016/02/1292650.html</a> –&gt;<br><a href="https://stackoverflow.com/questions/34449561/hadoop-map-reduce-job-class-org-apache-hive-hcatalog-mapreduce-hcatinputformat" target="_blank" rel="noopener">https://stackoverflow.com/questions/34449561/hadoop-map-reduce-job-class-org-apache-hive-hcatalog-mapreduce-hcatinputformat</a> –&gt;<br><a href="https://issues.apache.org/jira/browse/KYLIN-1021" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/KYLIN-1021</a></p><ul><li><code>解决：</code><br>在$KYLIN_HOME/conf/kylin.properties配置：<br>kylin.job.mr.lib.dir=/opt/cloudera/parcels/CDH-5.10.0-1.cdh5.10.0.p0.41/jars </li></ul><h2 id="kylin-Container-内存不够"><a href="#kylin-Container-内存不够" class="headerlink" title="kylin Container 内存不够"></a>kylin Container 内存不够</h2><ul><li><p>running beyond physical memory limits</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Container [pid=22991,containerID=container_1494324779160_0130_01_000002] is running beyond physical memory limits. </span><br><span class="line">Current usage: 607.6 MB of 512 MB physical memory used; 1.1 GB of 1.0 GB virtual memory used. Killing container. </span><br><span class="line">Dump of the process-tree for container_1494324779160_0130_01_000002 : </span><br><span class="line">|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE </span><br><span class="line">|- 24045 22991 22991 22991 (java) 1301 77 1076248576 155172 </span><br><span class="line">/usr/java/jdk1.7.0_67-cloudera/bin/java </span><br><span class="line">-Djava.net.preferIPv4Stack=true </span><br><span class="line">-Dhadoop.metrics.log.level=WARN </span><br><span class="line">-Djava.net.preferIPv4Stack=true -Xmx419430400 </span><br><span class="line">-Djava.io.tmpdir=/hbase/yarn/nm3/usercache/root/appcache/application_1494324779160_0130/container_1494324779160_0130_01_000002/tmp </span><br><span class="line">-Dlog4j.configuration=container-log4j.properties </span><br><span class="line">-Dyarn.app.container.log.dir=/hbase/yarn/container-logs/application_1494324779160_0130/container_1494324779160_0130_01_000002 </span><br><span class="line">-Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA </span><br><span class="line">-Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 10.141.5.25 33530 attempt_1494324779160_0130_m_000000_0 2 |- 22991 22988 22991 22991 (bash) 12 22 110931968 386 /bin/bash -c /usr/java/jdk1.7.0_67-cloudera/bin/java </span><br><span class="line">-Djava.net.preferIPv4Stack=true </span><br><span class="line">-Dhadoop.metrics.log.level=WARN </span><br><span class="line">-Djava.net.preferIPv4Stack=true -Xmx419430400 </span><br><span class="line">-Djava.io.tmpdir=/hbase/yarn/nm3/usercache/root/appcache/application_1494324779160_0130/container_1494324779160_0130_01_000002/tmp </span><br><span class="line">-Dlog4j.configuration=container-log4j.properties </span><br><span class="line">-Dyarn.app.container.log.dir=/hbase/yarn/container-logs/application_1494324779160_0130/container_1494324779160_0130_01_000002 </span><br><span class="line">-Dyarn.app.container.log.filesize=0 </span><br><span class="line">-Dhadoop.root.logger=INFO,CLA </span><br><span class="line">-Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 10.141.5.25 33530 attempt_1494324779160_0130_m_000000_0 2 1&gt;/hbase/yarn/container-logs/application_1494324779160_0130/container_1494324779160_0130_01_000002/stdout 2&gt;/hbase/yarn/container-logs/application_1494324779160_0130/container_1494324779160_0130_01_000002/stderr </span><br><span class="line">Container killed on request. Exit code is 143 Container exited with a non-zero exit code 143</span><br></pre></td></tr></table></figure></li><li><p><code>参考：</code><br><a href="https://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits" target="_blank" rel="noopener">https://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits</a></p></li></ul><h2 id="在kylin中执行SQL语句异常"><a href="#在kylin中执行SQL语句异常" class="headerlink" title="在kylin中执行SQL语句异常"></a>在kylin中执行SQL语句异常</h2><ul><li><p>Error while executing SQL</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Error while executing SQL "SELECT part_dt,sum(price) AS total_price,count(DISTINCT seller_id) AS sellers FROM kylin_sales GROUP BY part_dt ORDER BY part_dt LIMIT 50000": </span><br><span class="line">org.apache.hadoop.hbase.exceptions.UnknownProtocolException: </span><br><span class="line">org.apache.hadoop.hbase.exceptions.UnknownProtocolException: </span><br><span class="line">No registered coprocessor service found for name CubeVisitService in region KYLIN_CMQ2D8I0H1,\x00\x04,1495703949441.26edd2674722c672724d25cfa410e061. </span><br><span class="line">at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:7773) </span><br><span class="line">at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:1982) </span><br><span class="line">at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:1964) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33652) </span><br><span class="line">at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109) at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:185) </span><br><span class="line">at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:165)</span><br></pre></td></tr></table></figure></li><li><p><code>解决</code>：<br><a href="http://blog.csdn.net/sikongyuanruo/article/details/53439163" target="_blank" rel="noopener">http://blog.csdn.net/sikongyuanruo/article/details/53439163</a> –&gt;<br>可能的原因：kylin与当前的hbase匹配有问题，在官网上找到了解决的方法：<br><a href="http://kylin.apache.org/docs15/howto/howto_update_coprocessor.html" target="_blank" rel="noopener">http://kylin.apache.org/docs15/howto/howto_update_coprocessor.html</a> 即，执行下面的shell命令：<br>$KYLIN_HOME/bin/kylin.sh org.apache.kylin.storage.hbase.util.DeployCoprocessorCLI $KYLIN_HOME/lib/kylin-coprocessor-*.jar all</p></li></ul><h2 id="kylin执行时找不到类"><a href="#kylin执行时找不到类" class="headerlink" title="kylin执行时找不到类"></a>kylin执行时找不到类</h2><ul><li><p>Error: java.lang.ClassNotFoundException</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Error: java.lang.ClassNotFoundException: org.apache.kylin.engine.mr.KylinMapper at </span><br><span class="line">    java.net.URLClassLoader$1.run(URLClassLoader.java:366) at </span><br><span class="line">    java.net.URLClassLoader$1.run(URLClassLoader.java:355) at </span><br><span class="line">    java.security.AccessController.doPrivileged(Native Method) at </span><br><span class="line">    java.net.URLClassLoader.findClass(URLClassLoader.java:354) at </span><br><span class="line">    java.lang.ClassLoader.loadClass(ClassLoader.java:425) at </span><br><span class="line">    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at </span><br><span class="line">    java.lang.ClassLoader.loadClass(ClassLoader.java:358) at </span><br><span class="line">    java.lang.ClassLoader.defineClass1(Native Method) at </span><br><span class="line">    java.lang.ClassLoader.defineClass(ClassLoader.java:800) at </span><br><span class="line">    java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at </span><br><span class="line">    java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at </span><br><span class="line">    java.net.URLClassLoader.access$100(URLClassLoader.java:71) at </span><br><span class="line">    java.net.URLClassLoader$1.run(URLClassLoader.java:361) at </span><br><span class="line">    java.net.URLClassLoader$1.run(URLClassLoader.java:355) at </span><br><span class="line">    java.security.AccessController.doPrivileged(Native Method) at </span><br><span class="line">    java.net.URLClassLoader.findClass(URLClassLoader.java:354) at </span><br><span class="line">    java.lang.ClassLoader.loadClass(ClassLoader.java:425) at </span><br><span class="line">    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at </span><br><span class="line">    java.lang.ClassLoader.loadClass(ClassLoader.java:358) at </span><br><span class="line">    java.lang.Class.forName0(Native Method) at </span><br><span class="line">    java.lang.Class.forName(Class.java:270) at </span><br><span class="line">    org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2138) at </span><br><span class="line">    org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2103) at </span><br><span class="line">    org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2197) at </span><br><span class="line">    org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:196) at </span><br><span class="line">    org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:745) at </span><br><span class="line">    org.apache.hadoop.mapred.MapTask.run(MapTask.java:341) at </span><br><span class="line">    org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164) at </span><br><span class="line">    java.security.AccessController.doPrivileged(Native Method) at </span><br><span class="line">    javax.security.auth.Subject.doAs(Subject.java:415) at </span><br><span class="line">    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796) at </span><br><span class="line">    org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</span><br></pre></td></tr></table></figure></li><li><p><code>解决：</code><br>默认安装kylin后，kylin相关的lib并没有在yarn中，运行任务时job就会抛出异常，java.lang.ClassNotFoundException，解决思路就是添加jar。比如上面就缺少kylin-engine-mr</p></li></ul><ol><li>上传jar到kylin lib</li><li>并且做软连接(只需要在kylin对应的节点做软连接)</li><li>ln -s /hbase/kylin-2.0/lib/kylin-engine-mr /opt/cloudera/parcels/CDH/jars/</li><li>后面还会遇到一些这样的问题，这是我遇到过的，上传的jar<br><img src="https://img.xiaoxiaomo.com/blog/img/kylin7.png" alt="kylin 上传的jar"></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kylin </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>About the installation of kylin</title>
      <link href="/2017/03/10/Kylin-about-the-installation/"/>
      <url>/2017/03/10/Kylin-about-the-installation/</url>
      <content type="html"><![CDATA[<p>　　我在这里就不去写一些关于Kylin的一些介绍了，而对于kylin的安装我想网上的博客也不少，那为什么还要写呢？主要有以下几点：</p><ol><li>博客太多太杂，难免会遇到一些坑</li><li>该kylin的安装，主要是结合cloudera cdh安装</li><li>针对的是kylin 2.0版本，里面有些参数已经对于之前的版本有所改动了</li></ol><a id="more"></a><h2 id="1-下载："><a href="#1-下载：" class="headerlink" title="1. 下载："></a>1. 下载：</h2><p><a href="http://kylin.apache.org/cn/download/" target="_blank" rel="noopener">http://kylin.apache.org/cn/download/</a><br><img src="https://img.xiaoxiaomo.com/blog/img/kylin1.png" alt="kylin下载"></p><h2 id="2-解压，重命名"><a href="#2-解压，重命名" class="headerlink" title="2. 解压，重命名"></a>2. 解压，重命名</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-kylin-2.0.0-bin-cdh57.tar.gz</span><br><span class="line">mv apache-kylin-2.0.0-bin kylin-2.0</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog/img/kylin2.png" alt="kylin解压，重命名"></p><h2 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/kylin3.png" alt="kylin配置环境变量"><br><strong>export HCAT_HOME=$HIVE_HOME/hcatalog</strong><br><strong>注意：</strong> <code>CDH里面是一个角色/opt/cloudera/parcels/CDH/lib/hive-hcatalog/</code></p><h2 id="4-环境检查"><a href="#4-环境检查" class="headerlink" title="4. 环境检查"></a>4. 环境检查</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/kylin4.png" alt="kylin 环境检查"></p><h2 id="5-配置kylin-properties"><a href="#5-配置kylin-properties" class="headerlink" title="5. 配置kylin.properties"></a>5. 配置kylin.properties</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kylin.job.jar=$&#123;KYLIN_HOME&#125;/lib/kylin-job-2.0.0.jar</span><br><span class="line">kylin.coprocessor.local.jar=$&#123;KYLIN_HOME&#125;/lib/kylin-coprocessor-2.0.0.jar</span><br><span class="line">kylin.job.yarn.app.rest.check.status.url=http://hostname:8088/ws/v1/cluster/apps/$&#123;job_id&#125;?anonymous=true</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog/img/kylin5.png" alt="配置kylin.properties"></p><ul><li><strong>注意：</strong> 这样修改后启动是没有错误的，但是会提示警告信息，所以最好修改为：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kylin.engine.mr.job-jar=$&#123;KYLIN_HOME&#125;/lib/kylin-job-2.0.0.jar</span><br><span class="line">kylin.storage.hbase.coprocessor-local-jar=$&#123;KYLIN_HOME&#125;/lib/kylin-coprocessor-2.0.0.jar</span><br><span class="line">kylin.engine.mr.yarn-check-status-url=http://hostname:8088/ws/v1/cluster/apps/$&#123;job_id&#125;?anonymous=true</span><br></pre></td></tr></table></figure></li></ul><h2 id="6-启动，访问"><a href="#6-启动，访问" class="headerlink" title="6. 启动，访问"></a>6. 启动，访问</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/kylin6.png" alt="kylin启动，访问"><br>用户名/密码：ADMIN/KYLIN,ANALYST/ANALYST,MODELER/MODELER</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kylin </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--强制删除表</title>
      <link href="/2016/11/12/HBase-%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E8%A1%A8/"/>
      <url>/2016/11/12/HBase-%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E8%A1%A8/</url>
      <content type="html"><![CDATA[<p>　　<code>HBase 强制删除表</code>，这个网上记录的也有，但是发现有些记录的有问题，如果要是在生产环境中就需要谨慎的去操作了。在这里我记录一下自己工作中遇到的这个问题，以及解决步骤，遇到类似问题可以参考一下。</p><h1 id="发现异常信息"><a href="#发现异常信息" class="headerlink" title="发现异常信息"></a>发现异常信息</h1><ul><li><strong>发现表无法操作了，查看一下状态：</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">003</span>:<span class="number">0</span>&gt; desc <span class="string">'HBaseTable'</span></span><br><span class="line">Table HBaseTable is DISABLED</span><br><span class="line">HBaseTable</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; <span class="string">'d'</span>, DATA_BLOCK_ENCODING =&gt; <span class="string">'NONE'</span>, BLOOMFILTER =&gt; <span class="string">'ROW'</span>, REPLICATION_SCOPE =&gt; <span class="string">'0'</span>, </span><br><span class="line">VERSIONS =&gt; <span class="string">'3'</span>, COMPRESSION =&gt; <span class="string">'SNAPPY'</span>, MIN_VERSIONS =&gt; <span class="string">'0'</span>, TTL =&gt; <span class="string">'FOREVER'</span>, </span><br><span class="line">KEEP_DELETED_CELLS =&gt; <span class="string">'FALSE'</span>, BLOCKSIZE =&gt; <span class="string">'65536'</span>,IN_MEMORY=&gt;<span class="string">'false'</span>,BLOCKCACHE=&gt;<span class="string">'true'</span>&#125;</span><br><span class="line"><span class="number">1</span> row(s) in <span class="number">0.0900</span> seconds</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li><p><strong>表状态为DISABLED，那就enable 该表：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):004:0&gt; enable 'HBaseTable' ##如下异常：</span><br><span class="line">ERROR: org.apache.hadoop.hbase.TableNotDisabledException: HBaseTable</span><br><span class="line">        at org.apache.hadoop.hbase.master.handler.EnableTableHandler.prepare(EnableTableHandler.java:<span class="number">121</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.master.HMaster.enableTable(HMaster.java:<span class="number">1654</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.master.MasterRpcServices.enableTable(MasterRpcServices.java:<span class="number">572</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$<span class="number">2</span>.callBlockingMethod(MasterProtos.java:<span class="number">44233</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:<span class="number">2034</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:<span class="number">107</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:<span class="number">130</span>)</span><br><span class="line">        at org.apache.hadoop.hbase.ipc.RpcExecutor$<span class="number">1</span>.run(RpcExecutor.java:<span class="number">107</span>)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"></span><br><span class="line">Here is some help <span class="keyword">for</span> <span class="keyword">this</span> command:</span><br><span class="line">Start enable of named table:</span><br><span class="line">  hbase&gt; enable <span class="string">'t1'</span></span><br><span class="line">  hbase&gt; enable <span class="string">'ns1:t1'</span></span><br></pre></td></tr></table></figure></li><li><p>通过<code>desc</code>查看描述信息，发现表的状态为<code>DISABLED</code>，然后<code>enable</code>该表，无效~! 当时有点蒙逼！</p></li></ul><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><ol><li>发现该表<code>enable</code>、<code>disable</code>、<code>drop</code>都无效，也无法删除</li><li><p>检查表 <code>region</code> 信息，<code>hbase hbck TableNotDisabledException</code> 有错误信息.可能就是因为之前导入数据的时候该表有一个建立二级索引的协处理器，但是没有该表的二级索引表，异常导致HBase挂掉了，再次导入数据后导致region信息不一致了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">02</span>:<span class="number">34</span>:<span class="number">02</span>,<span class="number">645</span> ERROR org.apache.hadoop.hbase.client.AsyncProcess: Failed to get region location</span><br><span class="line">org.apache.hadoop.hbase.TableNotFoundException: HBaseTableIdx</span><br></pre></td></tr></table></figure></li><li><p>参考 <a href="http://stackoverflow.com/questions/14557742/table-is-neither-enables-nor-disabled-in-hbase" target="_blank" rel="noopener">http://stackoverflow.com/questions/14557742/table-is-neither-enables-nor-disabled-in-hbase</a>，通过hbase hbck -fixMeta -fixAssignments.无法修复！</p></li></ol><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><ul><li><strong>强制删除表</strong></li></ul><ol><li><code>删除zk中的数据</code>，[zk: localhost:2181(CONNECTED) 2] rmr /hbase/table/HBaseTable</li><li><code>删除HDFS上的数据</code>，hadoop fs -rmr /hbase/data/default/HBaseTable</li><li><code>删除meta表信息</code>，在meta表查询（下面是HBase 版本1.0.0，meta表在hbase库中，注意一下HBase版本，找到自己的meta表就行）<br>scan ‘hbase:meta’,{STARTROW=&gt;’HBaseTable000’,ENDROW=&gt;’HBaseTable~~~’,COLUMN=&gt;’info:server’}<br>如查询到信息如下：<br>HBaseTable,,1478497826515.a004067142d51f88a067528bca69a6ec. column=info:server, timestamp=1478518834995, value=xxo:60020<br>….<br>通过rowkey删除，记得删除把该表的meta数据删除干净(server，serverstartcode，regioninfo，seqnumDuringOpen)<br>delete ‘hbase:meta’,’HBaseTable,,1478497826515.a004067142d51f88a067528bca69a6ec.’,’info:server’<br>delete ‘hbase:meta’,’HBaseTable,,1478497826515.a004067142d51f88a067528bca69a6ec.’,’info:serverstartcode’<br>delete ‘hbase:meta’,’HBaseTable,,1478497826515.a004067142d51f88a067528bca69a6ec.’,’info:regioninfo’<br>delete ‘hbase:meta’,’HBaseTable,,1478497826515.a004067142d51f88a067528bca69a6ec.’,’info:seqnumDuringOpen’  </li></ol><ul><li>这时候去hbase中查看，发现还有该表，但是对该HBase表操作提示没有表信息了，<strong>这时候重启regionserver就解决问题了，如果是正式环境就不要重启了，直接创建一下该表就能正常使用了</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">093</span>:<span class="number">0</span>&gt; list</span><br><span class="line">HBaseTable</span><br><span class="line">hbase(main):<span class="number">094</span>:<span class="number">0</span>&gt; desc <span class="string">'HBaseTable'</span></span><br><span class="line">ERROR: Unknown table HBaseTable!</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>VirtualBox--网络配置</title>
      <link href="/2016/11/11/VirtualBox-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"/>
      <url>/2016/11/11/VirtualBox-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　下面是对VirtualBox进行网络配置，我需要的网络要求是<strong>虚拟机可以通过外网，虚拟机与虚拟机之间可以相互访问</strong>。<br>对于VMWare相对来说简单一点，其实VirtualBox也比较简单，只是概念稍微绕一些，不想VMWare那样通过一个nat就能访问外网内网。<br>VirtualBox的四种网络模式各有各的优点，不过不能同时支持我的需求，<br><code>所以需要同时启动两块网卡，一种采用默认的NAT方式访问外网，一种使用Host-Only模式使得主机和虚拟机之间可以相互访问。</code></p><a id="more"></a><h1 id="全局设定"><a href="#全局设定" class="headerlink" title="全局设定"></a>全局设定</h1><ol><li><p>网络–nat，添加一个NatNetWork,不需要做任何修改<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox1.png" alt="VirtualBox 全局设定-nat"><br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox2.png" alt="VirtualBox 全局设定-nat,网络明细"></p></li><li><p>网络–host-only<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox3.png" alt="VirtualBox 全局设定-host-only"><br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox4.png" alt="VirtualBox 全局设定-host-only,网络明细"><br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox5.png" alt="VirtualBox 全局设定-host-only，DHCP"></p></li></ol><h1 id="虚拟机网络"><a href="#虚拟机网络" class="headerlink" title="虚拟机网络"></a>虚拟机网络</h1><ul><li>虚拟机网络配置(关闭linux)</li></ul><ol><li>选中虚拟机–右键设置–网络–网卡1<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox6.png" alt="虚拟机网络--网卡1">    </li><li>网络–网卡2(勾选启用，并选择host-only)<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox7.png" alt="虚拟机网络--网卡2">    </li></ol><h1 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h1><ul><li>虚拟机网络网络配置(启动虚拟机)</li></ul><ol><li><p>eth0（网卡nat）<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox8.png" alt="VirtualBox eth0（网卡nat）"></p></li><li><p>ech1 (网卡host-only)<br>默认可能没有先复制ech0然后去掉uuid,在/etc/udev/rules.d/70-persistent-net.rules中找到eth1的HWADDR地址<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox9.png" alt="VirtualBox ech1 (网卡host-only)">    </p></li><li><p>重启网卡<br>service network restart</p></li></ol><h1 id="校验"><a href="#校验" class="headerlink" title="校验"></a>校验</h1><ol><li><p>虚拟机ping外网<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox10.png" alt="VirtualBox 虚拟机ping外网">    </p></li><li><p>虚拟机ping虚拟机<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox11.png" alt="VirtualBox 虚拟机ping虚拟机">     </p></li><li><p>主机ping虚拟机（当然主机也能通过xshell等工具连通虚拟机了）<br><img src="https://img.xiaoxiaomo.com/blog/img/virtualbox12.png" alt="VirtualBox 主机ping虚拟机">    </p></li></ol><ul><li><code>备注：</code></li></ul><ol><li>复制的虚拟机，需要修改网卡name,mac地址</li><li>修改后需要重启，不然直接重启网卡会报错 No such device eth0</li><li>重启网卡后发现无异常，但是就是不能上网，需要sudo dhclient</li></ol><ul><li><code>参考：</code><br><a href="http://blog.csdn.net/witsmakemen/article/details/45563627" target="_blank" rel="noopener">http://blog.csdn.net/witsmakemen/article/details/45563627</a><br><a href="http://www.cnblogs.com/jayviper/p/3198189.html" target="_blank" rel="noopener">http://www.cnblogs.com/jayviper/p/3198189.html</a><br><a href="http://blog.csdn.net/imred/article/details/53493109" target="_blank" rel="noopener">http://blog.csdn.net/imred/article/details/53493109</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 虚拟机 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Oozie--安装配置及注意事项</title>
      <link href="/2016/11/06/Oozie-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
      <url>/2016/11/06/Oozie-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
      <content type="html"><![CDATA[<p>　　简单介绍一下，<code>oozie</code>。<code>oozie就是一个workflow协调系统，主要用来管理Hadoop作业(job)</code>。属于web应用程序，由<strong>oozie client</strong>和<strong>oozie server</strong>两个组件构成。oozie server运行于java servlet容器（tomcat）中的web程序。</p><h2 id="OOZIE"><a href="#OOZIE" class="headerlink" title="OOZIE"></a>OOZIE</h2><ol><li>Oozie定义了<code>控制流节点</code>（Control Flow Nodes）和<code>动作节点</code>（Action Nodes）</li><li>控制流节点定义了流程的开始和结束，以及控制流程的执行路径（Execution Path），如decision、fork、join等；</li><li>动作节点包括Hadoop map-reduce、Hadoop文件系统、Pig、SSH、HTTP、eMail和Oozie子流程。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161106171640.png" alt=""></li></ol><a id="more"></a><h2 id="Oozie-安装"><a href="#Oozie-安装" class="headerlink" title="Oozie 安装"></a>Oozie 安装</h2><ul><li>我就不讲解具体安装步骤了，有下面两种安装方式：</li></ul><ol><li>手动安装Oozie：可以查看该博客 <a href="http://blog.csdn.net/teddeyang/article/details/16339533" target="_blank" rel="noopener">http://blog.csdn.net/teddeyang/article/details/16339533</a></li><li>通过CM进行oozie组件添加（安装之前需要有mapreduce)</li></ol><h2 id="Oozie-配置"><a href="#Oozie-配置" class="headerlink" title="Oozie 配置"></a>Oozie 配置</h2><ul><li><strong>安装完Oozie后，对常用的几个配置的修改和查看</strong>：</li></ul><ol><li><strong>节点内存配置</strong>，该配置给<code>Oozie Server</code> 使用，如果Oozie 调度任务比较大可以设置大一点，512M或者1G。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F164844841.png" alt=""></li><li><strong>oozie.service.callablequeueservice.callable.concurrency （节点并发）</strong>，同时并发最大执行Oozie 调度任务。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F163328431.png" alt=""></li><li><strong>oozie.service.callablequeueservice.queue.size（队列大小）</strong>，这个默认10000，足够了。</li><li><strong>oozie元数据更改</strong>，默认为<code>PostgreSQL</code>，一般来讲我们修改为<code>MySQL</code>，不建议使用Derby。修改元数据库要注意以下几点：<br>4.1. 首先要创建第三方元数据库<br>4.2. 添加数据库驱动,（/opt/cloudera/parcels/CDH/lib/oozi目录下的 libserver目录和libtools目录）<br>4.3. 安装共享库，修改完数据库之后记得点一下“安装 Oozie 共享库”，想当于初始化了一下，和这两个目录有关：<blockquote><p>/opt/cloudera/parcels/CDH/lib/oozie/oozie-sharelib-mr1(如果 CDH MR 资源调度服务为mapreduce)<br>/opt/cloudera/parcels/CDH/lib/oozie/oozie-sharelib-yarn(如果 CDH MR 资源调度服务为yarn)</p></blockquote><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F161926711.png" alt=""><br><code>注</code>：MySQL驱动包不需要版本号，即 mysql-connector-java.jar</li></ol><h2 id="Oozie-插件安装"><a href="#Oozie-插件安装" class="headerlink" title="Oozie 插件安装"></a>Oozie 插件安装</h2><ul><li><p>ext2.2添加 </p><blockquote><p>将ext-2.2.tar.gz解压放到<code>/opt/cloudera/parcels/CDH/lib/oozie/libext</code>目录下即可<br>注意：在界面setting里面可以设置一下时区，只对插件界面显示有效</p></blockquote></li><li><p>参考资料</p></li><li><a href="https://oozie.apache.org/" target="_blank" rel="noopener">https://oozie.apache.org/</a></li><li><a href="http://blog.cloudera.com/blog/category/oozie/" target="_blank" rel="noopener">http://blog.cloudera.com/blog/category/oozie/</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Oozie </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Sentry--通过Cloudera Manager配置Sentry</title>
      <link href="/2016/10/19/Sentry-%E9%80%9A%E8%BF%87Cloudera-Manager%E9%85%8D%E7%BD%AESentry/"/>
      <url>/2016/10/19/Sentry-%E9%80%9A%E8%BF%87Cloudera-Manager%E9%85%8D%E7%BD%AESentry/</url>
      <content type="html"><![CDATA[<p>　　本篇博客讲解一下通过<code>Cloudera Manager</code>配置<code>Sentry</code>的一个过程，如果对Sentry不够了解的可以查看这篇博客<a href="http://blog.javachen.com/2015/04/29/apache-sentry-architecture.html" target="_blank" rel="noopener">http://blog.javachen.com/2015/04/29/apache-sentry-architecture.html</a>。添加<code>Sentry服务</code>，以及<code>Cloudera Manager</code>的界面配置这些都很简单，我就做一些简要说明，重点会说明我实际在<code>Sentry</code>配置过程中遇到的一些坑吧。其他配置方式可以参考博客<a href="http://blog.csdn.net/shenliang1985/article/details/50463432" target="_blank" rel="noopener">http://blog.csdn.net/shenliang1985/article/details/50463432</a>，说明：本博客CDH版本5.5.1，以及到目前最新版本CDH版本5.8.0也同样适用。</p><h2 id="添加Sentry服务"><a href="#添加Sentry服务" class="headerlink" title="添加Sentry服务"></a>添加Sentry服务</h2><ul><li>添加Sentry很简单，下一步下一步即可，选择sentry服务也只需要一台主机。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579234.png" alt="通过Cloudera Manager界面添加Sentry服务"></li></ul><a id="more"></a><ul><li>选择<code>数据库</code>时，最好使用MySQL,需要注意的一点就是:</li></ul><ol><li>在数据库节点如下“fetch-loadTest-26”下面需要安装MySQL并有相应的用户和数据库</li><li>在Sentry Server节点如上“fetch-loadTest-25”需要有MySQL驱动包<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579235.png" alt=""></li></ol><h2 id="CM管理页面配置"><a href="#CM管理页面配置" class="headerlink" title="CM管理页面配置"></a>CM管理页面配置</h2><ul><li><p><strong>在hue配置中修改</strong>, hue选择为Sentry<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579236.png" alt=""></p></li><li><p><strong>在Hive配置中修改</strong></p></li></ul><ol><li>搜索Impersonation，取消下面该选项<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1829748125.png" alt=""></li><li>在sentry-site.xml 的 Hive 服务高级配置代码段（安全阀）<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>sentry.hive.testing.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><ul><li><p><strong>在Sentry中配置</strong>，添加一个root(这有点奇怪，必须添加root用户)<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1831755375.png" alt=""></p><h2 id="HUE页面配置"><a href="#HUE页面配置" class="headerlink" title="HUE页面配置"></a>HUE页面配置</h2><ul><li><p>登陆hue，发现多出一个Security选项，我们就可以通过Sentry表来管理，选项下面直接管理hive表<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1831755377.png" alt=""></p></li><li><p><code>注意</code>：再CDH5.8.0默认Hue™ 3.10里面Security选项有所不同，但使用都是相同的，如下：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579299.png" alt=""></p></li></ul></li></ul><h2 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h2><ul><li><strong>用户管理界面下，添加root用户和root组，作为超级管理员，提供授权等功能</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1834283593.png" alt=""></li></ul><h2 id="授权管理"><a href="#授权管理" class="headerlink" title="授权管理"></a>授权管理</h2><ol><li><p>通过root登陆hue，在用户管理员下添加<code>test1用户</code>、<code>test1用户组</code>，并在Security下给test1组<code>授权</code>（勾选创建主目录会在hdfs上创建相应目录）；<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1836861484.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1836983390.png" alt=""></p></li><li><p>在安装<code>HiveServer2</code>的机器上添加相应的<code>Linux用户</code>(<strong>如果不添加，即使授权了也无法查看到信息</strong>)</p><blockquote><p>[root@xiaoxiaomo ~]# groupadd test1 &amp;&amp; useradd -g test1 test1  ##创建Linux组和用户<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1837338843.png" alt=""></p></blockquote></li><li><p>通过<code>Security选项</code>下的，<code>Roles</code>给用户组<code>test1</code>授权<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579300.png" alt=""></p></li></ol><p>3.1. <code>添加</code>test1_role角色，设置为test1组，并授权db=default给该组(<code>PS：改组映射的是linux用户组</code>)<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579301.png" alt=""></p><p>3.2. 然后我们登陆test1用户，查看信息，Okay了！<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F1750579302.png" alt="Sentry授权成功!"></p><ul><li><code>注意</code>：</li></ul><ol><li>hue用户管理界面下添加的用户组，和Sentry里面授权的组没有直接关系；</li><li>Sentry里面分配角色权限的组和Linux里面的组关联；</li><li>当我们添加完hue用户和组时，一般在linux相应这么添加，如下命令<br>3.1. 新增加一个用户并将其列入一个已有的用户组中：<code>adduser -g 组 用户</code>；<br>3.2. 一个已有用户追加到一个已有用户组：<code>usermod -a -G 组 用户</code>；<br>3.3. 直接修改组<code>usermod -g 组 用户</code>，上面的-a代表 append。</li></ol><ul><li>参考资料<br><a href="http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/" target="_blank" rel="noopener">http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/ </a><br><a href="http://blog.javachen.com/2015/04/30/install-and-config-sentry.html" target="_blank" rel="noopener">http://blog.javachen.com/2015/04/30/install-and-config-sentry.html</a><br><a href="http://www.cloudera.com/documentation/archive/cdh/4-x/4-7-1/CDH4-Security-Guide/cdh4sg_Sentry.html" target="_blank" rel="noopener">http://www.cloudera.com/documentation/archive/cdh/4-x/4-7-1/CDH4-Security-Guide/cdh4sg_Sentry.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
            <tag> Sentry </tag>
            
            <tag> Hue </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Sentry--Sentry无法授权的问题</title>
      <link href="/2016/10/18/Sentry-Sentry%E6%97%A0%E6%B3%95%E6%8E%88%E6%9D%83%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/2016/10/18/Sentry-Sentry%E6%97%A0%E6%B3%95%E6%8E%88%E6%9D%83%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h2><ul><li>添加完Sentry,什么都配置好了，添加相应<code>hue用户</code>，把hue用户授权给<code>hue组</code>，查看<code>Sentry表</code>:<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161817212203.png" alt="发现无法操作权限"></li></ul><a id="more"></a><ul><li>即，在<code>hue里面使用sentry，没有修改配置角色的权限</code>，很郁闷，通过官网的视频开看明明是有的！<a href="http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/" target="_blank" rel="noopener">http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/ </a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161817212202.jpg" alt="官网视频截图"></li></ul><h2 id="查找原因"><a href="#查找原因" class="headerlink" title="查找原因"></a>查找原因</h2><ul><li><em>修改后，去查看各种配置，修改各种权限，还是没有结果。全都设置为最大权限了，为啥还是不行，这里卡了很长的一段时间</em>。<strong>发现忘了一件事情，没看日志</strong>。于是就看了看<code>日志</code>：<code>点击角色-实例--然后Log Files，如下：</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Role: TListSentryRolesRequest(protocol_version:<span class="number">2</span>, requestorUserName:hue, groupName:<span class="keyword">default</span>) couldn<span class="string">'t be retrieved.</span></span><br><span class="line"><span class="string">org.apache.sentry.provider.db.SentryNoSuchObjectException: Group default</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.persistent.SentryStore.getMSentryRolesByGroupName(SentryStore.java:1140)</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.persistent.SentryStore.getTSentryRolesByGroupName(SentryStore.java:1170)</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.thrift.SentryPolicyStoreProcessor.list_sentry_roles_by_group(SentryPolicyStoreProcessor.java:567)</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.thrift.SentryPolicyService$Processor$list_sentry_roles_by_group.getResult(SentryPolicyService.java:1017)</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.thrift.SentryPolicyService$Processor$list_sentry_roles_by_group.getResult(SentryPolicyService.java:1002)</span></span><br><span class="line"><span class="string">at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)</span></span><br><span class="line"><span class="string">at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)</span></span><br><span class="line"><span class="string">at org.apache.sentry.provider.db.service.thrift.SentryProcessorWrapper.process(SentryProcessorWrapper.java:35)</span></span><br><span class="line"><span class="string">at org.apache.thrift.TMultiplexedProcessor.process(TMultiplexedProcessor.java:123)</span></span><br><span class="line"><span class="string">at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)</span></span><br><span class="line"><span class="string">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span></span><br><span class="line"><span class="string">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</span></span><br><span class="line"><span class="string">at java.lang.Thread.run(Thread.java:745)</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><ul><li><p>Google了一下，发现了问题：<a href="https://groups.google.com/a/cloudera.org/forum/#!topic/hue-user/vNPeGDCysFQ" target="_blank" rel="noopener">https://groups.google.com/a/cloudera.org/forum/#!topic/hue-user/vNPeGDCysFQ</a></p></li><li><p><strong>我复制过来，粘贴在下面</strong>：</p></li></ul><hr><p>The ‘default’ group is comes from Hue (<a href="https://github.com/cloudera/hue/blob/master/desktop/conf.dist/hue.ini#L1072)" target="_blank" rel="noopener">https://github.com/cloudera/hue/blob/master/desktop/conf.dist/hue.ini#L1072)</a>, it is not a unix group so it won’t be understood by Sentry.<br>We improved the error message recently in <a href="https://github.com/cloudera/hue/commit/1c0e1e3f86330ac77cdb1b30db710767fd3b9d69" target="_blank" rel="noopener">https://github.com/cloudera/hue/commit/1c0e1e3f86330ac77cdb1b30db710767fd3b9d69</a> so it won’t show up. The current workaround is to not select this group.<br>Same with hive, if this is not a unix group Sentry won’t understand it.<br>As long as your admin users belong to one of sentry.service.admin.group in Hue they will have edit permissions in the Sentry UI</p><hr><ul><li><p>hue用户默认是“default”组，但是“default”它不是linux/unix组，所以Sentry就无法识别，然后在hue里面添加一个比如“root”组，然后把改组授权给相应用户就行了。</p></li><li><p>注  ：<br>一般做Sentry权限管理的，使用一个超级管理员用户就可以了，用它来专门做权限。</p></li></ul>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
            <tag> Sentry </tag>
            
            <tag> Hue </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SBT--Error during sbt execution: Error retrieving required libraries</title>
      <link href="/2016/10/16/SBT-Error-during-sbt-execution-Error-retrieving-required-libraries/"/>
      <url>/2016/10/16/SBT-Error-during-sbt-execution-Error-retrieving-required-libraries/</url>
      <content type="html"><![CDATA[<h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><ul><li><code>信息如下</code>：<blockquote><p>:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS<br>download failed: org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar<br>Error during sbt execution: Error retrieving required libraries<br>  (see D:\dev\sbt\boot\update.log for complete log)<br>Error: Could not retrieve sbt 0.13.8</p></blockquote></li></ul><a id="more"></a><ul><li><code>具体信息</code>：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">Getting org.scala-sbt sbt 0.13.8 ...</span><br><span class="line">downloading http://uk.maven.org/maven2/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar ...</span><br><span class="line">downloading http://repo2.maven.org/maven2/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar ...</span><br><span class="line"></span><br><span class="line">:: problems summary ::</span><br><span class="line">:::: WARNINGS</span><br><span class="line">[FAILED     ] org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar: invalid sha1: expected=0b67c710549b20c5d380576a3deb88f6abd7e12a computed=42c31359fbe529703b2cd2ec5213abe123454c3b (9174ms)</span><br><span class="line"></span><br><span class="line">[FAILED     ] org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar: invalid sha1: expected=0b67c710549b20c5d380576a3deb88f6abd7e12a computed=42c31359fbe529703b2cd2ec5213abe123454c3b (7719ms)</span><br><span class="line"></span><br><span class="line">[FAILED     ] org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar:  (0ms)</span><br><span class="line"></span><br><span class="line">==== local: tried</span><br><span class="line"></span><br><span class="line">  D:\dev\sbt\ivy2\local\org.scalamacros\quasiquotes_2.10\2.0.1\jars\quasiquotes_2.10.jar</span><br><span class="line"></span><br><span class="line">==== ui: tried</span><br><span class="line"></span><br><span class="line">  http://uk.maven.org/maven2/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar</span><br><span class="line"></span><br><span class="line">==== ui-ivy: tried</span><br><span class="line"></span><br><span class="line">  http://uk.maven.org/maven2/org.scalamacros/quasiquotes_2.10/2.0.1/jars/quasiquotes_2.10.jar</span><br><span class="line"></span><br><span class="line">==== typesafe: tried</span><br><span class="line"></span><br><span class="line">  http://repo.typesafe.com/typesafe/releases/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar</span><br><span class="line"></span><br><span class="line">==== typesafe-ivy: tried</span><br><span class="line"></span><br><span class="line">  http://repo.typesafe.com/typesafe/ivy-releases/org.scalamacros/quasiquotes_2.10/2.0.1/jars/quasiquotes_2.10.jar</span><br><span class="line"></span><br><span class="line">==== sbt-plugin: tried</span><br><span class="line"></span><br><span class="line">  http://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar</span><br><span class="line"></span><br><span class="line">==== sonatype: tried</span><br><span class="line"></span><br><span class="line">  http://oss.sonatype.org/content/repositories/snapshots/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar</span><br><span class="line"></span><br><span class="line">==== repo2: tried</span><br><span class="line"></span><br><span class="line">  http://repo2.maven.org/maven2/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar</span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line">::              FAILED DOWNLOADS            ::</span><br><span class="line"></span><br><span class="line">:: ^ see resolution messages for details  ^ ::</span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line">:: org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar</span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS</span><br><span class="line">download failed: org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar</span><br><span class="line">Error during sbt execution: Error retrieving required libraries</span><br><span class="line">  (see D:\dev\sbt\boot\update.log for complete log)</span><br><span class="line">Error: Could not retrieve sbt 0.13.8</span><br></pre></td></tr></table></figure></li></ul><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ul><li>方法一：添加可用的仓库；</li><li>方法二：手动下载依赖，放入到仓库中即可；</li></ul>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 工具 </tag>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SBT--入门并在IDEA中使用</title>
      <link href="/2016/10/16/SBT-%E5%85%A5%E9%97%A8%E5%B9%B6%E5%9C%A8IDEA%E4%B8%AD%E4%BD%BF%E7%94%A8/"/>
      <url>/2016/10/16/SBT-%E5%85%A5%E9%97%A8%E5%B9%B6%E5%9C%A8IDEA%E4%B8%AD%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="SBT简介"><a href="#SBT简介" class="headerlink" title="SBT简介"></a>SBT简介</h2><p>　　<strong>SBT</strong>(<code>Simple Build Tool</code>)，对于<a href="http://www.scala-sbt.org/" title="SBT官网" target="_blank" rel="noopener">SBT</a>，<a href="http://www.scala-sbt.org/" title="官网" target="_blank" rel="noopener">官网</a>是这样介绍的”<code>The interactive build tool，Use Scala to define your tasks. Then run them in parallel from the shell.</code>“。即是一个现代构建工具，它是用Scala编写的，对编译Scala、Spark项目提供了不错的支持。和Maven一样它也是一个通用的构建工具。</p><h2 id="SBT安装"><a href="#SBT安装" class="headerlink" title="SBT安装"></a>SBT安装</h2><ul><li>下载：<a href="http://www.scala-sbt.org/release/docs/Setup.html" target="_blank" rel="noopener">http://www.scala-sbt.org/release/docs/Setup.html</a>，下载后目录如下，只有两个目录<code>bin</code>和<code>conf</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129350.png" alt=""></li></ul><a id="more"></a><ol><li><p><strong>配置环境变量</strong>：<br>SBT_HOME=D:\dev\sbt<br>%SBT_HOME%\bin;</p></li><li><p><strong>修改配置文件</strong>：<a href="https://github.com/jasonTangxd/Blog_Resources_20160508/blob/9cd8c2fd13309914f748b933931aed4b1478f1d4/resources/sbt/conf/sbtconfig.txt" target="_blank" rel="noopener"><strong>sbtconfig.txt</strong></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Set the java args to high</span><br><span class="line"></span><br><span class="line">-Xmx512M</span><br><span class="line"></span><br><span class="line">-XX:MaxPermSize=<span class="number">256</span>m</span><br><span class="line"></span><br><span class="line">-XX:ReservedCodeCacheSize=<span class="number">128</span>m</span><br><span class="line"></span><br><span class="line"># Set the extra SBT options</span><br><span class="line">-Dactivator.checkForUpdates=<span class="literal">false</span></span><br><span class="line">-Dsbt.<span class="built_in">log</span>.format=<span class="literal">true</span></span><br><span class="line">-Dhttp.proxyHost=proxy.tencent.com</span><br><span class="line">-Dhttp.proxyPort=<span class="number">8080</span></span><br><span class="line">-Dhttps.proxyHost=proxy.tencent.com</span><br><span class="line">-Dhttps.proxyPort=<span class="number">8080</span></span><br><span class="line"></span><br><span class="line"># 设置boot目录以及ivy本地仓库地址</span><br><span class="line">-Dsbt.boot.directory=D:/dev/sbt/boot/</span><br><span class="line">-Dsbt.ivy.home=D:/dev/sbt/ivy2/</span><br><span class="line">-Dsbt.repository.config=D:/dev/sbt/conf/repo.properties</span><br></pre></td></tr></table></figure></li><li><p><strong>在<a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/9cd8c2fd13309914f748b933931aed4b1478f1d4/resources/sbt/conf" target="_blank" rel="noopener">conf</a>目录下创建<a href="https://github.com/jasonTangxd/Blog_Resources_20160508/blob/9cd8c2fd13309914f748b933931aed4b1478f1d4/resources/sbt/conf/repo.properties" target="_blank" rel="noopener">repo.properties</a>文件</strong>，内容如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[repositories]</span><br><span class="line"></span><br><span class="line">local</span><br><span class="line"></span><br><span class="line">ui:http:<span class="comment">//uk.maven.org/maven2/</span></span><br><span class="line">ui-ivy:http:<span class="comment">//uk.maven.org/maven2/,[organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext] </span></span><br><span class="line"></span><br><span class="line">typesafe:http:<span class="comment">//repo.typesafe.com/typesafe/releases/</span></span><br><span class="line">typesafe-ivy: http:<span class="comment">//repo.typesafe.com/typesafe/ivy-releases/,[organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span></span><br><span class="line">sbt-plugin: http:<span class="comment">//repo.scala-sbt.org/scalasbt/sbt-plugin-releases/  </span></span><br><span class="line">sonatype: http:<span class="comment">//oss.sonatype.org/content/repositories/snapshots  </span></span><br><span class="line">repo2: http:<span class="comment">//repo2.maven.org/maven2/</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="SBT运行"><a href="#SBT运行" class="headerlink" title="SBT运行"></a>SBT运行</h2><ul><li>测试一下：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129351.png" alt=""><br>如果不配置repo.properties文件，默认会去 <a href="https://repo1.maven.org/maven2/" target="_blank" rel="noopener">https://repo1.maven.org/maven2/</a>地址下载jar。</li></ul><h2 id="在IDEA中使用"><a href="#在IDEA中使用" class="headerlink" title="在IDEA中使用"></a>在IDEA中使用</h2><ol><li><p><strong>安装</strong>：idea 安装配置SBT，点击install安装后重启IDEA<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129352.png" alt=""></p></li><li><p><strong>配置idea</strong>：如果不配置，<code>SBT_HOME</code>下面的配置是对idea无效的，有两种方式</p></li></ol><ul><li>第一种：解压sbt-launch.jar，修改里面的sbt.boot.properties文件，在repositories配置项中添加镜像配置重新打包（这里就不做具体说明）</li><li>第二种：<br>2.1. 在idea配置<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129353.png" alt=""><br>2.2. 在用户目录下的.sbt文件夹下，创建一个<a href="https://github.com/jasonTangxd/Blog_Resources_20160508/blob/9cd8c2fd13309914f748b933931aed4b1478f1d4/resources/sbt/.sbt/repositories" target="_blank" rel="noopener">repositories</a>文件，文件内容为镜像文件repo.properties的内容。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129354.png" alt=""></li></ul><h2 id="创建SBT项目"><a href="#创建SBT项目" class="headerlink" title="创建SBT项目"></a>创建SBT项目</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161016222543.png" alt="创建SBT项目"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201610162129355.png" alt="可以看见在通过我们自定义的仓库下载依赖"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161016224914.png" alt="项目整体结构"></p><ul><li>参考资料<br><a href="http://www.scala-sbt.org/release/docs/zh-cn/Getting-Started.html" target="_blank" rel="noopener">http://www.scala-sbt.org/release/docs/zh-cn/Getting-Started.html</a><br><a href="http://blog.csdn.net/cjuexuan/article/details/51148002" target="_blank" rel="noopener">http://blog.csdn.net/cjuexuan/article/details/51148002</a><br><a href="http://blog.csdn.net/jameshadoop/article/details/52295710" target="_blank" rel="noopener">http://blog.csdn.net/jameshadoop/article/details/52295710</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 工具 </tag>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Cloudera--CDH5.x.x集群IP更改</title>
      <link href="/2016/08/24/Cloudera-CDH5-x-x%E9%9B%86%E7%BE%A4IP%E6%9B%B4%E6%94%B9/"/>
      <url>/2016/08/24/Cloudera-CDH5-x-x%E9%9B%86%E7%BE%A4IP%E6%9B%B4%E6%94%B9/</url>
      <content type="html"><![CDATA[<p>　　我想，对于<strong>Cloudera CDH5</strong>集群中ip的更改，虽然发生的几率小，但是还是有的，之前公司就由于某种原因，需要更改集群IP地址（网段）。今天同样遇到了这样的需求，由于自己通过虚拟机搭建了CDH5.5.1集群，在之前使用的是<strong>NET模式</strong>只能本机访问，现在有一个需求就是让同网段下的其他电脑也能访问，于是就更改为<strong>桥接模式</strong>。下面就以此为例记录一下整个集群更改IP的过程，<code>注意</code>：我这里演示的是一个节点，对于集群中的多个节点同样适用。</p><h2 id="第一步更改IP映射"><a href="#第一步更改IP映射" class="headerlink" title="第一步更改IP映射"></a>第一步更改IP映射</h2><ol><li><p>首先，我们修改所有节点ip地址，我这里从<code>192.168.33.77</code>改为<code>192.168.1.77</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130256.png" alt="修改ip和网关"></p></li><li><p>修改集群hosts映射文件/etc/hosts（如果改了hostsname需要做免密码登录）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130605.png" alt="/etc/hosts文件"></p></li></ol><a id="more"></a><h2 id="更改Parcel-存储库URL"><a href="#更改Parcel-存储库URL" class="headerlink" title="更改Parcel 存储库URL"></a>更改Parcel 存储库URL</h2><ol><li><p>通过集群查看一下当前状态，全是问号，即严重问题<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130606.png" alt="通过集群查看一下当前状态，全是问号"></p></li><li><p>通过界面先更改Parcel 存储库URL，不然会检测CDH版本不匹配等<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130607.png" alt="更改Parcel 存储库URL"></p></li></ol><h2 id="停止CM-agent-server服务"><a href="#停止CM-agent-server服务" class="headerlink" title="停止CM agent/server服务"></a>停止CM agent/server服务</h2><ul><li>首先停止CM agent/server服务，命令如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo12 ~]# service cloudera-scm-agent stop</span><br><span class="line">[root@xxo12 ~]# service cloudera-scm-server stop</span><br></pre></td></tr></table></figure></li></ul><h2 id="修改postgresql中的IP"><a href="#修改postgresql中的IP" class="headerlink" title="修改postgresql中的IP"></a>修改postgresql中的IP</h2><ol><li>查看密码：grep password /etc/cloudera-scm-server/db.properties</li><li>使用查看的密码登录postgresql：psql -h localhost -p 7432 -U scm</li><li>查看postgresql中的ip：select host_id, host_identifier, name, ip_address from hosts;</li><li>修改postgresql中的ip：update hosts set (ip_address) = (‘192.168.1.77’) where host_id=1;<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130608.png" alt="登录postgresql"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130609.png" alt="更在postgresql中的IP"></li></ol><h2 id="修改节点的agent的配置文件"><a href="#修改节点的agent的配置文件" class="headerlink" title="修改节点的agent的配置文件"></a>修改节点的agent的配置文件</h2><ol><li>打开<strong>cloudera-scm-agent</strong>的配置文件,将<strong>server_host</strong>设置成新的ip<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo12 ~]# vi /etc/cloudera-scm-agent/config.ini</span><br><span class="line">[General]</span><br><span class="line"><span class="meta">#</span> Hostname of the CM server.</span><br><span class="line">server_host=192.168.1.77  ##设置为新ip</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130619.png" alt="更改cloudera-scm-agent的配置文件"></p><h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><ul><li>修改完成后重启服务，如有异常注意查看日志，<code>/var/log/</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo12 ~]# service cloudera-scm-agent start</span><br><span class="line">[root@xxo12 ~]# service cloudera-scm-server start</span><br></pre></td></tr></table></figure></li></ul><h2 id="访问CM-web管理界面"><a href="#访问CM-web管理界面" class="headerlink" title="访问CM web管理界面"></a>访问CM web管理界面</h2><p><a href="http://ip:7180" target="_blank" rel="noopener">http://ip:7180</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160904130629.png" alt="访问CM web管理界面"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloudera </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>未知数</title>
      <link href="/2016/08/13/%E6%9C%AA%E7%9F%A5%E6%95%B0/"/>
      <url>/2016/08/13/%E6%9C%AA%E7%9F%A5%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20161113161625.png" alt=""><br><a id="more"></a></p><ul><li><strong><code>心蕊</code></strong>：好安静喔，如果时间可以停留在这里该多好</li><li><strong><code>小绿</code></strong>：对啊</li><li><strong><code>心蕊</code></strong>：不过考上大学之后，大家都散了，今天就变成回忆了</li><li><strong><code>小绿</code></strong>：怎么会散了</li><li><strong><code>心蕊</code></strong>：考上不同的大学，距离就远了，远了感情就疏远了呀</li><li><strong><code>小绿</code></strong>：可以继续联络啊</li><li><strong><code>心蕊</code></strong>：未来的事说不准，再加上距离的话未知数就更多了</li></ul><p>　　这是前端时间看过的一部电影《六弄咖啡馆》，对上面的对话影响很深刻，便记录了下来~</p><p>　　……</p><p>　　未来的事说不准，有太多的未知数</p><ul><li><strong><code>小绿</code></strong>：我在乎的，只是你不知道而已</li></ul>]]></content>
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive--执行流程和源码解析</title>
      <link href="/2016/08/06/Hive-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%92%8C%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
      <url>/2016/08/06/Hive-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%92%8C%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>　　<strong>Hive</strong>，在工作中使用相对较多，并且比较简单便捷，今天在家闲着没事，就写一遍博客来对hive的<strong>执行流程做一些分析</strong>，还有<strong>阅读一下它的源码</strong>，看看这个hive是怎么<strong>编译</strong>这个HiveQL，怎么去<strong>解析</strong>，怎么和我们<strong>hdfs上的数据关联</strong>，在<strong>mapreduce阶段</strong>怎么进行计算的。由于这个源码比较多，不是很好截图，有时候我会一部分一部分的截取。最主要的还是你们自己按照这个流程去看几遍，可以看看具体的细节。</p><ul><li>下面我们来看一张<strong>经典的图</strong>，本博客也是围绕这张图展开的讲解：</li><li><strong>Hive与Hadoop的调用关系图：</strong><a id="more"></a><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F201605290132537.png" alt="Hive与Hadoop的调用关系图"></li></ul><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ol><li><p>下载hive的源码，我是直接在maven中添加的maven依赖如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hadoop依赖包 START --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- hadoop依赖包 END--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- hive依赖包 START--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.14.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- hive依赖包 END--&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>启动hive 并删除日志文件，因为我们要获取新的日志文件进行分析</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########################1. 日志文件默认目录/tmp/当前用户目录/下###############</span></span><br><span class="line">[root@xxo07 root]<span class="comment"># pwd </span></span><br><span class="line">/tmp/root</span><br><span class="line"></span><br><span class="line"><span class="comment">########################2. 删除一下当天日志文件###############</span></span><br><span class="line">[root@xxo07 root]<span class="comment"># ll</span></span><br><span class="line">total 1832</span><br><span class="line">-rw-r--r--. 1 root root   67038 May 29 13:51 hive.log</span><br><span class="line">-rw-r--r--. 1 root root 1798483 May 28 20:58 hive.log.2016-05-28</span><br><span class="line">[root@xxo07 root]<span class="comment"># rm -rf hive.log</span></span><br></pre></td></tr></table></figure></li><li><p>执行hive语句</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from t_5 order by id ;</span><br><span class="line">Query ID = root_20160529142525_97b24c9c-a861-44d7-8fba-2c076c997c34</span><br><span class="line">Total <span class="built_in">jobs</span> = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">limit</span> the maximum number of reducers:</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">set</span> a constant number of reducers:</span><br><span class="line">  <span class="built_in">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1464498685344_0003, Tracking URL = http://xxo07:8088/proxy/application_1464498685344_0003/</span><br><span class="line">Kill Command = /usr/<span class="built_in">local</span>/hadoop-2.6.0/bin/hadoop job  -<span class="built_in">kill</span> job_1464498685344_0003</span><br><span class="line">Interrupting... Be patient, this might take some time.</span><br><span class="line">Press Ctrl+C again to <span class="built_in">kill</span> JVM</span><br><span class="line">killing job with: job_1464498685344_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-1: number of mappers: 0; number of reducers: 0</span><br><span class="line">2016-05-29 14:25:57,132 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">Ended Job = job_1464498685344_0003 with errors</span><br><span class="line">Error during job, obtaining debugging information...</span><br><span class="line">FAILED: Execution Error, <span class="built_in">return</span> code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL</span><br><span class="line">Total MapReduce CPU Time Spent: 0 msec</span><br><span class="line">hive&gt; select * from t_5 order by id ;</span><br><span class="line">Query ID = root_20160529142626_a68f490b-4e9f-43c7-a3b8-d16210751de7</span><br><span class="line">Total <span class="built_in">jobs</span> = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">limit</span> the maximum number of reducers:</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">set</span> a constant number of reducers:</span><br><span class="line">  <span class="built_in">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1464498685344_0004, Tracking URL = http://xxo07:8088/proxy/application_1464498685344_0004/</span><br><span class="line">Kill Command = /usr/<span class="built_in">local</span>/hadoop-2.6.0/bin/hadoop job  -<span class="built_in">kill</span> job_1464498685344_0004</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-1: number of mappers: 2; number of reducers: 1</span><br><span class="line">2016-05-29 14:26:30,745 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2016-05-29 14:27:53,143 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec</span><br><span class="line">2016-05-29 14:28:20,569 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 8.3 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 8 seconds 300 msec</span><br><span class="line">Ended Job = job_1464498685344_0004</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 8.3 sec   HDFS Read: 1028 HDFS Write: 160 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 8 seconds 300 msec</span><br><span class="line">OK</span><br><span class="line">12016-05-28cq</span><br><span class="line">12015-05-30wz</span><br><span class="line">22016-05-28cq</span><br><span class="line">22015-05-30yy</span><br><span class="line">32016-05-28cq</span><br><span class="line">42016-05-28cq</span><br><span class="line">52016-05-28cq</span><br><span class="line">52015-05-30cq</span><br><span class="line">72015-05-30bj</span><br><span class="line">92015-05-30hz</span><br><span class="line">Time taken: 130.479 seconds, Fetched: 10 row(s)</span><br></pre></td></tr></table></figure></li></ol><h2 id="分析日志文件"><a href="#分析日志文件" class="headerlink" title="分析日志文件"></a>分析日志文件</h2><ol><li><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/hive/log" target="_blank" rel="noopener">下载日志文件</a>并做了一下整理，整理后日志文件的总体结构如下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;run&gt;</span><br><span class="line">&lt;TimeToSubmit&gt;</span><br><span class="line">&lt;compile&gt;</span><br><span class="line">&lt;parse&gt;&lt;/parse&gt;</span><br><span class="line">&lt;semanticAnalyze&gt;</span><br><span class="line">&lt;partition-retrieving&gt;&lt;/partition-retrieving&gt;</span><br><span class="line">&lt;/semanticAnalyze&gt;</span><br><span class="line">&lt;/compile&gt;</span><br><span class="line">&lt;execute&gt;</span><br><span class="line">&lt;runTasks&gt;</span><br><span class="line">&lt;serializePlan&gt;&lt;/serializePlan&gt;</span><br><span class="line">&lt;getSplits&gt;&lt;/getSplits&gt;</span><br><span class="line">&lt;/runTasks&gt;</span><br><span class="line">&lt;/execute&gt;</span><br><span class="line">&lt;/TimeToSubmit&gt;</span><br><span class="line">&lt;/run&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">### 1. 程序开始于run方法，run方法下面有两个重要的方法compile和execute；</span></span><br><span class="line"><span class="comment">### 2. compile ： 方法下面有parse 和 semanticAnalyze；</span></span><br><span class="line"><span class="comment">### 2. execute ： 运行任务runTasks，做一些序列化、分割切片splite，计算 即mapreduce阶段</span></span><br></pre></td></tr></table></figure></li></ol><ul><li><p>第一阶段：运行run-TimeToSubmit-compile-parse</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">###################### 1. 程序开始于这个run方法 #######################################</span></span><br><span class="line">&lt;PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">###################### 2. rum下面有TimeToSubmit方法 ##################################</span></span><br><span class="line">  &lt;PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   Concurrency mode is disabled, not creating a lock manager</span><br><span class="line"></span><br><span class="line"><span class="comment">###################### 3. 运行compile ################################################</span></span><br><span class="line">    &lt;PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line"></span><br><span class="line">     <span class="comment">################ 3.1. 运行compile，下面的parse解析HiveQL #########################</span></span><br><span class="line">      &lt;PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">       Parsing <span class="built_in">command</span>: select * from t_5 order by id</span><br><span class="line">       Parse Completed</span><br><span class="line">      &lt;/PERFLOG method=parse start=1464503172611 end=1464503172613 duration=2 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">     <span class="comment">############### 3.1. 解析完成 ###################################################</span></span><br></pre></td></tr></table></figure></li><li><p>第二阶段：运行semanticAnalyze语义分析阶段</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">#################### 3.1. 运行compile，下面的semanticAnalyze语义分析 ################</span></span><br><span class="line">  &lt;PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   Starting Semantic Analysis      <span class="comment">#### 开始语义分析</span></span><br><span class="line">   Completed phase 1 of Semantic Analysis</span><br><span class="line">   Get metadata <span class="keyword">for</span> <span class="built_in">source</span> tables  <span class="comment">#### 通过derby或者mysql获取metadata信息</span></span><br><span class="line">   0: get_table : db=xxo tbl=t_5   <span class="comment">#### 获取数据库中的表t_5</span></span><br><span class="line">   ugi=rootip=unknown-ip-addrcmd=get_table : db=xxo tbl=t_5</span><br><span class="line">   Get metadata <span class="keyword">for</span> subqueries</span><br><span class="line">   Get metadata <span class="keyword">for</span> destination tables <span class="comment">###表的表述信息</span></span><br><span class="line">   New scratch dir is hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1</span><br><span class="line">   Completed getting MetaData <span class="keyword">in</span> Semantic Analysis</span><br><span class="line">   Set stats collection dir : hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/-ext-10002</span><br><span class="line">   Processing <span class="keyword">for</span> FS(4)</span><br><span class="line">   Processing <span class="keyword">for</span> SEL(3)</span><br><span class="line">   Processing <span class="keyword">for</span> RS(2)</span><br><span class="line">   Processing <span class="keyword">for</span> SEL(1)</span><br><span class="line">   Processing <span class="keyword">for</span> TS(0)</span><br><span class="line">   RS 2 oldColExprMap: &#123;VALUE._col1=Column[_col2], VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]&#125;</span><br><span class="line">   RS 2 newColExprMap: &#123;VALUE._col1=Column[_col2], VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">########### partition ###################</span></span><br><span class="line">&lt;PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner&gt;</span><br><span class="line">  0: get_partitions : db=xxo tbl=t_5</span><br><span class="line">      ugi=rootip=unknown-ip-addrcmd=get_partitions : db=xxo tbl=t_5</span><br><span class="line">&lt;/PERFLOG method=partition-retrieving start=1464503172762 end=1464503172819 duration=57 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner&gt;</span><br><span class="line">   </span><br><span class="line">   Looking <span class="keyword">for</span> table scans <span class="built_in">where</span> optimization is applicable</span><br><span class="line">   Found 0 null table scans</span><br><span class="line">   Looking <span class="keyword">for</span> table scans <span class="built_in">where</span> optimization is applicable</span><br><span class="line">   Found 0 null table scans</span><br><span class="line">   Looking <span class="keyword">for</span> table scans <span class="built_in">where</span> optimization is applicable</span><br><span class="line">   Found 0 null table scans</span><br><span class="line">   Completed plan generation     <span class="comment">#####完成plan</span></span><br><span class="line">   Semantic Analysis Completed</span><br><span class="line">  &lt;/PERFLOG method=semanticAnalyze start=1464503172613 end=1464503172841 duration=228 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   Initializing Self OP[5]</span><br><span class="line">   Operator 5 OP initialized</span><br><span class="line">   Initialization Done 5 OP</span><br><span class="line">   Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:t_5.id, <span class="built_in">type</span>:int, comment:null), FieldSchema(name:t_5.dt, <span class="built_in">type</span>:date, comment:null), FieldSchema(name:t_5.city, <span class="built_in">type</span>:string, comment:null)], properties:null)</span><br><span class="line">  <span class="comment">################ 3.1. semanticAnalyze完成 ################################</span></span><br><span class="line"></span><br><span class="line">&lt;/PERFLOG method=compile start=1464503172610 end=1464503172850 duration=240 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line"><span class="comment">################## 3. compile完成 ############################################</span></span><br></pre></td></tr></table></figure></li><li><p>第三阶段：运行execute阶段，在execute中开启了线程,执行job任务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################## 4. execute开始执行 ############################################</span></span><br><span class="line">&lt;PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   Starting <span class="built_in">command</span>: select * from t_5 order by id</span><br><span class="line">   Query ID = root_20160529142626_a68f490b-4e9f-43c7-a3b8-d16210751de7</span><br><span class="line">   Total <span class="built_in">jobs</span> = 1</span><br><span class="line"></span><br><span class="line"><span class="comment">################### 2. TimeToSubmit在这里结束，其实是因为开启了多线程###########</span></span><br><span class="line">&lt;/PERFLOG method=TimeToSubmit start=1464503172610 end=1464503172854 duration=244 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br></pre></td></tr></table></figure></li><li><p>第四阶段：线程运行runTasks , 就是具体的MapReduce过程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">&lt;PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   Launching Job 1 out of 1       <span class="comment">##########################执行 launchTask 方法</span></span><br><span class="line">   </span><br><span class="line">   <span class="comment">######### 调用Task.initialize方法 ##########################</span></span><br><span class="line">   <span class="comment">######### 实例化了一个TaskRunner ############################</span></span><br><span class="line">   <span class="comment">######### 执行 launchTask中的runSequential方法 返回TaskRunner</span></span><br><span class="line">   Starting task [Stage-1:MAPRED] <span class="keyword">in</span> serial mode </span><br><span class="line">   </span><br><span class="line">   <span class="comment">########################### 加载和设置一些配置文件######################</span></span><br><span class="line">   Number of reduce tasks determined at compile time: 1    </span><br><span class="line">   In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):   <span class="comment">####加载参数</span></span><br><span class="line">   <span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">   In order to <span class="built_in">limit</span> the maximum number of reducers:</span><br><span class="line">   <span class="built_in">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">   In order to <span class="built_in">set</span> a constant number of reducers:</span><br><span class="line">   <span class="built_in">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">   New scratch dir is hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1</span><br><span class="line">   Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</span><br><span class="line">   Processing <span class="built_in">alias</span> t_5</span><br><span class="line"></span><br><span class="line">   <span class="comment">######################### Adding input file #########################################################</span></span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=bj</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=bj</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=cq</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=cq</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=hz</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=hz</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=wz</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=wz</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=yy</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=yy</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2016-05-28/city=cq</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2016-05-28/city=cq</span><br><span class="line">   Adding input file hdfs://xxo07:9000/user/hive/warehouse/t_1/t_1.txt</span><br><span class="line">   Content Summary not cached <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/t_1/t_1.txt</span><br><span class="line">   Changed input file to hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/-mr-10003/0</span><br><span class="line">   New scratch dir is hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1</span><br></pre></td></tr></table></figure></li><li><p>serializePlan</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############################# serializePlan ###################################</span></span><br><span class="line">&lt;PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities&gt;</span><br><span class="line">   Serializing MapWork via kryo</span><br><span class="line">&lt;/PERFLOG method=serializePlan start=1464503172964 end=1464503173007 duration=43 from=org.apache.hadoop.hive.ql.exec.Utilities&gt;</span><br><span class="line">&lt;PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities&gt;</span><br><span class="line">   Serializing ReduceWork via kryo</span><br><span class="line">&lt;/PERFLOG method=serializePlan start=1464503173015 end=1464503173148 duration=133 from=org.apache.hadoop.hive.ql.exec.Utilities&gt;</span><br></pre></td></tr></table></figure></li><li><p>连接ResourceManager</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Connecting to ResourceManager at xxo07/192.168.33.72:8032</span><br><span class="line">Connecting to ResourceManager at xxo07/192.168.33.72:8032</span><br><span class="line">Hadoop <span class="built_in">command</span>-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</span><br></pre></td></tr></table></figure></li><li><p>getSplits 分割、切片</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&gt;</span><br><span class="line">   <span class="comment">#################### CombineHiveInputSplit 合并hive Split文件</span></span><br><span class="line">   CombineHiveInputSplit creating pool <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=bj; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=bj</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=cq; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=cq</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=hz; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=hz</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=wz; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=wz</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=yy; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2015-05-30/city=yy</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2016-05-28/city=cq; using filter path hdfs://xxo07:9000/user/hive/warehouse/xxo.db/t_5/dt=2016-05-28/city=cq</span><br><span class="line">   CombineHiveInputSplit: pool is already created <span class="keyword">for</span> hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/-mr-10003/0; using filter path hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/-mr-10003/0</span><br><span class="line">   Total input paths to process : 7</span><br><span class="line">   DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0</span><br><span class="line">   number of splits 2</span><br><span class="line">&lt;/PERFLOG method=getSplits start=1464503174738 end=1464503174933 duration=195 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&gt;</span><br></pre></td></tr></table></figure></li><li><p>在hadoop中，提交并开始一个job任务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">   Number of all splits 2</span><br><span class="line">   number of splits:2</span><br><span class="line">   Submitting tokens <span class="keyword">for</span> job: job_1464498685344_0004</span><br><span class="line">   Submitted application application_1464498685344_0004</span><br><span class="line">   The url to track the job: http://xxo07:8088/proxy/application_1464498685344_0004/</span><br><span class="line">   Starting Job = job_1464498685344_0004, Tracking URL = http://xxo07:8088/proxy/application_1464498685344_0004/</span><br><span class="line">   Kill Command = /usr/<span class="built_in">local</span>/hadoop-2.6.0/bin/hadoop job  -<span class="built_in">kill</span> job_1464498685344_0004</span><br><span class="line">   Hadoop job information <span class="keyword">for</span> Stage-1: number of mappers: 2; number of reducers: 1</span><br><span class="line">   Group org.apache.hadoop.mapred.Task<span class="variable">$Counter</span> is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead</span><br><span class="line">   2016-05-29 14:26:30,745 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">   2016-05-29 14:27:53,143 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec</span><br><span class="line">   2016-05-29 14:28:20,569 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 8.3 sec <span class="comment">###任务结束</span></span><br><span class="line">   MapReduce Total cumulative CPU time: 8 seconds 300 msec</span><br><span class="line">   Ended Job = job_1464498685344_0004</span><br><span class="line">   Moving tmp dir: hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/_tmp.-ext-10001 to: hdfs://xxo07:9000/tmp/hive/root/9d2c112b-118e-46a1-8a08-c60c5bbc6fe0/hive_2016-05-29_14-26-12_611_2648166283911131981-1/-ext-10001</span><br><span class="line"></span><br><span class="line"><span class="comment">#################runTasks阶段结束###############################</span></span><br><span class="line">&lt;/PERFLOG method=runTasks start=1464503172855 end=1464503303027 duration=130172 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#################execute阶段结束###############################</span></span><br><span class="line">&lt;/PERFLOG method=Driver.execute start=1464503172850 end=1464503303049 duration=130199 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   MapReduce Jobs Launched:</span><br><span class="line">   Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 8.3 sec   HDFS Read: 1028 HDFS Write: 160 SUCCESS</span><br><span class="line">   Total MapReduce CPU Time Spent: 8 seconds 300 msec</span><br><span class="line">   OK</span><br><span class="line"></span><br><span class="line">&lt;PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">&lt;/PERFLOG method=releaseLocks start=1464503303086 end=1464503303087 duration=1 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">##################### run 结束######################################</span></span><br><span class="line">&lt;/PERFLOG method=Driver.run start=1464503172609 end=1464503303087 duration=130478 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">   mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir</span><br><span class="line">   Total input paths to process : 1</span><br><span class="line">   5 finished. closing...</span><br><span class="line">   5 Close <span class="keyword">done</span></span><br><span class="line">   Time taken: 130.479 seconds, Fetched: 10 row(s)</span><br><span class="line"></span><br><span class="line">&lt;PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver&gt;</span><br><span class="line">&lt;/PERFLOG method=releaseLocks start=1464503304801 end=1464503304802 duration=1 from=org.apache.hadoop.hive.ql.Driver&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><ol><li><p><strong>从 run() 方法到 runInternal() 方法</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529174036.jpg" alt="从run()方法 到 runInternal()方法"></p></li><li><p><strong>runInternal() 方法里面有compileInternal编译和execute方法</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529174843.jpg" alt="进入compileInternal()方法进行编译"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529175305.jpg" alt="进入execute()方法执行"></p></li><li><p>下面我们先来看一下<strong>compileInternal()方法</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529175504.jpg" alt="调用compile()方法，做语法，语义，计划生成"></p></li><li><p><strong>compile方法中有parse方法和semanticAnalyze方法</strong>，语义分析完成后，会将语句中的相应信息放入到 <code>org.apache.hadoop.hive.ql.QueryPlan</code>中<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529180514.jpg" alt="compile方法中的解析parse"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529181323.jpg" alt="compile方法中的语义分析"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529182108.jpg" alt="解析parse方法"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529182636.jpg" alt="语义分析抽象类 BaseSemanticAnalyzer 有很多的子类"></p></li><li><p><strong>execute方法，从<code>QueryPlan</code>中获取信息，执行物理计划，就是提交 job 给 hadoop 进行执行</strong>。 通过调用<code>launchTask</code>方法，然后运行线程<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529184136.jpg" alt="execute方法 调用launchTask方法"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529184948.jpg" alt="launchTask方法，运行tast任务"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160529191319.jpg" alt="executeTask方法执行具体的物理计划"></p></li></ol><ul><li>本博客hive产生的日志：<br><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/hive/log" target="_blank" rel="noopener">https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/hive/log</a>　　　　　　</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--MapReduce源码分析</title>
      <link href="/2016/07/08/Hadoop-MapReduce%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2016/07/08/Hadoop-MapReduce%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>　　本片博客<a href="http://blog.xiaoxiaomo.com/2016/07/08/Hadoop-MapReduce源码分析/">Hadoop的MapReduce源码分析</a>，主要对上篇博客<a href="http://blog.xiaoxiaomo.com/2016/07/03/Hadoop-MapReduce详解/">Hadoop-MapReduce详解/</a>做进一步的理解。MapReduce源码分析东西太多，截图都截累了，前面比较详细一点靠后面可能只把主要的贴了上来，空闲了我在做一些补充吧！ </p><ul><li><strong>MapReduce过程概述</strong>：</li></ul><ol><li><strong>Job提交任务</strong>，会做初始化配置文件、检查Output Path、请求RM获取JobId、复制资源文件到HDFS等操作然后提交job作业；</li><li><strong>RM接收到作业</strong>后会初始化Job对象，然后启动一个NM会从HDFS获取资源文件分配一个Container,在Container中启动一个AM，在过程中会把文件分割为多个输入分片；</li><li>每个输入分片会让一个<strong>map任务来处理</strong>，<strong>输出多个键值对</strong>，输出的结果会暂且放在一个环形内存缓冲区中；</li><li>紧接着就是<strong>分区</strong>，目的是把k2分配到不同的reduce task；</li><li><strong>map输出</strong>时可能会有很多的溢出文件，要将这些文件合并。合并的过程中会不断地进行排序和combia操作，最后合并成了一个已分区且已排序的文件。</li><li><strong>reduce阶段</strong>，接收到不同map任务传来的数据，如果接收数据大超过阈值就会溢出写入磁盘，溢出文件增多合并成大的有序的文件（反复地执行排序，合并操作）</li><li><strong>MapReduce会让写入磁盘的数据尽可能地少</strong>，并且最后一次合并的结果并没有写入磁盘，而是直接输入到reduce函数。<a id="more"></a><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce00.jpg" alt=".MapReduce的Shuffle和排序，图片来源：http://weixiaolu.iteye.com/blog/1474172"></li></ol><h1 id="Job提交作业"><a href="#Job提交作业" class="headerlink" title="Job提交作业"></a>Job提交作业</h1><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce39.png" alt="对Job提交作业画了一个简单的图"></p><ol><li><p><strong>Job开始提交任务</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce01.png" alt="一个简单的MapReduce开始提交任务"></p></li><li><p>接下来我们进入<strong>Job</strong>类看一看<strong>waitForCompletion</strong>方法，<strong>waitForCompletion</strong>方法中主要调用了两个方法：<code>submit()</code>和<code>monitorAndPrintJob()</code>，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce02.png" alt="Job类的waitForCompletion()方法"></p></li></ol><h2 id="submit方法"><a href="#submit方法" class="headerlink" title="submit方法"></a>submit方法</h2><ul><li>在waitForCompletion中，我们先看一看<strong>submit</strong>方法，该方法<strong>主要提交Job，调用JobSubmitter.submitJobInternal()方法完成</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce03.png" alt="waitForCompletion的submit()方法"></li></ul><h3 id="submitJobInternal"><a href="#submitJobInternal" class="headerlink" title="submitJobInternal"></a>submitJobInternal</h3><ul><li><p><strong>submitJobInternal()，主要有以下几个主要功能：</strong><br>1、会检查job的Output Path；<br>2、设置Job ID<br>3、设置Job 命令选项<br>4、分割、切片并创建splits文件<br>5、复制配置文件到HDFS<br>6、正在的提交Job</p></li><li><p>具体代码如下：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce04.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce05.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce06.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce07.png" alt="submitJobInternal()方法"></p></li></ul><ol><li><strong>checkSpecs()</strong> 方法检查output文件；</li><li><strong>setJobID()</strong> 设置Job ID；</li><li><strong>writeSplits()</strong> 写Splits文件；</li><li><strong>cleanUpTokenReferral()</strong> 清除jobtoken referrals；</li><li><strong>writeConf()</strong> 写入job相关的配置文件到HDFS；</li><li><strong>submitClient.submitJob()</strong> 做真正的提交Job。</li></ol><h3 id="writeSplits"><a href="#writeSplits" class="headerlink" title="writeSplits"></a>writeSplits</h3><ul><li><p>在看<strong>submitClient.submitJob()</strong>之前我们先看一看分割、切片<strong> writeSplits()</strong> 方法<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce08.png" alt="writeSplits() 方法"></p></li><li><p><strong>writeSplits</strong>下面调用了<strong>writeNewSplits()</strong>和<strong>writeOldSplits()</strong>方法，我们只看一个writeNewSplits方法：</p></li></ul><ol><li>通过InputFormat的getSplits()方法获取一个List</li><li>排序后再创建SplitFiles<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce09.png" alt="writeNewSplits()方法"></li></ol><h3 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h3><p>InputFormat抽象类仅有两个抽象方法：</p><ol><li><strong>List<inputsplit> getSplits()</inputsplit></strong>， 获取由输入文件计算出输入分片(InputSplit)，解决数据或文件分割成片问题。</li><li><strong>RecordReader&lt;K,V&gt; createRecordReader()</strong>，创建RecordReader，从InputSplit中读取数据，解决读取分片中数据问题</li><li><strong>具体完成以下功能</strong>：<br>3.1. 验证作业输入的正确性<br>3.2. 将输入文件切割成逻辑分片(InputSplit)，一个InputSplit将会被分配给一个独立的MapTask<br>3.3. 提供RecordReader实现，读取InputSplit中的“K-V对”供Mapper使用 </li></ol><ul><li><strong>一、getSplits()</strong></li><li><p>一.1、<strong>getSplits()</strong>是<strong>InputFormat</strong>接口的抽象方法，所以我们在具体<strong>InputFormat</strong>的实现类下面的实现方法就行了，如下图：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce10.png" alt="具体**InputFormat**的实现类"></p></li><li><p>一.2、下面我们来看看<strong>FileInputFormat</strong>在这里，记得弄清楚Splits和Block的关系<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce11.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce12.png" alt="FileInputFormat的getSplits()方法"></p></li></ul><ol><li><strong>一个InputSplit对应一个Map Task </strong>；</li><li><strong>默认文件可分割(true)，这样一个block（128MB）就对应一个InputSplit(通过computeSplitSize(…)方法)</strong>；</li><li><strong>通过分析while循环，得知一个InputSplit对应一个block有利于map计算的数据本地化</strong>；</li><li>如<strong>果文件不允许分隔</strong>，<strong>整个文件作为一个InputSplit</strong>，这样<strong>一个InputSplit就可能对应多个block</strong>。<br>注意：getSplits完成后返回一个List InputSplit，然后对它进行<strong>排序sort</strong>和<strong>创建Split文件</strong>createSplitFiles具体的排序算法这些博主就不一一贴图了，比较好理解，大家可以自己去看看。</li></ol><h3 id="提交JOB到RM"><a href="#提交JOB到RM" class="headerlink" title="提交JOB到RM"></a>提交JOB到RM</h3><p>下面看一看<strong>ClientProtocol 提交Job submitJob</strong>的实现类<strong>YARNRunner</strong>，主要是提交<strong>Job</strong>到<strong>ResourceManager</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce13.png" alt="submitJob的实现类YARNRunner"></p><h2 id="monitorAndPrintJob"><a href="#monitorAndPrintJob" class="headerlink" title="monitorAndPrintJob"></a>monitorAndPrintJob</h2><ul><li>上面submit方法已经提交job了，该方法就是做一些监控，并打印日志信息<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce14.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce15.png" alt="monitorAndPrintJob()方法"></li></ul><h1 id="读取InputSplit中的数据"><a href="#读取InputSplit中的数据" class="headerlink" title="读取InputSplit中的数据"></a>读取InputSplit中的数据</h1><ul><li><strong>读取InputSplit中的数据，转成k1,v1</strong> ，由<strong>LineRecordReader</strong>完成，存在于<strong>TextInputFormat</strong>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce16.png" alt="TextInputFormat类"></li></ul><ol><li><strong>TextInputFormat方法</strong> 相当于一个解释器，有很多的解释器，TextInputFormat为默认的文本解释器；</li><li><strong>TextInputFormat方法</strong>  重写了<strong>isSplitable</strong>方法和 <strong>RecordReader</strong> 方法（）相当于定义了自己的规则；</li><li><strong>getRecordReader方法</strong> 最后返回了一个<strong>LineRecordReader的实例</strong>。<br><strong>注</strong>：我们的job程序默认使用的就是TextInputFormat，该类的泛型已经明确指定了，所以在job配置的时候，不需要指定k1,v1的类型。</li></ol><ul><li><strong>下面我们来一起看一看LineRecordReader类</strong>：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce17.png" alt="LineRecordReader类"></li></ul><ol><li><p><strong>先看看父类RecordReader</strong> 因为比较清晰明了，这几个方法很重要，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce18.png" alt="LineRecordReader的父类RecordReader"></p></li><li><p><strong>返回LineRecordReader，看一看大致有哪些具体实现</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce19.png" alt="返回LineRecordReader"></p></li><li><p>看一看几个重要的方法，如下图源码每次调用nextKeyValue()时，value表示当前行的内容，key表示已经读取后的位置具体实现：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce20.png" alt="LineRecordReader的nextKeyValue具体的实现"></p></li><li><p>在MR框架中，有很多InputFormat和FileInputFormat的实现类。比如<strong>SequenceFileInputFormat</strong>，<strong>NLineInputFormat</strong>、<strong>DBInputFormat等</strong>。<strong>DBInputFormat</strong>表示从SQL表中读取数据，可以看出我们不仅仅是从HDFS中取数据作为输入还可以从数据库中读取数据，来一个简单的截图：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce21.png" alt="InputFormat的具体实现DBInputFormat"></p></li></ol><h1 id="执行map-task"><a href="#执行map-task" class="headerlink" title="执行map task"></a>执行map task</h1><ol><li>在我们写代码的时候，可以覆盖<strong>setup</strong>、<strong>map</strong>、<strong>cleanup</strong>方法；</li><li><p>框架调用map的时候，是通过反射的方式产生的，然后调用实例化对象中的run()。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce22.png" alt="Mapper类"></p></li><li><p>注意我们<strong>Mapper类</strong>的<strong>write()</strong>方法，其实是调用了<code>org.apache.hadoop.mapreduce.Mapper.Context</code></p></li></ol><ul><li>程序真正执行时，是启动了一个<strong>YarnChild类</strong>，下面我们来分析框架如何调用map task或者reduce task。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce23.png" alt="YarnChild类的run()方法"></li></ul><ol><li><p><strong>看一下taskFinal的一个实现类是MapTask</strong>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce24.png" alt="taskFinal的一个实现类是MapTask"></p></li><li><p>继续分析下面的<strong>runNewMapper()</strong>方法<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce25.png" alt="下面跳过一部分代码截图......"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce26.png" alt="runNewMapper()方法"><br>在这里可以看出：</p><blockquote><p>如果没有reduce task，那么map直接把&lt;k2,v2&gt;输出。如果有，创建排序的输出。<br>在这里，output实际上是WordCountMapper类中的map()方法里面的context.write()实际调用，就是在output中调用的。</p></blockquote></li><li><p>接下来分析<strong>NewOutputCollector类的实现的构造方法</strong>，<strong>partitioner类是在这里实例化的</strong>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce27.png" alt="NewOutputCollector类的实现的构造方法"></p></li></ol><h1 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h1><ul><li><p>我们还是在NewOutputCollector方法里主要看看write(…)方法。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce28.png" alt="NewOutputCollector的write(...)方法"></p></li><li><p><strong>当在WordCountMapper类的map()方法中调用context.write(…)</strong>的时候，实际上是调用<strong>collector.collect(…)</strong> ，在这个方法的形参中，第三个参数就是分区。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce29.png" alt="collector.collect(...)方法"></p></li><li><p>在这里collector的实现类是MapOutputBuffer类。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce30.png" alt="常见异常，以及SpillThread"></p></li></ul><h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><ul><li>我们就到了SpillThread类，接下来分析SpillThread类，直接看run()方法，代码比较简洁：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce31.png" alt="SpillThread类的run()方法"></li></ul><ol start="2"><li>继续分析<strong>sortAndSpill()</strong>方法，可以看到，在spill之前，会先进行sort操作。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce32.png" alt="sortAndSpill()方法"></li></ol><h1 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h1><ul><li>现在我们任然在<strong>SpillThread类</strong>里面，继续看下面的代码：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce33.png" alt="SpillThread类里面的合并逻辑代码部分"><br>上面的代码说明：如果没有combiner，直接把&lt;k2,v2&gt;写入到磁盘。如果有combiner，先执行combiner再写入磁盘。</li></ul><h1 id="写入磁盘-spill"><a href="#写入磁盘-spill" class="headerlink" title="写入磁盘(spill)"></a>写入磁盘(spill)</h1><ul><li><strong>写入磁盘(spill)</strong>，实际上是通过调用<strong>InMemoryWriter</strong>来实现的。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce34.png" alt="写入磁盘(spill)"></li></ul><h1 id="reduce的全过程"><a href="#reduce的全过程" class="headerlink" title="reduce的全过程"></a>reduce的全过程</h1><ul><li><p>上面已经把map的过程走完了，截图真累！！下面我们简单看看Reduce吧！Reducer和Mapper很类似,这里就不一一解释了：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce35.png" alt="Reducer和Mapper很类似"></p></li><li><p><strong>直奔主题ReduceTask的run()方法</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce36.png" alt=""></p></li><li><p>继续向下看代码。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce37.png" alt="运行shuffer代码逻辑"></p></li><li><p>查看shuffleComsumerPlugin.run()的时候，跳转到Shuffle类中。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fmapreduce38.png" alt=""></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--MapReduce详解</title>
      <link href="/2016/07/03/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3/"/>
      <url>/2016/07/03/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　前面的几篇博客主要介绍了<a href="http://blog.xiaoxiaomo.com/tags/Hadoop/">Hadoop</a>的存储<a href="http://blog.xiaoxiaomo.com/2016/04/11/Hadoop-HDFS架构和Shell/">HDFS</a>，接下来几篇博客主要介绍<strong>Hadoop的计算框架MapReduce</strong>。当然这方面的技术博客已经特别多而且都写得很优秀，我写本篇博客之前也有过相关阅读，受益匪浅。对一些博客和资料的参考都会才博客下方参考资料中列出。</p><ul><li><code>本片博客主要讲解</code>:</li></ul><ol><li>理解MapReduce具体是个什么东西</li><li>通过具体代码来体现一下MapReduce</li><li>MapReduce具体的流程和运行机制</li></ol><a id="more"></a><h1 id="理解MapReduce"><a href="#理解MapReduce" class="headerlink" title="理解MapReduce"></a>理解MapReduce</h1><ul><li><strong>MapRedeuce</strong>，我们可以把它分开来理解：</li></ul><ol><li><code>Mapping</code>：<strong>对集合里的每个目标应用同一个操作</strong>。即，<em>如果你想把表单里每个单元格乘以二，那么把这个函数单独地应用在每个单元格上的操作就属于mapping</em>（这里体现了<strong>移动计算</strong>而不是移动数据）；</li><li><code>Reducing</code>：<strong>遍历集合中的元素来返回一个综合的结果</strong>。即，输出表单里一列数字的和这个任务属于reducing。</li></ol><ul><li><p><strong>计算框架</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412199999.png" alt="一个简单的MapReduce执行流程"><br>简单理解，<code>MapReduce计算框架（一个输入和输出的过程）</code>：</p><blockquote><p><strong>把需要计算的东西放入到MapReduce中进行计算，然后返回一个我们期望的结果</strong>。所以<strong>首先</strong>我们需要一个来源（需要计算的东西）即输入（input），<strong>然后</strong>MapReduce操作这个输入（input），通过定义好的计算模型，<strong>最后</strong>得到一个（期望的结果）输出（output）。</p></blockquote></li><li><p><strong>计算模型</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160703142402.png" alt="Map和Reduce"><br>在这里我们主要讨论的是<code>MapReduce计算模型</code>：</p><blockquote><p>在运行一个mapreduce计算任务时候，任务过程被分为两个阶段：map阶段和reduce阶段，每个阶段都是用键值对（key/value）作为输入（input）和输出（output）。而程序员要做的就是定义好这两个阶段的函数：map函数和reduce函数。</p></blockquote></li></ul><h1 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h1><ul><li>以MapReduce统计单词次数为例（伪代码），主要<code>四个模块</code>来讲解，如上图计算框架：<br>①、输入<br>②、map计算<br>③、reduce计算<br>④、输出</li></ul><ol><li><p><strong>Input，数据读入</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置数据输入来源</span></span><br><span class="line">FileInputFormat.setInputPaths(job, args[<span class="number">0</span>]);</span><br><span class="line">FileInputFormat.setInputDirRecursive(job, <span class="keyword">true</span>); <span class="comment">//递归</span></span><br><span class="line">job.setInputFormatClass(TextInputFormat.class);<span class="comment">//设置输入格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//TextInputFormat，一种默认的文本输入格式，Mapper一次读取文本中的一行数据。</span></span><br></pre></td></tr></table></figure></li><li><p><strong>使用Mapper计算</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置Job的Mapper计算类和K2、V2类型</span></span><br><span class="line">job.setMapperClass(WordCountMapper.class);<span class="comment">//1.设置Mapper类</span></span><br><span class="line">job.setMapOutputKeyClass(Text.class);<span class="comment">//设置Mapper输出Key的类型</span></span><br><span class="line">job.setMapOutputValueClass(LongWritable.class);<span class="comment">//设置Mapper输出Value的类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WordCountMapper类</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义的Map 需要继承Mapper</span></span><br><span class="line"><span class="comment"> * K1 : 行序号</span></span><br><span class="line"><span class="comment"> * V1 : 行信息</span></span><br><span class="line"><span class="comment"> * K2 : 单词</span></span><br><span class="line"><span class="comment"> * V2 : 次数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>,<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">LongWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    Text k2 = <span class="keyword">new</span> Text() ;</span><br><span class="line">    LongWritable v2 = <span class="keyword">new</span> LongWritable();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> </span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 获取行信息</span></span><br><span class="line">        String line = value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 获取行的所用单词</span></span><br><span class="line">        String[] words = line.split(<span class="string">"\t"</span>);<span class="comment">//这里假设一行文本单词分隔符为"\t"</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            k2.set(word.getBytes()) ; <span class="comment">//设置键</span></span><br><span class="line">            v2.set(<span class="number">1</span>);                <span class="comment">//设置值</span></span><br><span class="line">            context.write(k2,v2);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>使用Reducer合并计算</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置Job的Reducer计算类和K3、V3类型</span></span><br><span class="line">job.setReducerClass(WordCountReducer.class);<span class="comment">//自定义的Reducer类</span></span><br><span class="line">job.setOutputKeyClass(Text.class);<span class="comment">//输出Key类型</span></span><br><span class="line">job.setOutputValueClass(LongWritable.class);<span class="comment">//输出Value类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WordCountReducer 类</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义的Reduce 需要继承Reducer</span></span><br><span class="line"><span class="comment"> * K2 : 字符串</span></span><br><span class="line"><span class="comment"> * V3 : 次数（分组）</span></span><br><span class="line"><span class="comment"> * K3 : 字符串</span></span><br><span class="line"><span class="comment"> * V3 : 次数（统计总的）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">LongWritable</span>,<span class="title">Text</span>,<span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    LongWritable v3 = <span class="keyword">new</span> LongWritable() ;</span><br><span class="line">    <span class="keyword">int</span> sum  = <span class="number">0</span> ;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> </span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        sum = <span class="number">0</span> ;</span><br><span class="line">        <span class="keyword">for</span> (LongWritable value : values) &#123;</span><br><span class="line">            sum +=value.get() ;</span><br><span class="line">        &#125;</span><br><span class="line">        v3.set(sum);</span><br><span class="line">        context.write( key , v3 );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>Output，数据写出</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br></pre></td></tr></table></figure></li></ol><h1 id="MapReduce运行机制"><a href="#MapReduce运行机制" class="headerlink" title="MapReduce运行机制"></a>MapReduce运行机制</h1><ul><li>下面从<code>两个方面</code>来讲解MapReduce的运行机制：</li></ul><ol><li><strong>角色职责</strong>;</li><li><strong>图说MapReduce</strong>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419199999.jpg" alt="MapReduce计算模型的运行机制"></li></ol><h2 id="角色职责"><a href="#角色职责" class="headerlink" title="角色职责"></a>角色职责</h2><ol><li><p><strong>程序运行时过程设计到的一个角色实体</strong><br>1.1. <code>Client</code>：编写mapreduce程序，配置作业，提交作业的客户端 ；<br>1.2. <code>ResourceManager</code>：集群中的资源分配管理 ；<br>1.3. <code>NodeManager</code>：启动和监管各自节点上的计算资源 ；<br>1.4. <code>ApplicationMaster</code>：每个程序对应一个AM，负责程序的任务调度，本身也是运行在NM的Container中 ；<br>1.5. <code>HDFS</code>：分布式文件系统，保存作业的数据、配置信息等等。</p></li><li><p><strong>客户端提交Job</strong><br>2.1. 客户端编写好Job后，调用Job实例的Submit()或者waitForCompletion()方法提交作业；<br>2.2. 客户端向ResourceManager请求分配一个Application ID，客户端会对程序的输出、输入路径进行检查，如果没有问题，进行作业输入分片的计算。</p></li><li><p><strong>Job提交到ResourceManager</strong><br>3.1. 将作业运行所需要的资源拷贝到HDFS中（jar包、配置文件和计算出来的输入分片信息等）；<br>3.2. 调用ResourceManager的submitApplication方法将作业提交到ResourceManager。</p></li><li><p><strong>给作业分配ApplicationMaster</strong><br>4.1. ResourceManager收到submitApplication方法的调用之后会命令一个NodeManager启动一个Container ；<br>4.2. 在该NodeManager的Container上启动管理该作业的ApplicationMaster进程。</p></li><li><p><strong>ApplicationMaster初始化作业</strong><br>5.1. ApplicationMaster对作业进行初始化操作；<br>5.2. ApplicationMaster从HDFS中获得输入分片信息(map、reduce任务数)</p></li><li><p><strong>任务分配</strong><br>6.1. ApplicationMaster为其每个map和reduce任务向RM请求计算资源；<br>6.2. map任务优先于reduce任，map数据优先考虑本地化的数据。</p></li><li><p><strong>任务执行</strong>，在 Container 上启动任务（通过YarnChild进程来运行），执行map/reduce任务。</p></li></ol><h2 id="图说MapReduce"><a href="#图说MapReduce" class="headerlink" title="图说MapReduce"></a>图说MapReduce</h2><p><img src="https://img.xiaoxiaomo.com/blog/img/mapreduce1.jpg" alt="MapReduce详细的执行流程"></p><ol><li><p><strong>输入分片（input split）</strong><br>一个大的文件会根据block块切分成多个分片，每个输入分片会让一个map任务来处理（默认情况下，HDFS的块为128M作为一个分片）。<br>例如一个300MB的文件就会被切分问3个分片（128MB InputSplit、128MB InputSplit、44MB InputSplit），交给三个map任务去处理。</p></li><li><p><strong>map任务阶段</strong>：由我们自己编写，最后调用 context.write(…)；<br>map输出的结果会暂且放在一个环形内存缓冲区中（<code>默认mapreduce.task.io.sort.mb=100M</code>）,当该缓冲区快要溢出时（<code>默认mapreduce.map.sort.spill.percent=0.8</code>）,会在本地文件系统中创建一个溢出文件，将该缓冲区中的数据写入这个文件；</p></li><li><p><strong>partition分区阶段</strong><br>3.1. 在map中调用 context.write(k2,v2)方法输出&lt;k2,v2&gt;，该方法会立刻调用 Partitioner类对数据进行分区，一个分区对应一个 reduce task。<br>3.2. 默认的分区实现类是 <code>HashPartitioner</code> ，根据<code>k2的哈希值 % numReduceTasks</code>，可能出现“数据倾斜”现象。<br>3.3. 可以自定义 partition ，调用 job.setPartitioner(…)自己定义分区函数。</p></li><li><p><strong>combiner合并阶段</strong>：将属于同一个reduce处理的输出结果进行合并操作<br>4.1. 是可选的；<br>4.2. 目的有三个：1.减少Key-Value对；2.减少网络传输；3.减少Reduce的处理。</p></li><li><p><strong>shuffle阶段</strong>：即Map和Reduce中间的这个过程<br>5.1. 首先 <code>map</code> 在做输出时候会在内存里开启一个环形内存缓冲区，专门用来做输出，同时map还会启动一个守护线程；<br>5.2. 如缓冲区的内存达到了阈值的80%，守护线程就会把内容写到磁盘上，这个过程叫<code>spill</code>，另外的20%内存可以继续写入要写进磁盘的数据；<br>5.3. 写入磁盘和写入内存操作是互不干扰的，<code>如果缓存区被撑满了，那么map就会阻塞写入内存的操作</code>，让写入磁盘操作完成后再继续执行写入内存操作;<br>5.4. 写入磁盘时会有个排序操作，如果定义了combiner函数，那么排序前还会执行combiner操作；<br>5.5. 每次spill操作也就是写入磁盘操作时候就会写一个溢出文件，也就是说在做map输出有几次spill就会产生多少个溢出文件，等map输出全部做完后，map会合并这些输出文件，这个过程里还会有一个Partitioner操作（如上）<br>5.6. 最后 <code>reduce</code> 就是合并map输出文件，Partitioner会找到对应的map输出文件，然后进行复制操作，复制操作时reduce会开启几个复制线程，这些线程默认个数是5个（可修改），这个复制过程和map写入磁盘过程类似，也有阈值和内存大小，阈值一样可以在配置文件里配置，而内存大小是直接使用reduce的tasktracker的内存大小，复制时候reduce还会进行排序操作和合并文件操作，这些操作完了就会进行reduce计算了。</p></li><li><p><strong>reduce阶段</strong>：由我们自己编写，最终结果存储在hdfs上的,具体在图中就能看出了，就不一一阐述了。</p></li></ol><ul><li>参考资料<br><a href="https://github.com/kite-sdk/kite/wiki/Hadoop-MapReduce-Tutorial" target="_blank" rel="noopener">https://github.com/kite-sdk/kite/wiki/Hadoop-MapReduce-Tutorial</a><br><a href="http://www.cnblogs.com/sharpxiajun/p/3151395.html" target="_blank" rel="noopener">http://www.cnblogs.com/sharpxiajun/p/3151395.html</a><br><a href="http://blog.csdn.net/qq1010885678/article/details/51337323" target="_blank" rel="noopener">http://blog.csdn.net/qq1010885678/article/details/51337323</a><br><a href="http://blog.csdn.net/u014313009/article/details/38072269" target="_blank" rel="noopener">http://blog.csdn.net/u014313009/article/details/38072269 （Shuffle阶段讲的很好）</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--HDFS之读写流程</title>
      <link href="/2016/06/26/Hadoop-HDFS%E4%B9%8B%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/"/>
      <url>/2016/06/26/Hadoop-HDFS%E4%B9%8B%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>　　之前的博客，<a href="http://blog.xiaoxiaomo.com/2016/06/25/Hadoop-HDFS之NameNode/">HDFS NameNode</a> 和<a href="http://blog.xiaoxiaomo.com/2016/06/26/Hadoop-HDFS之DataNode/">HDFS DataNode</a> 让我们对HDFS两个重要的角色，NameNode和DataNode有了一定的认识。NameNode负责维护元数据信息，DataNode负责Block块数据的存储。HDFS的设计就是<strong>一次写入，多次读取，不支持文件修改</strong>，所以呢，文件的读写就变得相当重要，下面我们就一起来看一看HDFS文件的读写流程吧！</p><h2 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h2><ul><li><strong>DataNode的写操作流程</strong> 可以分为两部分：</li></ul><ol><li>准备工作，包括与NameNode的通信等；</li><li>真正的写操作。</li></ol><a id="more"></a><ul><li><strong>准备工作</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412195903.png" alt="准备工作"></li></ul><ol><li><strong>HDFS client先会去询问NameNode</strong>，看哪些DataNode可以存储文件。<strong>文件的拆分是在HDFS client中完成的</strong>，比如拆分成<em>A</em>、<code>B</code>、<code>C</code>。</li><li><strong>NameNode查看它的元数据信息</strong>，发现<strong>DataNode</strong> <code>1</code>，<code>2</code>，<code>7</code>上有空间可以存储Block A，于是将此信息告诉HDFS Client。</li><li><strong>HDFS Client接到NameNode返回的DataNode列表信息后</strong>，它会直接<strong>联系第一个DataNode1</strong>，让它准备好接收<strong>Block A</strong>（建立TCP连接）。</li><li>在DataNode1建立好TCP连接后它会把HDFS Client要写<strong>Block A</strong>的<strong>请求顺序</strong>传给DataNode2(<strong><em>在与HDFS Client建立好TCP连接后从HDFS Client获得的DataNodeli信息</em></strong>)，同理传递给DataNode7。</li><li>当DataNode7准备好后，会<strong>回传信息</strong>过来，<strong>HDFS Client接到信息后表示都准备好了</strong>，就可以写数据了。</li></ol><ul><li><strong>写入数据</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412195756.png" alt="写入数据"></li></ul><ol><li><strong>HDFS Client开始往DataNode1写入Block A数据</strong>。同准备工作一样，当DataNode1接收完Block A数据后，它会顺序将Block A数据传输给DataNode2，然后DataNode2再传输给DataNode7。</li><li>每个D<strong>ataNode</strong>在接收完Block A数据后，会发消息给<strong>NameNode</strong>，告诉它Block数据已经接收完毕。</li><li><code>NameNode</code>同时会根据它接收到的消息更新它保存的文件系统元数据信息。</li><li>当<strong>Block A 成功写入3个DataNode之后，DataNode1会发送一个成功信息给HDFS Client</strong>，同时<strong>HDFS Client也会发一个Block A成功写入的信息给NameNode</strong>。之后，HDFS Client才能开始继续处理下一个Block-Block B。</li></ol><h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><ul><li><strong>读取文件</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412202260.png" alt="读取文件"></li></ul><ol><li><strong>HDFS Client会先去联系NameNode</strong>，询问file.txt总共分为<code>几个Block</code>而且这些Block分别<strong>存放在哪些DataNode上</strong>。</li><li>由于每个Block都会存在几个<code>副本</code>，所以NameNode会把file.txt文件组成的Block所对应的<strong>所有DataNode列表</strong>都返回给HDFS Client。</li><li>然后<strong>HDFS Client会选择DataNode列表里的第一个DataNode去读取对应的Block</strong>。比如由于Block A存储在DataNode1，2，7，那么HDFS Client会到DataNode1去读取Block A；Block C存储在DataNode，7，8，9，那么HDFS Client就回到DataNode7去读取Block C。</li></ol><ul><li>参考资料<br><a href="http://www.jianshu.com/p/7e52a7f8d16d" target="_blank" rel="noopener">http://www.jianshu.com/p/7e52a7f8d16d</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--HDFS之DataNode</title>
      <link href="/2016/06/26/Hadoop-HDFS%E4%B9%8BDataNode/"/>
      <url>/2016/06/26/Hadoop-HDFS%E4%B9%8BDataNode/</url>
      <content type="html"><![CDATA[<p>　　<strong>HDFS DataNode</strong>，提供真实文件数据的存储服务。上篇博客<a href="http://blog.xiaoxiaomo.com/2016/06/25/Hadoop-HDFS之NameNode/">HDFS NameNode</a> 讲的是HDFS元数据，本篇主要讲解<strong>HDFS</strong>存储的真实数据。这些真实数据重点由两个部分组成，<strong>一、Block</strong>块（数据存储单元），<strong>二、文件备份数</strong>，掌握Block块信息，副本数的设置。</p><h2 id="Block块"><a href="#Block块" class="headerlink" title="Block块"></a>Block块</h2><ul><li><strong>文件块（block）</strong>：最基本的存储单位。</li></ul><ol><li>对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个<strong>Block</strong>；</li><li>HDFS，<strong>默认Block大小是128MB(2.0版本)</strong>，以一个256MB文件，共有256/128=2个Block；</li><li>HDFS中，<strong>如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间</strong>。</li></ol><a id="more"></a><ul><li><strong>NameNode和Block块关系</strong></li></ul><ol><li><p>首先上传test.txt文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 test]# ll -h  ##大小4KB,33字节</span><br><span class="line">total 4.0K</span><br><span class="line">-rw-r--r--. 1 root root 33 Jun 26 20:04 test.txt</span><br><span class="line">[root@xxo07 test]# hdfs dfs -put test.txt /in/test/</span><br></pre></td></tr></table></figure></li><li><p>查看详细信息，可以看见<strong>blkck ID:1073742177</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626202129.png" alt="File information"></p></li><li><p>导出fsimage文件（具体怎么导出，<a href="http://blog.xiaoxiaomo.com/2016/06/25/Hadoop-HDFS之NameNode/">查看</a>），<strong>blkck ID:1073742177</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626231658.png" alt="在fsimage文件中查看test文件信息"></p></li></ol><ul><li><strong>Block数据信息</strong></li></ul><ol><li><p>NameNode数据目录</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/hadoop_repo/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>查看我们上面的test文件block块数据信息<code>${dfs.namenode.name.dir}/current/</code>下，<strong>blkck ID:1073742177</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626232437.png" alt="在fsimage文件中查看test文件信息"></p></li><li><p>查看具体信息，可以发现是我们之前的文本信息，所以block块其实存放了原数据，没有任何序列化压缩等操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 subdir1]# more blk_1073742177 |more</span><br><span class="line">hello world</span><br><span class="line">xxo</span><br><span class="line">xiaoxiaomo blog</span><br></pre></td></tr></table></figure></li></ol><h2 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h2><ul><li>设置副本的三种方式：</li></ul><ol><li><p>多复本，默认是三个，可以通过<strong>配置文件<code>hdfs-site.xml</code>设置</strong>，我这里默认设置了一个副本（对已经上传了的文件不生效）:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>可以在<strong>上传文件时指定副本数</strong>（<em>这是使用了-D去从新修改了参数</em>）:<br>hadoop dfs -D dfs.replication=2 -put test.txt /in</p></li></ol><ol start="3"><li>通过命令来更改已经上传的文件的副本数(这里把副本数修改为2)：<br>[root@xxo07 hadoop]# hadoop fs -setrep -R 2 /in/test<br>Replication 2 set: /in/test/test.txt</li></ol><ul><li><p><strong>注意</strong>：<strong>如果你只有1个datanode，却指定副本数为2，是不会生效的，因为每个datanode上只能存放一个副本</strong>（<em>这样就会提示丢失了一个副本</em>）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 hadoop]# hadoop fsck /in/test/test.txt</span><br><span class="line">......</span><br><span class="line">Status: HEALTHY</span><br><span class="line"> Total size:33 B</span><br><span class="line"> Total dirs:0</span><br><span class="line"> Total files:1</span><br><span class="line"> Total symlinks:0</span><br><span class="line"> Total blocks (validated):1 (avg. block size 33 B)</span><br><span class="line"> Minimally replicated blocks:1 (100.0 %)</span><br><span class="line"> Over-replicated blocks:0 (0.0 %)</span><br><span class="line"> Under-replicated blocks:1 (100.0 %)</span><br><span class="line"> Mis-replicated blocks:0 (0.0 %)</span><br><span class="line"> Default replication factor:1</span><br><span class="line"> Average block replication:1.0</span><br><span class="line"> Corrupt blocks:0</span><br><span class="line"> Missing replicas:1 (50.0 %) ##丢失50%，因为我只有一个namenode,设置了2个副本，就会报告有丢失</span><br><span class="line"> Number of data-nodes:1</span><br><span class="line"> Number of racks:1</span><br></pre></td></tr></table></figure></li><li><p>通过命令：<code>hadoop fsck</code>查看具体信息<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626235432.png" alt="通过命令hadoop fsck 查看test文件信息"></p></li><li><p>如果某个NameNode节点挂掉</p></li></ul><ol><li><p>首先在副本机制下是没有什么问题的，如果节点没有全部挂掉，如果后期我们修复了机器，副本这么办呢？</p></li><li><p>下面来模拟一下：<br>2.1. 有节点xxo04（NameNode|DataNode）、xxo05（DataNode）、xxo06（SecondaryNameNode|DataNode）：<br>2.2. kill 掉xxo05,此时通过<code>hdfs fsck</code>或web界面是看不出效果的，如果执行了<code>start-balancer.sh</code>结果就出来了<br>Default replication factor:    3<br>Average block replication:    2.0<br>Missing replicas:        1 (33.333332 %)<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160627005634.png" alt="start-balancer.sh 之后查看效果"></p></li><li><p>如果几点修好后，启动NameNode即可<code>hadoop-daemon.sh start datanode</code></p></li></ol><h2 id="副本策略"><a href="#副本策略" class="headerlink" title="副本策略"></a>副本策略</h2><ul><li><p><strong>副本技术</strong><br>副本技术即分布式数据复制技术，是分布式计算的一个重要组成部分。该技术允许数据在多个服务器端共享，一个本地服务器可以存取不同物理地点的远程服务器上的数据，也可以使所有的服务器均持有数据的拷贝。</p></li><li><p><strong>副本技术优点</strong>：</p></li></ul><ol><li><strong>提高系统可靠性</strong>：系统不可避免的会产生故障和错误，拥有多个副本的文件系统不会导致无法访问的情况，从而提高了系统的可用性。另外，系统可以通过其他完好的副本对发生错误的副本进行修复，从而提高了系统的容错性。</li><li><strong>负载均衡</strong>：副本可以对系统的负载量进行扩展。多个副本存放在不同的服务器上，可有效的分担工作量，从而将较大的工作量有效的分布在不同的站点上。</li><li><strong>提高访问效率</strong>：将副本创建在访问频度较大的区域，即副本在访问节点的附近，相应减小了其通信开销，从而提高了整体的访问效率。</li></ol><ul><li><strong>副本放置策略</strong></li></ul><ol><li>块副本存放位置的选择严重影响 HDFS 的可靠性和性能。HDFS 采用机架敏感（rack awareness）的副本存放策略来提高数据的可靠性、可用性和网络带宽的利用率。</li><li>HDFS 副本放置策略，例如副本数为3：<br>2.1. 将第一个副本放在本地节点；<br>2.2. 将第二个副本放到本地机架上的另外一个节点；<br>2.3. 将第三个副本放到不同机架上的节点。</li><li>这种方式减少了机架间的写流量，从而提高了写的性能。机架故障的几率远小于节点故障。这种方式并不影响数据可靠性和可用性的限制，并且它确实减少了读操作的网络聚合带宽，因为文件块仅存在两个不同的机架，而不是三个。文件的副本不是均匀地分布在机架当中，1/3 副本在同一个节点上，1/3 副本在同一个机架上，另外 1/3 副本均匀地分布在其他机架上。这种方式提高了写的性能，并且不影响数据的可靠性和读性能。</li></ol><ul><li>参考资料<br><a href="http://www.ibm.com/developerworks/cn/data/library/bd-1505-hdfs-uilbps-optimize/index.html" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/data/library/bd-1505-hdfs-uilbps-optimize/index.html(副本存放策略讲的挺好)</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--HDFS之NameNode</title>
      <link href="/2016/06/25/Hadoop-HDFS%E4%B9%8BNameNode/"/>
      <url>/2016/06/25/Hadoop-HDFS%E4%B9%8BNameNode/</url>
      <content type="html"><![CDATA[<p>　　之前就打算写一下Hadoop系列博客的，由于写别的东西去了，一直也没抽空出来，上篇<a href="http://blog.xiaoxiaomo.com/2016/04/11/Hadoop-HDFS架构和Shell/">Hadoop–HDFS架构和Shell</a>对HDFS的一个简单概述，还是两三个月前的事情了。做了这么久的Hadoop了，在这里算是自我总结一下吧，本篇博客主要讲解一下<strong>Hadoop HDFS的NameNode</strong>。</p><ul><li><strong>重点掌握</strong>：</li></ul><ol><li><code>NameNode</code> 的作用；</li><li><code>NameNode</code> 元数据的底层结构；</li><li><code>SecondaryNameNode</code> 的作用以及工作流程，以及为什么需要SecondaryNameNode。</li></ol><a id="more"></a><h2 id="NameNode简介"><a href="#NameNode简介" class="headerlink" title="NameNode简介"></a>NameNode简介</h2><ul><li><strong>管理节点</strong></li></ul><ol><li><strong>核心元数据</strong>，包括文件(夹)的目录结构和属性信息，还有文件与其所在位置的映射信息。</li><li><strong>一切读写的操作必须经过NameNode，但是传输数据本身不经过NameNode</strong>（好好理解这句话）。</li></ol><h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><ul><li><p><strong>NameNode</strong> 包括以下文件：（<strong>保存在linux的文件系统中</strong>）</p><blockquote><ol><li><code>fsimage</code>：元数据镜像文件，存储某一时段NameNode内存元数据信息即保存了最新的元数据checkpoint。</li><li><code>edits</code>：操作日志文件。</li><li><code>fstime</code>：保存最近一次checkpoint的时间<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412193118.png" alt="NameNode元数据信息"></li></ol></blockquote></li><li><p><strong>NameNode</strong> 元数据</p></li></ul><ol><li>NameNode 为了保证交互速度，会在内存中保存这些元数据信息，但同时也会将这些信息保存到硬盘上进行持久化存储；</li><li>fsimage文件是内存中的元数据在硬盘上的checkpoint，它是一种序列化的格式，不能直接修改。</li><li>Hadoop在重启时就是通过<code>fsimage+edits</code>来状态恢复，fsimage相当于一个checkpoint，首先将最新的checkpoint的元数据信息从fsimage中加载到内存，然后逐一执行edits修改日志文件中的操作以恢复到重启之前的最终状态。</li><li>Hadoop的持久化过程是将上一次checkpoint以后最近一段时间的操作保存到修改日志文件edits中。</li></ol><h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>上面出现的一个问题是：edits会随着时间增加而越来越大，导致以后重启时需要花费很长的时间来按照edits中记录的操作进行恢复，于是Hadoop就专门弄了一个进程<strong>SecondaryNameNode</strong>。</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626120418.png" alt="SecondaryNameNode工作流程"></p><ul><li><strong>SecondaryNameNode节点</strong> 的主要功能是周期性将元数据节点的命名空间镜像文件（<em>fsimage</em>）和修改日志（<em>edits</em>）进行合并，以防edits日志文件过大。下面来看一看<strong>合并的流程</strong>：</li></ul><ol><li>SecondaryNameNode节点 需要合并时，首先通知<code>NameNode节点</code>生成新的日志文件，以后的日志都写到新的日志文件中。</li><li>SecondaryNameNode节点 用<code>http get</code>从<code>NameNode节点</code>获得<code>fsimage文件</code>及<code>旧的edits日志文件</code>。</li><li>SecondaryNameNode节点 将 <strong>fsimage 文件加载到内存中，并执行日志文件中的操作，然后生成新的fsimage文件</strong>。</li><li>SecondaryNameNode 节点将新的fsimage文件用http post<strong>传回</strong>NameNode节点上。</li><li>NameNode 节点可以将旧的fsimage文件及旧的日志文件，换为新的fsimage文件和新的日志文件(第一步生成的)，然后更新fstime文件，写入此次checkpoint的时间。</li><li>这样NameNode 节点中的fsimage文件保存了最新的checkpoint的元数据信息，日志文件也重新开始，不会变的很大了</li></ol><ul><li><code>注意</code>：</li></ul><ol><li>这种机制有个问题：因edits存放在NameNode中，当NameNode挂掉，edits也会丢失，导致<strong>利用Secondary NameNode恢复Namenode时，会有部分数据丢失</strong>。</li><li>HDFS设置了两种机制进行条件合并（hdfs-site.xml）：<br>第一种：当时间间隔大于或者等于dfs.namenode.checkpoint.period配置的时间是做合并（默认一小时）<br>第二种：当最后一次往journalNode写入的TxId（这个可以在namenode日志或者50070界面可以看到）和最近一次做Checkpoint的TxId的差值大于或者等于dfs.namenode.checkpoint.txns配置的数量（默认1000000）时做一次合并<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626195254.png" alt="HDFS设置了两种条件合并"></li></ol><h2 id="底层文件查看"><a href="#底层文件查看" class="headerlink" title="底层文件查看"></a>底层文件查看</h2><ul><li><p>保存的<code>NameNode元数据</code>信息，在<code>HADOOP_HOME/etc/hadoop/hdfs-site.xml 的 dfs.namenode.name.dir</code>配置，如下图：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/hadoop_repo/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 我切换到/usr/local/hadoop_repo/name/current就能查看元数据信息了 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- value可以配置多个，用逗号隔开，这样也算是一种备份方式吧--&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>第一步：开启服务</strong>，查看某个fsimage文件，开启服务命令：<code>bin/hdfs oiv -i fsimage文件</code>，不然提示：ls: Connection refused</p></li><li><p><strong>第二步：查看内容</strong>，命令：<code>bin/hdfs dfs -ls -R webhdfs://127.0.0.1:5978/</code>。我的hdfs里面有hbase和hive的数据，所以元数据也比较多，这里来个部分截图（这个看上去就和<code>web</code>以及<code>hdfs dfs -ls</code>查看的结果差不多）：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626143146.png" alt="NameNode元数据信息"></p></li><li><p><strong>第三步：导出结果</strong>，这是导出fsimage文件内容，命令：<code>hdfs oiv -p XML -i /usr/local/hadoop_repo/name/current/fsimage_0000000000000003292 -o fsimage.xml</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626174605.png" alt="导出的fsimage.xml文件"></p></li></ul><ol><li>xml节点在上面大家也能看见，主要看inode节点，下面就是文件以及文件夹的基本信息；</li><li><code>id</code>、<code>name</code>、<code>type</code>、<code>mtime</code>、<code>permission</code>、<code>nsquota</code>、<code>dsquota</code>；</li><li>如果是文件还有更多属性，比如<code>atime</code>、<code>perferredBlockSize</code>、<code>blocks</code>等</li><li>fsimage 保存有如下信息：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">一、加载Img头信息，如下：</span><br><span class="line">  <span class="number">1</span>、imgVersion(<span class="keyword">int</span>)：当前image的版本信息</span><br><span class="line">  <span class="number">2</span>、namespaceID(<span class="keyword">int</span>)：用来确保别的HDFS instance中的datanode不会误连上当前NN。</span><br><span class="line">  <span class="number">3</span>、numFiles(<span class="keyword">long</span>)：整个文件系统中包含有多少文件和目录</span><br><span class="line">  <span class="number">4</span>、genStamp(<span class="keyword">long</span>)：生成该image时的时间戳信息。</span><br><span class="line">二 、如果加载目录，包含以下信息：</span><br><span class="line">  <span class="number">1</span>、path(String)：该目录的路径，如”/user/build/build-index”</span><br><span class="line">  <span class="number">2</span>、replications(<span class="keyword">short</span>)：副本数（目录虽然没有副本，但这里记录的目录副本数也为<span class="number">3</span>）</span><br><span class="line">  <span class="number">3</span>、mtime(<span class="keyword">long</span>)：该目录的修改时间的时间戳信息</span><br><span class="line">  <span class="number">4</span>、atime(<span class="keyword">long</span>)：该目录的访问时间的时间戳信息</span><br><span class="line">  <span class="number">5</span>、blocksize(<span class="keyword">long</span>)：目录的blocksize都为<span class="number">0</span></span><br><span class="line">  <span class="number">6</span>、numBlocks(<span class="keyword">int</span>)：文件块数,<span class="number">-1</span>表示目录,大于<span class="number">1</span>时，表示该文件对应有多个block信息</span><br><span class="line">  <span class="number">7</span>、nsQuota(<span class="keyword">long</span>)：<span class="keyword">namespace</span> Quota值，若没加Quota限制则为<span class="number">-1</span></span><br><span class="line">  <span class="number">8</span>、dsQuota(<span class="keyword">long</span>)：disk Quota值，若没加限制则也为<span class="number">-1</span></span><br><span class="line">  <span class="number">9</span>、username(String)：该目录的所属用户名</span><br><span class="line">  <span class="number">10</span>、group(String)：该目录的所属组</span><br><span class="line">  <span class="number">11</span>、permission(<span class="keyword">short</span>)：该目录的permission信息，如<span class="number">644</span>等，有一个<span class="keyword">short</span>来记录。</span><br><span class="line">三、如果加载文件，则还会额外包含如下信息：</span><br><span class="line">  <span class="number">1</span>、blockid(<span class="keyword">long</span>)：属于该文件的block的blockid，</span><br><span class="line">  <span class="number">2</span>、numBytes(<span class="keyword">long</span>)：该block的大小</span><br><span class="line">  <span class="number">3</span>、genStamp(<span class="keyword">long</span>)：该block的时间戳</span><br></pre></td></tr></table></figure></li></ol><p>在namenode启动时，就需要对fsimage按照如下格式进行顺序的加载，以将fsimage中记录的HDFS元数据信息加载到内存中。</p><ul><li><strong>第三步：继续导出</strong>，这是导出edits文件内容，命令：<code>bin/hdfs oev -i /usr/local/hadoop_repo/name/current/edits_0000000000000003295-0000000000000003296 -o edits.xml</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160626180932.png" alt="导出的edits.xml文件"></li></ul><ol><li>最大的节点是<code>EDITS</code>，下面就是版本信息<code>EDITS_VERSION</code>和很多的<code>RECORD</code>节点;</li><li>每个<strong>edits</strong>文件第一个<code>RECORD</code>的<code>RECORD</code>都是以<code>OP_START_LOG_SEGMENT</code>开头;</li><li><code>RECORD</code>类型有很多，比如 OP_ADD、OP_TIMES、OP_DELETE、OP_ALLOCATE_BLOCK_ID、OP_ADD_BLOCK、OP_RENAME_OLD、OP_CLOSE等</li></ol><ul><li><strong>总结</strong>：</li></ul><ol><li>从上面我们就可以看出，edits文件的信息特别详细，记录了每一步操作，所以文件大小增长也特别的快；</li><li>fsimage文件内容就是edits文件详细步骤的浓缩。</li></ol><ul><li>参考资料<br><a href="http://blog.csdn.net/youzai24/article/details/8306456" target="_blank" rel="noopener">http://blog.csdn.net/youzai24/article/details/8306456(写的很好)</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--Shell</title>
      <link href="/2016/06/23/HBase-Shell/"/>
      <url>/2016/06/23/HBase-Shell/</url>
      <content type="html"><![CDATA[<p>　　有段时间没更新了，今天就来个简单的吧–<strong>HBase的Shell</strong>。这个没什么技术含量，主要是<strong>帮助文档太强大</strong>了！可以说无需刻意记忆，<code>help command</code>就搞定了。那为什么还要写这篇博客呢？那就回到了第一句话“<strong>有段时间没更新了”来个简单的(●’◡’●)</strong>”！其实，不是啦，主要是用来提醒自己两件事情，一多看帮助文档和源码，二不要忽视简单的东西脚踏实地。（<em>注：HBase版本0.98.8-hadoop2</em>）</p><a id="more"></a><h2 id="HBase-help"><a href="#HBase-help" class="headerlink" title="HBase help"></a>HBase help</h2><ul><li><p><strong>进入Shell</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 ~]<span class="comment"># hbase shell</span></span><br><span class="line">HBase Shell; enter <span class="string">'help&lt;RETURN&gt;'</span> <span class="keyword">for</span> list of supported commands.</span><br><span class="line">Type <span class="string">"exit&lt;RETURN&gt;"</span> to leave the HBase Shell</span><br><span class="line">Version 0.98.8-hadoop2, r6cfc8d064754251365e070a10a82eb169956d5fe, Fri Nov 14 18:26:29 PST 2014</span><br></pre></td></tr></table></figure></li><li><p><strong>HBase help</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; hbase <span class="built_in">help</span></span><br><span class="line">HBase Shell, version 0.98.8-hadoop2, r6cfc8d064754251365e070a10axxo6d5fe, Fri Nov 14 18:26:29 PST 2014</span><br><span class="line">Type <span class="string">'help "COMMAND"'</span>, (e.g. <span class="string">'help "get"'</span> -- the quotes are necessary) <span class="keyword">for</span> <span class="built_in">help</span> on a specific <span class="built_in">command</span>.</span><br><span class="line">Commands are grouped. Type <span class="string">'help "COMMAND_GROUP"'</span>, (e.g. <span class="string">'help "general"'</span>) <span class="keyword">for</span> <span class="built_in">help</span> on a <span class="built_in">command</span> group.</span><br><span class="line"></span><br><span class="line"><span class="comment">################################## Shell 分组了，便于记忆 ########################################</span></span><br><span class="line">COMMAND GROUPS:</span><br><span class="line">  Group name: general  <span class="comment">##普通命令</span></span><br><span class="line">  Commands: status, table_help, version, whoami</span><br><span class="line"></span><br><span class="line">  Group name: ddl    <span class="comment">##数据定义语言（data definition language） 不用解释 重点掌握</span></span><br><span class="line">  Commands: alter, alter_async, alter_status, create, describe, <span class="built_in">disable</span>, disable_all, drop, drop_all, </span><br><span class="line">   <span class="built_in">enable</span>, enable_all, exists, get_table, is_disabled, is_enabled, list, show_filters</span><br><span class="line"></span><br><span class="line">  Group name: namespace  <span class="comment">##这个命令空间命令相对table命令用的少，给table命令让步了然他加了后缀</span></span><br><span class="line">  Commands: alter_namespace, create_namespace, describe_namespace, drop_namespace, list_namespace, </span><br><span class="line">   list_namespace_tables</span><br><span class="line"></span><br><span class="line">  Group name: dml   <span class="comment">##数据操作语言（Data Manipulation Language 不用解释 重点掌握</span></span><br><span class="line">  Commands: append,count,delete,deleteall,get,get_counter,incr,put,scan,truncate,truncate_preserve</span><br><span class="line"></span><br><span class="line">  Group name: tools <span class="comment">##一般很少用，一旦用上久的细心点</span></span><br><span class="line">  Commands: assign, balance_switch, balancer, catalogjanitor_enabled, catalogjanitor_run, </span><br><span class="line">   catalogjanitor_switch, close_region, compact, compact_rs, flush, hlog_roll, major_compact, </span><br><span class="line">   merge_region, move, split, trace, unassign, zk_dump</span><br><span class="line"></span><br><span class="line">  Group name: replication <span class="comment">##备份操作命</span></span><br><span class="line">  Commands: add_peer, disable_peer, enable_peer, list_peers, list_replicated_tables, remove_peer, </span><br><span class="line">    set_peer_tableCFs, show_peer_tableCFs</span><br><span class="line"></span><br><span class="line">  Group name: snapshots <span class="comment">##快照，和元数据相关 0.95之后默认开启snapshot功能，之前版本的需要手动开启</span></span><br><span class="line">  Commands: clone_snapshot,delete_snapshot,list_snapshots,rename_snapshot,restore_snapshot,snapshot</span><br><span class="line"></span><br><span class="line">  Group name: security  <span class="comment">##授权</span></span><br><span class="line">  Commands: grant, revoke, user_permission</span><br><span class="line"></span><br><span class="line">  Group name: visibility labels <span class="comment">##可见性标签操作命令</span></span><br><span class="line">  Commands: add_labels, clear_auths, get_auths, set_auths, set_visibility</span><br><span class="line"></span><br><span class="line"><span class="comment">################################# Shell 用法 #########################################</span></span><br><span class="line">SHELL USAGE:</span><br><span class="line">Quote all names <span class="keyword">in</span> HBase Shell such as table and column names.  Commas delimit</span><br><span class="line"><span class="built_in">command</span> parameters.  Type &lt;RETURN&gt; after entering a <span class="built_in">command</span> to run it.</span><br><span class="line">Dictionaries of configuration used <span class="keyword">in</span> the creation and alteration of tables are</span><br><span class="line">Ruby Hashes. They look like this:</span><br><span class="line"></span><br><span class="line">  &#123;<span class="string">'key1'</span> =&gt; <span class="string">'value1'</span>, <span class="string">'key2'</span> =&gt; <span class="string">'value2'</span>, ...&#125;</span><br><span class="line"></span><br><span class="line">and are opened and closed with curley-braces.  Key/values are delimited by the</span><br><span class="line"><span class="string">'=&gt;'</span> character combination.  Usually keys are predefined constants such as</span><br><span class="line">NAME, VERSIONS, COMPRESSION, etc.  Constants <span class="keyword">do</span> not need to be quoted.  Type</span><br><span class="line"><span class="string">'Object.constants'</span> to see a (messy) list of all constants <span class="keyword">in</span> the environment.</span><br><span class="line"></span><br><span class="line">If you are using binary keys or values and need to enter them <span class="keyword">in</span> the shell, use</span><br><span class="line">double-quote<span class="string">'d hexadecimal representation. For example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  hbase&gt; get '</span>t1<span class="string">', "key\x03\x3f\xcd"</span></span><br><span class="line"><span class="string">  hbase&gt; get '</span>t1<span class="string">', "key\003\023\011"</span></span><br><span class="line"><span class="string">  hbase&gt; put '</span>t1<span class="string">', "test\xef\xff", '</span>f1:<span class="string">', "\x01\x33\x40"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The HBase shell is the (J)Ruby IRB with the above HBase-specific commands added.</span></span><br><span class="line"><span class="string">For more on the HBase Shell, see http://hbase.apache.org/book.html</span></span><br><span class="line"><span class="string">NoMethodError: undefined method `hbase'</span> <span class="keyword">for</span> <span class="comment">#&lt;Object:0x2b6b35f4&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h2><ul><li>其他就不在这里一一举例了，比如想查看careat的用法直接“ <code>help &#39;create&#39;</code> ” 就 ok,如下图：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160624001022.png" alt="help &#39;create&#39; "><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160624001113.png" alt="create Examples"></li></ul><h2 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h2><ul><li><strong>以用户表user为例</strong>，如下图：</li></ul><ol><li>行键 row_key ： uid(倒置) ;</li><li>列族 column_famliy : nm和Info</li><li>限定符(列族Info的限定符 ) ： flos(关注) | fans(粉丝) | fw(鲜花)</li><li>表结构：如下<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160625122358.png" alt="一张用户表user"></li></ol><ul><li><strong>操作</strong></li></ul><ol><li><p>创建一个具有两个列族“nm”和“info”的表“user”，注意单引号和逗号。<br>hbase(main):001:0&gt; create ‘user’,’nm’,’info’</p></li><li><p>list，查看当前 HBase 中具有哪些表。<br>hbase(main):012:0&gt; list</p></li><li><p>describe 查看表构造。<br>hbase(main):003:0&gt; describe ‘user’<br>Table user is ENABLED<br>COLUMN FAMILIES DESCRIPTION<br>{NAME =&gt; ‘info’, DATA_BLOCK_ENCODING =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’, REPLICATION_SCOPE =&gt; ‘<br>0’, VERSIONS =&gt; ‘1’, COMPRESSION =&gt; ‘NONE’, MIN_VERSIONS =&gt; ‘0’, TTL =&gt; ‘FOREVER’, KEEP_DELE<br>TED_CELLS =&gt; ‘FALSE’, BLOCKSIZE =&gt; ‘65536’, IN_MEMORY =&gt; ‘false’, BLOCKCACHE =&gt; ‘true’}<br>{NAME =&gt; ‘nm’, DATA_BLOCK_ENCODING =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’, REPLICATION_SCOPE =&gt; ‘0’<br>, VERSIONS =&gt; ‘1’, COMPRESSION =&gt; ‘NONE’, MIN_VERSIONS =&gt; ‘0’, TTL =&gt; ‘FOREVER’, KEEP_DELETE<br>D_CELLS =&gt; ‘FALSE’, BLOCKSIZE =&gt; ‘65536’, IN_MEMORY =&gt; ‘false’, BLOCKCACHE =&gt; ‘true’}<br>2 row(s) in 0.0750 seconds</p></li><li><p>put 命令向表中插入数据,参数分别为表名、行名、列名和值<br>a. 加入数据,第一行键为“25”,列族“nm”,值为 xiaoxiao。第二行略<br>hbase(main):006:0&gt; put ‘user’,’25’,’nm’,’xiaoxiao’<br>hbase(main):007:0&gt; put ‘user’,’71’,’nm’,’momo’<br>hbase(main):010:0&gt; put ‘user’,’25’,’info:flos’,’52’</p></li><li><p>get 查询<br>hbase(main):010:0&gt; get ‘user’,’71’<br>COLUMN                   CELL<br>nm:                     timestamp=1466829836778, value=momo<br>hbase(main):011:0&gt; get ‘user’,’25’,’info:flos’<br>COLUMN                   CELL<br>info:flos               timestamp=1466830066408, value=52 </p></li><li><p>scan 查询，这个比较强大<br>hbase(main):012:0&gt; scan ‘user’<br>ROW                      COLUMN+CELL<br>25                      column=info:flos, timestamp=1466830066408, value=52<br>25                      column=nm:, timestamp=1466829764632, value=xiaoxiao<br>71                      column=nm:, timestamp=1466829836778, value=momo </p></li><li><p>count 统计行数<br>hbase(main):015:0&gt; count ‘user’<br>2 row(s) in 0.0530 seconds<br>=&gt; 2</p></li><li><p>delete 删除某条数据<br>hbase(main):028:0&gt; delete ‘user’,’72’,’info:fans’</p></li><li><p>truncate 清空数据，谨慎使用<br>hbase(main):029:0&gt; truncate ‘user’</p></li><li><p>drop 删除表，drop之前需要disbale table<br>hbase(main):030:0&gt;  disable ‘user’<br>hbase(main):032:0&gt;  drop ‘user’</p></li><li><p>status 查看状态<br>hbase(main):033:0&gt; status<br>1 servers, 0 dead, 4.0000 average load</p></li><li><p>version 查看版本<br>hbase(main):032:0&gt; version<br>0.98.8-hadoop2, r6cfc8d064754251365e070a10a82eb169956d5fe, Fri Nov 14 18:26:29 PST 2014</p></li><li><p>exit 退出<br>hbase(main):033:0&gt; exit</p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Storm--DRPC</title>
      <link href="/2016/06/10/Storm-DRPC/"/>
      <url>/2016/06/10/Storm-DRPC/</url>
      <content type="html"><![CDATA[<p>　　<strong>DRPC</strong> （<em>Distributed RPC</em>）分布式远程过程调用，Storm中的DRPC提供了集群中处理功能的访问接口。相当于集群向外暴露一个功能接口，用户可以在任何地方进行调用。DRPC的真正目的就是使用storm的实时并行计算功能。以一个输入流作为函数参数，以一个输出流的形式发射每个函数调用的结果。</p><h2 id="DRPC介绍"><a href="#DRPC介绍" class="headerlink" title="DRPC介绍"></a>DRPC介绍</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610160519.jpg" alt="Storm DRPC"></p><a id="more"></a><ol><li>Storm是一个分布式实时处理框架,它支持以DRPC方式调用.可以理解为Storm是一个集群,DRPC提供了集群中处理功能的访问接口；</li><li>DPRC是Storm提供的一套开发组建，使用DRPC可以极大的简化这一过程；</li><li>Storm里面引入DRPC主要是利用storm的实时计算能力来并行化CPU intensive的计算。DRPC的storm topology以函数的参数流作为输入，而把这些函数调用的返回值作为topology的输出流；</li><li>DRPC其实不能算是storm本身的一个特性，它是通过组合storm的原语spout，bolt， topology而成的一种模式(pattern)；</li><li>本来应该把DRPC单独打成一个包的， 但是DRPC实在是太有用了，所以我们我们把它和storm捆绑在一起；</li><li>可以通过在Topoloye中的spout中建立一个TCP/HTTP监听来接收数据，在最后一个Bolt中将数据发送到指定位置也是可以的。</li></ol><h2 id="DRPC工作流程"><a href="#DRPC工作流程" class="headerlink" title="DRPC工作流程"></a>DRPC工作流程</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610164227.jpg" alt="DRPC工作流程"></p><ol><li>客户端给DRPC服务器发送要执行的方法的名字，以及这个方法的参数。</li><li>实现了这个函数的topology使用DRPCSpout从DRPC服务器接收函数调用流。每个函数调用被DRPC服务器标记了一个唯一的id。</li><li>这个topology然后计算结果，在topology的最后一个叫做ReturnResults的bolt会连接到DRPC服务器，并且把这个调用的结果发送给DRPC服务器(通过那个唯一的id标识)。</li><li>DRPC服务器用那个唯一id来跟等待的客户端匹配上，唤醒这个客户端并且把结果发送给它。</li></ol><h2 id="DRPC使用"><a href="#DRPC使用" class="headerlink" title="DRPC使用"></a>DRPC使用</h2><ul><li>一、启动Storm中的DRPC Server</li></ul><ol><li>修改Storm/conf/storm.yaml中的drpc server地址(所有节点都需要修改)；</li><li>storm drpc命令启动drpc server。</li></ol><ul><li>二、创建一个DRPC 的Topology，提交到storm中运行，有两种方式创建：</li></ul><ol><li><p>直接使用 Storm 提供的LinearDRPCTopologyBuilder。 （不过该方法在0.82版本中显示为已过期，被trident取代）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">package com.xxo.drpc;</span><br><span class="line"></span><br><span class="line">import backtype.storm.Config;</span><br><span class="line">import backtype.storm.ILocalDRPC;</span><br><span class="line">import backtype.storm.LocalCluster;</span><br><span class="line">import backtype.storm.LocalDRPC;</span><br><span class="line">import backtype.storm.drpc.LinearDRPCTopologyBuilder;</span><br><span class="line">import backtype.storm.task.OutputCollector;</span><br><span class="line">import backtype.storm.task.TopologyContext;</span><br><span class="line">import backtype.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import backtype.storm.topology.base.BaseRichBolt;</span><br><span class="line">import backtype.storm.tuple.Fields;</span><br><span class="line">import backtype.storm.tuple.Tuple;</span><br><span class="line">import backtype.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line">/**</span><br><span class="line"> * DRPC</span><br><span class="line"> * Created by xiaoxiaomo on 2016/6/10.</span><br><span class="line"> */</span><br><span class="line">public class LocalDrpcTopology &#123;</span><br><span class="line">public static class MyBolt extends BaseRichBolt&#123;</span><br><span class="line"></span><br><span class="line">private OutputCollector collector;</span><br><span class="line">@Override</span><br><span class="line">public void prepare(Map stormConf, TopologyContext context,</span><br><span class="line">OutputCollector collector) &#123;</span><br><span class="line">this.collector = collector;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 这个tuple中封装两个元素</span><br><span class="line"> * 第一个元素：请求的id</span><br><span class="line"> * 第二个元素：请求的参数</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">public void execute(Tuple input) &#123;</span><br><span class="line">String value = input.getString(1);</span><br><span class="line">value = <span class="string">"hello "</span>+value;</span><br><span class="line">this.collector.emit(new Values(input.getValue(0),value));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">declarer.declare(new Fields(<span class="string">"id"</span>,<span class="string">"value"</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 这里使用本地调用</span><br><span class="line"> */</span><br><span class="line">public static void main(String[] args) throws Exception &#123;</span><br><span class="line">@SuppressWarnings(<span class="string">"deprecation"</span>)</span><br><span class="line">//创建一个线性DRPC拓扑构建器</span><br><span class="line">LinearDRPCTopologyBuilder builder = new LinearDRPCTopologyBuilder(<span class="string">"hello"</span>);</span><br><span class="line">builder.addBolt(new MyBolt());</span><br><span class="line"></span><br><span class="line">LocalCluster localCluster = new LocalCluster();</span><br><span class="line">String simpleName = local.class.getSimpleName();</span><br><span class="line">ILocalDRPC drpc = new LocalDRPC();</span><br><span class="line">local.submitTopology(simpleName, new Config(), builder.createLocalTopology(drpc));</span><br><span class="line"></span><br><span class="line">String result = drpc.execute(<span class="string">"hello"</span>, <span class="string">"storm"</span>);</span><br><span class="line">System.out.println(<span class="string">"客户端调用的结果："</span> + result);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>直接使用 Storm 提供的通用TopologyBuilder。 不过需要自己手动加上开始的DRPCSpout和结束的ReturnResults。（LinearDRPCTopologyBuilder也是这样封装的）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line"><span class="comment">//开始的Spout</span></span><br><span class="line">DRPCSpout drpcSpout = <span class="keyword">new</span> DRPCSpout(<span class="string">"DrpcBuildTopology"</span>);</span><br><span class="line">builder.setSpout(<span class="string">"drpc-input"</span>, drpcSpout, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//真正处理的Bolt</span></span><br><span class="line">builder.setBolt(<span class="string">"cpp"</span>, <span class="keyword">new</span> MyBolt(), <span class="number">5</span>).noneGrouping(<span class="string">"drpc-input"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//结束的ReturnResults</span></span><br><span class="line">builder.setBolt(<span class="string">"return"</span>, <span class="keyword">new</span> ReturnResults(),<span class="number">5</span>).noneGrouping(<span class="string">"cpp"</span>);</span><br><span class="line"></span><br><span class="line">StormSubmitter.submitTopology(<span class="string">"DrpcBuildTopology"</span>, <span class="keyword">new</span> Config(), builder.createTopology());</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>三、<strong>通过DRPCClient对Cluster进行访问</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DRPCClient client = <span class="keyword">new</span> DRPCClient(<span class="string">"192.168.1.171"</span>, <span class="number">3772</span>);</span><br><span class="line">String result = drpcClient.execute(<span class="string">"hello"</span>, <span class="string">"world"</span>);</span><br><span class="line">System.out.println(<span class="string">"服务端返回的结果："</span>+result);</span><br></pre></td></tr></table></figure></li><li><p>参考资料<br><a href="http://storm.apache.org/releases/0.9.6/Distributed-RPC.html" target="_blank" rel="noopener">http://storm.apache.org/releases/0.9.6/Distributed-RPC.html</a><br><a href="http://www.dataguru.cn/article-5572-1.html" target="_blank" rel="noopener">http://www.dataguru.cn/article-5572-1.html</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Storm--故障容忍和消息可靠性</title>
      <link href="/2016/06/10/Storm-%E6%95%85%E9%9A%9C%E5%AE%B9%E5%BF%8D%E5%92%8C%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7/"/>
      <url>/2016/06/10/Storm-%E6%95%85%E9%9A%9C%E5%AE%B9%E5%BF%8D%E5%92%8C%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7/</url>
      <content type="html"><![CDATA[<p>　　如果Storm集群中某个Worker挂了会怎样？Nimbus和Supervisor挂掉了又会怎样？Storm流式处理数据又是怎样保证每条数据都能完全被处理的呢？这将是本博客讨论的重点，<strong>Storm的故障容忍</strong>，以及<strong>Storm的消息可靠性</strong>和<strong>Acker机制</strong>。</p><a id="more"></a><h2 id="故障容忍"><a href="#故障容忍" class="headerlink" title="故障容忍"></a>故障容忍</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li><p><strong>Worker进程不会因Nimbus或者Supervisor的挂掉而受到影响</strong></p><blockquote><ol><li><code>worker进程死掉</code>： Supervisor会重启它。如果这个Worker连续在启动时失败，并且无法让Nimbus观察到它的心跳，Nimbus将这个Worker重新分配到另一台机器上。</li><li><code>supervisor进程死掉</code>： 这样不会影响之前已经提交的topology的运行，只是后期不会再向这个节点分配任务了。</li><li><code>nimbus进程死掉</code>： 这样不会影响之前已经提交的topology的运行，只是后期不能向集群中提交topology了。</li></ol></blockquote></li><li><p><strong>Nimbus和Supervisor daemon进程</strong>，设计成快速失败(无论何时当遇到任何异常情况，将会执行自毁)和无状态（所有的状态都保存在Zookeeper或者磁盘上）。</p></li><li><strong>Nimbus和Supervisor daemon进程</strong>，必须在监控下运行，如使用daemontools或者monit工具。</li><li><strong>Nimbus是会有单点故障的问题</strong>，但Nimbus进程挂掉也不会引起任何灾难发生。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a><strong>示例</strong></h3><ul><li>我这里有一个一主两从的节点，从节点主机名为xxo09、xxo10。然后向集群中提交了一个求和的topology，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610122144.jpg" alt="首先，向Storm集群提交了一个求和topology"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610122850.jpg" alt="查看Storm UI,发现spout和bolt都在xxo10上"></li><li><p><strong>kill worker进程</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610123741.jpg" alt="kill 掉xxo10上worker进程，自动在xxo09上启动了"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610124040.jpg" alt="Worker总topology重新分配到xxo09机器上"></p></li><li><p><strong>kill supervisor进程</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610130416.jpg" alt="kill 掉supervisor进程"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160610130459.jpg" alt="worker继续在工作"></p></li></ul><h2 id="消息可靠性"><a href="#消息可靠性" class="headerlink" title="消息可靠性"></a>消息可靠性</h2><p>上面我们讨论了，storm的故障容错，下面我们继续来看一看strom是如何保证消息的可靠性的。</p><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><ol><li>在Topology中，Spout通过SpoutOutputCollector的emit()方法发射一个tuple(源)即消息。而后经过在该Topology中定义的多个Bolt处理时，可能会产生一个或多个新的Tuple。源Tuple和新产生的Tuple便构成了一个<strong>Tuple树</strong>。</li><li>当整棵<strong>Tuple树</strong>被处理完成，才算一个Tuple被完全处理，其中任何一个节点的Tuple处理失败或超时，则整棵<strong>Tuple树</strong>处理失败。</li><li><strong>Storm的消息可靠性</strong> : 指的是storm保证每个tuple都能被toplology完全处理。而且处理的结果要么成功要么失败。出现失败的原因可能有两种即节点处理失败或者处理超时。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.spoutOutputCollector.emit( <span class="keyword">new</span> Values(i) );</span><br></pre></td></tr></table></figure></li></ol><h3 id="可靠性设置"><a href="#可靠性设置" class="headerlink" title="可靠性设置"></a>可靠性设置</h3><ul><li><p>如何开启：在spout中发射数据的时候，带上messageid,messageid和tuple中的元素的关系需要程序员自己维护</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.collector.emit(new Values(<span class="string">"num"</span>),messageid)</span><br></pre></td></tr></table></figure></li><li><p>如果对消息进去确认：这个工作其实是由acker线程进行追踪tuple的状态，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//当在bolt中对数据处理成功的时候，需要调用</span></span><br><span class="line"><span class="keyword">this</span>.collector.ack(tuple) <span class="comment">//这个时候，spout类中的ack方法会被调用。（这个方法是一个回调方法）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//如果在bolt中处理tuple的时候，最后没有调用ack方法(前提是：开起来acker消息确认机制)</span></span><br><span class="line"><span class="comment">//这个时候，当达到tuple的处理超时时间的时候，这个方法会被默认处理失败。这样spout类中的fail方法就会被调用。</span></span><br><span class="line">config.put(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, <span class="number">10</span>); <span class="comment">//设置超时时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//针对多个bolt的topology，需要把bolt发射出来的tuple作为上一级tuple的一个衍生tuple，</span></span><br><span class="line"><span class="comment">//相当于把这些tuple组成一个tuple树，</span></span><br><span class="line"><span class="comment">//此时，只有所有衍生的tuple都调用ack方法的时候，spout中的ack方法才会被调用。保证tuple被完全处理</span></span><br><span class="line"><span class="keyword">this</span>.collector.emit(input,<span class="keyword">new</span> Values(value));</span><br></pre></td></tr></table></figure></li></ul><h3 id="acker示例"><a href="#acker示例" class="headerlink" title="acker示例"></a>acker示例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.acker;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> backtype.storm.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.generated.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.spout.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.task.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.topology.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.topology.base.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.tuple.*;</span><br><span class="line"><span class="keyword">import</span> backtype.storm.utils.Utils;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 求和</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/6/6.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AckerSumTopology</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger( AckerSumTopology.class ) ;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义Spout</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span> ;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 该方法只会被调用一次</span></span><br><span class="line"><span class="comment">         * 做一些初始化的操作</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> map</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> collector</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map map, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.collector = collector;</span><br><span class="line">            i = <span class="number">0</span> ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 会不停的执行，像一个死循环</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            i++;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//messageid和tuple是一一对应的</span></span><br><span class="line">            <span class="comment">//可以认为messageid 是tuple里面的数据主键id</span></span><br><span class="line">            <span class="comment">//messageid和tuple关系需要程序员自己去维护</span></span><br><span class="line">            <span class="comment">//注意：只有在发spout中发射tuple的时候带上messageid，才说明开启了消息确认机制</span></span><br><span class="line">            <span class="keyword">this</span>.collector.emit( <span class="keyword">new</span> Values(i) , i );</span><br><span class="line">            Utils.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> declarer</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">            declarer.declare( <span class="keyword">new</span> Fields(<span class="string">"num"</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ack</span><span class="params">(Object msgId)</span> </span>&#123;</span><br><span class="line">            System.out.println( <span class="string">"消息msgId："</span>+msgId + <span class="string">"，处理成功！"</span> );</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fail</span><span class="params">(Object msgId)</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"消息msgId："</span> + msgId + <span class="string">"，处理失败！"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义Bolt</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 做初始化操作</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> map</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> collector</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.collector = collector ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 循环执行，当对应的spout有输出时，该方法就会被调用一次</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> tuple</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">"求和："</span> + tuple.getIntegerByField(<span class="string">"num"</span>));</span><br><span class="line"><span class="comment">//                if( tuple.getIntegerByField("num") &gt; 10 )&#123; //test 手动抛出异常</span></span><br><span class="line"><span class="comment">//                    throw new RuntimeException("num &gt; 10!") ;</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//                outputCollector.ack( tuple );</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> ( Exception e )&#123;</span><br><span class="line">                collector.fail( tuple);</span><br><span class="line">                logger.error(<span class="string">" execute tuple error! "</span> , e  );</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        builder.setSpout(<span class="string">"spout_1"</span>, <span class="keyword">new</span> SumSpout());</span><br><span class="line">        <span class="comment">//通过shuffleGrouping，可以指定bolt接收哪个组件发射出来的数据</span></span><br><span class="line">        builder.setBolt(<span class="string">"bolt_1"</span>,<span class="keyword">new</span> SumBolt()).setNumTasks(<span class="number">5</span>).shuffleGrouping(<span class="string">"spout_1"</span>);</span><br><span class="line"></span><br><span class="line">        LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用.setNumTasks(5) 预留task，方便后期进行rebalance</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置超时</span></span><br><span class="line">        <span class="comment">////在指定的时间内，如果bolt没有确认tuple处理成功，那么系统会默认这个tuple处理失败</span></span><br><span class="line">        conf.put( Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS , <span class="number">10</span> ) ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//集群</span></span><br><span class="line">        <span class="keyword">if</span>( args != <span class="keyword">null</span> &amp;&amp; args.length &gt; <span class="number">0</span> )&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                StormSubmitter.submitTopology(</span><br><span class="line">                    AckerSumTopology.class.getSimpleName() , conf , builder.createTopology() );</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//本地</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            cluster.submitTopology( <span class="string">"cluster_1"</span>, conf ,builder.createTopology());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Storm--并行度</title>
      <link href="/2016/06/09/Storm-%E5%B9%B6%E8%A1%8C%E5%BA%A6/"/>
      <url>/2016/06/09/Storm-%E5%B9%B6%E8%A1%8C%E5%BA%A6/</url>
      <content type="html"><![CDATA[<p>　　<strong>storm的并行度</strong>，其实就是让storm中的组件使用多线程来运行，正常情况下，每一个组件都是一个线程来运行的。</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609220808.jpg" alt="Storm的并行度"></p><a id="more"></a><p>　　storm中的组件在运行的时候都会生成一些task(实例，还可以理解为new Spout或者new bolt)。这个task先要运行的话，需要在线程(executor)中运行，线程需要存在于进程(worker)内部。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="关系简介"><a href="#关系简介" class="headerlink" title="关系简介"></a>关系简介</h3><ol><li><strong>Worker进程</strong>存在于每个<strong>工作节点Supervisor</strong>中，一个Worker进程中可以含有一个或者多个Executor线程，每个Executor线程都会启动一个消息循环线程，用于接收、处理和发送消息，当Executor收到其下某一task的消息后，就会调用该Task对应的处理逻辑对消息进行处理；</li><li>1个topology可以有多个worker进程，1个worker进程只为1个topology服务。即<strong>1个worker进程执行的是1个topology的子集</strong>；</li><li><strong>一个线程Executor，运行时只会运行一个task</strong>，如果有多个，循环执行，即其他的task出去等待状态；</li><li>task，最终运行spout或bolt中代码的执行单元，即<strong>task可能是spout组件也有可能是bolt组件</strong>；</li><li><strong>默认情况下</strong>: <code>1个supervisor</code>节点最多可以启动<code>4个worker进程</code>，每<code>1个topology</code>默认占用<code>1个worker进程</code>，<code>每个spout或者bolt</code>会占用<code>1个executor</code>，<code>每个executor</code>启动<code>1个task</code>。</li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609225228.jpg" alt="Storm Supervisor"></p><ul><li><strong>注意</strong> ： 在同一个线程中，如果有多个task，这些task一定是相同组件实例；</li></ul><p>　　</p><h3 id="官网实例"><a href="#官网实例" class="headerlink" title="官网实例"></a>官网实例</h3><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609225446.jpg" alt="Storm 官网蓝绿黄例子"><br>上图拓扑中有2个 worker 进程。</p><ol><li>蓝色的 BlueSpout 有2个 executor线程，每个 executor 有1个 task，并行度为 2；</li><li>绿色的 GreenBolt 有2个 executor线程，每个 executor 有2个 task，并行度为 2；</li><li>黄色的 YellowBolt 有6个 executor线程，每个 executor 有1个 task，并行度为 6；</li><li>拓扑的总并行度就是 2 + 2 + 6 = 10。具体分配到每个 worker 就有 10 / 2 = 5 个 executor。</li></ol><h2 id="提高并行度"><a href="#提高并行度" class="headerlink" title="提高并行度"></a>提高并行度</h2><ul><li>并行度是基于线程数量来确定的，线程数被平均分配到Worker进程中。</li><li><strong>提高storm并行度的方法</strong>：</li></ul><ol><li>最直接的就是提高某一个组件的<code>executor</code>线程数；</li><li>从worker层面和task层面：<br>2.1. <code>work</code>：可以把很多线程分配到多个worker进程中；<br>2.2. <code>task</code>：提高task任务数量（<em>并不能提高并行度</em>），可以为后期进行<strong>弹性计算（rebalance）</strong>即后期<strong>动态调整某一组件的并行度</strong>。<strong>因为当topology提交到集群之后，task任务数目就不能改变了。</strong></li></ol><h3 id="并行度设置"><a href="#并行度设置" class="headerlink" title="并行度设置"></a>并行度设置</h3><ul><li><strong>配置worker进程数量</strong></li></ul><ol><li><p>默认一个从节点上可以启动 4 个worker进程(<em>defaults.yaml</em>)。自己可以在storm配置文件中配置，参数supervisor.slots.ports;</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">supervisor.slots.ports: <span class="comment">##指定storm通讯端口，注意超线程</span></span><br><span class="line">      - 6701</span><br><span class="line">      - 6702</span><br><span class="line">      - 6703</span><br><span class="line">      - 6704</span><br></pre></td></tr></table></figure></li><li><p>默认一个topology只使用一个worker进程，可以通过代码<code>config.setNumWorkers(workers)</code>来设置使用多个worker进程;<br>2.1. 最好一台机器上的一个topology只使用一个worker,主要原因是减少了worker进程之间的数据传输（Netty）；<br>2.2. 如果worker使用完的话再提交topology就不会执行，会处于等待状态；</p></li><li><p>增加worker 是增加topology 计算能力的简单方法，spout 和bolt 组件都不需要做变更。</p></li></ol><ul><li><p><strong>配置executor线程数量</strong><br>默认情况下一个executor运行一个task，可以通过在代码中设置每个组件需要的执行线程数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">builder.setSpout(id, spout, parallelism_hint); <span class="comment">##parallelism_hint设置spout的线程数量</span></span><br><span class="line">builder.setBolt(id, bolt, parallelism_hint);   <span class="comment">##parallelism_hint设置bolt的线程数量</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置task数量</strong></p></li></ul><ol><li>task是通过 spout/bolt的声明中setNumTasks(num)设置对应spout/bolt的task个数，默认每个 executor 的 task 数为 1；</li><li>executor的数量会小于等于task的数量(为了rebalance)。</li></ol><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><ul><li>下面就一上图【Storm 官网蓝绿黄例子】做一个并行度设置，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609235346.jpg" alt="Storm 官网蓝绿黄并行度设置"></li></ul><h2 id="弹性计算"><a href="#弹性计算" class="headerlink" title="弹性计算"></a>弹性计算</h2><ul><li>从上面得知：</li></ul><ol><li>当<code>topology</code>提交到集群之后，<code>task任务</code>数目就不能改变了（线程数可以变）；</li><li>因此弹性计算就需要提前给一个组件的线程创建多个task;</li></ol><ul><li>动态调整：</li></ul><ol><li>topology提交到Storm集群中运行后，通过storm rebalance 命令可对topology进行动态调整。比如增加Topology的worker数，修改Bolt，Spout的并行执行数量 parallelism等，从而实现topology的动态调整，达到弹性计算的目的。</li><li>命令：<br>2.1. <code>storm rebalance topology-name -n new-work-num</code>  ////调整指定topology的worknum；<br>2.2. <code>storm rebalance topology-name -e component=parallelism</code> ////调整指定topology中指定component的并行数量。</li></ol><h2 id="并行度设置多少"><a href="#并行度设置多少" class="headerlink" title="并行度设置多少"></a>并行度设置多少</h2><ul><li>并行度设置多少合适？通过查阅资料大概总结如下：</li></ul><ol><li>单spout每秒大概可以发送500个tuple</li><li>单bolt每秒大概可以接收2000个tuple</li><li>单acker每秒大概可以接收6000个tuple</li><li>根据上面的指标可以根据当前业务的数据量对并行度进行动态调整。</li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Storm--实时数据处理框架</title>
      <link href="/2016/06/08/Storm-%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/"/>
      <url>/2016/06/08/Storm-%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/</url>
      <content type="html"><![CDATA[<p>　　<strong>Storm</strong> 是Twitter开源的一个<strong>实时数据处理框架</strong>。<strong>Storm能实现高频数据和大规模数据的实时处理</strong>，很多人喜欢拿Hadoop来进行比较，其实他们差别挺大的，关键是应用场景不一样。</p><h2 id="Storm简介"><a href="#Storm简介" class="headerlink" title="Storm简介"></a>Storm简介</h2><ul><li><p><strong>Storm与Hadoop区别</strong>主要有以下几点：</p><blockquote><ol><li>场景： <strong>Hadoop</strong> 处理批量数据，不讲究时效性，<strong>Storm</strong> 是要处理某一新增数据时用的，要讲时效性；</li><li>数据： <strong>Hadoop</strong> 处理的是hdfs上TB级别的数据(历史数据)，<strong>Storm</strong> 是处理的是实时新增的某一笔数据(实时数据)；</li><li>速度： <strong>Hadoop</strong> 是以处理hdfs上TB级别数据为目的，速度慢，<strong>Storm</strong> 是只要处理新增的某一笔数据即可，速度快。<a id="more"></a></li></ol></blockquote></li><li><p><strong>Storm应用场景总结</strong>：</p><blockquote><ol><li><strong>数据流处理</strong>： 与其它流处理系统不同，storm不需要中间队列媒介</li><li><strong>实时计算</strong>： 可连续不断的进行实时数据处理，把处理的结果实时更新展示到客户端</li><li><strong>分布式远程过程调用</strong>： 可充分利用集群中CPU资源，进行CPU密集型计算。</li></ol></blockquote></li></ul><h3 id="Storm体系结构"><a href="#Storm体系结构" class="headerlink" title="Storm体系结构"></a>Storm体系结构</h3><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160608233416.jpg" alt="Storm 体系架构图"><br><code>Nimbus</code>：负责资源分配和任务调度。<br><code>Zookeeper</code>：负责Nimbus和多个Supervisor之间的所有协调工作。<br><code>Supervisor</code>：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。<br><code>Worker</code>：工作<strong>进程</strong>，一个工作进程中可以含有一个或者多个Executor线程。<br><code>Executor</code>:<strong>线程</strong>，里面运行着多个Task。<br><code>Task</code>：worker中每一个spout/bolt的线程称为一个task. 一个task中一定是运行的是相同组件。</p><h3 id="Storm组件"><a href="#Storm组件" class="headerlink" title="Storm组件"></a>Storm组件</h3><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609001650.jpg" alt="Storm 组件"><br><code>Topology</code> : 用于封装一个实时计算应用程序的逻辑，类似于Hadoop的MapReduce Job;<br><code>Stream</code> : 消息流，是一个没有边界的tuple序列，这些tuples会被以一种分布式的方式并行地创建和处理;<br><code>Spouts</code> : 数据源，是消息生产者，他会从一个外部源读取数据并向topology里面面发出消息：tuple;<br><code>Bolts</code> : 处理消息，所有消息处理逻辑被封装在bolts里面，处理输入的数据流并产生新的输出数据流,可执行过滤，聚合，查询数据库等操作;<br><code>Stream groupings</code> :  消息分发策略,定义一个Topology的其中一步是定义每个tuple接受什么样的流作为输入,stream grouping就是用来定义一个stream应该如何分配给Bolts们。</p><h2 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h2><ul><li>Storm是主从结构：<strong>主节点</strong>和<strong>工作节点</strong></li></ul><ol><li><code>master节点</code>：运行Nimbus进程，负责分发代码，安排任务，监控运行状态（主要是节点成功失败状态），一般还运行ui进程；</li><li><code>worker节点</code>：运行Supervisor进程，负责执行一个Topology的一个子集，一般还运行logviewer进程。</li></ol><ul><li>简单的介绍这基本安装</li></ul><ol><li>前提：<a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-集群搭建/">安装zookeeper集群</a>(注意：各集群节点时间保持一致)</li><li>下载上传解压<a href="https://storm.apache.org/downloads.html" target="_blank" rel="noopener">apache-storm-0.9.3.tar.gz</a></li><li>修改文件conf/storm.yaml（实例中：一主两从节点，主节点为xxo08）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160609004555.jpg" alt="配置 storm.yaml"></li><li>复制配置信息到其他节点（配置完全一样，scp即可）</li><li>启动：<br>5.1. 在主节点xxo08启动Nimbus进程、ui进程；<br>5.2. 在工作节点xxo09、xxo10启动Supervisor进程、logviewer进程；<br><strong>eg</strong>：<code>nohup /opt/storm-0.9.3/bin/storm nimbus &gt;/dev/null 2&gt;&amp;1 &amp;</code></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>算法--Paxos深入理解</title>
      <link href="/2016/06/07/%E7%AE%97%E6%B3%95-Paxos%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
      <url>/2016/06/07/%E7%AE%97%E6%B3%95-Paxos%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　分布式系统中的节点通信存在两种模型：<strong>共享内存（Shared memory）</strong>和<strong>消息传递（Messages passing）</strong>。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即拜占庭错误的情况。Paxos算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性（来源<a href="https://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">维基百科</a>）。</p><ul><li><strong>Paxos 是什么</strong>？</li></ul><ol><li>一个可靠的存储系统: 基于多数派读写;</li><li>强一致性；</li><li>每个paxos实例用来存储一个值;</li><li>用2轮RPC来确定一个值;</li><li>一个值‘确定’后不能被修改；</li><li>‘确定’指被多数派接受写入。</li></ol><a id="more"></a><h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><ul><li>总结一句话：<strong>信息准确无篡改，通信环境可信。</strong></li></ul><ol><li>网络消息的传送,可能需要任意长的时间,可能丢失,或者重复.但是消息并没有伪造,篡改的.即没有所谓”<strong>拜占庭问题</strong>“——非拜占庭模型。</li><li><strong>拜占庭模型（Byzantine model）</strong>： 消息可能丢失、重复或者内容损坏。换而言之，非拜占庭模型就是允许消息的丢失或者重复，但是不会出现内容损坏的情况。</li></ol><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><ul><li>解决多结点间一致性问题（集群中一个修改或者申请成为主结点的提议），所谓一致性算法就是要能够保证:在建议的不同的值之中,最终只能有一个被确定下来.</li><li>三个特性:</li></ul><ol><li>终止性： 每一个进程最终确定了一个值</li><li>同意性： 每一个进程确定的值是相同的</li><li>正确性： 每一个所确定的值,是某个进程所”建议”的.即任一进程所确定的值,不是非法的.</li></ol><h3 id="主要角色"><a href="#主要角色" class="headerlink" title="主要角色"></a>主要角色</h3><ul><li><strong>Proposer</strong> ： 提议者，提出议案（同时存在一个或者多个，他们各自发出提案）；</li><li><strong>Acceptor</strong> ： 接受者，收到议案后选择是否接受；</li><li><strong>Learner</strong> ： 学习者，只学习正确的决议；</li></ul><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li><strong>提案</strong> : 每个proposer向acceptor们提交提案时都会附带一个序号和决议内容{序号,决议内容}；序号是取舍提案的依据，value是提案的唯一标识，即即使序号不一样value相同，依然是同一个提案。</li><li><strong>prepare请求</strong>： 提案请求，proposer 向acceptor多数派发送提案请求。</li><li><strong>批准（chosen）</strong>： 一个多数派接受了一个提案，并且在该proposer发送accept请求确认之后，那么我们说该提案被批准。</li><li><strong>accept请求</strong>： 批准请求，proposer 征求acceptor批准自己的提案。</li><li><strong>接受（accept）</strong>： acceptor总会接收它收到的第一个提案；如果序号比之前接受的提案序号都高，那么它也会接收提案；</li><li><strong>多数派</strong>： 是所有acceptor的一个子集，元素个数多余一半就称之为多数派。他代表了某一群acceptor。根据抽屉原理，任意两个多数派之间必然有交集。</li></ul><h3 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h3><ul><li><strong>算法保持一致性的约束</strong>：</li></ul><ol><li>P1：一个acceptor必须接受（accept）第一次收到的提案。</li><li>P2：一旦一个具有value v的提案被批准（chosen），那么之后批准（chosen）的提案必须具有value v。</li></ol><ul><li><strong>算法保持一致性约束的加强</strong>，即加强上文提到的P2约束条件：</li></ul><ol><li>P2a：一旦一个具有value v的提案被批准（chosen），那么之后任何acceptor再次接受（accept）的提案必须具有value v。</li><li>P2b：一旦一个具有value v的提案被批准（chosen），那么以后任何proposer提出的提案必须具有value v。</li><li>P2c：如果一个编号为n的提案具有value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于n的任何提案，要么他们已经接受（accept）的所有编号小于n的提案中编号最大的那个提案具有value v。</li></ol><h3 id="过程描述"><a href="#过程描述" class="headerlink" title="过程描述"></a><strong>过程描述</strong></h3><ol><li><strong>Proposer(提议者)</strong> 首先选择一个提议序号 <strong>n</strong> 给 <strong>Acceptor(接受者)</strong> 节点发出 <strong>prepare</strong> 消息。</li><li><strong>Acceptor</strong> 收到prepare消息后，有下面两种情况：</li><li><strong>Acceptor</strong> 没有回应过编号大于<strong>n</strong>的<strong>prepare</strong>请求时，<strong>acceptor</strong> 接受（accept）编号为 <strong>n</strong> 的提案；</li><li><strong>Acceptor</strong> 已经回复过编号大于<strong>n</strong>的<strong>prepare</strong>请求时，则<strong>Acceptor</strong>将自己上次接受的提议回复给<strong>Proposer</strong>，并且承诺不再回复小于n的提议；</li><li><strong>Proposers</strong> 没有收到 <strong>Acceptor</strong> 中的多数派的回复，Proposers生成一个新的提议值再次发送给Acceptor批准；</li><li><strong>Proposers</strong> 收到 <strong>Acceptor</strong> 中的多数派对 <strong>prepare</strong> 的回复后，进入批准阶段。</li><li>如果超过一半的Acceptor接受，提议值生效。Proposers发送acknowledge消息通知所有的Acceptor提议生效</li></ol><h2 id="实例证明"><a href="#实例证明" class="headerlink" title="实例证明"></a>实例证明</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>下面我们有一个集群五个节点，即A、B、C、D、E五台机器，处于一种平等地位阶段，需要从中选择一个主节点，来管理这个集群，例如zookeeper的选举机制。</li><li>参选者为A、B两台机器(提议者)，C、D、E机器来为AB投票（接受者）。</li><li>这里为了简化理解，就不像zookeeper那样还投自己一票，这里我们只让C、D、E三台机器参与投票。</li></ul><h3 id="一种串行场景"><a href="#一种串行场景" class="headerlink" title="一种串行场景"></a>一种串行场景</h3><ol><li>首先A、B分别去获取了一个唯一的编号1、2；</li><li>然后带着各自的编号去询问(提议)C、D、E看他们是否可以投票给自己(<em>注：如果还没有投就可以投，已经投了就不能投了</em>)；</li><li>如果机器C、D、E都收到了编号1的询问，由于之前还没有任何机器询问，于是把（编号1）保存下来；并返回信息给A机器，告诉A机器我可以投你（此时还没投）；</li><li>机器A收到了至少两个回复，有点激动了，发出提议“投我”，内容为（编号1，投A）；</li><li>C、D、E机器收到消息后，发现编号和自己保存的编号一致，就把信息（编号1，投A）保存下来，返回内容（Accepted）表示已投A（已接受）；</li><li>此时A机器，就收到至少2台机器的投票（Accepted），总票数大于一半（得到大多数的支持）；</li><li>此时如果B机器发起内容（编号2）的提议，C、D、E机器收到后，由于（编号2）比（编号1）大，会把（编号2）保存下来；又由于之前已经投了A机器了，所以没办法投B了，就返回信息给B说可能已经晚了，已经投了A机器内容（编号1，投了A）</li><li>B机器，接收到至少2台机器返回信息（编号1，投了A），发现大多数都已经投了A机器，明白大势已去，即不再发起询问，接受A为Master的现实。</li></ol><h3 id="并发场景"><a href="#并发场景" class="headerlink" title="并发场景"></a>并发场景</h3><ol><li>首先A、B分别去获取了一个唯一的编号1、2；</li><li>A机器到达C、D，此时C、D还不知道投谁呢，现在拉票的A机器来了，就记录（编号1）表示要投A机器；</li><li>B机器到达D、E，此时D由于之前说好了投A但是还没投，来了一个编号更大的，由于之前规定在还没投的情况下如果遇到了更大编号的就选择投更大的，D机器于是决定改为投B，记录(编号2)、E记录之前都还没准备投，现在就肯定是投B了，记录(编号2)；</li><li>A机器这时候慢悠悠的到达E，殊不知E已由更大的编号2，所以A机器的编号1被拒绝了；</li><li>此时A机器，至少收到两个回复，感觉还是有希望，发出“投我”（编号1，投A）去询问C、D、E；</li><li>此时B机器，也至少收到两个回复，感觉有希望，发出“投我”（编号2，投B）去询问C、D、E；</li><li>机器C收到A的提议，发现编号一样，保存信息（编号1，投A），返回信息（Accepted）表示我投你了；</li><li>机器D收到A的提议，发现编号小于（编号2），因此返回信息（Rejected，编号2），告诉A机器我已经准备投2；</li><li>机器E可能没有收到A的提议；</li><li>机器B同时发送“投我”（编号2，投B）给C、D、E，D、E都到信息，发现和自己准备投的编号相同，于是返回信息（Accepted）表示我投你了；</li><li>此时B机器，至少收到了两台机器的（Accepted）内容，确认已被多数派所接受；</li><li>此时A机器，收到一个（Accepted）和（Rejected，编号2）；机器A重新发起提议，编号提升为3，即内容为（编号3）；</li><li>机器C收到A机器提议，发现（编号3）大于之前保存的（编号1），就把（编号3）保存下来；由于C机器之前已经接受A机器上次的提议，于是返回信息（编号1，投A）；</li><li>机器D收到A机器提议，发现（编号3）大于之前保存的（编号2），把（编号3）保存下来；由于D机器之前已经接受B机器上次的提议，于是返回信息（编号2，投B）；</li><li>机器E有可能没有收到提议，如收到就返回（编号2，投B）</li><li>此时机器A至少收到两台机器的回复，比较两个回复的编号大小，选择大编号对应的值为最新的提议；</li><li>机器A会再次发出消息给回复它的那至少两台机器，内容为（编号3，投B）；</li><li>机器C、D或E收到（编号3，投B），发现和自己保存的编号相同，因此保存（编号3，投B），同时返回消息内容为（Accepted）；</li><li>机器A收到了至少2台机器（accepted）内容，确认投B已经被多数派接受；</li></ol><ul><li>参考资料</li></ul><ol><li><a href="http://www.happy615.com/?p=344" target="_blank" rel="noopener">http://www.happy615.com/?p=344</a></li><li><a href="http://iunknown.iteye.com/blog/2246484?from=message&amp;isappinstalled=0" target="_blank" rel="noopener">http://iunknown.iteye.com/blog/2246484?from=message&amp;isappinstalled=0</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98</a></li><li><a href="https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95</a></li><li><a href="http://pan.baidu.com/s/1c16e5EC" target="_blank" rel="noopener">paxos-simple.pdf</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--读写数据</title>
      <link href="/2016/06/05/HBase-%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/"/>
      <url>/2016/06/05/HBase-%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<p>　　<strong>HBase</strong>（<em>Hadoop Database</em>），是一个<code>高可靠性</code>、<code>高性能</code>、<code>面向列</code>、<code>可伸缩</code>的<strong>分布式存储系统</strong>。HBase是<strong>基于hadoop分布式文件系统（HDFS）</strong>，模仿了Google文件系统<strong>BigTable</strong>数据库所有功能。</p><p>　　本博客主要介绍HBase的体系结构，如<code>HMaster</code>、<code>HRegionServer</code>、<code>HRegion</code>、<code>Store</code>、<code>MemStore</code>、<code>StoreFile</code>、<code>HLog</code>、<code>HFile</code>、<code>KeyValue</code>等、HBase数据的读写流程，以及读写流程中所用到<code>LSM树</code>、<code>墓碑标记</code>、<code>布隆过滤器</code>等。</p><a id="more"></a><h2 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h2><p> HBASE的基本架构组成如下：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605123204.png" alt="HBase的基本架构"></p><ul><li><strong>Zookeeper 协调管理</strong></li></ul><ol><li>保证每个时刻只有一个HMaster在运行，一旦Zookeeper感知不到HMaster就会重新选举出一个新的HMaster；</li><li>实时监控Region Server的状态，将Region server的上线和下线信息实时通知给Master；</li><li>存贮所有Region的寻址入口；</li><li>存储Hbase的schema,包括有哪些table，每个table有哪些column family。</li></ol><ul><li><strong>HMaster</strong></li></ul><ol><li>负责维护表和元数据（包括region）；</li><li>负责region切分、合并、负载均衡等；</li><li>处理schema更新请求；</li><li>如果HMaster挂掉,还可以进行正常的数据读写，提供服务。</li></ol><ul><li><strong>HRegionServe</strong></li></ul><ol><li>一个 HBase 实例包括多个HRegionServer ；</li><li>HRegionServer包含了一个HLog部分和HRegion部分（多个HRegion，即内部管理了一系列HRegion对象）。</li></ol><ul><li><strong>HRegion</strong></li></ul><ol><li>每个HRegion对应了Table中的一个Region；</li><li>HRegion中由多个HStore组成；</li><li>每个HStore对应了Table中的一个Column Family的存储；<br><strong>注</strong>：可以看出每个Column Family其实就是一个集中的存储单元，因此最好将具备共同IO特性的column放在一个Column Family中，这样最高效。</li></ol><ul><li><strong>HStore</strong></li></ul><ol><li>HBase 存储的核心，包含两部分 memStore(内存)和多个StoreFile（HDFS文件）；</li><li>MemStore：用户写入的数据首先会放入MemStore，当MemStore满了以后会Flush成一个StoreFile；</li><li>StoreFiles：底层实现是HFile，当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile。</li></ol><h2 id="读写数据"><a href="#读写数据" class="headerlink" title="读写数据"></a>读写数据</h2><ul><li>下面我们来看一下HBase具体的读写数据的流程：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605123205.png" alt="HBase的数据流程"></li></ul><h3 id="写数据"><a href="#写数据" class="headerlink" title="写数据"></a>写数据</h3><ul><li><strong>Hbase写数据流程</strong>：</li></ul><ol><li><strong>Client</strong> 发起了一个 <strong>HTable.put(Put)</strong> 请求给 <strong>HRegionServer</strong>；</li><li><strong>HRegionServer</strong> 会将请求定位到某个具体的<strong>HRegion</strong>上面；</li><li>决定是否写<strong>WAL log</strong> ，即图中的 <strong>Hlog</strong>；</li><li><strong>WAL结束后，Put数据保存到MemStore中</strong>，同时检查MemStore状态，如果满了，则触发<strong>Flush to Disk</strong>请求；</li><li>每次<strong>flush</strong>就会将数据写成<strong>HFile</strong>文件并存到<strong>HDFS</strong>上，并且存储最后写入的数据序列号，这样就可以知道哪些数据已经存入了永久存储的<strong>HDFS</strong>中;</li><li>当文件达到一定数量（默认<strong>3</strong>）就会触发<strong>Compact</strong>操作 -&gt; 多个<strong>HFile</strong>合并成一个的<strong>HFile</strong>文件，同时进行版本合并和数据删除；</li><li>并保证文件的总数在可控范围之内，<strong>major合并</strong>最后将文件集中的合并成一个文件，此后刷写又会不断创建小文件。</li><li>当<strong>HFile</strong>越来越大 -&gt; 单个<strong>HFile</strong>大小超过一定阈值（默认<strong>10G</strong>）后，触发<strong>Split</strong>操作，把当前<strong>Region Split</strong>成2个<strong>Region</strong>；</li><li><strong>Region</strong>会下线，新<strong>Split</strong>出的2个孩子<strong>Region</strong>会被<strong>HMaster</strong>分配到相应的<strong>HRegionServer</strong> 上，使得原先1个<strong>Region</strong>的压力得以分流到2个<strong>Region</strong>上</li><li>由此过程可知，<strong>HBase</strong>只是增加数据，有所得更新和删除操作，都是在<strong>Compact</strong>阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证<strong>I/O</strong>高性能。</li></ol><ul><li><p><strong>当HRegionServer意外终止</strong>： HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。</p></li><li><p><strong>WAL(Write Ahead Log)文件</strong>： 是一个标准的Hadoop SequenceFile，文件中存储了HLogKey，这些Keys包含了和实际数据对应的序列号，主要用于崩溃恢复。在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中，HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据），因为HLog是顺序写入的所以非常高效。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605123206.png?imageView2/1/w/400/h/250&amp;raw=true" alt="WAL(Write Ahead Log)"></p></li><li><p><strong>HFile文件</strong>： HFile文件是不定长的，长度固定的只有其中的两块：Trailer中有指针指向其他数据块的起始点，File Info中记录了文件的一些Meta信息，Data Index和Meta Index块记录了每个Data块和Meta块的起始点。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605142627.jpg" alt="HFile文件内部结构"></p></li><li><p><strong>LSM树（log-structured merge-tree）</strong>： </p></li></ul><ol><li>数据<strong>首先被存储在日志文件</strong>，这些文件内的数据完全有序。当有日志文件被修改时，对应的更新会被先<strong>保存在内存中来加速查询</strong>；</li><li>当多次修改，使内存空间被逐渐被占满后，<strong>LSM树会把有序的“键-记录”对写到磁盘中</strong>，同时创建一个新的数据存储文件。此时，因为最近的修改都被持久化了，内存中保存的最近更新就可以被丢弃了；</li><li>所有节点都是满的并按页存储。修改数据文件的操作通过滚动合并完成；</li><li>多次数据刷写之后会<strong>创建许多数据存储文件</strong>，后台线程就会自动将<strong>小文件聚合成大文件</strong>，这样磁盘查找就会被限制在少数几个数据存储文件中。磁盘上的树结构也可以拆分成独立的小单元，这样更新就可以被分散到多个数据存储文件中；</li><li><strong>查询</strong>： 先查找内存中的存储，然后再查找磁盘上的文件。这样在客户端看来数据存储文件的位置是透明的；</li><li><strong>删除</strong>： 是一种特殊的更改，当删除标记被存储之后，查找会跳过这些删除过的键。当页被重写时，有删除标记的键会被丢弃。此外，后台运维过程可以处理预先设定的删除请求。这些请求由TTL（time-to-live）触发，例如，当TTL设为20天后，合并进程会检查这些预设的时间戳，同时在重写数据块时丢弃过期的记录。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605142628.jpg" alt="lSM+树中的多页数据块迭代合并的过程"></li></ol><h3 id="读数据"><a href="#读数据" class="headerlink" title="读数据"></a>读数据</h3><ul><li><strong>Hbase读数据流程</strong>：</li></ul><ol><li>Client会通过内部缓存的相关的-ROOT-中的信息和.META.中的信息直接连接与请求数据匹配的HRegionserver（0.98.8版本是在系统表meta中）； </li><li>然后直接定位到该服务器上与客户请求对应的region，客户请求首先会查询该region在内存中的缓存——memstore(memstore是是一个按key排序的树形结构的缓冲区)；</li><li>如果在memstore中查到结果则直接将结果返回给client； </li><li>在memstore中没有查到匹配的数据，接下来会读已持久化的storefile文件（HFile）中的数据。storefile也是按key排序的树形结构的文件——并且是特别为范围查询或block查询优化过的；另外hbase读取磁盘文件是按其基本I/O单元(即 hbase block)读数据的；</li><li>如果在BlockCache中能查到要造的数据则这届返回结果，否则就读去相应的storefile文件中读取一block的数据，如果还没有读到要查的数据，就将该数据block放到HRegion Server的blockcache中，然后接着读下一block块儿的数据，一直到这样循环的block数据直到找到要请求的数据并返回结果；如果将该region中的数据都没有查到要找的数据，最后接直接返回null，表示没有找的匹配的数据。当然blockcache会在其大小大于一的阀值（heapsize <em> hfile.block.cache.size </em> 0.85）后启动基于LRU算法的淘汰机制，将最老最不常用的block删除。</li></ol><ul><li><p><strong>墓碑标记</strong>: 由于所有的存储文件都是不可变的，从这些文件中删除一个特定的值是做不到的，通过重写存储文件将已经被删除的单元格移除也是毫无意义的,墓碑标记就是用于此类情况的，它标记着”已删除”信息，这个标记可以是单独一个单元格、多个单元格或一整行。</p></li><li><p><strong>布隆过滤器</strong>： 提高随机读的性能，具体讲解可查看参考资料<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160605142630.jpg" alt="布隆过滤器"></p></li></ul><ul><li>参考资料</li></ul><ol><li><a href="http://blog.csdn.net/xtwolf008/article/details/16974725" target="_blank" rel="noopener">http://blog.csdn.net/xtwolf008/article/details/16974725</a></li><li><a href="http://www.epubit.com.cn/book/onlinechapter/26097" target="_blank" rel="noopener">《HBase-权威指南》</a></li><li><a href="http://www.ithao123.cn/content-8008915.html" target="_blank" rel="noopener">http://www.ithao123.cn/content-8008915.html</a></li><li><a href="http://www.bkjia.com/yjs/1015134.html" target="_blank" rel="noopener">http://www.bkjia.com/yjs/1015134.html（BloomFilter介绍）</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--伪分布和集群模式</title>
      <link href="/2016/06/04/HBase-%E4%BC%AA%E5%88%86%E5%B8%83%E5%92%8C%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"/>
      <url>/2016/06/04/HBase-%E4%BC%AA%E5%88%86%E5%B8%83%E5%92%8C%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>　　本博客主要介绍一下，<code>HBase伪分布模式安装</code>和 <code>HBase集群模式的安装</code>，以 <a href="http://pan.baidu.com/s/1eSlrLM6" target="_blank" rel="noopener">hbase-0.98.8-hadoop2-bin.tar.gz</a> 为例 。 操作比较简单，基本都是之前安装 <a href="http://blog.xiaoxiaomo.com/2016/05/09/Hadoop-2-0集群/">hadoop</a> 、<a href="http://blog.xiaoxiaomo.com/2016/04/28/Redis-集群/">redis</a>、<a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-集群搭建/">zookeeper</a>、<a href="http://blog.xiaoxiaomo.com/2016/05/13/Kafka-分布式消息队列/">kafka</a>、<a href="http://blog.xiaoxiaomo.com/2016/05/13/Kafka-分布式消息队列/">flume</a> 、<a href="http://blog.xiaoxiaomo.com/2016/05/27/Hive-概述与使用/">hive</a> 等一样的流程。<strong>下载后上传解压，修改一下配置文件环境变量</strong>，<strong>配置</strong>临时和数据目录，然后<strong>启动</strong>即可。集群就是先<strong>规划</strong>，然后<strong>配置</strong>好一台后 <strong>scp</strong> 等就OK了。</p><p>　　在搭建<strong>HBase</strong>的时候，<strong>需要保证Hdfs已经能正常运行</strong>。<strong>HBase</strong>还需要<code>zookeeper</code>来做协调管理，但HBase也有内置的zk，如果需要使用外部的zk,需要修改配置文件<code>hbase-site</code>如下我们就配置了外部的zk。<br><a id="more"></a></p><h2 id="伪分布"><a href="#伪分布" class="headerlink" title="伪分布"></a>伪分布</h2><ol><li><p><strong>上传并解压重命名</strong> <a href="http://pan.baidu.com/s/1eSlrLM6" target="_blank" rel="noopener">hbase-0.98.8-hadoop2-bin.tar.gz</a> 到<code>/usr/local</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo16 up]<span class="comment"># tar -zxvf hbase-0.98.8-hadoop2-bin.tar.gz -C /usr/local/ ##解压</span></span><br><span class="line">[root@xxo16 up]<span class="comment"># mv /usr/local/hbase-0.98.8-hadoop2/ /usr/local/hbase-0.98.8 ##重命名</span></span><br></pre></td></tr></table></figure></li><li><p><strong>添加环境变量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo16 up]<span class="comment"># vim /etc/profile</span></span><br><span class="line">......... eg : </span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/<span class="built_in">local</span>/hbase-0.98.8</span><br><span class="line">PATH=.:<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/sbin:<span class="variable">$&#123;HBASE_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">[root@xxo16 up]<span class="comment"># source /etc/profile</span></span><br></pre></td></tr></table></figure></li><li><p><strong>修改$HBASE_HOME/conf/hbase-env.sh</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.7.0_79</span><br><span class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/usr/<span class="built_in">local</span>/hbase-0.98.8/repo/logs</span><br><span class="line"><span class="built_in">export</span> HBASE_ROOT_LOGGER=INFO,DRFA</span><br></pre></td></tr></table></figure></li><li><p><strong>修改$HBASE_HOME/conf/hbase-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 临时目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hbase-0.98.8/repo/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://xxo16:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--zk --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>xxo16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hbase-0.98.8/repo/zk<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">##**注意**：</span><br><span class="line">##$HBASE_HOME/conf/hbase-site.xml的hbase.rootdir的主机和端口号与</span><br><span class="line">##$HADOOP_HOME/conf/core-site.xml的fs.default.name的主机和端口号一致</span><br></pre></td></tr></table></figure></li><li><p><strong>修改日志文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase.log.dir=/usr/<span class="built_in">local</span>/hbase-0.98.8/repo/logs</span><br></pre></td></tr></table></figure></li><li><p><strong>创建repo目录</strong><br><strong>原因</strong>：上面我们已经把日志文件，<code>zk</code> 数据目录，临时目录放到了 <code>repo</code> 的文件中，所以我们去 <code>HBase</code> 跟目录创建一个文件夹，方便统一管理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo16 conf]<span class="comment"># mkdir /usr/local/hbase-0.98.8/repo</span></span><br></pre></td></tr></table></figure></li><li><p><strong>启动查看进程</strong></p></li></ol><ul><li><p><strong>先启动Hadoop，后启动HBase</strong>，具体的启动日志如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo16 conf]<span class="comment"># start-hbase.sh </span></span><br><span class="line">xxo16: starting zookeeper, logging to /usr/<span class="built_in">local</span>/hbase-0.98.8/repo/logs/hbase-root-zookeeper-xxo16.out</span><br><span class="line">starting master, logging to /usr/<span class="built_in">local</span>/hbase-0.98.8/repo/logs/hbase-root-master-xxo16.out</span><br><span class="line">The authenticity of host <span class="string">'localhost (::1)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is 3c:55:d3:bb:e9:15:5a:48:07:c4:22:6a:01:a5:45:cc.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">localhost: Warning: Permanently added '</span>localhost<span class="string">' (RSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">localhost: starting regionserver, logging to /usr/local/hbase-0.98.8/repo/logs/hbase-root-regionserver-xxo16.out</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@xxo16 conf]# jps   ######查看进程</span></span><br><span class="line"><span class="string">3049 NameNode</span></span><br><span class="line"><span class="string">3659 HMaster</span></span><br><span class="line"><span class="string">3298 SecondaryNameNode</span></span><br><span class="line"><span class="string">3606 HQuorumPeer</span></span><br><span class="line"><span class="string">3879 Jps</span></span><br><span class="line"><span class="string">3136 DataNode</span></span><br><span class="line"><span class="string">3791 HRegionServer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">###########当然我们也可以单独的去启动进程############################</span></span><br><span class="line"><span class="string">[root@xxo16 conf]# hbase-daemon.sh start master</span></span><br><span class="line"><span class="string">[root@xxo16 conf]# hbase-daemon.sh start regionserver</span></span><br></pre></td></tr></table></figure></li><li><p>访问HBabse<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160604160243.jpg" alt="访问 HBase"></p></li></ul><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><ul><li><strong>规划</strong> ： 如我有三台机器，<code>xxo16</code>,<code>xxo17</code>,<code>xxo18</code></li><li><strong>第1-6步</strong> ： 对于 <code>HBase集群模式搭建</code>，很简单，相对于<code>HBase伪分布模式</code>就是多了几台机器而已。所以基本的配置和上面<strong>伪分布模式1-6步基本一样</strong>，这里省略。</li><li><p><strong>第七步</strong> ： 修改<code>regionservers</code>内容为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xxo16</span><br><span class="line">xxo17</span><br><span class="line">xxo18</span><br></pre></td></tr></table></figure></li><li><p><strong>第八步</strong> ： 修改配置文件<code>hbase-site.xml</code><strong> hbase.zookeeper.quorum</strong> value为 <strong>xxo16,xxo17,xxo18</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>xxo16,xxo17,xxo18<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>第九步</strong> ： 启动即可。</p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase--PleaseHoldException和TableNotDisabledException</title>
      <link href="/2016/06/02/HBase-PleaseHoldException%E5%92%8CTableNotDisabledException/"/>
      <url>/2016/06/02/HBase-PleaseHoldException%E5%92%8CTableNotDisabledException/</url>
      <content type="html"><![CDATA[<p>　　解决问题的能力，就是属于经验的一部分。慢慢积累，今天操作hbase的时候报了两个错误，PleaseHoldException和TableNotDisabledException，具体异常信息如下：</p><h2 id="PleaseHoldException"><a href="#PleaseHoldException" class="headerlink" title="PleaseHoldException"></a>PleaseHoldException</h2><ul><li>异常信息：<br><strong>ERROR</strong>: <strong>org.apache.hadoop.hbase.PleaseHoldException: Master is initializing</strong></li></ul><a id="more"></a><ul><li><p>具体日志如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; <span class="built_in">enable</span> <span class="string">'t_2'</span></span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hbase-0.98.8/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line"></span><br><span class="line">ERROR: org.apache.hadoop.hbase.PleaseHoldException: Master is initializing</span><br><span class="line">at org.apache.hadoop.hbase.master.HMaster.checkInitialized(HMaster.java:2426)</span><br><span class="line">at org.apache.hadoop.hbase.master.HMaster.enableTable(HMaster.java:1956)</span><br><span class="line">at org.apache.hadoop.hbase.master.HMaster.enableTable(HMaster.java:1972)</span><br><span class="line">at org.apache.hadoop.hbase.protobuf.generated.MasterProtos<span class="variable">$MasterService</span><span class="variable">$2</span>.callBlockingMethod(MasterProtos.java:41473)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.FifoRpcScheduler<span class="variable">$1</span>.run(FifoRpcScheduler.java:74)</span><br><span class="line">at java.util.concurrent.Executors<span class="variable">$RunnableAdapter</span>.call(Executors.java:471)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:262)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:615)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br><span class="line"></span><br><span class="line">Here is some <span class="built_in">help</span> <span class="keyword">for</span> this <span class="built_in">command</span>:</span><br><span class="line">Start <span class="built_in">enable</span> of named table:</span><br><span class="line">  hbase&gt; <span class="built_in">enable</span> <span class="string">'t1'</span></span><br><span class="line">  hbase&gt; <span class="built_in">enable</span> <span class="string">'ns1:t1'</span></span><br></pre></td></tr></table></figure></li><li><p>解决：</p></li></ul><ol><li>对于网上的说法很多，大部分人说是ip，主机名映射的问题，<code>ubuntu 需要将/etc/hosts 中的127.0.1.1 修改为  127.0.0.1</code>。这个问题主要就是<strong>hadoop异常</strong>，如果是刚启动的集群就需要检查一下配置文件，如果集群之前是正常的这时我们就需要查看一下各个节点是否异常。</li><li>我<strong>的错误出现在节点异常，修复后重启hadoop就行了</strong>，这个问题有些不确定因素展示只能提示到这里，以后要时候新发现会过来再次更新该博客。</li></ol><h2 id="TableNotDisabledException"><a href="#TableNotDisabledException" class="headerlink" title="TableNotDisabledException"></a>TableNotDisabledException</h2><ul><li><p>异常信息：<br><strong>ERROR</strong>: <strong>org.apache.hadoop.hbase.TableNotDisabledException:</strong></p></li><li><p>具体日志如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; <span class="built_in">enable</span> <span class="string">'t_2'</span></span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hbase-0.98.8/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line"></span><br><span class="line">ERROR: org.apache.hadoop.hbase.TableNotDisabledException: t_2</span><br><span class="line">at org.apache.hadoop.hbase.master.handler.EnableTableHandler.prepare(EnableTableHandler.java:111)</span><br><span class="line">at org.apache.hadoop.hbase.master.HMaster.enableTable(HMaster.java:1961)</span><br><span class="line">at org.apache.hadoop.hbase.master.HMaster.enableTable(HMaster.java:1972)</span><br><span class="line">at org.apache.hadoop.hbase.protobuf.generated.MasterProtos<span class="variable">$MasterService</span><span class="variable">$2</span>.callBlockingMethod(MasterProtos.java:41473)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)</span><br><span class="line">at org.apache.hadoop.hbase.ipc.FifoRpcScheduler<span class="variable">$1</span>.run(FifoRpcScheduler.java:74)</span><br><span class="line">at java.util.concurrent.Executors<span class="variable">$RunnableAdapter</span>.call(Executors.java:471)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:262)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:615)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br><span class="line"></span><br><span class="line">Here is some <span class="built_in">help</span> <span class="keyword">for</span> this <span class="built_in">command</span>:</span><br><span class="line">Start <span class="built_in">enable</span> of named table:</span><br><span class="line">  hbase&gt; <span class="built_in">enable</span> <span class="string">'t1'</span></span><br><span class="line">  hbase&gt; <span class="built_in">enable</span> <span class="string">'ns1:t1'</span></span><br></pre></td></tr></table></figure></li></ul><p>我在<code>enable</code>或者<code>disable</code>的时候报错，<strong>TableNotDisabledException</strong>。</p><ul><li>解决</li></ul><p><strong>我们需要将zookeeper里面的表信息删除</strong>，具体操作如下：</p><ol><li><p><strong>运行命令</strong><br>hbase zkcli</p></li><li><p><strong>删除表信息，如我这里表为‘t_2’</strong><br>delete /hbase/table/t_2</p></li><li><p><strong>操作信息如下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#######################1. 连接到zk客户端 ###########################################</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># hbase zkcli</span></span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hbase-0.98.8/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">Connecting to xxo05:2181,xxo04:2181,xxo06:2181</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line">JLine support is enabled</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################2. 查看 ###########################################</span></span><br><span class="line">[zk: xxo05:2181,xxo04:2181,xxo06:2181(CONNECTED) 3] ls /</span><br><span class="line">[hbase, zookeeper]</span><br><span class="line">[zk: xxo05:2181,xxo04:2181,xxo06:2181(CONNECTED) 4] ls /hbase</span><br><span class="line">[meta-region-server, backup-masters, region-in-transition, draining, table, running, table-lock, balancer, master, namespace, hbaseid, online-snapshot, replication, splitWAL, recovering-regions, rs]</span><br><span class="line">[zk: xxo05:2181,xxo04:2181,xxo06:2181(CONNECTED) 5] ls /hbase/table</span><br><span class="line">[hbase:meta, courses, hbase:namespace, t_2, t_3]</span><br><span class="line"></span><br><span class="line"><span class="comment">####################3. 执行删除操作 ###################################</span></span><br><span class="line">[zk: xxo05:2181,xxo04:2181,xxo06:2181(CONNECTED) 0] delete /hbase/table/t_2</span><br><span class="line">[zk: xxo05:2181,xxo04:2181,xxo06:2181(CONNECTED) 5] ls /hbase/table <span class="comment">##查看</span></span><br><span class="line">[hbase:meta, courses, hbase:namespace, t_3]</span><br><span class="line"></span><br><span class="line"><span class="comment">####################4. enable ok ###################################</span></span><br><span class="line">hbase(main):002:0&gt; <span class="built_in">enable</span> <span class="string">'t_2'</span></span><br><span class="line">0 row(s) <span class="keyword">in</span> 0.1630 seconds</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>如果任然不行执行修复命令</strong>：hbase hbck -fixMeta -fixAssignments</li></ul>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive--数据类型与表</title>
      <link href="/2016/05/28/Hive-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E8%A1%A8/"/>
      <url>/2016/05/28/Hive-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E8%A1%A8/</url>
      <content type="html"><![CDATA[<p>　　本片博客介绍了<strong>数据类型</strong>以及<strong>数据的映射</strong>，主要讲解<strong>表</strong>，表的<strong>创建</strong>，表的<strong>两种类型</strong>（受控表、外部表）。还有<strong>分区</strong>、<strong>桶表</strong>和<strong>视图</strong>。</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>Hive支持的数据类型如下:</p><ul><li><strong>基本类型</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tinyint smallint <span class="keyword">int</span> bigint</span><br><span class="line">boolean</span><br><span class="line"><span class="keyword">float</span> <span class="keyword">double</span></span><br><span class="line"><span class="built_in">string</span></span><br><span class="line">binary 字节数组(Hive <span class="number">0.8</span><span class="number">.0</span> 以上才可用)</span><br><span class="line">timestamp (Hive <span class="number">0.8</span><span class="number">.0</span> 以上才可用)</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li><strong>复合类型</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>: <span class="built_in">array</span>&lt;data_type&gt;</span><br><span class="line"><span class="built_in">map</span>: <span class="built_in">map</span>&lt;primitive_type, data_type&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span>:</span> <span class="class"><span class="keyword">struct</span>&lt;col_name : data_type [COMMENT col_comment], ...&gt;</span></span><br><span class="line"><span class="class"><span class="title">union</span>:</span> uniontype&lt;data_type, data_type, ...&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="数据的映射"><a href="#数据的映射" class="headerlink" title="数据的映射"></a>数据的映射</h2><p>在<a href="http://blog.xiaoxiaomo.com/2016/05/27/Hive-概述与使用/">上篇博客</a>中，我们提到：<strong>hive将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</strong>那么hive到底是怎么去映射的呢？</p><ul><li>其实就是：</li></ul><ol><li>当我们创建一张表时，就生成了metadata到数据库中，表信息保存在一张叫SDS表中，location字段指定了表数据的位置。</li><li>local默认路径为<code>/user/hive/warehouse/db</code>数据库/表名相同的文件下/目录下面（即使我们直接上传文件到该目录表也能加载）。</li><li>加载后解析数据，通过默认的分隔符进行解析，行的默认分隔符为“\n”。</li></ol><ul><li>示例：</li></ul><ol><li><p>创建一张表<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528171810.jpg" alt="创建一张表，并查看详细metadata信息"></p></li><li><p>vim写入数据，并上传到hdfs中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 data]<span class="comment"># momore t_1.txt </span></span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">[root@xxo07 data]<span class="comment"># hdfs dfs -put t_1.txt /user/hive/warehouse/t_1/</span></span><br></pre></td></tr></table></figure></li><li><p>查看hdfs<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528173824.jpg" alt="查看hdfs"></p></li><li><p>查看我们的表</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from t_1;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line">Time taken: <span class="number">0.917</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br></pre></td></tr></table></figure></li></ol><h2 id="表"><a href="#表" class="headerlink" title="表"></a>表</h2><h3 id="表的创建"><a href="#表的创建" class="headerlink" title="表的创建"></a>表的创建</h3><ul><li>分隔符</li></ul><ol><li>通过上面的例子我们知道，数据的映射，并且默认的<code>行</code>分隔符为“\n”；</li><li><code>列</code>默认分割符为“\001”,<code>collection items</code>默认为“\002”,<code>map keys</code>默认为“\003”,</li><li>创建表时我们可以自定义分隔符。</li><li>hive是<strong>读模式</strong>，<strong>数据库加载数据的时候不进行数据的合法性校验，在查询数据的时候将不合法的数据显示为NULL</strong>。这样加载速度快，适合大数据的加载。</li></ol><ul><li><p>示例：下面我们来创建一个学生表的表，有字段 <code>id</code>,<code>name</code>,<code>tel</code>,<code>scores</code>,<code>addrs</code> 如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create database xxo;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.246 seconds</span><br><span class="line">hive&gt; use xxo;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.029 seconds</span><br><span class="line">hive&gt; create table t_student(                                                           </span><br><span class="line">    &gt; id int,</span><br><span class="line">    &gt; name string,</span><br><span class="line">    &gt; tel array&lt;string&gt;,        </span><br><span class="line">    &gt; scores map&lt;string,int&gt;,</span><br><span class="line">    &gt; addrs struct&lt;home:string,post:int&gt;</span><br><span class="line">    &gt; ) row format delimited</span><br><span class="line">    &gt; fields terminated by <span class="string">'\t'</span></span><br><span class="line">    &gt; collection items terminated by <span class="string">','</span></span><br><span class="line">    &gt; map keys terminated by <span class="string">':'</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.404 seconds</span><br></pre></td></tr></table></figure></li><li><p><strong>注</strong>：上面已经指定了，列分隔符为“\t”，数组的items分隔符为“，”，map 的分隔符为“：”。</p></li><li><p>创建数据</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 data]<span class="meta"># more t_2.txt </span></span><br><span class="line"><span class="number">1</span>张三<span class="number">15826008600</span>,<span class="number">02358888</span>math:<span class="number">99</span>,en:<span class="number">100</span>重庆,<span class="number">500000</span></span><br><span class="line"><span class="number">2</span>李四<span class="number">15826008601</span>,<span class="number">02358818</span>math:<span class="number">97</span>,en:<span class="number">10</span>重庆,<span class="number">500000</span></span><br><span class="line"><span class="number">3</span>王五<span class="number">15826008602</span>,<span class="number">02358828</span>math:<span class="number">89</span>,en:<span class="number">100</span>云阳,<span class="number">500600</span></span><br><span class="line"><span class="number">4</span>赵六<span class="number">15826008603</span>,<span class="number">02358838</span>math:<span class="number">100</span>,en:<span class="number">30</span>万州,<span class="number">500500</span></span><br><span class="line"><span class="number">5</span>田七<span class="number">15826008604</span>,<span class="number">02358848</span>math:<span class="number">90</span>,en:<span class="number">80</span>北京,<span class="number">100000</span></span><br></pre></td></tr></table></figure></li><li><p>查询数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###########没有通过hdfs直接上传而是通过hive加载数据#################################</span></span><br><span class="line">hive&gt; load data <span class="built_in">local</span> inpath <span class="string">'t_2.txt'</span> overwrite into table t_student;</span><br><span class="line">Loading data to table xxo.t_student</span><br><span class="line">Table xxo.t_student stats: [numFiles=1, numRows=0, totalSize=293, rawDataSize=0]</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.363 seconds</span><br><span class="line">hive&gt; select * from t_student;                                        </span><br><span class="line">OK</span><br><span class="line">1张三[<span class="string">"15826008600"</span>,<span class="string">"02358888"</span>]&#123;<span class="string">"math"</span>:99,<span class="string">"en"</span>:100&#125;&#123;<span class="string">"home"</span>:<span class="string">"重庆"</span>,<span class="string">"post"</span>:500000&#125;</span><br><span class="line">2李四[<span class="string">"15826008601"</span>,<span class="string">"02358818"</span>]&#123;<span class="string">"math"</span>:97,<span class="string">"en"</span>:10&#125;&#123;<span class="string">"home"</span>:<span class="string">"重庆"</span>,<span class="string">"post"</span>:500000&#125;</span><br><span class="line">3王五[<span class="string">"15826008602"</span>,<span class="string">"02358828"</span>]&#123;<span class="string">"math"</span>:89,<span class="string">"en"</span>:100&#125;&#123;<span class="string">"home"</span>:<span class="string">"云阳"</span>,<span class="string">"post"</span>:500600&#125;</span><br><span class="line">4赵六[<span class="string">"15826008603"</span>,<span class="string">"02358838"</span>]&#123;<span class="string">"math"</span>:100,<span class="string">"en"</span>:30&#125;&#123;<span class="string">"home"</span>:<span class="string">"万州"</span>,<span class="string">"post"</span>:500500&#125;</span><br><span class="line">5田七[<span class="string">"15826008604"</span>,<span class="string">"02358848"</span>]&#123;<span class="string">"math"</span>:90,<span class="string">"en"</span>:80&#125;&#123;<span class="string">"home"</span>:<span class="string">"北京"</span>,<span class="string">"post"</span>:100000&#125;</span><br><span class="line">Time taken: 0.178 seconds, Fetched: 5 row(s)</span><br></pre></td></tr></table></figure></li></ul><h3 id="受控表"><a href="#受控表" class="headerlink" title="受控表"></a>受控表</h3><ul><li>默认我们创建的表为<code>NAMAGED_TABLE</code>类型，叫做<strong>受控表（内部表）</strong>。</li><li>受控表中的数据生命周期受到了表定义的影响，即表删除数据也会同时删除。</li></ul><h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h3><ul><li>表类型为<code>EXTERNAL_TABLE</code>数据不受表定义的影响，即删除外部表数据并不会被删除，只会删除，metadata中的数据;</li><li><p>数据加载，就是对外部hdfs上数据的引用。</p></li><li><p><strong>示例：</strong></p></li></ul><ol><li><p>创建外部表t_2<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528183426.jpg" alt="创建 外部表"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528184710.jpg" alt="查看mysql记录的metadata信息"></p></li><li><p>加载外部hdfs上的数据<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528183545.jpg" alt="创建 外部表"></p></li><li><p>再次查看外部表，发现外部表的location已经改变为我们指定的数据目录<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528183754.jpg" alt="外部表 location已经改变"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528184758.jpg" alt="查看metadata mysql表中location信息"></p></li><li><p>删除t_2表，数据任然在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop table t_2;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.135 seconds</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528185253.jpg" alt="删除t_2表后，数据任然在"></p><ul><li>表类型转换<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528185751.jpg" alt="把t_3表转为外部表，如果value是false则转为内部表"></li></ul><h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p><strong>分区表</strong>：包含动态分区与静态分区。<strong>注意</strong>：分区列不是表中的一个实际的字段，而是一个或者多个伪列。<strong>分区表就是将表中的数据按需指定分区字段进行划分，使用分区很方便对数据进行部分查询</strong>。</p><h4 id="静态分"><a href="#静态分" class="headerlink" title="静态分"></a>静态分</h4><ul><li><p>创建分区表<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528193234.jpg" alt="创建分区表"></p></li><li><p>加载数据<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528193338.jpg" alt="创建需要加载的测试数据"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528195615.jpg" alt="分区表，加载数据"></p></li><li><p>查看hdfs上的数据<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528195741.jpg" alt="查看hdfs上的数据"></p></li></ul><ul><li>查看表的partions<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show partitions t_5;</span><br><span class="line">OK</span><br><span class="line">dt=2016-05-28/city=cq</span><br><span class="line">dt=2016-05-29/city=bj</span><br><span class="line">Time taken: 0.109 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure></li></ul><h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><ul><li><strong>示例：</strong></li></ul><ol><li><p>创建临时表，并加载数据到临时表<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528203622.jpg" alt="加载数据"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528203811.jpg" alt="加载数据"></p></li><li><p>动态分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; insert overwrite table t_5 partition(dt,city) select t.id,t.dt,t.city from tmp t;</span><br><span class="line">Query ID = root_20160528201717_4d5a2424-ad99-43bb-a480-c0c6c1df3517</span><br><span class="line">Total <span class="built_in">jobs</span> = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is <span class="built_in">set</span> to 0 since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1464437918991_0001, Tracking URL = http://xxo07:8088/proxy/application_1464437918991_0001/</span></span><br><span class="line"><span class="string">Kill Command = /usr/local/hadoop-2.6.0/bin/hadoop job  -kill job_1464437918991_0001</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2016-05-28 20:19:16,822 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2016-05-28 20:19:38,275 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 2 seconds 260 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1464437918991_0001</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://xxo07:9000/tmp/hive/root/7157795c-3864-480e-b89b-abaaacc4740e/hive_2016-05-28_20-17-54_291_6680117664647621540-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table xxo.t_5 partition (dt=null, city=null)</span></span><br><span class="line"><span class="string"> Time taken for load dynamic partitions : 1023</span></span><br><span class="line"><span class="string">Loading partition &#123;dt=2015-05-30, city=wz&#125;</span></span><br><span class="line"><span class="string">Loading partition &#123;dt=2015-05-30, city=hz&#125;</span></span><br><span class="line"><span class="string">Loading partition &#123;dt=2015-05-30, city=bj&#125;</span></span><br><span class="line"><span class="string">Loading partition &#123;dt=2015-05-30, city=yy&#125;</span></span><br><span class="line"><span class="string">Loading partition &#123;dt=2015-05-30, city=cq&#125;</span></span><br><span class="line"><span class="string"> Time taken for adding to write entity : 12</span></span><br><span class="line"><span class="string">Partition xxo.t_5&#123;dt=2015-05-30, city=bj&#125; stats: [numFiles=1, numRows=1, totalSize=2, rawDataSize=1]</span></span><br><span class="line"><span class="string">Partition xxo.t_5&#123;dt=2015-05-30, city=cq&#125; stats: [numFiles=1, numRows=1, totalSize=2, rawDataSize=1]</span></span><br><span class="line"><span class="string">Partition xxo.t_5&#123;dt=2015-05-30, city=hz&#125; stats: [numFiles=1, numRows=1, totalSize=2, rawDataSize=1]</span></span><br><span class="line"><span class="string">Partition xxo.t_5&#123;dt=2015-05-30, city=wz&#125; stats: [numFiles=1, numRows=1, totalSize=2, rawDataSize=1]</span></span><br><span class="line"><span class="string">Partition xxo.t_5&#123;dt=2015-05-30, city=yy&#125; stats: [numFiles=1, numRows=1, totalSize=2, rawDataSize=1]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 2.26 sec   HDFS Read: 290 HDFS Write: 287 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 2 seconds 260 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 109.86 seconds</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#####################查询数据########################################</span></span><br><span class="line"><span class="string">hive&gt; select * from t_5 where dt='</span>2015-05-30<span class="string">';</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">72015-05-30bj</span></span><br><span class="line"><span class="string">52015-05-30cq</span></span><br><span class="line"><span class="string">92015-05-30hz</span></span><br><span class="line"><span class="string">12015-05-30wz</span></span><br><span class="line"><span class="string">22015-05-30yy</span></span><br><span class="line"><span class="string">Time taken: 0.094 seconds, Fetched: 5 row(s)</span></span><br><span class="line"><span class="string">hive&gt; select * from t_5 where city='</span>yy<span class="string">';      </span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">22015-05-30yy</span></span><br><span class="line"><span class="string">Time taken: 0.075 seconds, Fetched: 1 row(s)</span></span><br></pre></td></tr></table></figure></li><li><p>直观浏览一下<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528204306.jpg" alt="浏览分区"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528204234.jpg" alt="浏览分区中的数据"></p></li></ol><h3 id="桶表"><a href="#桶表" class="headerlink" title="桶表"></a>桶表</h3><p><strong>桶表 ： </strong> 就是相对均匀的存放数据，每张表查询起来效率都差不多。</p><ol><li>桶表是对数据进行哈希取值，然后放到不同文件中存储；</li><li>数据都来源于现有的表中；</li></ol><ul><li><strong>用途 ： </strong> 在做多表关联时，为了提高查询效率；或做抽样。</li><li><strong>示例：</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">bashhive&gt; create table t_bucket(id int) clustered by (id) into 3 buckets;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.377 seconds</span><br><span class="line">hive&gt; set hive.enforce.bucketing = true; ##设置支持桶表</span><br><span class="line"></span><br><span class="line">############################导入数据############################################</span><br><span class="line">hive&gt; insert into table t_bucket select id from t_4;</span><br><span class="line">Automatically selecting local only mode for query</span><br><span class="line">Query ID = root_20160528205252_4ba59e97-c11b-45ad-bdd0-11fb8d2bebd8</span><br><span class="line">Total jobs = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is set to 0 since there&apos;s no reduce operator</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0</span><br><span class="line">2016-05-28 20:52:36,063 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2016-05-28 20:52:37,130 Stage-1 map = 100%,  reduce = 0%</span><br><span class="line">Ended Job = job_local98714577_0001</span><br><span class="line">Stage-4 is selected by condition resolver.</span><br><span class="line">Stage-3 is filtered out by condition resolver.</span><br><span class="line">Stage-5 is filtered out by condition resolver.</span><br><span class="line">Moving data to: hdfs://xxo07:9000/tmp/hive/root/9b9b6fa1-9f00-4635-be4d-ac4ac635d546/hive_2016-05-28_20-52-30_591_4317152904230482106-1/-ext-10000</span><br><span class="line">Loading data to table xxo.t_bucket</span><br><span class="line">Table xxo.t_bucket stats: [numFiles=4, numRows=10, totalSize=24, rawDataSize=14]</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1:  HDFS Read: 24 HDFS Write: 92 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 0 msec</span><br><span class="line">OK</span><br><span class="line">Time taken: 7.225 seconds</span><br><span class="line"></span><br><span class="line">##########################查询###########################################</span><br><span class="line">hive&gt; select * from t_bucket;</span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">5</span><br><span class="line">9</span><br><span class="line">12</span><br><span class="line">18</span><br><span class="line">1</span><br><span class="line">5</span><br><span class="line">9</span><br><span class="line">12</span><br><span class="line">18</span><br><span class="line">Time taken: 0.171 seconds, Fetched: 10 row(s)</span><br></pre></td></tr></table></figure></li></ul><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><ul><li>Hive 中，也有视图的概念，那我们都知道视图实际上是一张虚拟的表，是对数据的逻辑表示，只是一种显示的方式，主要的作用呢：</li></ul><ol><li>视图能够简化用户的操作</li><li>视图使用户能以多钟角度看待同一数据</li><li>视图对重构数据库提供了一定程度的逻辑独立性</li><li>视图能够对机密数据提供安全保护</li><li>适当的利用视图可以更清晰的表达查询</li></ol><ul><li><strong>示例：</strong></li></ul><ol><li><p>创建视图</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">################创建视图###############################</span></span><br><span class="line">hive&gt; create view t5_view as select * from t_5;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.184 seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">################查看数据##############################</span></span><br><span class="line">hive&gt; select * from t5_view;                   </span><br><span class="line">OK</span><br><span class="line">72015-05-30bj</span><br><span class="line">52015-05-30cq</span><br><span class="line">92015-05-30hz</span><br><span class="line">12015-05-30wz</span><br><span class="line">22015-05-30yy</span><br><span class="line">12016-05-28cq</span><br><span class="line">22016-05-28cq</span><br><span class="line">32016-05-28cq</span><br><span class="line">42016-05-28cq</span><br><span class="line">52016-05-28cq</span><br><span class="line">Time taken: 0.228 seconds, Fetched: 10 row(s)</span><br></pre></td></tr></table></figure></li><li><p>查看hdfs<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528211356.jpg" alt="发现并没视图的数据"></p></li><li><p>查看元数据<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528211632.jpg" alt="元数据存有该视图信息"></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive--概述与使用</title>
      <link href="/2016/05/27/Hive-%E6%A6%82%E8%BF%B0%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
      <url>/2016/05/27/Hive-%E6%A6%82%E8%BF%B0%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>　　本博客主要讲解<strong>Hive的特点</strong>、<strong>Hive的数据存储</strong>、<strong>数据单元</strong>、<strong>Hive的系统架构</strong>、<strong>Hive的metastore</strong>。以及<strong>安装hive</strong>和简单使用，最后<strong>修改hive默认的metadata derby为mysq</strong>l。</p><h2 id="认识Hive"><a href="#认识Hive" class="headerlink" title="认识Hive"></a>认识Hive</h2><p>　　<code>Hive</code><strong>是基于<code>Hadoop</code>的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类<code>SQL</code>查询功能。</strong>本质就是将<code>SQL</code>转换为<code>MapReduce</code>程序。与关系型数据库的SQL 略有不同，但支持了绝大多数的语句如DDL、DML 以及常见的聚合函数、连接查询、条件查询。HIVE不<strong>适合用于联机事务处理</strong>，也<strong>不提供实时查询功能</strong>。<strong>它最适合应用在基于大量不可变数据的批处理作业。</strong></p><a id="more"></a><ul><li><strong>Hive特点</strong></li></ul><ol><li>支持索引，加快数据查询。</li><li>不同的存储类型，如数据库、文件、表、视图、索引</li><li>将元数据保存在关系数据库中，大大减少了在查询过程中执行语义检查的时间。</li><li>可以直接使用存储在Hadoop 文件系统中的数据。</li><li>内置大量用户函数UDF 来操作时间、字符串和其他的数据挖掘工具，支持用户扩展UDF 函数来完成内置函数无法实现的操作。</li><li>类SQL 的查询方式，将SQL 查询转换为MapReduce 的job 在Hadoop集群上执行。</li></ol><ul><li><strong>Hive的数据存储</strong></li></ul><ol><li>存储基于Hadoop HDFS，没有专门的数据存储格式。</li><li>存储结构：数据库、文件、表、视图、索引。</li><li>Hive默认可以直接加载文本文件（<strong>TextFile</strong>），<strong>SequenceFile</strong>、<strong>RCFile</strong> (facebook)。</li><li>在我们创建表时，指定数据的列、行分隔符，Hive就可以解析数据。（当然它有自己默认的行列分隔符’\n’,’\001’）</li></ol><ul><li><p><strong>Hive的数据单元</strong><br><strong>databases</strong> ： 数据库，和关系型数据库中一个概念；<br><strong>tables</strong> ： 表。和关系型数据库中的表一个概念；<br><strong>partitions</strong> ： 分区。将同一组数据存放到一个固定的分区中。<br><strong>buckets(clusters)</strong> : 分桶。对现有数据再进行划分。</p></li><li><p><strong>Hive的系统架构</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528123155.jpg" alt="Hive的系统架构"><br>•用户接口，包括 CLI，JDBC/ODBC，WebUI<br>•元数据存储，通常是存储在关系数据库如 mysql, derby 中<br>•解释器、编译器、优化器、执行器<br>•Hadoop：用 HDFS 进行存储，利用 MapReduce 进行计算</p></li><li><p><strong>Hive的metastore</strong><br><code>metastore</code> : 是hive元数据的集中存放地。<br><code>metastore</code> : 默认使用内嵌的derby数据库作为存储引擎<br><code>Derby</code> ： 引擎的缺点：一次只能打开一个会话（一般使用mysql）<br>Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等</p></li><li><p><strong>HiveQL和SQL的对比</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160528140050.jpg" alt="HiveQL和SQL的对比"></p></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li><strong>准备</strong>：</li></ul><ol><li>提前已安装好hadoop</li><li><strong>Hive</strong> <a href="http://hive.apache.org/downloads.html" target="_blank" rel="noopener">下载</a>，作者使用<a href="http://pan.baidu.com/s/1hsCXGEC" target="_blank" rel="noopener">apache-hive-0.14.0-bin.tar.gz</a></li></ol><ul><li><strong>安装</strong></li></ul><ol><li><p>解压hive文件，进入$HIVE_HOME/conf/修改文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp  hive-env.sh.template  hive-env.sh</span><br><span class="line">cp  hive-default.xml.template  hive-site.xml</span><br></pre></td></tr></table></figure></li><li><p><strong>修改$HIVE_HOME/bin的hive-env.sh</strong>，增加以下三行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################ 添加环境变量 ，例如#############################</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.7.0_79</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/hive</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop-2.6.0</span><br></pre></td></tr></table></figure></li><li><p><strong>修改$HIVE_HOME/conf/hive-site.xml</strong>，临时目录</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><ul><li>运行hdfs</li><li>运行：$HIVE_HOME/bin/hive<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 bin]<span class="comment"># hive</span></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/hive/lib/hive-common-0.14.0.jar!/hive-log4j.properties</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/usr/<span class="built_in">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/opt/hive/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 0.667 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################创建表############################</span></span><br><span class="line">hive&gt; create table t_1(id int);</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.736 seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################查看表信息########################</span></span><br><span class="line">hive&gt; desc extended t_1;</span><br><span class="line">OK</span><br><span class="line">id                  int                                     </span><br><span class="line">  </span><br><span class="line">Detailed Table InformationTable(tableName:t_1, dbName:default, owner:root, createTime:1464418129, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, <span class="built_in">type</span>:int, comment:null)], location:hdfs://xxo07:9000/user/hive/warehouse/t_1, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:<span class="literal">false</span>, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:&#123;serialization.format=1&#125;), bucketCols:[], sortCols:[], parameters:&#123;&#125;, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:&#123;&#125;), storedAsSubDirectories:<span class="literal">false</span>), partitionKeys:[], parameters:&#123;transient_lastDdlTime=1464418129&#125;, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)</span><br><span class="line">Time taken: 0.787 seconds, Fetched: 3 row(s)</span><br><span class="line">hive&gt; quit;</span><br></pre></td></tr></table></figure></li></ul><h2 id="修改metadata为mysql"><a href="#修改metadata为mysql" class="headerlink" title="修改metadata为mysql"></a>修改metadata为mysql</h2><ol><li><p>以本地mysql为例 , 修改$HIVE_HOME/conf/hive-site.xml ,修改链接url、驱动、账号、密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">&lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=<span class="literal">true</span>&amp;amp;useUnicode=<span class="literal">true</span>&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>复制mysql驱动jar包到$HIVE_HOME/lib/目录下<br>可以在这下载：<a href="https://blog.csdn.net/qiangqiang816/article/details/81541090" target="_blank" rel="noopener">https://blog.csdn.net/qiangqiang816/article/details/81541090</a></p></li><li><p>初始化数据库命令：schematool -dbType mysql -initSchema</p></li><li><p>启动。查看mysql数据库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use hive;</span><br><span class="line">Reading table information <span class="keyword">for</span> completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------------------+</span><br><span class="line">| Tables_in_hive            |</span><br><span class="line">+---------------------------+</span><br><span class="line">| BUCKETING_COLS            |</span><br><span class="line">| CDS                       |</span><br><span class="line">| COLUMNS_V2                |</span><br><span class="line">| DATABASE_PARAMS           |</span><br><span class="line">| DBS                       |</span><br><span class="line">| FUNCS                     |</span><br><span class="line">| FUNC_RU                   |</span><br><span class="line">| GLOBAL_PRIVS              |</span><br><span class="line">| PARTITIONS                |</span><br><span class="line">| PARTITION_KEYS            |</span><br><span class="line">| PARTITION_KEY_VALS        |</span><br><span class="line">| PARTITION_PARAMS          |</span><br><span class="line">| PART_COL_STATS            |</span><br><span class="line">| ROLES                     |</span><br><span class="line">| SDS                       |</span><br><span class="line">| SD_PARAMS                 |</span><br><span class="line">| SEQUENCE_TABLE            |</span><br><span class="line">| SERDES                    |</span><br><span class="line">| SERDE_PARAMS              |</span><br><span class="line">| SKEWED_COL_NAMES          |</span><br><span class="line">| SKEWED_COL_VALUE_LOC_MAP  |</span><br><span class="line">| SKEWED_STRING_LIST        |</span><br><span class="line">| SKEWED_STRING_LIST_VALUES |</span><br><span class="line">| SKEWED_VALUES             |</span><br><span class="line">| SORT_COLS                 |</span><br><span class="line">| TABLE_PARAMS              |</span><br><span class="line">| TAB_COL_STATS             |</span><br><span class="line">| TBLS                      |</span><br><span class="line">| VERSION                   |</span><br><span class="line">+---------------------------+</span><br><span class="line">29 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure></li></ol><ul><li>参考资料：<br>《Hive编程指南》</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flume--负载均衡和故障转移</title>
      <link href="/2016/05/23/Flume-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/"/>
      <url>/2016/05/23/Flume-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/</url>
      <content type="html"><![CDATA[<p>　　<strong>Flume Sink Processors</strong>，source里的event流经channel，进入sink。在sink中可以分组，<strong>sink groups</strong>允许给一个实体设置多个sinks，sink processors可以使在sink group中所有sink具有<strong>负载均衡的能力</strong>，或者在一个sink失效后切换到另一个sink的<strong>fail over模式</strong>。</p><ul><li>下面来看一下<em>Sink Processors</em>的<strong>结构图</strong>：<br><img src="https://img.xiaoxiaomo.com/blog/img/20160523204943.jpg" alt="Sink Processors 结构图"></li></ul><a id="more"></a><ul><li>具体配置可以看<strong>文档</strong>：<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522232336.jpg" alt="Flume Sink Processors"></li></ul><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li><strong>机器配置</strong> -博主有三台机器，分别是<code>xxo08</code>、<code>xxo09</code>、<code>xxo10</code><br><code>xxo08</code> ： 一个agent，exec source用于读取<em>/opt/data/access.log</em>数据，并使用了4个avro sink;<br><code>xxo09</code> ： 两个agent，端口分别为44444，44445 ，都为avro source用于接收xxo08 avro sink过来的数据;<br><code>xxo10</code> ： 两个agent，端口分别为44444，44445 ，都为avro source用于接收xxo08 avro sink过来的数据;</li></ul><h2 id="default"><a href="#default" class="headerlink" title="default"></a>default</h2><ul><li><p><strong>默认的sink processor只接受一个sink，不用创建sink group</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Default Sink Processor（默认）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2 k3 k4</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># exec source</span></span><br><span class="line">a1.sources.r1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.r1.command = tail -F /opt/data/access.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 avro sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname=xxo09</span><br><span class="line">a1.sinks.k1.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname=xxo10</span><br><span class="line">a1.sinks.k2.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k3.type = avro</span><br><span class="line">a1.sinks.k3.hostname=xxo09</span><br><span class="line">a1.sinks.k3.port=44445</span><br><span class="line"></span><br><span class="line">a1.sinks.k4.type = avro</span><br><span class="line">a1.sinks.k4.hostname=xxo10</span><br><span class="line">a1.sinks.k4.port=44445</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"><span class="comment">####存储在channel中的最大容量#################</span></span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"><span class="comment">####从一个source中去或者给一个sink，每个事务中最大的事件数#########</span></span><br><span class="line">a1.channels.c1.transactionCapacity = 100 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br><span class="line">a1.sinks.k3.channel = c1</span><br><span class="line">a1.sinks.k4.channel = c1</span><br></pre></td></tr></table></figure></li><li><p>下面我向access.log文件<strong>快速写入450条数据</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># echo "3" &gt;&gt; /opt/data/access.log</span></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="comment">####发现数据全部都到了xxo09的44445端口</span></span><br><span class="line">2016-05-23 23:26:36,286 (New I/O  worker <span class="comment">#1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0x39baaf57, /192.168.33.73:60764 =&gt; /192.168.33.74:44445] CONNECTED: /192.168.33.73:60764</span></span><br><span class="line">2016-05-23 23:26:42,330 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: &#123; headers:&#123;&#125; body: 33      3 &#125;</span><br><span class="line">2016-05-23 23:26:42,330 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: &#123; headers:&#123;&#125; body: 33      3 &#125;</span><br><span class="line">2016-05-23 23:26:42,330 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: &#123; headers:&#123;&#125; body: 33      3 &#125;</span><br><span class="line">2016-05-23 23:26:42,331 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: &#123; headers:&#123;&#125; body: 33      3 &#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li><li><p><strong>注意</strong>：很慢的写数据时不定的</p></li></ul><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><ul><li><strong>负载均衡</strong>：<code>即sink组内部根据负载算法（round_robin轮询、random随机）选择sink，后续可以选择不同机器上的agent实现负载均衡</code>。</li></ul><h3 id="random"><a href="#random" class="headerlink" title="random"></a>random</h3><ul><li><p><strong>配置如下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Default Sink Processor（负载均衡-随机）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2 k3 k4</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># exec source</span></span><br><span class="line">a1.sources.r1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.r1.command = tail -F /opt/data/access.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 avro sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname=xxo09</span><br><span class="line">a1.sinks.k1.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname=xxo10</span><br><span class="line">a1.sinks.k2.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k3.type = avro</span><br><span class="line">a1.sinks.k3.hostname=xxo09</span><br><span class="line">a1.sinks.k3.port=44445</span><br><span class="line"></span><br><span class="line">a1.sinks.k4.type = avro</span><br><span class="line">a1.sinks.k4.hostname=xxo10</span><br><span class="line">a1.sinks.k4.port=44445</span><br><span class="line"></span><br><span class="line"><span class="comment">#define sinkgroups random</span></span><br><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2 k3 k4</span><br><span class="line">a1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.backoff = <span class="literal">true</span></span><br><span class="line">a1.sinkgroups.g1.processor.selector = random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br><span class="line">a1.sinks.k3.channel = c1</span><br><span class="line">a1.sinks.k4.channel = c1</span><br></pre></td></tr></table></figure></li><li><p><strong>源码如下</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> Iterator&lt;T&gt; <span class="title">createIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  List&lt;Integer&gt; indexList = getIndexList();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> size = indexList.size();</span><br><span class="line">  <span class="keyword">int</span>[] indexOrder = <span class="keyword">new</span> <span class="keyword">int</span>[size];</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (indexList.size() != <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> pick = random.nextInt(indexList.size());</span><br><span class="line">    indexOrder[indexList.size() - <span class="number">1</span>] = indexList.remove(pick);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  indexOrder[<span class="number">0</span>] = indexList.get(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> SpecificOrderIterator&lt;T&gt;(indexOrder, getObjects());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>测试数据 450条数据</strong></p></li></ul><ol><li>博主就向<em>/opt/data/access.log</em>中快速写入<em>450</em>条数据</li><li>博主在内存channel中设置了，每次最大送到sink中的event数量也是100（<em>如上配置</em>）</li><li><p>测试结果,如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">xxo09 端口<span class="number">44444</span> 条数：<span class="number">41</span></span><br><span class="line">xxo09 端口<span class="number">44445</span> 条数：<span class="number">100</span></span><br><span class="line">xxo10 端口<span class="number">44444</span> 条数：<span class="number">206</span></span><br><span class="line">xxo10 端口<span class="number">44445</span> 条数：<span class="number">10</span></span><br></pre></td></tr></table></figure></li><li><p>并且在xxo10 端口44444中100-101中基本不存在时间间隔，在200-201中存在时间间隔<br><img src="https://img.xiaoxiaomo.com/blog/img/20160523220510.jpg" alt="随机选取,接下来很快被选中了"><br><img src="https://img.xiaoxiaomo.com/blog/img/20160523220838.jpg" alt="随机选取,继续随机并没有很快被选中"></p></li></ol><h3 id="round-robin"><a href="#round-robin" class="headerlink" title="round_robin"></a>round_robin</h3><ul><li><p><strong>轮询，其实很简单，就是挨个挨个的来推送到sink</strong>，下面来看一下源码(<em>RoundRobinOrderSelector</em>)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Iterator&lt;T&gt; <span class="title">createIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    List&lt;Integer&gt; activeIndices = getIndexList();</span><br><span class="line">    <span class="keyword">int</span> size = activeIndices.size();</span><br><span class="line">    <span class="comment">// possible that the size has shrunk so gotta adjust nextHead for that</span></span><br><span class="line">    <span class="keyword">if</span> (nextHead &gt;= size) &#123;</span><br><span class="line">      nextHead = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">######每次开始时，nextHead加1##################</span><br><span class="line">    <span class="keyword">int</span> begin = nextHead++;</span><br><span class="line">    <span class="keyword">if</span> (nextHead == activeIndices.size()) &#123;</span><br><span class="line">      nextHead = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>[] indexOrder = <span class="keyword">new</span> <span class="keyword">int</span>[size];</span><br><span class="line"></span><br><span class="line">######重点是下面的代码##########################</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">      indexOrder[i] = activeIndices.get((begin + i) % size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> SpecificOrderIterator&lt;T&gt;(indexOrder, getObjects());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>测试轮询</strong>：</p></li></ul><ol><li>由于博主在内存channel中设置了，每次最大送到sink中的event数量也是100</li><li>博主就向<em>/opt/data/access.log</em>中快速写入450条数据</li><li>测试结果,有三个sink中刚好为100条event,另一个event为150条数据，其中150条数据的记录时间如下:<br><img src="https://img.xiaoxiaomo.com/blog/img/20160523214335.jpg" alt="Flume 轮询"></li></ol><h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Default Sink Processor（故障转移）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2 k3 k4</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># exec source</span></span><br><span class="line">a1.sources.r1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.r1.command = tail -F /opt/data/access.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 avro sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname=xxo09</span><br><span class="line">a1.sinks.k1.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname=xxo10</span><br><span class="line">a1.sinks.k2.port=44444</span><br><span class="line"></span><br><span class="line">a1.sinks.k3.type = avro</span><br><span class="line">a1.sinks.k3.hostname=xxo09</span><br><span class="line">a1.sinks.k3.port=44445</span><br><span class="line"></span><br><span class="line">a1.sinks.k4.type = avro</span><br><span class="line">a1.sinks.k4.hostname=xxo10</span><br><span class="line">a1.sinks.k4.port=44445</span><br><span class="line"></span><br><span class="line"><span class="comment">#define sinkgroups Failover </span></span><br><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2 k3 k4</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 5</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 6</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k3 = 10</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k4 = 8</span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br><span class="line">a1.sinks.k3.channel = c1</span><br><span class="line">a1.sinks.k4.channel = c1</span><br></pre></td></tr></table></figure><ul><li><strong>测试结果</strong>：</li></ul><ol><li>如上配置，<code>xxo09,端口44445</code>优先级最高(<em>10</em>)，测试450条数据，全部都去了那儿。</li><li>如果<strong>中途强制kill掉</strong>，剩余event会转移到<code>xxo10 端口44445</code>的agent(<strong>故障成功转移</strong>)！</li><li>强制kill时会有如下<strong>提示</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 flume]<span class="comment"># 2016-05-24 02:16:31,492 (SinkRunner-PollingRunner-FailoverSinkProcessor) [WARN - org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:185)] Sink k3 failed and has been sent to failover list</span></span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to send events</span><br><span class="line">at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:392)</span><br><span class="line">at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)</span><br><span class="line">at org.apache.flume.SinkRunner<span class="variable">$PollingRunner</span>.run(SinkRunner.java:147)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: xxo09, port: 44445 &#125;: Failed to send batch</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:315)</span><br><span class="line">at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:376)</span><br><span class="line">... 3 more</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: xxo09, port: 44445 &#125;: RPC request exception</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:365)</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:303)</span><br><span class="line">... 4 more</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: java.io.IOException: Error connecting to xxo09/192.168.33.74:44445</span><br><span class="line">at java.util.concurrent.FutureTask.report(FutureTask.java:122)</span><br><span class="line">at java.util.concurrent.FutureTask.get(FutureTask.java:202)</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:357)</span><br><span class="line">... 5 more</span><br><span class="line">Caused by: java.io.IOException: Error connecting to xxo09/192.168.33.74:44445</span><br><span class="line">at org.apache.avro.ipc.NettyTransceiver.getChannel(NettyTransceiver.java:261)</span><br><span class="line">at org.apache.avro.ipc.NettyTransceiver.getRemoteName(NettyTransceiver.java:386)</span><br><span class="line">at org.apache.avro.ipc.Requestor.writeHandshake(Requestor.java:202)</span><br><span class="line">at org.apache.avro.ipc.Requestor.access<span class="variable">$300</span>(Requestor.java:52)</span><br><span class="line">at org.apache.avro.ipc.Requestor<span class="variable">$Request</span>.getBytes(Requestor.java:478)</span><br><span class="line">at org.apache.avro.ipc.Requestor.request(Requestor.java:147)</span><br><span class="line">at org.apache.avro.ipc.Requestor.request(Requestor.java:129)</span><br><span class="line">at org.apache.avro.ipc.specific.SpecificRequestor.invoke(SpecificRequestor.java:84)</span><br><span class="line">at com.sun.proxy.<span class="variable">$Proxy4</span>.appendBatch(Unknown Source)</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient<span class="variable">$2</span>.call(NettyAvroRpcClient.java:348)</span><br><span class="line">at org.apache.flume.api.NettyAvroRpcClient<span class="variable">$2</span>.call(NettyAvroRpcClient.java:344)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:262)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor<span class="variable">$Worker</span>.run(ThreadPoolExecutor.java:615)</span><br><span class="line">... 1 more</span><br><span class="line">Caused by: java.net.ConnectException: Connection refused</span><br><span class="line">at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</span><br><span class="line">at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)</span><br><span class="line">at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink<span class="variable">$Boss</span>.connect(NioClientSocketPipelineSink.java:496)</span><br><span class="line">at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink<span class="variable">$Boss</span>.processSelectedKeys(NioClientSocketPipelineSink.java:452)</span><br><span class="line">at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink<span class="variable">$Boss</span>.run(NioClientSocketPipelineSink.java:365)</span><br><span class="line">... 3 more</span><br><span class="line">2016-05-24 02:16:35,651 (SinkRunner-PollingRunner-FailoverSinkProcessor) [INFO - org.apache.flume.sink.AbstractRpcSink.createConnection(AbstractRpcSink.java:206)] Rpc sink k3: Building RpcClient with hostname: xxo09, port: 44445</span><br><span class="line">2016-05-24 02:16:35,651 (SinkRunner-PollingRunner-FailoverSinkProcessor) [INFO - org.apache.flume.sink.AvroSink.initializeRpcClient(AvroSink.java:126)] Attempting to create Avro Rpc client.</span><br><span class="line">2016-05-24 02:16:35,652 (SinkRunner-PollingRunner-FailoverSinkProcessor) [WARN - org.apache.flume.api.NettyAvroRpcClient.configure(NettyAvroRpcClient.java:634)] Using default maxIOWorkers</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li></ol><h2 id="博客源码"><a href="#博客源码" class="headerlink" title="博客源码"></a>博客源码</h2><ul><li>本例中使用的配置源码下载：<br><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/flume/processors" target="_blank" rel="noopener">https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/flume/processors</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flume </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flume--集群及项目实战</title>
      <link href="/2016/05/22/Flume-%E9%9B%86%E7%BE%A4%E5%8F%8A%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
      <url>/2016/05/22/Flume-%E9%9B%86%E7%BE%A4%E5%8F%8A%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解<strong>flume集群的搭建及项目实战</strong>，flume集群相对来说比较简单，重点是后面的项目实战。如果对<strong>flume</strong>还不够理解或者它的<strong>组件</strong>不熟悉可以阅读上篇博客：<a href="http://blog.xiaoxiaomo.com/2016/05/22/Flume-日志收集/">http://blog.xiaoxiaomo.com/2016/05/22/Flume-日志收集/</a></p><h2 id="Flume-集群"><a href="#Flume-集群" class="headerlink" title="Flume 集群"></a>Flume 集群</h2><ol><li><strong>解压缩</strong> ： tar -zxvf <a href="href=&quot;http://www.apache.org/dyn/closer.lua/flume/1.6.0/apache-flume-1.6.0-bin.tar.gz&quot;">apache-flume-1.6.0-bin.tar.gz</a> -C /opt/ ;</li><li><strong>重命名</strong> ： mv /opt/apache-flume-1.6.0-bin/ /opt/flume（可省略） ;</li><li><strong>复制配置文件</strong> ： cp conf/flume-env.sh.template conf/flume-env.sh ;</li><li><strong>修改conf/flume-env.sh</strong> : JAVA_HOME ;</li><li><strong>复制flume到其他节点</strong> ： scp -r …… 。</li></ol><a id="more"></a><h2 id="常见架构"><a href="#常见架构" class="headerlink" title="常见架构"></a>常见架构</h2><ul><li><strong>常见架构</strong><br><img src="https://img.xiaoxiaomo.com/blog/img/20160522191722.jpg" alt="agent到另一个agent"><br><img src="https://img.xiaoxiaomo.com/blog/img/20160522191750.jpg" alt="整合多个agent，最后汇总"><br><img src="https://img.xiaoxiaomo.com/blog/img/20160522191808.jpg" alt="多路复用"></li></ul><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><ul><li>A、B两台机器实时生产日志主要类型为<code>access.log</code>、<code>ugcheader.log</code>、<code>ugctail.log</code> , <strong>要求</strong>：</li></ul><ol><li>把A、B 机器中的access.log、ugcheader.log、ugctail.log 汇总到C机器上然后统一收集到hdfs和Kafka中。</li><li>在hdfs中要求的目录为：用作离线统计。<br><strong>/source/access/2016-01-01/</strong><br><strong>/source/ugcheader/2016-01-01/</strong><br><strong>/source/ugctail/2016-01-01/</strong></li><li>Kafka分topic , 用作实时分析。</li></ol><h3 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h3><p><img src="https://img.xiaoxiaomo.com/blog/img/20160522195635.jpg" alt="项目结构图"></p><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ul><li><p><strong>机器</strong> (<em>博主使用了三台机器</em>)<br>A机器 : xxo 08 安装 ： <a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">zookeeper</a> 、 <a href="http://blog.xiaoxiaomo.com/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/">kafka</a> 、<a href="http://blog.xiaoxiaomo.com/2016/05/22/Flume-%E9%9B%86%E7%BE%A4%E5%8F%8A%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/#Flume-集群">flume</a><br>B机器 : xxo 09 安装 ： <a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">zookeeper</a> 、 <a href="http://blog.xiaoxiaomo.com/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/">kafka</a> 、<a href="http://blog.xiaoxiaomo.com/2016/05/22/Flume-%E9%9B%86%E7%BE%A4%E5%8F%8A%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/#Flume-集群">flume</a><br>C机器 : xxo 10 安装 ： <a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">zookeeper</a> 、 <a href="http://blog.xiaoxiaomo.com/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/">kafka</a> 、<a href="http://blog.xiaoxiaomo.com/2016/05/22/Flume-%E9%9B%86%E7%BE%A4%E5%8F%8A%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/#Flume-集群">flume</a> 、<a href="http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/">hadoop伪分布式</a></p></li><li><p><strong>启动</strong></p></li></ul><ol><li>启动zookeeper : /opt/zookeeper/bin/zkServer.sh start</li><li>启动kafka : nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt;&gt;/opt/logs/kafka-server.log 2&gt;&amp;1 &amp;</li><li>启动hdfs : start-dfs.sh </li><li>这里查看一下xxo10的进程 : <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 flume]<span class="comment"># jps</span></span><br><span class="line">1305 Kafka</span><br><span class="line">1252 QuorumPeerMain</span><br><span class="line">1786 Jps</span><br><span class="line">1542 DataNode</span><br><span class="line">1454 NameNode</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>创建topic</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partition 3  --topic access </span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partition 3  --topic ugchead </span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partition 3  --topic ugctail </span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --list --zookeeper xxo08:2181,xxo09:2181,xxo10:2181   ###查看</span></span><br><span class="line">access</span><br><span class="line">ugchead</span><br><span class="line">ugctail</span><br></pre></td></tr></table></figure></li></ul><h3 id="C机器"><a href="#C机器" class="headerlink" title="C机器"></a>C机器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 flume]<span class="comment"># vim conf/hdfs_kafka.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################### C机器 #########################################</span></span><br><span class="line"><span class="comment">#################################### 两个channel、两个sink ##########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = kfk fs</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"></span><br><span class="line"><span class="comment"># varo source</span></span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="comment"># source r1定义拦截器，为消息添加时间戳</span></span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor<span class="variable">$Builder</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kfk sink</span></span><br><span class="line">a1.sinks.kfk.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line"><span class="comment">#a1.sinks.kfk.topic = mytopic</span></span><br><span class="line">a1.sinks.kfk.brokerList = xxo08:9092,xxo09:9092,xxo10:9092</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># hdfs sink</span></span><br><span class="line">a1.sinks.fs.type = hdfs</span><br><span class="line">a1.sinks.fs.hdfs.path = hdfs://xxo10:9000/<span class="built_in">source</span>/%&#123;<span class="built_in">type</span>&#125;/%Y%m%d</span><br><span class="line">a1.sinks.fs.hdfs.filePrefix = events-</span><br><span class="line">a1.sinks.fs.hdfs.fileType = DataStream</span><br><span class="line"><span class="comment">#a1.sinks.fs.hdfs.fileType = CompressedStream</span></span><br><span class="line"><span class="comment">#a1.sinks.fs.hdfs.codeC = gzip</span></span><br><span class="line"><span class="comment">#不按照条数生成文件</span></span><br><span class="line">a1.sinks.fs.hdfs.rollCount = 0</span><br><span class="line"><span class="comment">#如果压缩存储的话HDFS上的文件达到64M时生成一个文件注意是压缩前大小为64生成一个文件，然后压缩存储。</span></span><br><span class="line">a1.sinks.fs.hdfs.rollSize = 67108864</span><br><span class="line">a1.sinks.fs.hdfs.rollInterval = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 10000</span><br><span class="line">a1.channels.c1.transactionCapacity = 1000</span><br><span class="line"></span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line">a1.channels.c2.capacity = 10000</span><br><span class="line">a1.channels.c2.transactionCapacity = 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.kfk.channel = c1</span><br><span class="line">a1.sinks.fs.channel = c2</span><br></pre></td></tr></table></figure><ul><li>启动<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 ~]# cd /opt/apache-flume/</span><br><span class="line">[root@xxo10 flume]# bin/flume-ng agent --conf conf/ --conf-file conf/hdfs_kafka.conf --name a1 -Dflume.root.logger=INFO,console &amp;</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">......Component type: SINK, name: kfk started  ##启动成功</span><br></pre></td></tr></table></figure></li></ul><h3 id="A机器"><a href="#A机器" class="headerlink" title="A机器"></a><strong>A机器</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 flume]<span class="comment"># vim conf/hdfs_kafka.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################### A机器 #########################################</span></span><br><span class="line"><span class="comment">#################################### 3个source #####################################</span></span><br><span class="line"><span class="comment">#################################### 2个拦截器 ######################################</span></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = access ugchead ugctail</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三个sources</span></span><br><span class="line">a1.sources.access.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.access.command = tail -F /root/data/access.log</span><br><span class="line"></span><br><span class="line">a1.sources.ugchead.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.ugchead.command = tail -F /root/data/ugchead.log</span><br><span class="line"></span><br><span class="line">a1.sources.ugctail.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.ugctail.command = tail -F /root/data/ugctail.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = xxo10</span><br><span class="line">a1.sinks.k1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="comment"># channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 10000</span><br><span class="line">a1.channels.c1.transactionCapacity = 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># interceptor</span></span><br><span class="line">a1.sources.access.interceptors = i1 i2</span><br><span class="line">a1.sources.access.interceptors.i1.type=static</span><br><span class="line">a1.sources.access.interceptors.i1.key = <span class="built_in">type</span></span><br><span class="line">a1.sources.access.interceptors.i1.value = access</span><br><span class="line">a1.sources.access.interceptors.i2.type=static</span><br><span class="line">a1.sources.access.interceptors.i2.key = topic</span><br><span class="line">a1.sources.access.interceptors.i2.value = access</span><br><span class="line"></span><br><span class="line">a1.sources.ugchead.interceptors = i1 i2</span><br><span class="line">a1.sources.ugchead.interceptors.i1.type=static</span><br><span class="line">a1.sources.ugchead.interceptors.i1.key = <span class="built_in">type</span></span><br><span class="line">a1.sources.ugchead.interceptors.i1.value = ugchead</span><br><span class="line">a1.sources.ugchead.interceptors.i2.type=static</span><br><span class="line">a1.sources.ugchead.interceptors.i2.key = topic</span><br><span class="line">a1.sources.ugchead.interceptors.i2.value = ugchead</span><br><span class="line"></span><br><span class="line">a1.sources.ugctail.interceptors = i1 i2</span><br><span class="line">a1.sources.ugctail.interceptors.i1.type=static</span><br><span class="line">a1.sources.ugctail.interceptors.i1.key = <span class="built_in">type</span></span><br><span class="line">a1.sources.ugctail.interceptors.i1.value = ugctail</span><br><span class="line">a1.sources.ugctail.interceptors.i2.type=static</span><br><span class="line">a1.sources.ugctail.interceptors.i2.key = topic</span><br><span class="line">a1.sources.ugctail.interceptors.i2.value = ugctail</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.access.channels = c1</span><br><span class="line">a1.sources.ugchead.channels = c1</span><br><span class="line">a1.sources.ugctail.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><ul><li>启动A机器<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 flume]<span class="comment"># bin/flume-ng agent --conf conf/ --conf-file conf/hdfs_kafka.conf --name a1 -Dflume.root.logger=INFO,console &amp;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="验证功能"><a href="#验证功能" class="headerlink" title="验证功能"></a>验证功能</h3><ul><li>我这里启动了一个向<code>access.log</code>、<code>ugcheader.log</code>、<code>ugctail.log</code>添加数据的java程序:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 ~]<span class="comment"># java -cp KafkaFlumeProject_20160519-1.0-SNAPSHOT-jar-with-dependencies.jar com.xxo.utils.Creator</span></span><br></pre></td></tr></table></figure></li></ul><ol><li><p>查看<strong>hdfs</strong>的情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 ~]<span class="comment"># hdfs dfs -text /source/ugchead/20160523/* | more </span></span><br><span class="line">1001221.8.9.6 80be83f3fd-a218-4f98-91d8-6b4f0bb4558b750b6203-4a7d-42d5-82e4-906415b70f6310207&#123;<span class="string">"ugctype"</span>:<span class="string">"consumer"</span>,</span><br><span class="line"><span class="string">"userId"</span>:<span class="string">"40604"</span>,<span class="string">"coin"</span>:<span class="string">"10"</span>,<span class="string">"number"</span>:<span class="string">"2"</span>&#125;1463685721663</span><br><span class="line">1003218.75.100.114ea11f1d2-680d-4645-a52e-74d5f2317dfd8109eda1-aeac-43fe-94b1-85d2d193491320101&#123;<span class="string">"ugctype"</span>:<span class="string">"fav"</span>,<span class="string">"user</span></span><br><span class="line"><span class="string">Id"</span>:<span class="string">"40604"</span>,<span class="string">"item"</span>:<span class="string">"13"</span>&#125;1463685722666</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li><li><p><strong>kafka</strong>消费者</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########################## 这里查看一下access ###############################</span></span><br><span class="line">[root@xxo09 ~]<span class="comment"># /opt/kafka/bin/kafka-console-consumer.sh --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic access  --from-beginning </span></span><br><span class="line">1001218.26.219.186070c8525-b857-414d-98b6-13134da08401102010GET /tologin HTTP/1.1408/update/passMozilla/5.0 (Windows; U; Windows NT 5.1)Gecko/20070803 Firefox/1.5.0.121463676319717</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li><li><p>查看日志：<br>tac /opt/flume/logs/flume.log | more</p></li></ol><h3 id="同步节点"><a href="#同步节点" class="headerlink" title="同步节点"></a>同步节点</h3><ul><li>【B机器】<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####################### 拷贝 ##################################</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># scp /opt/flume/conf/hdfs_kafka.conf root@xxo09:/opt/flume/conf/</span></span><br><span class="line">hdfs_kafka.conf              100% 1803     1.8KB/s   00:00 </span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 远程启动 ###############################</span></span><br><span class="line">[root@xxo08 flume]<span class="comment"># ssh root@xxo09 "/opt/flume/bin/flume-ng agent --conf /opt/flume/conf/ --conf-file /opt/flume/conf/hdfs_kafka.conf --name a1" &amp;</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="博客源码"><a href="#博客源码" class="headerlink" title="博客源码"></a>博客源码</h2><ul><li>本例中使用的配置源码下载：<br><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/flume/project" target="_blank" rel="noopener">https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/flume/project</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flume </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flume--日志收集</title>
      <link href="/2016/05/22/Flume-%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/"/>
      <url>/2016/05/22/Flume-%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/</url>
      <content type="html"><![CDATA[<p>　　<strong>Flume是一个分布式、高可靠、高可用的日志收集系统。能够有效的收集、聚合、移动大量的日志。</strong>把各种类型的<strong>数据源</strong>采集汇总到各种类型的<strong>目的地</strong>,flume有一个口号：“我们不生产数据，我们是数据的搬运工。”</p><ul><li>那我们怎么去搬运数据呢？让我们想想，那就需要一个入口（<strong>采集数据</strong>），和一个出口(<strong>推送数据</strong>)，中间再加上一些队列(<strong>暂存数据</strong>，让数据流动起来)，这样一来我们就可以去搬运数据了，自己也可以去实现一个简单的搬运数据的。当然我们已经不需要了，因为大牛已经帮我们实现了就是<strong>flume</strong>,能采集各种数据(<strong>各种source</strong>),推动到各种目的地（<strong>sink</strong>）。下面我们来看看flume的组件结构：<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522173311.jpg" alt="flume组件"></li></ul><a id="more"></a><h2 id="Flume-理解"><a href="#Flume-理解" class="headerlink" title="Flume 理解"></a>Flume 理解</h2><p><strong>Flume 的核心（agent）就是把数据从数据源收集过来，再送到目的地</strong>。为了保证高可靠输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。 </p><ol><li><code>Flume</code> :  传输的数据的基本单位是 <code>Event</code>，如果是文本文件，通常是一行记录，这也是事务的基本单位。</li><li><code>Event</code> :  （<em>包含：headers:{} 、body</em>） 从 <strong>Source</strong>，流向 <strong>Channel</strong>，再到 <strong>Sink</strong>，本身为一个 byte 数组。</li><li><code>Source</code> :  <strong>对数据进行收集，分成transtion 和 event 打入到channel之中</strong>。</li><li><code>Channel</code> :  <strong>就像一个管道(队列)，接收 Source 的输出，再推送给 Sink 消费</strong>。数据直到进入到下一个Channel中或者进入终端才会被删除。即:中转Event临时存储，在 sources 和 sinks之间起一个<strong>连接作用</strong> 。</li><li><code>Sink</code> :  <strong>取出 Channel 中的数据，然后送给外部源（HDFS、HBase）或者其他 Source</strong>。</li></ol><ul><li><strong>Flume处理流程总结：</strong><br>Flume由事件(Event)贯穿了整个数据流动。事件是Flume的基本数据单位，它<strong>携带日志数据</strong>(字节数组形式)和<strong>头信息</strong>，这些Event由Agent外部的Source生成，当<strong>Source捕获事件后会进行特定的格式化</strong>，然后Source会把事件<strong>推入(单个或多个)Channel中（缓冲区）</strong>，它将保存事件直到Sink处理完该事件。<strong>Sink负责持久化日志或者把事件推向另一个Source</strong>。</li></ul><h2 id="Flume-组件"><a href="#Flume-组件" class="headerlink" title="Flume 组件"></a>Flume 组件</h2><ul><li><strong>Flume提供了大量内置的Source、Channel和Sink。不同类型的Source,Channel和Sink可以自由组合</strong>。比如：source 来源可以是日志文件，Avro和Thrift端口Kafka等， Channel可以把事件暂存在内存里，也可以持久化到本地硬盘上。Sink可以把日志写入HDFS、Hive、HBase，甚至是另外一个Source等。</li></ul><h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><ul><li><p><strong>常见采集的数据类型</strong>：<br><code>Exec Source</code>、<code>Avro Source</code>、<code>NetCat Source</code>、<code>Spooling Directory Source</code>、<code>Kafka Source</code>等。详细查看：<a href="http://flume.apache.org/FlumeUserGuide.html#flume-sources" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html#flume-sources</a></p></li><li><p><strong>Source应用</strong>：</p></li></ul><ol><li><p><code>Avro Source</code>：监听一个<strong> avro 服务</strong>端口，采集Avro数据序列化后的数据；<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522183127.jpg" alt="Avro Source"><br><strong>type</strong>：avrosource的类型，必须是avro。<br><strong>bind</strong>：要监听的(本机的)主机名或者ip。此监听不是过滤发送方。一台电脑不是说只有一个IP。有多网卡的电脑，对应多个IP。<br><strong>port</strong>：绑定的本地的端口。</p></li><li><p><code>Exec Source</code>：基于Unix的<strong>command在标准输出</strong>上采集数据（<em>tail -F</em>）；<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522183807.jpg" alt="Exec Source"><br><strong>type</strong>:source的类型：必须是exec。<br><strong>command</strong>：要执行命令。</p></li><li><p><code>NetCat Source</code>： <strong>绑定的端口（tcp、udp）</strong>，将流经端口的每一个文本行数据作为Event输入；<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522183531.jpg" alt="NetCat Source"><br><strong>type</strong>：source的类型，必须是netcat。<br><strong>bind</strong>：要监听的(本机的)主机名或者ip。此监听不是过滤发送方。一台电脑不是说只有一个IP。有多网卡的电脑，对应多个IP。<br><strong>port</strong>：绑定的本地的端口。</p></li><li><p><code>Kafka Source</code>：从<strong> kafka 服务</strong>中采集数据；<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522183629.jpg" alt="Kafka Source"></p></li><li><p><code>Thrift Source</code>：监听一个<strong> Thrift 服务</strong>端口，采集Thrift数据序列化后的数据；<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522183721.jpg" alt="Thrift Source"></p></li><li><p><code>JMS Source</code>：<strong> Java 消息服务</strong>数据源，Java消息服务是一个与具体平台无关的API，这是支持jms规范的数据源采集；</p></li><li><code>Spooling Directory Source</code>：通过<strong>文件夹</strong>里的新增的文件作为数据源的采集；</li><li><code>HTTP Source</code>：监听<strong> HTTP POST和 GET </strong>产生的数据的采集；</li></ol><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><ul><li><p><strong>常见采集的数据类型</strong>：<br><code>Memory Channel</code>、<code>File Channel</code>、<code>JDBC Channel</code>、<code>Kafka Channel</code>等。详细查看：<a href="http://flume.apache.org/FlumeUserGuide.html#flume-channels" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html#flume-channels</a></p></li><li><p><strong>Channel应用</strong></p></li></ul><ol><li><p><code>Memory Channel</code>：使用<strong> 内存 </strong>作为数据的存储(<em>详情大家可以去官网，或者阅读下载下来的doc文档</em>)。<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522185207.jpg" alt="Memory Channel"><br><strong>channel的类型</strong> ： 必须为memory<br><strong>capacity</strong> ： channel中的最大event数目<br><strong>transactionCapacity</strong> ： channel中允许事务的最大event数目</p></li><li><p><code>JDBC Channel</code>：使用<strong> jdbc </strong>数据源来作为数据的存储。</p></li><li><code>Kafka Channel</code>：使用<strong> kafka服务 </strong>来作为数据的存储。</li><li><code>File Channel</code>：使用<strong> 文件 </strong>来作为数据的存储。</li><li><code>Spillable Memory Channel</code>：使用<strong>内存和文件</strong>作为数据的存储，即：先存在内存中，如果内存中数据达到阀值则flush到文件中。</li></ol><h3 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h3><ul><li><p><strong>常见采集的数据类型</strong>：<br><code>HDFS Sink</code>、<code>Hive Sink</code>、<code>Logger Sink</code>、<code>Avro Sink</code>、<code>Thrift Sink</code>、<code>File Roll Sink</code>、<code>HBaseSink</code>、<code>Kafka Sink</code>等。详细查看：<a href="http://flume.apache.org/FlumeUserGuide.html#flume-sinks" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html#flume-sinks</a></p></li><li><p><strong>Sink应用</strong>：</p></li></ul><ol><li><p><code>HDFS Sink</code>：将数据传输到 <strong>hdfs</strong> 集群中。<br><img src="https://img.xiaoxiaomo.com/blog/img/20160522190722.jpg" alt="HDFS Sink"><br><strong>type</strong> ： sink的类型 必须是hdfs。<br><strong>hdfs.path</strong> ： hdfs的上传路径。<br><strong>hdfs.filePrefix</strong> ： hdfs文件的前缀。默认是:FlumeData<br><strong>hdfs.rollInterval</strong> : 间隔多久产生新文件，默认是:30（秒） 0表示不以时间间隔为准。<br><strong>hdfs.rollSize</strong> ： 文件到达多大再产生一个新文件，默认是:1024（bytes）0表示不以文件大小为准。<br><strong>hdfs.rollCount</strong> ： event达到多大再产生一个新文件，默认是:10（个）0表示不以event数目为准。<br><strong>hdfs.batchSize</strong> ： 每次往hdfs里提交多少个event，默认为100<br><strong>hdfs.fileType</strong> ： hdfs文件的格式<br><strong>hdfs.codeC</strong> ： 压缩方式：gzip, bzip2, lzo, lzop, snappy</p></li><li><p><code>Hive Sink</code>：将数据传输到 <strong>hive</strong> 的表中。</p></li><li><p><code>Logger Sink</code>：将数据作为 <strong>日志</strong> 处理（根据flume中的设置的日志的级别显示）。<br>要在控制台显示在运行agent的时候加入：-Dflume.root.logger=INFO,console 。<br><strong>type</strong> ： sink的类型：必须是 logger。<br><strong>maxBytesToLog</strong> ： 打印body的最长的字节数 默认为16</p></li><li><p><code>Avro Sink</code>：数据被转换成 <strong>Avro Event</strong> ，然后发送到指定的服务端口上。</p></li><li><code>Thrift Sink</code>：数据被转换成 <strong>Thrift Event</strong> ，然后发送到指定的的服务端口上。</li><li><code>Kafka Sink</code>：将数据发送到 <strong>kafka服务</strong> 中。（注意依赖类库）</li><li><code>IRC Sink</code>：数据向指定的 <strong>IRC服务</strong> 和端口中发送。</li><li><code>File Roll Sink</code>：数据传输到 <strong>本地文件</strong> 中。</li><li><code>Null Sink</code>：<strong>取消数据的传输</strong>，即不发送到任何目的地。</li><li><code>HBaseSink</code>：将数据发往 <strong>hbase</strong> 数据库中。</li><li><code>MorphlineSolrSink</code>：数据发送到 <strong>Solr搜索服务器</strong> （集群）。</li><li><code>ElasticSearchSink</code>：数据发送到 <strong>Elastic Search</strong> 搜索服务器（集群）。</li></ol><h3 id="Interceptor"><a href="#Interceptor" class="headerlink" title="Interceptor"></a>Interceptor</h3><ol><li><p><code>Timestamp Interceptor</code> : <strong>时间戳拦截器</strong> 在header里加入key为timestamp，value为当前时间。<br><strong>type</strong> ： 拦截器的类型，必须为timestamp<br><strong>preserveExisting</strong> ： 如果此拦截器增加的key已经存在，如果这个值设置为true则保持原来的值，否则覆盖原来的值。默认为false</p></li><li><p><code>Host Interceptor</code> :  <strong>主机名或者ip拦截器</strong>，在header里加入ip或者主机名<br><strong>type</strong> ： 拦截器的类型，必须为host<br><strong>preserveExisting</strong> ： 如果此拦截器增加的key已经存在，如果这个值设置为true则保持原来的值，否则覆盖原来的值。默认为false<br><strong>useIP</strong> ： 如果设置为true则使用ip地址，否则使用主机名，默认为true<br><strong>hostHeader</strong> ： 使用的header的key名字，默认为host</p></li><li><p><code>Static Interceptor</code> ： <strong>静态拦截器</strong>，是在header里加入固定的key和value。<br><strong>type</strong> ： avrosource的类型，必须是static。<br><strong>preserveExisting</strong> : 如果此拦截器增加的key已经存在，如果这个值设置为true则保持原来的值，否则覆盖原来的值。默认为false<br><strong>key</strong> : 静态拦截器添加的key的名字<br><strong>value</strong> : 静态拦截器添加的key对应的value值</p></li></ol><h3 id="Channel-Selector"><a href="#Channel-Selector" class="headerlink" title="Channel Selector"></a>Channel Selector</h3><ul><li><code>Multiplexing Channel Selector</code> 根据header的key的值分配channel<blockquote><p><strong>selector.type</strong> 默认为replicating<br><strong>selector.header</strong>：选择作为判断的key<br><strong>selector.default</strong>：默认的channel配置<br><strong>selector.mapping.*</strong>：匹配到的channel的配置</p></blockquote></li></ul><p><img src="https://img.xiaoxiaomo.com/blog/img/20160522205253.jpg" alt="flume 整体结构图"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flume </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Idea/Eclipse--Windows下调试Hadoop</title>
      <link href="/2016/05/20/Idea-Eclipse-Windows%E4%B8%8B%E8%B0%83%E8%AF%95Hadoop/"/>
      <url>/2016/05/20/Idea-Eclipse-Windows%E4%B8%8B%E8%B0%83%E8%AF%95Hadoop/</url>
      <content type="html"><![CDATA[<p>　　我想大家对于java的单元测试<strong>junit</strong>都很熟悉了吧，这里我就不介绍了。下面主要介绍Hadoop的测试（<strong>mrunit</strong>）的使用，以及在windows下我们在开发工具（<strong>Idea/Eclipse</strong>）本地调试和集群模式。本博客项目结构如下：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521005213.png" alt="Maven 项目结构"></p><a id="more"></a><h2 id="MRunit"><a href="#MRunit" class="headerlink" title="MRunit"></a>MRunit</h2><p>就直接进入主题吧，对于mrunit的使用，首先我们加入依赖包：</p><ul><li><p><strong>mrunit和junit依赖</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mrunit --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.mrunit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mrunit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">classifier</span>&gt;</span>hadoop2<span class="tag">&lt;/<span class="name">classifier</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- junit --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>一个简单的WordCountApp用于统计单词的MapReduce</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过MapReduce统计单词次数</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/20.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = Logger.getLogger( WordCountApp.class ) ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        Job job = Job.getInstance( conf,WordCountApp.class.getSimpleName()) ;</span><br><span class="line">        job.setJarByClass(WordCountApp.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 数据来源</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, args[<span class="number">0</span>]);</span><br><span class="line">        FileInputFormat.setInputDirRecursive(job, <span class="keyword">true</span>); <span class="comment">//递归</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 使用Mapper计算</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 使用Reducer合并计算</span></span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 数据写入</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 执行</span></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>) ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义的Map 需要继承Mapper</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>,<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">LongWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        Text k2 = <span class="keyword">new</span> Text() ;</span><br><span class="line">        LongWritable v2 = <span class="keyword">new</span> LongWritable();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//1. 获取行信息</span></span><br><span class="line">            String line = value.toString();</span><br><span class="line">            logger.info(<span class="string">"该行数据："</span> + line);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//2. 获取行的所用单词</span></span><br><span class="line">            String[] words = line.split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                logger.info( <span class="string">" 设置的键和值："</span> + word + <span class="string">" - 1"</span>);</span><br><span class="line">                k2.set(word.getBytes()) ; <span class="comment">//设置键</span></span><br><span class="line">                v2.set(<span class="number">1</span>);                <span class="comment">//设置值</span></span><br><span class="line">                context.write(k2,v2);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义的Reduce 需要继承Reducer</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span> , <span class="title">LongWritable</span> ,<span class="title">Text</span> ,<span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//K1 = K3</span></span><br><span class="line">        LongWritable v3 = <span class="keyword">new</span> LongWritable() ;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = <span class="number">0</span> ;</span><br><span class="line"></span><br><span class="line">            logger.info(<span class="string">"Reduce 键key："</span> + key);</span><br><span class="line">            <span class="keyword">for</span> (LongWritable value : values) &#123;</span><br><span class="line">                logger.info(<span class="string">" 设置的值："</span> + value);</span><br><span class="line">                sum +=value.get() ;</span><br><span class="line">            &#125;</span><br><span class="line">            v3.set(sum);</span><br><span class="line">            context.write( key , v3 );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>下面我们就来写一个简单的mrunit吧，代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Lists;</span><br><span class="line"><span class="keyword">import</span> com.xxo.mr.WordCountApp;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mrunit.mapreduce.MapDriver;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mrunit.mapreduce.ReduceDriver;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * mrunit Test</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/20.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountAppTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//单词统计Mapper</span></span><br><span class="line"><span class="keyword">private</span> WordCountApp.WordCountMapper wordCountMapper;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//单词统计Reducer</span></span><br><span class="line"><span class="keyword">private</span> WordCountApp.WordCountReducer wordCountReducer;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Mapper和Reducer的Driver</span></span><br><span class="line"><span class="keyword">private</span> MapDriver&lt;LongWritable, Text, Text, LongWritable&gt;  mapDriver;</span><br><span class="line"><span class="keyword">private</span> ReduceDriver&lt;Text, LongWritable, Text, LongWritable&gt; reduceDriver;</span><br><span class="line"><span class="comment">//private MapReduceDriver mrDriver;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.wordCountMapper = <span class="keyword">new</span> WordCountApp.WordCountMapper();</span><br><span class="line"><span class="keyword">this</span>.wordCountReducer = <span class="keyword">new</span> WordCountApp.WordCountReducer();</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.mapDriver = MapDriver.newMapDriver(wordCountMapper);</span><br><span class="line"><span class="keyword">this</span>.reduceDriver = ReduceDriver.newReduceDriver(wordCountReducer);</span><br><span class="line">        <span class="comment">//也可以这样写：同时测试map和reduce</span></span><br><span class="line"><span class="comment">//this.mrDriver = MapReduceDriver.newMapReduceDriver(wordCountMapper, wordCountReducer);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMap</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="comment">//设置输入数据</span></span><br><span class="line"><span class="keyword">this</span>.mapDriver.addInput(<span class="keyword">new</span> LongWritable(<span class="number">0</span>), <span class="keyword">new</span> Text(<span class="string">"blog\txiaoxiaomo"</span>));</span><br><span class="line"><span class="keyword">this</span>.mapDriver.addInput(<span class="keyword">new</span> LongWritable(<span class="number">0</span>), <span class="keyword">new</span> Text(<span class="string">"xxo\tblog"</span>));</span><br><span class="line"><span class="keyword">this</span>.mapDriver.addOutput(<span class="keyword">new</span> Text(<span class="string">"blog"</span>), <span class="keyword">new</span> LongWritable(<span class="number">1</span>));</span><br><span class="line"><span class="keyword">this</span>.mapDriver.addOutput(<span class="keyword">new</span> Text(<span class="string">"xiaoxiaomo"</span>), <span class="keyword">new</span> LongWritable(<span class="number">1</span>));</span><br><span class="line"><span class="keyword">this</span>.mapDriver.addOutput(<span class="keyword">new</span> Text(<span class="string">"xxo"</span>), <span class="keyword">new</span> LongWritable(<span class="number">1</span>));</span><br><span class="line">        <span class="keyword">this</span>.mapDriver.addOutput(<span class="keyword">new</span> Text(<span class="string">"blog"</span>), <span class="keyword">new</span> LongWritable(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.mapDriver.runTest();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReduce</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">ArrayList&lt;LongWritable&gt; values = Lists.newArrayList(<span class="keyword">new</span> LongWritable(<span class="number">1</span>), <span class="keyword">new</span> LongWritable(<span class="number">2</span>));</span><br><span class="line"><span class="keyword">this</span>.reduceDriver.addInput(<span class="keyword">new</span> Text(<span class="string">"xiaoxiaomo"</span>), values);</span><br><span class="line"><span class="keyword">this</span>.reduceDriver.addInput(<span class="keyword">new</span> Text(<span class="string">"blog"</span>), values);</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.reduceDriver.run();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">///////运行结果</span></span><br><span class="line"><span class="comment">///////Mapper</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:01 WordCountApp [INFO] 该行数据：blogxiaoxiaomo</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:01 WordCountApp [INFO]  设置的键和值：blog - 1</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:02 WordCountApp [INFO]  设置的键和值：xiaoxiaomo - 1</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:02 WordCountApp [INFO] 该行数据：xxoblog</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:02 WordCountApp [INFO]  设置的键和值：xxo - 1</span></span><br><span class="line"><span class="comment">//2016-05-21 01:06:02 WordCountApp [INFO]  设置的键和值：blog - 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">///////Reduce</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO] Reduce 键key：xiaoxiaomo</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO]  设置的值：1</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO]  设置的值：2</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO] Reduce 键key：blog</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO]  设置的值：1</span></span><br><span class="line"><span class="comment">//2016-05-21 01:07:53 WordCountApp [INFO]  设置的值：2</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="调试hadoop"><a href="#调试hadoop" class="headerlink" title="调试hadoop"></a>调试hadoop</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ol><li><p>首先下载：<a href="http://download.csdn.net/detail/tang__xuandong/9526676" target="_blank" rel="noopener">hadoop2.6.0_util(x64).zip</a>、<a href="http://download.csdn.net/detail/tang__xuandong/9526659" target="_blank" rel="noopener">hadoop2.6.0_util(x32).zip</a></p></li><li><p>下载后解压到目录（博主解压到：D:\dev\hadoop\bin\下面）bin下面包含文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop.dll</span><br><span class="line">hadoop.exp</span><br><span class="line">hadoop.lib</span><br><span class="line">hadoop.pdb</span><br><span class="line">libwinutils.lib</span><br><span class="line">winutils.exe</span><br><span class="line">winutils.pdb</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量（<em>配置好后记得重启你的IDE工具</em>）<br><code>HADOOP_HOME=D:\dev\hadoop</code><br><code>PATH=%HADOOP_HOME%\bin</code></p></li></ol><h3 id="IDEA-调试hadoop"><a href="#IDEA-调试hadoop" class="headerlink" title="IDEA 调试hadoop"></a>IDEA 调试hadoop</h3><h4 id="本地调试"><a href="#本地调试" class="headerlink" title="本地调试"></a>本地调试</h4><ul><li><p>一、<strong>点击Idea 右上角配置运行环境</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521092442.png" alt="配置hadoop本地调试环境"></p></li><li><p>二、<strong>点击“+”号，添加配置</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521092555.png" alt="创建application"></p></li><li><p>三、<strong>设置运行环境变量和参数</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521093347.png" alt="指定main class和运行参数"></p></li><li><p>四、<strong>运行结果如下：</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521100104.png" alt="idea debug hadoop 运行结果"></p></li></ul><h4 id="远程模式"><a href="#远程模式" class="headerlink" title="远程模式"></a>远程模式</h4><p>集群模式是本地向集群提交作业。</p><ol><li><p>将集群中的配置文件<strong>core-site.xml</strong>，<strong>hdfs-site.xml</strong>，<strong>mapred-site.xml</strong>，<strong>yarn-site.xml</strong>文件放在项目的resources目录下</p></li><li><p><strong>在mapred-site.xml中添加如下内容：</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.app-submission.cross-platform<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>HadoopMRunit_Winutils_20150520-1.0-SNAPSHOT-jar-with-dependencies.jar<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>D:\\dev\\idea\\HadoopMRunit_Winutils_20150520\\target\\HadoopMRunit_Winutils_20150520-1.0-SNAPSHOT-jar-with-dependencies.jar<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置运行环境</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521105258.png" alt="配置main class和运行参数"></p></li><li><p><strong>Maven 打包</strong> ：<code>mvn clean install</code></p></li><li><strong>运行即可</strong></li></ol><h3 id="eclipse-调试hadoop"><a href="#eclipse-调试hadoop" class="headerlink" title="eclipse 调试hadoop"></a>eclipse 调试hadoop</h3><ul><li>在ec<strong>lipse中调试hadoop基本和idea一样的，只是设置运行参数的位置不同而已</strong>，就不详细讲解了，如图：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521130018.png" alt="eclipse中配置运行参数"></li></ul><h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><ul><li><p>一、<strong>org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">05</span>-<span class="number">21</span> <span class="number">09</span>:<span class="number">39</span>:<span class="number">44</span> JobSubmitter [INFO] Cleaning up the staging area file:/tmp/hadoop-Jason/mapred/staging/Jason477647952/.staging/job_local477647952_0001</span><br><span class="line">Exception in thread <span class="string">"main"</span> java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z</span><br><span class="line">at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)</span><br><span class="line">at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:<span class="number">557</span>)</span><br><span class="line">at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:<span class="number">977</span>)</span><br><span class="line">at org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:<span class="number">187</span>)</span><br><span class="line">at org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:<span class="number">174</span>)</span><br><span class="line">at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:<span class="number">108</span>)</span><br><span class="line">at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(LocalDirAllocator.java:<span class="number">285</span>)</span><br><span class="line">at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:<span class="number">344</span>)</span><br><span class="line">at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:<span class="number">150</span>)</span><br><span class="line">at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:<span class="number">131</span>)</span><br><span class="line">at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:<span class="number">115</span>)</span><br><span class="line">at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:<span class="number">131</span>)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.&lt;init&gt;(LocalJobRunner.java:<span class="number">163</span>)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:<span class="number">731</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:<span class="number">536</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$<span class="number">10</span>.run(Job.java:<span class="number">1296</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$<span class="number">10</span>.run(Job.java:<span class="number">1293</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1628</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.submit(Job.java:<span class="number">1293</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:<span class="number">1314</span>)</span><br><span class="line">at com.xxo.mr.WordCount.main(WordCount.java:<span class="number">73</span>)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:<span class="number">601</span>)</span><br><span class="line">at com.intellij.rt.execution.application.AppMain.main(AppMain.java:<span class="number">140</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>分析</strong>：从错误信息和源码发现，权限不足<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521115641.png" alt="源码文件，校验授权"></p></li><li><p><strong>解决办法</strong>（两种办法）：</p></li></ul><ol><li>以管理员的身份启动ide开发工具。</li><li>还有一种办法就是重写源代码，如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160521120416.png" alt="重写源码"></li></ol><ul><li><p>二、<strong>Permission denied: user=Jason, access=EXECUTE, inode=”/history”:root:supergroup:drwxrwx—</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">05</span>-<span class="number">21</span> <span class="number">10</span>:<span class="number">53</span>:<span class="number">18</span> JobSubmitter [INFO] Cleaning up the staging area /history/Jason/.staging/job_1463827152309_0001</span><br><span class="line">Exception in thread <span class="string">"main"</span> org.apache.hadoop.security.AccessControlException: Permission denied: user=Jason, access=EXECUTE, inode=<span class="string">"/history"</span>:root:supergroup:drwxrwx---</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:<span class="number">271</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:<span class="number">257</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:<span class="number">208</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:<span class="number">171</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:<span class="number">6512</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:<span class="number">6494</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOwner(FSNamesystem.java:<span class="number">6413</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermissionInt(FSNamesystem.java:<span class="number">1719</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:<span class="number">1699</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setPermission(NameNodeRpcServer.java:<span class="number">614</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setPermission(ClientNamenodeProtocolServerSideTranslatorPB.java:<span class="number">443</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$<span class="number">2</span>.callBlockingMethod(ClientNamenodeProtocolProtos.java)</span><br><span class="line">at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:<span class="number">619</span>)</span><br><span class="line">at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:<span class="number">962</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$Handler$<span class="number">1</span>.run(Server.java:<span class="number">2039</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$Handler$<span class="number">1</span>.run(Server.java:<span class="number">2035</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1628</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$Handler.run(Server.java:<span class="number">2033</span>)</span><br><span class="line"></span><br><span class="line">at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line">at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)</span><br><span class="line">at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">525</span>)</span><br><span class="line">at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:<span class="number">106</span>)</span><br><span class="line">at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:<span class="number">73</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSClient.setPermission(DFSClient.java:<span class="number">2326</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">24</span>.doCall(DistributedFileSystem.java:<span class="number">1286</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">24</span>.doCall(DistributedFileSystem.java:<span class="number">1282</span>)</span><br><span class="line">at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:<span class="number">81</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.DistributedFileSystem.setPermission(DistributedFileSystem.java:<span class="number">1282</span>)</span><br><span class="line">at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:<span class="number">599</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:<span class="number">182</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:<span class="number">390</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:<span class="number">483</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$<span class="number">10</span>.run(Job.java:<span class="number">1296</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$<span class="number">10</span>.run(Job.java:<span class="number">1293</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1628</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.submit(Job.java:<span class="number">1293</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:<span class="number">1314</span>)</span><br><span class="line">at com.xxo.mr.WordCountApp.main(WordCountApp.java:<span class="number">47</span>)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:<span class="number">601</span>)</span><br><span class="line">at com.intellij.rt.execution.application.AppMain.main(AppMain.java:<span class="number">140</span>)</span><br><span class="line">Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=Jason, access=EXECUTE, inode=<span class="string">"/history"</span>:root:supergroup:drwxrwx---</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:<span class="number">271</span>)</span><br></pre></td></tr></table></figure></li><li><p>分析：线上/history/文件权限不足</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo03 up]<span class="comment"># hdfs dfs -ls /history/</span></span><br><span class="line">Found 3 items</span><br><span class="line">drwx--x--x   - Jason supergroup          0 2016-05-21 18:43 /<span class="built_in">history</span>/Jason</span><br><span class="line">drwxrwx--x   - root  supergroup          0 2016-05-11 05:48 /<span class="built_in">history</span>/<span class="built_in">history</span></span><br><span class="line">drwx--x--x   - root  supergroup          0 2016-05-11 06:17 /<span class="built_in">history</span>/root</span><br></pre></td></tr></table></figure></li><li><p>解决办法：添加权限给本地用户（Jason）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo03 /]<span class="comment"># hdfs dfs -chmod -R a+x /history</span></span><br><span class="line">[root@xxo03 /]<span class="comment"># hdfs dfs -ls /</span></span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   1 root supergroup      57925 2016-05-09 07:40 /hadoop.log</span><br><span class="line">drwxrwx--x   - root supergroup          0 2016-05-21 18:43 /<span class="built_in">history</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2016-05-11 06:25 /<span class="keyword">in</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2016-05-11 07:11 /out</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2016-05-11 06:17 /tmp</span><br></pre></td></tr></table></figure></li><li><p>项目源码下载：<br><a href="http://download.csdn.net/detail/tang__xuandong/9527054" target="_blank" rel="noopener">http://download.csdn.net/detail/tang__xuandong/9527054</a>　　　　</p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Flume--kafka source启动异常</title>
      <link href="/2016/05/19/Flume-kafka-source%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8/"/>
      <url>/2016/05/19/Flume-kafka-source%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<ul><li>在flume中配置了一个kafka source的agent。如下：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 使用kafka作为一个sources</span><br><span class="line"></span><br><span class="line"># Name the components on <span class="keyword">this</span> agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># kfka source</span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line">a1.sources.r1.zookeeperConnect = xxo08:<span class="number">2181</span>,xxo09:<span class="number">2181</span>,xxo10:<span class="number">2181</span>##zk集群</span><br><span class="line">a1.sources.r1.topic = word</span><br><span class="line">a1.sources.r1.groupId = flume</span><br><span class="line">a1.sources.r1.kafka.consumer.timeout.ms = <span class="number">3000</span></span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = <span class="number">1000</span></span><br><span class="line">a1.channels.c1.transactionCapacity = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"># Bind the source <span class="keyword">and</span> sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h2 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h2><ul><li><p>启动一个agent的时候报了一个错：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">05</span>-<span class="number">20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">710</span> (lifecycleSupervisor-<span class="number">1</span>-<span class="number">3</span>) [ERROR - org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">253</span>)] Unable to start PollableSourceRunner: &#123; source:org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125; counterGroup:&#123; name:<span class="keyword">null</span> counters:&#123;&#125; &#125; &#125; - Exception follows.</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/zookeeper/Watcher</span><br><span class="line">at java.lang.ClassLoader.defineClass1(Native Method)</span><br><span class="line">at java.lang.ClassLoader.defineClass(ClassLoader.java:<span class="number">800</span>)</span><br><span class="line">at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:<span class="number">142</span>)</span><br><span class="line">at java.net.URLClassLoader.defineClass(URLClassLoader.java:<span class="number">449</span>)</span><br><span class="line">at java.net.URLClassLoader.access$<span class="number">100</span>(URLClassLoader.java:<span class="number">71</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">361</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">at kafka.consumer.ZookeeperConsumerConnector.connectZk(ZookeeperConsumerConnector.scala:<span class="number">156</span>)</span><br><span class="line">at kafka.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">114</span>)</span><br><span class="line">at kafka.javaapi.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">65</span>)</span><br><span class="line">at kafka.javaapi.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">67</span>)</span><br><span class="line">at kafka.consumer.Consumer$.createJavaConsumerConnector(ConsumerConnector.scala:<span class="number">100</span>)</span><br><span class="line">at kafka.consumer.Consumer.createJavaConsumerConnector(ConsumerConnector.scala)</span><br><span class="line">at org.apache.flume.source.kafka.KafkaSourceUtil.getConsumer(KafkaSourceUtil.java:<span class="number">47</span>)</span><br><span class="line">at org.apache.flume.source.kafka.KafkaSource.start(KafkaSource.java:<span class="number">200</span>)</span><br><span class="line">at org.apache.flume.source.PollableSourceRunner.start(PollableSourceRunner.java:<span class="number">74</span>)</span><br><span class="line">at org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">251</span>)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">471</span>)</span><br><span class="line">at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:<span class="number">304</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$<span class="number">301</span>(ScheduledThreadPoolExecutor.java:<span class="number">178</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:<span class="number">293</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.zookeeper.Watcher</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">366</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">... <span class="number">29</span> more</span><br></pre></td></tr></table></figure></li><li><p>具体启动信息如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 flume]<span class="meta"># bin/flume-ng agent --conf conf/ --conf-file conf/kafka_source.conf --name a1 -Dflume.root.logger=INFO,console</span></span><br><span class="line">Info: Sourcing environment configuration script /opt/flume/conf/flume-env.sh</span><br><span class="line">Info: <span class="function">Including Hive libraries found <span class="title">via</span> <span class="params">()</span> <span class="keyword">for</span> Hive access</span></span><br><span class="line">+ exec /usr/local/jdk1.7.0_79/bin/java -Xmx20m -Dflume.root.logger=INFO,console -cp '/opt/flume/conf:/opt/flume/lib/*:/lib/*' -Djava.library.path= org.apache.flume.node.Application --conf-file conf/kafka_source.conf --name a1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">943</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-0</span>) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start(PollingPropertiesFileConfigurationProvider.java:<span class="number">61</span>)] Configuration provider starting</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">949</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:<span class="number">133</span>)] Reloading configuration file:conf/kafka_source.conf</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">960</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:<span class="number">931</span>)] Added sinks: k1 Agent: a1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">961</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:<span class="number">1017</span>)] Processing:k1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">962</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:<span class="number">1017</span>)] Processing:k1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">981</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.conf.FlumeConfiguration.validateConfiguration(FlumeConfiguration.java:<span class="number">141</span>)] Post-validation flume configuration contains configuration <span class="keyword">for</span> agents: [a1]</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">982</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:<span class="number">145</span>)] Creating channels</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">06</span>,<span class="number">994</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.channel.DefaultChannelFactory.create(DefaultChannelFactory.java:<span class="number">42</span>)] Creating instance of channel c1 type memory</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">001</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:<span class="number">200</span>)] Created channel c1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">003</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.source.DefaultSourceFactory.create(DefaultSourceFactory.java:<span class="number">41</span>)] Creating instance of source r1, type org.apache.flume.source.kafka.KafkaSource</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">011</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.source.kafka.KafkaSourceUtil.getKafkaProperties(KafkaSourceUtil.java:<span class="number">37</span>)] context=&#123; parameters:&#123;topic=hello, groupId=flume, zookeeperConnect=xxo08:<span class="number">2181</span>,xxo09:<span class="number">2181</span>,xxo10:<span class="number">2181</span>, kafka.consumer.timeout.ms=<span class="number">3000</span>, channels=c1, type=org.apache.flume.source.kafka.KafkaSource&#125; &#125;</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">051</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.sink.DefaultSinkFactory.create(DefaultSinkFactory.java:<span class="number">42</span>)] Creating instance of sink: k1, type: logger</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">057</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.AbstractConfigurationProvider.getConfiguration(AbstractConfigurationProvider.java:<span class="number">114</span>)] Channel c1 connected to [r1, k1]</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">071</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:<span class="number">138</span>)] Starting <span class="keyword">new</span> configuration:&#123; sourceRunners:&#123;r1=PollableSourceRunner: &#123; source:org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125; counterGroup:&#123; name:null counters:&#123;&#125; &#125; &#125;&#125; sinkRunners:&#123;k1=SinkRunner: &#123; policy:org.apache.flume.sink.DefaultSinkProcessor@<span class="number">4</span>ab9ba02 counterGroup:&#123; name:null counters:&#123;&#125; &#125; &#125;&#125; channels:&#123;c1=org.apache.flume.channel.MemoryChannel&#123;name: c1&#125;&#125; &#125;</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">071</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:<span class="number">145</span>)] Starting Channel c1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">140</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-0</span>) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.<span class="keyword">register</span>(MonitoredCounterGroup.java:<span class="number">120</span>)] Monitored counter group <span class="keyword">for</span> type: CHANNEL, name: c1: Successfully registered <span class="keyword">new</span> MBean.</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">142</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-0</span>) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:<span class="number">96</span>)] Component type: CHANNEL, name: c1 started</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">143</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:<span class="number">173</span>)] Starting Sink k1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">148</span> (conf-file-poller<span class="number">-0</span>) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:<span class="number">184</span>)] Starting Source r1</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">149</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - org.apache.flume.source.kafka.KafkaSource.start(KafkaSource.java:<span class="number">196</span>)] Starting org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125;...</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">601</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] Verifying properties</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">663</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] Property <span class="keyword">auto</span>.commit.enable is overridden to <span class="literal">false</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">663</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] Property consumer.timeout.ms is overridden to <span class="number">3000</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">663</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] Property group.id is overridden to flume</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">664</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] Property zookeeper.connect is overridden to xxo08:<span class="number">2181</span>,xxo09:<span class="number">2181</span>,xxo10:<span class="number">2181</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">708</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [INFO - kafka.utils.Logging$class.info(Logging.scala:<span class="number">68</span>)] [flume_xxo08<span class="number">-1463677867706</span>-e244b0f9], Connecting to zookeeper instance at xxo08:<span class="number">2181</span>,xxo09:<span class="number">2181</span>,xxo10:<span class="number">2181</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">710</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [ERROR - org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">253</span>)] Unable to start PollableSourceRunner: &#123; source:org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125; counterGroup:&#123; name:null counters:&#123;&#125; &#125; &#125; - Exception follows.</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/zookeeper/Watcher</span><br><span class="line">at java.lang.ClassLoader.defineClass1(Native Method)</span><br><span class="line">at java.lang.ClassLoader.defineClass(ClassLoader.java:<span class="number">800</span>)</span><br><span class="line">at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:<span class="number">142</span>)</span><br><span class="line">at java.net.URLClassLoader.defineClass(URLClassLoader.java:<span class="number">449</span>)</span><br><span class="line">at java.net.URLClassLoader.access$<span class="number">100</span>(URLClassLoader.java:<span class="number">71</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1.</span>run(URLClassLoader.java:<span class="number">361</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1.</span>run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">at kafka.consumer.ZookeeperConsumerConnector.connectZk(ZookeeperConsumerConnector.scala:<span class="number">156</span>)</span><br><span class="line">at kafka.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">114</span>)</span><br><span class="line">at kafka.javaapi.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">65</span>)</span><br><span class="line">at kafka.javaapi.consumer.ZookeeperConsumerConnector.&lt;init&gt;(ZookeeperConsumerConnector.scala:<span class="number">67</span>)</span><br><span class="line">at kafka.consumer.Consumer$.createJavaConsumerConnector(ConsumerConnector.scala:<span class="number">100</span>)</span><br><span class="line">at kafka.consumer.Consumer.createJavaConsumerConnector(ConsumerConnector.scala)</span><br><span class="line">at org.apache.flume.source.kafka.KafkaSourceUtil.getConsumer(KafkaSourceUtil.java:<span class="number">47</span>)</span><br><span class="line">at org.apache.flume.source.kafka.KafkaSource.start(KafkaSource.java:<span class="number">200</span>)</span><br><span class="line">at org.apache.flume.source.PollableSourceRunner.start(PollableSourceRunner.java:<span class="number">74</span>)</span><br><span class="line">at org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">251</span>)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">471</span>)</span><br><span class="line">at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:<span class="number">304</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$<span class="number">301</span>(ScheduledThreadPoolExecutor.java:<span class="number">178</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:<span class="number">293</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.zookeeper.Watcher</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1.</span>run(URLClassLoader.java:<span class="number">366</span>)</span><br><span class="line">at java.net.URLClassLoader$<span class="number">1.</span>run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">... <span class="number">29</span> more</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">07</span>,<span class="number">719</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-3</span>) [ERROR - org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">264</span>)] Unsuccessful attempt to shutdown component: &#123;&#125; due to missing dependencies. Please shutdown the agentor disable <span class="keyword">this</span> component, <span class="keyword">or</span> the agent will bein an undefined state.</span><br><span class="line">java.lang.NullPointerException</span><br><span class="line">at org.apache.flume.source.PollableSourceRunner$PollingRunner.access$<span class="number">200</span>(PollableSourceRunner.java:<span class="number">125</span>)</span><br><span class="line">at org.apache.flume.source.PollableSourceRunner.stop(PollableSourceRunner.java:<span class="number">93</span>)</span><br><span class="line">at org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">259</span>)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">471</span>)</span><br><span class="line">at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:<span class="number">304</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$<span class="number">301</span>(ScheduledThreadPoolExecutor.java:<span class="number">178</span>)</span><br><span class="line">at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:<span class="number">293</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">10</span>,<span class="number">723</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-2</span>) [INFO - org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">233</span>)] Component PollableSourceRunner: &#123; source:org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125; counterGroup:&#123; name:null counters:&#123;&#125; &#125; &#125; is in error state, <span class="keyword">and</span> Flume will notattempt to change its state</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">13</span>,<span class="number">726</span> (lifecycleSupervisor<span class="number">-1</span><span class="number">-2</span>) [INFO - org.apache.flume.lifecycle.LifecycleSupervisor$MonitorRunnable.run(LifecycleSupervisor.java:<span class="number">233</span>)] Component PollableSourceRunner: &#123; source:org.apache.flume.source.kafka.KafkaSource&#123;name:r1,state:IDLE&#125; counterGroup:&#123; name:null counters:&#123;&#125; &#125; &#125; is in error state, <span class="keyword">and</span> Flume will notattempt to change its state</span><br><span class="line">^C2016<span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">610</span> (agent-shutdown-hook) [INFO - org.apache.flume.lifecycle.LifecycleSupervisor.stop(LifecycleSupervisor.java:<span class="number">79</span>)] Stopping lifecycle supervisor <span class="number">10</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">615</span> (agent-shutdown-hook) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop(PollingPropertiesFileConfigurationProvider.java:<span class="number">83</span>)] Configuration provider stopping</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">616</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">150</span>)] Component type: CHANNEL, name: c1 stopped</span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">617</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">156</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.start.time == <span class="number">1463677867142</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">617</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">162</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.stop.time == <span class="number">1463677874616</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">618</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.capacity == <span class="number">1000</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">618</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.current.size == <span class="number">0</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">618</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.event.put.attempt == <span class="number">0</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">618</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.event.put.success == <span class="number">0</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">619</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.event.take.attempt == <span class="number">2</span></span><br><span class="line"><span class="number">2016</span><span class="number">-05</span><span class="number">-20</span> <span class="number">01</span>:<span class="number">11</span>:<span class="number">14</span>,<span class="number">620</span> (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:<span class="number">178</span>)] Shutdown Metric <span class="keyword">for</span> type: CHANNEL, name: c1. channel.event.take.success == <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ul><li><strong>缺少了zookeeper-**</strong>.jar，博主这里的为：zookeeper-3.4.6.jar**</li></ul><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ul><li><strong>三种解决办法</strong>：</li></ul><ol><li>把 zookeeper-3.4.6.jar 拷贝到<code>${FLUME_HOME}/lib</code>下面，比如我的flume在/opt下面，我需要拷贝到<code>/opt/flume/lib/</code>下面。</li><li>配置 <strong>FLUME_CLASSPATH</strong>=”<strong>zookeeper jar 的地址</strong>“（默认注释掉了），例如：<code>FLUME_CLASSPATH=&quot;/opt/zookeeper/zookeeper-3.4.6.jar&quot;</code>（即指定到我zk下面的jar）。</li><li>博主测试时，机器中同时安装了 hadoop 也是可以的，因为 hadoop lib 下面默认带了 zk 的jar。</li></ol><p>　　　　　</p>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flume </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>游记--晴空万里的阳台山</title>
      <link href="/2016/05/16/%E6%B8%B8%E8%AE%B0-%E6%99%B4%E7%A9%BA%E4%B8%87%E9%87%8C%E7%9A%84%E9%98%B3%E5%8F%B0%E5%B1%B1/"/>
      <url>/2016/05/16/%E6%B8%B8%E8%AE%B0-%E6%99%B4%E7%A9%BA%E4%B8%87%E9%87%8C%E7%9A%84%E9%98%B3%E5%8F%B0%E5%B1%B1/</url>
      <content type="html"><![CDATA[<p>　　周五的时候，好友打来电话，说想出去<strong>爆走</strong>，正好我也有这个打算，于是让她准备了行程（<em>阳台山</em>），<strong>周日出发</strong>。周六还下着大雨，查了查天气，周日晴。<strong>也刚好是周六的雨造就了周日的晴空万里</strong>。——晴空万里的阳台山</p><h2 id="行程安排"><a href="#行程安排" class="headerlink" title="行程安排"></a>行程安排</h2><p>　　- 首次乘坐的地铁：从天通苑6：00出发，乘坐地铁5号线–（惠新西街南口转）–10号线–（海淀黄庄转）–4号大兴线–到达西苑。<br>　　- 从西苑不行4分钟作用到达346公交起始站，到北安河西口下车。<br><a id="more"></a></p><h2 id="出发"><a href="#出发" class="headerlink" title="出发"></a>出发</h2><ul><li>坐了一个多小时的地铁到达目的地，和好友汇合。看了下时间才7点过几分，就在对面的麦当劳吃了个早饭，<strong>吃完后7点半左右</strong>。</li><li><p>下图就是我的好友-晓玉。（<code>ps：我们不是男女朋友，是多年的好友</code>）<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_073701.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="刚吃饭早饭"></p></li><li><p>早饭过后，继续走向346公交站（起始站），5分钟左右到达。</p></li></ul><h2 id="到达目的地"><a href="#到达目的地" class="headerlink" title="到达目的地"></a>到达目的地</h2><ul><li><p>公交到站后，向西大概走800米到达目的地（也就是沿着下公交的那条公路继续向前走，ps：南方人一般分不清东南西北方向）。<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_083750.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="8:37到达目的地，阳台山"></p></li><li><p>门票10元，接下来就会走一段妙峰古道，也挺有意思的。是通往妙峰山享有盛名的一道靓丽风景线<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_085844.jpg?imageView2/1/w/400/h/450&amp;raw=true" alt="妙峰古道"></p></li><li><p>骆驼石为阳台山古香道上著名天然奇石之一，由无数卵砾挤压而成，地壳变迁使其停留于此。石高5米、长7米、重达百吨。现石刻为1997年制作<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_092047.jpg?imageView2/1/w/400/h/450&amp;raw=true" alt="古道，沿途的风景"></p></li><li><p>古道号称“金阶”，相传清朝同治年间，太监刘诚印和安德海为讨好慈禧太后，修治妙峰古道，用当地产岩石砌成台阶，山高路险，工程艰难，每铺石块就得用银一两，耗资巨大，切石成金故称“<strong>金阶</strong>”。路旁有“<strong>善来金阶</strong>”石刻为证。<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_091048.jpg?imageView2/1/w/400/h/450&amp;raw=true" alt="古道，沿途的风景"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_092027.jpg?imageView2/1/w/500/h/450&amp;raw=true" alt="善来金阶"></p></li></ul><h3 id="到达了半山腰"><a href="#到达了半山腰" class="headerlink" title="到达了半山腰"></a>到达了半山腰</h3><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_095401.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="沿途的风景"></p><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_103354.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="雨后的空气特别好"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_105622.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="白云蓝天"></p><h3 id="开始相互拍照了"><a href="#开始相互拍照了" class="headerlink" title="开始相互拍照了"></a>开始相互拍照了</h3><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_103119.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="先偷拍一张"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_111721.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="嘿嘿，拍一张"></p><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_110627.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt=""></p><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_110655.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt=""></p><h3 id="继续前进"><a href="#继续前进" class="headerlink" title="继续前进"></a>继续前进</h3><ul><li><p>看看这向上的生命<br><img src="http://photo.xiaoxiaomo.com/mmexport1463305672060.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="路边的花花草草"></p></li><li><p>这时候，脚开始有那么一点酸了，可以停下来休息一会儿，吃点东西，喝点水<br><img src="http://photo.xiaoxiaomo.com/mmexport1463305675264.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="休息中。。。。。。。"></p></li><li><p>经过体力的补充，很快的又上了一个阶段<br><img src="http://photo.xiaoxiaomo.com/mmexport1463305683098.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="又上了一层"></p></li><li><p>来一个全景图<br><img src="http://photo.xiaoxiaomo.com/mmexport1463305691894.jpg?imageView2/1/w/800/h/450&amp;raw=true" alt="全景图"></p></li></ul><h3 id="到达山顶"><a href="#到达山顶" class="headerlink" title="到达山顶"></a>到达山顶</h3><ul><li><p>11：30左右，到达山顶，上面有卖水的，休息了片刻，看看山上的风景，此时山上还有风，吹着风，拍拍照，我们就沿着阳台山的公路继续前进（向凤凰山方向）<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_113735.jpg?imageView2/1/w/800/h/450&amp;raw=true" alt="这白云挺好看的"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_113641.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="崎岖的公路"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_121533.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="沿途的风景"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_121558.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="空气特别好"><br><img src="http://photo.xiaoxiaomo.com/mmexport1463305711647.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"></p></li><li><p>我们从山顶的另一面下去<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_122056.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt=""><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_122133.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="很成功的一次性抓拍到"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_122511.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="感受一下风有多大"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_122946.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="挺美的"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_122953.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="天气实在是太好了"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_123004.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="留影"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_123018.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="这山路，牛逼"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_123040.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt=""><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_123301.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="心情舒畅，一路小跑下来"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_130156.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt=""><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_130219.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="休息中"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_130445.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="继续前进"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_130535.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="继续前进"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_130557.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="运动一下"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_131048.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="来一个自拍"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_131448.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="观望台"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_131552.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="看那吊吊的样子，想找打"></p></li></ul><h2 id="下山"><a href="#下山" class="headerlink" title="下山"></a>下山</h2><ul><li>我们从这个观望台左边的小路下山的，不想继续走上山的那条路了，其实我们也不知道这条路会通到哪里，但是应该可以下山。<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_134131.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="在这里还遇到了一个小松鼠"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_140742.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="无时无刻都不忘拍照的妹子"></li><li>快两点半了，感觉快到山下了，因为视野开阔了，不再是成片的树林<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142429.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="山路"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142413.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="快到了"></li><li><p>一路走来，感觉这里最危险了<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142442.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="一个危险的地方"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142458.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="要小心点"></p></li><li><p>继续前进，一路上没什么人，知道有一个泉水的地方，这里倒是有很多人在接泉水，应该挺出名的，在山下上来的人也在打听这个泉水我们也顺便在这里休息了一会儿。<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142736.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142806.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"></p></li><li><p>就这样来到了凤凰岭<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_144351.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="凤凰岭"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_145228.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="凤凰岭"></p></li></ul><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_145935.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_145947.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_145954.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_150441.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_150447.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_150854.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_142736.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="到达山顶"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_150755_1.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="休息中，留影"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_150913.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="看，她也累了"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_151148.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="风景"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_151157.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="感觉像一个笑脸"></p><h3 id="摘樱桃"><a href="#摘樱桃" class="headerlink" title="摘樱桃"></a>摘樱桃</h3><ul><li>下山的时候，有特别多的樱桃园</li><li>我们就进去摘樱桃了，在摘的过程中，吃了特别多<br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_160625.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="摘樱桃"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_160641.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="摘樱桃"><br><img src="http://photo.xiaoxiaomo.com/IMG_20160515_162702.jpg?imageView2/1/w/400/h/300&amp;raw=true" alt="樱桃"></li></ul><h3 id="回家休息了"><a href="#回家休息了" class="headerlink" title="回家休息了"></a>回家休息了</h3><p><img src="http://photo.xiaoxiaomo.com/IMG_20160515_182702.png?imageView2/1/w/400/h/580&amp;raw=true" alt="回家休息了"></p>]]></content>
      
      <categories>
          
          <category> 游记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 游记 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka--Consumer消费者</title>
      <link href="/2016/05/14/Kafka-Consumer%E6%B6%88%E8%B4%B9%E8%80%85/"/>
      <url>/2016/05/14/Kafka-Consumer%E6%B6%88%E8%B4%B9%E8%80%85/</url>
      <content type="html"><![CDATA[<p>　　Kafka 的 consumer 是以<strong>pull</strong>的形式获取消息数据的。 <strong>producer push消息到kafka cluster ，consumer从集群中pull消息</strong>，如下图。该博客主要讲解. Parts在消费者中的<strong>分配</strong>、以及相关的<strong>消费者顺序</strong>、<strong>底层结构元数据信息</strong>、<strong>Kafka数据读取和存储等</strong>。<br>　　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514200520.png" alt="kafka消息生产/消费"></p><h2 id="Parts在消费者中的分配"><a href="#Parts在消费者中的分配" class="headerlink" title="Parts在消费者中的分配"></a>Parts在消费者中的分配</h2><ul><li><strong>首先partition和consumer都会字典排序</strong></li></ul><ol><li><strong>分区Partition从小到大排序</strong>：分区顺序是0,1,2,3,4,5,6,7,8,9</li><li><strong>消费者Consumer id按照字典顺序排序</strong>：f0b87809-0, f1b87809-0, f1b87809-1</li></ol><a id="more"></a><ul><li><strong>如何计算分区</strong></li></ul><ol><li><strong>首先确认最少分区数</strong>： partition/consumer</li><li><strong>再确定额外分配数</strong>： partition%consumer</li></ol><ul><li><p><strong>源码算法</strong>：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514184131.png" alt="Partition的"><br>比如：有4个partition,3个consumer,这第一个就会分配2个，其他会分配一个。</p></li><li><p><strong>下面我们来演示一下Kafka强大的平衡机制吧(就是看看怎麼自動分配partition，同一topic)</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################下面是我们有4个Partition###################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 1Replicas: 1,2,0Isr: 1,2,0</span><br><span class="line">Topic: worldPartition: 1Leader: 2Replicas: 2,0,1Isr: 2,0,1</span><br><span class="line">Topic: worldPartition: 2Leader: 0Replicas: 0,1,2Isr: 0,1,2</span><br><span class="line">Topic: worldPartition: 3Leader: 1Replicas: 1,0,2Isr: 1,0,2</span><br></pre></td></tr></table></figure></li></ul><ol><li><p>当我们只有1个consumer时：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514193419.png" alt="1个consumer分配了4个partition"></p></li><li><p>我们接着再启动一个consumer<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514194256.png" alt="新启动的consumer分配了2个partition"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514194716.png" alt="原来的的consumer从新分配为2个partition"></p></li><li><p>大家明白了吧，我就不再继续启动了。<strong>增加或减少，consumer都会触发分区，重新分区。</strong></p></li></ol><h2 id="消费者顺序"><a href="#消费者顺序" class="headerlink" title="消费者顺序"></a>消费者顺序</h2><ul><li><strong>消费顺序对于组来说</strong>：</li></ul><ol><li>每一个消费者之间是<strong>无序的</strong>。</li><li>同一个消费者对应一个Partition是<strong>offset有序的</strong>。</li><li>同一个消费者对应多个Partition是<strong>顺序消费至最新状态</strong>。</li></ol><ul><li><strong>演示1</strong>：同一个消费者对应一个Partition是<strong>offset有序的</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################创建1个partition###################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partitions 1  --topic hello</span></span><br><span class="line">Created topic <span class="string">"hello"</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################查看 partition ###################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic hello</span></span><br><span class="line">Topic:helloPartitionCount:1ReplicationFactor:3Configs:</span><br><span class="line">Topic: helloPartition: 0Leader: 0Replicas: 0,1,2Isr: 0,1,2</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514205257.png" alt="对应一个Partition消费者有序消费数据"></p><ul><li><strong>演示2</strong>：同一个消费者对应多个Partition是<strong>顺序消费至最新状态</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################继续增加2个partition################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --alter --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 -partitions 3 --topic hello</span></span><br><span class="line">WARNING: If partitions are increased <span class="keyword">for</span> a topic that has a key, the partition logic or ordering of the messages will be affected</span><br><span class="line">Adding partitions succeeded!</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################查看 partition ###################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic hello</span></span><br><span class="line">Topic:helloPartitionCount:3ReplicationFactor:3Configs:</span><br><span class="line">Topic: helloPartition: 0Leader: 0Replicas: 0,1,2Isr: 0,1,2</span><br><span class="line">Topic: helloPartition: 1Leader: 1Replicas: 1,2,0Isr: 1,2,0</span><br><span class="line">Topic: helloPartition: 2Leader: 2Replicas: 2,0,1Isr: 2,0,1</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514211044.png" alt="对应多个Partition消费者顺序消费至最新状态"></p><h2 id="Kafka底层结构"><a href="#Kafka底层结构" class="headerlink" title="Kafka底层结构"></a>Kafka底层结构</h2><ul><li>分爲兩個部分<ol><li>broker   ：简单理解为topic的元数据信息（topics,ids），包含topic的分区情况、leader、状态、数据大小、地址端口、版本</li><li>consumer ：消费者的元数据信息，重点就是offset了。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514215445.png" alt="Kafka元数据结构图"></li></ol></li></ul><h3 id="Broker元数据"><a href="#Broker元数据" class="headerlink" title="Broker元数据"></a>Broker元数据</h3><h4 id="topics"><a href="#topics" class="headerlink" title="topics"></a>topics</h4><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514223520.png" alt="Broker topics"></p><h4 id="ids"><a href="#ids" class="headerlink" title="ids"></a>ids</h4><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514224801.png" alt="Broker ids"></p><h3 id="Consumer元数据"><a href="#Consumer元数据" class="headerlink" title="Consumer元数据"></a>Consumer元数据</h3><p>Partition：为了实现扩展性，一个非常大的topic可以分布到多个 broker 上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息 都会被分配一个有序的id（offset）。从上面示例我们也可以看出<strong>kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体 （多个partition间）的顺序。</strong></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514212150.png" alt="Partition写入状态"></p><p><strong>分区就是一个有序的,不可变的消息队列.新来的commit log持续往后面加数据.这些消息被分配了一个下标(或者偏移),就是offset,用来定位这一条消息。</strong></p><h4 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h4><ul><li><p>从上面得知，partition自己维护了一个offset，我们知道zk中保留了kafka的元数据信息。下面我们来看一下底层结构运行<strong>/opt/zookeeper/bin/zkCli.sh</strong> ：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514214722.png" alt="zookeeper元数据查看"></p></li><li><p><strong>注意</strong>：上图中offset=18不是即使更新到zk中的，默认是一分钟，可以设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########true时，Consumer会在消费消息后将offset同步到zookeeper################</span></span><br><span class="line"><span class="comment">#########当Consumer失败后，新的consumer就能从zookeeper获取最新的offset#########</span></span><br><span class="line">auto.commit.enable = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#########自动提交的时间间隔(默认如下60秒)#####################################</span></span><br><span class="line">auto.commit.interval.ms = 60 * 1000</span><br></pre></td></tr></table></figure></li></ul><h4 id="owners"><a href="#owners" class="headerlink" title="owners"></a>owners</h4><ul><li>里面存放了消费者ID<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514221850.png" alt="消费者进程ID"></li></ul><h4 id="ids-1"><a href="#ids-1" class="headerlink" title="ids"></a>ids</h4><p>ids： Consumer进程id，每一个consumer进程就有一个id（<em>每一个进程可以设置多个consumer线程</em>）。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514222441.png" alt="再启动一个consumer来看一下效果"></p><ul><li>我们再来查看一下ids:<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514223404.png" alt="消费者ids"></li></ul><h2 id="Kafka数据读取-存储"><a href="#Kafka数据读取-存储" class="headerlink" title="Kafka数据读取/存储"></a>Kafka数据读取/存储</h2><ul><li>先看一下本地log目录的分区文件夹，如下（<em>我的kafka存储的数据比较小，对应的partition都为0。该segment可以设置：<strong>log.segment.bytes</strong>，制日志segment文件的大小，超出该大小则追加到一个新的日志segment文件中（-1表示没有限制）</em>）：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 kafka]<span class="comment"># tree ../kafka-logs/</span></span><br><span class="line">../kafka-logs/</span><br><span class="line">├── hello-0</span><br><span class="line">│   ├── 00000000000000000000.index     <span class="comment">##索引文件</span></span><br><span class="line">│   └── 00000000000000000000.log       <span class="comment">##日志文件</span></span><br><span class="line">├── hello-1</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   └── 00000000000000000000.log</span><br><span class="line">├── hello-2</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   └── 00000000000000000000.log</span><br><span class="line">├── recovery-point-offset-checkpoint</span><br><span class="line">├── replication-offset-checkpoint</span><br><span class="line">├── world-0</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   └── 00000000000000000000.log</span><br><span class="line">├── world-1</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   └── 00000000000000000000.log</span><br><span class="line">├── world-2</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   └── 00000000000000000000.log</span><br><span class="line">└── world-3</span><br><span class="line">    ├── 00000000000000000000.index</span><br><span class="line">    └── 00000000000000000000.log</span><br><span class="line">7 directories, 16 files</span><br></pre></td></tr></table></figure></li></ul><h3 id="存储策略"><a href="#存储策略" class="headerlink" title="存储策略"></a>存储策略</h3><p><strong>partition存储的时候,分成了多个segment(段),然后通过一个index,索引,来标识第几段.</strong></p><ul><li><strong>具体的流程</strong>：<br>发布者发到某个topic的 消息会被分布到多个partition上（<em>随机或根据用户指定的函数进行分布</em>），broker收到发布消息往对应partition的最后一个segment上添加 该消息，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514231935.png" alt="kafka 存储策略"></p><h3 id="高效读取"><a href="#高效读取" class="headerlink" title="高效读取"></a>高效读取</h3><ul><li><strong>kafka高效读取有两个重要的东西，分段和索引</strong>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514232049.png" alt="kafka 高效读取"></li></ul><ol><li><p>每个片段一个文件并且此文件以该片段中最小的offset命名，<strong>查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个段中。</strong></p></li><li><p><strong>为每个分段后的数据文件建立了索引文件(index)</strong>，存储了【<strong>offset和message在文件中的position</strong>】。index中采用了<strong>稀疏存储</strong>。</p></li></ol><ul><li><strong>具体查找方法： </strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############比如我们有文件,需要查找2016的文件##################</span></span><br><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000002000.index</span><br><span class="line">00000000000000002000.log</span><br></pre></td></tr></table></figure></li></ul><ol><li>首先通过<strong>zk的元数据</strong>信息找到（position、broker、topic）然后我们就能在<strong>Partition的内存索引</strong>中根据<strong>offset </strong>2016找到到相应topic的文件位置和index文件。</li><li>把<strong>index文件加载到内容中，然后开始读取</strong>。</li><li>由于是稀疏索引所以相对来说节约空间，跳跃式的查找然后进一步找到2016，读取到<strong>对应的posistion</strong>。</li><li>最后通过posistion去找到<strong>message数据</strong>。</li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka--集群及API操作</title>
      <link href="/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/"/>
      <url>/2016/05/14/Kafka-%E9%9B%86%E7%BE%A4%E5%8F%8AAPI%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>　　本篇博客，主要讲解<strong>kafka集群配置</strong>、<strong>kafka的容错</strong>和<strong>kafka扩展机制</strong>。以及使用kafka<strong>模拟一个网络流量实时统计</strong>来看一看Kafka的一些api使用方法。</p><h2 id="kafka集群"><a href="#kafka集群" class="headerlink" title="kafka集群"></a>kafka集群</h2><h3 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h3><ul><li><strong>一、准备</strong>集群机器（这里使用3台）：主机名xxo08、xxo09、xxo10（<em>我把zookeeper集群也放在了这里</em>）。</li><li><p><strong>二、搭建并启动 </strong><a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"><strong>zookeeper集群</strong></a>。</p></li><li><p><strong>三、修改配置文件</strong></p></li></ul><ol><li>/opt/kafka/config/server.properties <strong>broker.id=0</strong>　　##broker的id每一个broker应该不同</li><li>log.dirs=<strong>/opt/kafka_logs</strong>　　##</li><li>zookeeper.connect=<strong>xxo08:2181,xxo09:2181,xxo10:2181</strong>  ##<strong>注意</strong>：我的zokeeper也在这三台机器上</li></ol><ul><li><strong>四、同步其它节点</strong><br>scp -r /opt/kafka/ root@xxo09:/opt/<br>scp -r /opt/kafka/ root@xxo10:/opt/<br>并修改<br>xxo09 /opt/kafka/config/server.properties <strong>broker.id=1</strong>　　##broker的id<br>xxo10 /opt/kafka/config/server.properties <strong>broker.id=2</strong>　　##broker的id</li></ul><a id="more"></a><ul><li><strong>五、启动所有server</strong><br>nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt;&gt;/opt/logs/kafka-server.log 2&gt;&amp;1 &amp;</li></ul><ul><li><p><strong>六、查看进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 ~]<span class="comment"># jps</span></span><br><span class="line">1337 QuorumPeerMain   <span class="comment">##zookeeper</span></span><br><span class="line">1411 Jps</span><br><span class="line">1362 Kafka      <span class="comment">##kafka</span></span><br></pre></td></tr></table></figure></li><li><p><strong>总结： </strong>对于broker来说是所有broker是独立的，由zk来协调管理。</p></li></ul><h2 id="容错和扩展机制"><a href="#容错和扩展机制" class="headerlink" title="容错和扩展机制"></a>容错和扩展机制</h2><p>上篇博客<a href="http://blog.xiaoxiaomo.com/2016/05/13/Kafka-分布式消息队列/">Kafka-分布式消息队列/</a>中我们使用了单机的kafka,在创建一个topic的时候，副本 <strong>replication-factor</strong> 指定为 <strong>1</strong>(<em>我们只有一个broker也只能指定为1</em>)。现在我们搭建了集群，三个kafka服务（<em>3个broker</em>）我们最多就能创建三个副本了。记住：<strong>kafka容错的保障是他的副本机制！</strong></p><h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><p><strong>如果，kafka集群中某个broker挂掉（fails），则zk会选择新的broker提供服务。</strong></p><ul><li><strong>下面来做一个测试，模拟节点宕机或挂掉，这里就强制kill掉某个kafka服务吧！</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########################1、创建一个hello的topic##################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partitions 4  --topic world</span></span><br><span class="line">Created topic <span class="string">"world"</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment">########################2、查看一下hello (分布在4个partition中，每个P有三个备份)####</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 2 Replicas: 2,1,0Isr: 2,1,0</span><br><span class="line">Topic: worldPartition: 1Leader: 0 Replicas: 0,2,1Isr: 0,2,1</span><br><span class="line">Topic: worldPartition: 2Leader: 1 Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 2 Replicas: 2,0,1Isr: 2,0,1</span><br><span class="line"><span class="comment">###############PartitionCount：　当前topic分区数</span></span><br><span class="line"><span class="comment">###############ReplicationFactor： 当前topic副本数</span></span><br><span class="line"><span class="comment">###############Configs： 当前topic自定义配置信息</span></span><br><span class="line"><span class="comment">###############Partition： patition序号</span></span><br><span class="line"><span class="comment">###############Leader： Leader的brokerID</span></span><br><span class="line"><span class="comment">###############Replicas： 所有副本的brokerId</span></span><br><span class="line"><span class="comment">###############Isr： 所有存活（可用）的brokerId</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################3、下面我们来强制kill掉,brokerId等于2的#####################</span></span><br><span class="line"><span class="comment">#######################注意我们在xxo10（brokerId=2）上操作#########################</span></span><br><span class="line">[root@xxo10 ~]<span class="comment"># jps</span></span><br><span class="line">1270 Kafka</span><br><span class="line">1372 Jps</span><br><span class="line">1245 QuorumPeerMain</span><br><span class="line">[root@xxo10 ~]<span class="comment"># kill -9 1270   ###########强制kill掉</span></span><br><span class="line">[root@xxo10 ~]<span class="comment"># jps</span></span><br><span class="line">1245 QuorumPeerMain</span><br><span class="line">1382 Jps</span><br><span class="line">[root@xxo10 ~]<span class="comment"># cd /opt/kafka</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################4、再来看一下topic 就会发现平衡机制已经重启分配partitoin######</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 1Replicas: 2,1,0Isr: 1,0</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0</span><br><span class="line">Topic: worldPartition: 3Leader: 0Replicas: 2,0,1Isr: 0,1</span><br></pre></td></tr></table></figure></li></ul><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>对于扩容，是公司中使用教多的，比如集群不够了，重新购买了服务器，需要把这台服务器加入到kafak集群中。新加入的这个节点<strong>zk会自动识别</strong>并让它在适当的机会选择此节点提供服务。</p><ol><li>新加入的节点，<strong>配置信息(<em>server.properties</em>)记得保持相对一致</strong>。</li><li>修改<strong>broker.id</strong>、<strong>log.dirs</strong>、<strong>zookeeper.connect</strong></li><li>如果直接拷贝kafka,记得拷贝后新节点<strong>zk和kafka的存储路径</strong>应该把数据都删掉，防止数据不一致问题。因为<strong>zk的dataDir里面存储了zk和kafka的元数据</strong>信息，<strong>kafka的数据在kafka的Data目录</strong>就会多出一下奇怪的数据。</li></ol><ul><li><strong>下面我们就假如新加入了一个节点就是xxo10(brokerId=2)，先来启动该节点</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 kafka]<span class="comment"># nohup bin/kafka-server-start.sh config/server.properties &gt;&gt; ../logs/kafka-server.log 2&gt;</span></span><br><span class="line">&amp;1 &amp;</span><br><span class="line">[1] 1412</span><br><span class="line"><span class="comment">##########1、启动后会发现这个节点不会是任何分区的leader，在Isr能看见它以存活########</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 1Replicas: 2,1,0Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1,2</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 0Replicas: 2,0,1Isr: 0,1,2</span><br><span class="line"></span><br><span class="line"><span class="comment">##########2、怎么重新均匀分配？########</span></span><br><span class="line"><span class="comment">##########2.1、Broker配置中的自动均衡策略######################################</span></span><br><span class="line"><span class="comment">#####Auto.leader.rebalance.enable=true######################################</span></span><br><span class="line"><span class="comment">#####leader.imbalance.check.interval.seconds 默认值：300#####################</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##########2.2、手动配置执行###################################################</span></span><br><span class="line"><span class="comment">##########下面我们手动配置一下#################################################</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-preferred-replica-election.sh --zookeeper xxo08:2181,xxo09:2181,xxo10:2181</span></span><br><span class="line">Successfully started preferred replica election <span class="keyword">for</span> partitions Set([world,0], [world,2], [world,3], [world,1])</span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 2Replicas: 2,1,0Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1,2</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 2Replicas: 2,0,1Isr: 0,1,2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####负载均衡，Kafka提供了一个 metadata API来管理broker之间的负载（对于0.7.x主要靠zookeeper来实现负载均衡）。</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="API操作"><a href="#API操作" class="headerlink" title="API操作"></a>API操作</h2><p>kafka使用了scala编写，但是提供了很多语言的API接口。比如scala、java、python、R、PHP等。<br>这里我就<strong>使用java来模拟一个网页流量的实时统计处理</strong>：</p><ul><li><p><strong>项目结构</strong>：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514162644.png" alt="项目结构"></p></li><li><p>一、<strong>配置文件</strong></p></li></ul><hr><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">###############<span class="meta">#producer.properties##########################</span></span><br><span class="line">metadata.broker.<span class="built_in">list</span>=xxo08:<span class="number">9092</span>,xxo09:<span class="number">9092</span>,xxo10:<span class="number">9092</span></span><br><span class="line">partitioner.class=com.xxo.kafka.MyPartition</span><br><span class="line">producer.type=sync</span><br><span class="line">compression.codec=none</span><br><span class="line">serializer.class=kafka.serializer.StringEncoder</span><br><span class="line"></span><br><span class="line">################consumer.properties##########################</span><br><span class="line">zookeeper.connect=xxo08:<span class="number">2181</span>,xxo08:<span class="number">2181</span>,xxo08:<span class="number">2181</span></span><br><span class="line">zookeeper.connection.timeout.ms=<span class="number">6000</span></span><br><span class="line">group.id=xiaoxiaomo  ###组ID</span><br></pre></td></tr></table></figure><ul><li><p>二、<strong>生产者，模拟用户访问数据</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> kafka.producer.KeyedMessage;</span><br><span class="line"><span class="keyword">import</span> kafka.producer.ProducerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 模拟生产用户访问数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProduceUserData</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> Map&lt;Integer,String&gt; path = <span class="keyword">new</span> HashMap&lt;Integer, String&gt;();</span><br><span class="line">    <span class="keyword">static</span> Map&lt;Integer,Integer&gt; userId = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建一个生产者对象</span></span><br><span class="line">        Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">        prop.load( ProduceUserData.class.getClassLoader().getResourceAsStream(<span class="string">"producer.properties"</span>) );</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> Producer&lt;String, String&gt;(<span class="keyword">new</span> ProducerConfig( prop ));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 构造message</span></span><br><span class="line">        String topic = <span class="string">"world"</span> ;  <span class="comment">//world 主题</span></span><br><span class="line">        List&lt;KeyedMessage&lt;String,String&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;KeyedMessage&lt;String, String&gt;&gt;() ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//用户数据</span></span><br><span class="line">        <span class="comment">//init path</span></span><br><span class="line">        path.put(<span class="number">0</span>,<span class="string">"http://xiaoxiaomo.com/"</span>);</span><br><span class="line">        path.put(<span class="number">1</span>,<span class="string">"http://blog.xiaoxiaomo.com/"</span>);</span><br><span class="line">        path.put(<span class="number">2</span>,<span class="string">"http://blog.xiaoxiaomo.com/archives/"</span>);</span><br><span class="line">        path.put(<span class="number">3</span>,<span class="string">"http://blog.xiaoxiaomo.com/photo/"</span>);</span><br><span class="line">        path.put(<span class="number">4</span>,<span class="string">"http://blog.xiaoxiaomo.com/about/"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//init userId</span></span><br><span class="line">        userId.put(<span class="number">0</span>,<span class="number">2010</span>);</span><br><span class="line">        userId.put(<span class="number">1</span>,<span class="number">1001</span>);</span><br><span class="line">        userId.put(<span class="number">2</span>,<span class="number">1002</span>);</span><br><span class="line">        userId.put(<span class="number">3</span>,<span class="number">2001</span>);</span><br><span class="line">        userId.put(<span class="number">4</span>,<span class="number">2002</span>);</span><br><span class="line">        userId.put(<span class="number">5</span>,<span class="number">3003</span>);</span><br><span class="line">        userId.put(<span class="number">6</span>,<span class="number">4004</span>);</span><br><span class="line">        userId.put(<span class="number">7</span>,<span class="number">1007</span>);</span><br><span class="line">        userId.put(<span class="number">8</span>,<span class="number">1008</span>);</span><br><span class="line">        userId.put(<span class="number">9</span>,<span class="number">1009</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">while</span> ( <span class="keyword">true</span> )&#123;</span><br><span class="line">            <span class="comment">//随机产生数据</span></span><br><span class="line">            <span class="keyword">int</span> pathIndex=random.nextInt(<span class="number">5</span>);</span><br><span class="line">            <span class="keyword">int</span> userIndex=random.nextInt(<span class="number">10</span>);</span><br><span class="line">            <span class="keyword">int</span> isVip=random.nextInt(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//构造一个用户访问数据</span></span><br><span class="line">            String visData = String.format(<span class="string">"%s\t%s\t%s\t%s"</span>,</span><br><span class="line">                    userId.get(userIndex),</span><br><span class="line">                    path.get(pathIndex),</span><br><span class="line">                    <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>).format(<span class="keyword">new</span> Date()), isVip) ;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//使用了pathIndex作为一个Key分区用</span></span><br><span class="line">            list.add( <span class="keyword">new</span> KeyedMessage&lt;String, String&gt;( topic ,String.valueOf(pathIndex) , visData ) );</span><br><span class="line"></span><br><span class="line">            <span class="comment">//3. 发送</span></span><br><span class="line">            producer.send(list);</span><br><span class="line"></span><br><span class="line">            Thread.sleep( random.nextInt(<span class="number">2000</span>) );</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭</span></span><br><span class="line">        <span class="comment">//producer.close();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>三、<strong>消费者，处理用户访问日志信息</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.consumer.Consumer;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.ConsumerIterator;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.KafkaStream;</span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.consumer.ConsumerConnector;</span><br><span class="line"><span class="keyword">import</span> kafka.message.MessageAndMetadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> * 处理用户访问日志信息</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerUserVisit</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> times = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> Map&lt;String,Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建消费者</span></span><br><span class="line">        Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">        prop.load( ConsumerUserVisit.class.getClassLoader().getResourceAsStream( <span class="string">"consumer.properties"</span> ) );</span><br><span class="line">        ConsumerConnector connector = Consumer.createJavaConsumerConnector(<span class="keyword">new</span> ConsumerConfig(prop));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.</span></span><br><span class="line">        String topic = <span class="string">"world"</span> ;</span><br><span class="line">        Map&lt;String, Integer&gt; topicCountMap =  <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">        topicCountMap.put( topic , <span class="number">3</span> ) ; <span class="comment">//这里启用了三个消费者线程</span></span><br><span class="line"></span><br><span class="line">        Map&lt;String, List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; streams = connector.createMessageStreams(topicCountMap);</span><br><span class="line">        List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt; streamList = streams.get(topic);</span><br><span class="line">        <span class="keyword">for</span> (KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; stream : streamList) &#123;</span><br><span class="line">            ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator = stream.iterator();</span><br><span class="line">            <span class="keyword">new</span> Thread( <span class="keyword">new</span> RunConsumer(  iterator ) ).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//处理访问数据</span></span><br><span class="line">        Timer timer = <span class="keyword">new</span> Timer(); <span class="comment">//定时来打印一下信息</span></span><br><span class="line">        timer.schedule(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (map) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (String key:map.keySet())&#123;</span><br><span class="line">                        System.out.println(String.format(<span class="string">"访问path： %s, 的次数： %s"</span>,key,map.get(key)));</span><br><span class="line">                    &#125;</span><br><span class="line">                    System.out.println(<span class="string">"总访问次数： "</span>+times);</span><br><span class="line">                    map.clear();</span><br><span class="line">                    times=<span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; , <span class="number">0</span> ,<span class="number">5</span>*<span class="number">1000</span> );</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 多线程处理数据，防阻塞</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RunConsumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator ;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">RunConsumer</span><span class="params">(ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.iterator = iterator ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> ( iterator.hasNext() )&#123;</span><br><span class="line">                MessageAndMetadata&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; next = iterator.next();</span><br><span class="line">                String str = <span class="keyword">new</span> String(next.message());</span><br><span class="line">                String[] strs = str.split(<span class="string">"\t"</span>);</span><br><span class="line">                Integer key = map.get(strs[<span class="number">1</span>]);</span><br><span class="line">                <span class="keyword">synchronized</span> ( map ) &#123;</span><br><span class="line">                    <span class="keyword">int</span> count = <span class="number">1</span> ;</span><br><span class="line">                    <span class="keyword">if</span>( key != <span class="keyword">null</span>  )&#123;</span><br><span class="line">                        count += key ;</span><br><span class="line">                    &#125;</span><br><span class="line">                    map.put( strs[<span class="number">1</span>] , count ) ;</span><br><span class="line">                    times ++ ;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>四、自定义Partition</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> kafka.utils.VerifiableProperties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义partition</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartition</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyPartition</span><span class="params">(VerifiableProperties verifiableProperties)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//记得要有这个构造函数，不然会报错！</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Object key, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>( key == <span class="keyword">null</span> ) <span class="keyword">return</span> <span class="number">0</span> ;</span><br><span class="line">        Integer k = Integer.parseInt(key+<span class="string">""</span>) ;</span><br><span class="line">        <span class="keyword">return</span> k % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>输出结果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">总访问次数： <span class="number">0</span></span><br><span class="line">总访问次数： <span class="number">0</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 5</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 2</span></span><br><span class="line">总访问次数： <span class="number">10</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 6</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 6</span></span><br><span class="line">总访问次数： <span class="number">18</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 6</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/, 的次数： 4</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 5</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 9</span></span><br><span class="line">总访问次数： <span class="number">27</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 24</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/, 的次数： 23</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 16</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 21</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 32</span></span><br><span class="line">总访问次数： <span class="number">116</span></span><br></pre></td></tr></table></figure></li><li><p>本博客所用源码下载地址：<a href="http://download.csdn.net/detail/tang__xuandong/9520209" target="_blank" rel="noopener">http://download.csdn.net/detail/tang__xuandong/9520209</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka--集群及API操作</title>
      <link href="/2016/05/14/Kafka-%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
      <url>/2016/05/14/Kafka-%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
      <content type="html"><![CDATA[<p>　　本篇博客，主要讲解<strong>kafka集群配置</strong>、<strong>kafka的容错</strong>和<strong>kafka扩展机制</strong>。以及使用kafka<strong>模拟一个网络流量实时统计</strong>来看一看Kafka的一些api使用方法。</p><h2 id="kafka集群"><a href="#kafka集群" class="headerlink" title="kafka集群"></a>kafka集群</h2><h3 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h3><ul><li><strong>一、准备</strong>集群机器（这里使用3台）：主机名xxo08、xxo09、xxo10（<em>我把zookeeper集群也放在了这里</em>）。</li><li><p><strong>二、搭建并启动 </strong><a href="http://blog.xiaoxiaomo.com/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"><strong>zookeeper集群</strong></a>。</p></li><li><p><strong>三、修改配置文件</strong></p></li></ul><ol><li>/opt/kafka/config/server.properties <strong>broker.id=0</strong>　　##broker的id每一个broker应该不同</li><li>log.dirs=<strong>/opt/kafka_logs</strong>　　##</li><li>zookeeper.connect=<strong>xxo08:2181,xxo09:2181,xxo10:2181</strong>  ##<strong>注意</strong>：我的zokeeper也在这三台机器上</li></ol><ul><li><strong>四、同步其它节点</strong><br>scp -r /opt/kafka/ root@xxo09:/opt/<br>scp -r /opt/kafka/ root@xxo10:/opt/<br>并修改<br>xxo09 /opt/kafka/config/server.properties <strong>broker.id=1</strong>　　##broker的id<br>xxo10 /opt/kafka/config/server.properties <strong>broker.id=2</strong>　　##broker的id</li></ul><a id="more"></a><ul><li><strong>五、启动所有server</strong><br>nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt;&gt;/opt/logs/kafka-server.log 2&gt;&amp;1 &amp;</li></ul><ul><li><p><strong>六、查看进程</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 ~]<span class="comment"># jps</span></span><br><span class="line">1337 QuorumPeerMain   <span class="comment">##zookeeper</span></span><br><span class="line">1411 Jps</span><br><span class="line">1362 Kafka      <span class="comment">##kafka</span></span><br></pre></td></tr></table></figure></li><li><p><strong>总结： </strong>对于broker来说是所有broker是独立的，由zk来协调管理。</p></li></ul><h2 id="容错和扩展机制"><a href="#容错和扩展机制" class="headerlink" title="容错和扩展机制"></a>容错和扩展机制</h2><p>上篇博客<a href="http://blog.xiaoxiaomo.com/2016/05/13/Kafka-分布式消息队列/">Kafka-分布式消息队列/</a>中我们使用了单机的kafka,在创建一个topic的时候，副本 <strong>replication-factor</strong> 指定为 <strong>1</strong>(<em>我们只有一个broker也只能指定为1</em>)。现在我们搭建了集群，三个kafka服务（<em>3个broker</em>）我们最多就能创建三个副本了。记住：<strong>kafka容错的保障是他的副本机制！</strong></p><h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><p><strong>如果，kafka集群中某个broker挂掉（fails），则zk会选择新的broker提供服务。</strong></p><ul><li><strong>下面来做一个测试，模拟节点宕机或挂掉，这里就强制kill掉某个kafka服务吧！</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########################1、创建一个hello的topic##################################</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --create --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --replication-factor 3 --partitions 4  --topic world</span></span><br><span class="line">Created topic <span class="string">"world"</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment">########################2、查看一下hello (分布在4个partition中，每个P有三个备份)####</span></span><br><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 2 Replicas: 2,1,0Isr: 2,1,0</span><br><span class="line">Topic: worldPartition: 1Leader: 0 Replicas: 0,2,1Isr: 0,2,1</span><br><span class="line">Topic: worldPartition: 2Leader: 1 Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 2 Replicas: 2,0,1Isr: 2,0,1</span><br><span class="line"><span class="comment">###############PartitionCount：　当前topic分区数</span></span><br><span class="line"><span class="comment">###############ReplicationFactor： 当前topic副本数</span></span><br><span class="line"><span class="comment">###############Configs： 当前topic自定义配置信息</span></span><br><span class="line"><span class="comment">###############Partition： patition序号</span></span><br><span class="line"><span class="comment">###############Leader： Leader的brokerID</span></span><br><span class="line"><span class="comment">###############Replicas： 所有副本的brokerId</span></span><br><span class="line"><span class="comment">###############Isr： 所有存活（可用）的brokerId</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################3、下面我们来强制kill掉,brokerId等于2的#####################</span></span><br><span class="line"><span class="comment">#######################注意我们在xxo10（brokerId=2）上操作#########################</span></span><br><span class="line">[root@xxo10 ~]<span class="comment"># jps</span></span><br><span class="line">1270 Kafka</span><br><span class="line">1372 Jps</span><br><span class="line">1245 QuorumPeerMain</span><br><span class="line">[root@xxo10 ~]<span class="comment"># kill -9 1270   ###########强制kill掉</span></span><br><span class="line">[root@xxo10 ~]<span class="comment"># jps</span></span><br><span class="line">1245 QuorumPeerMain</span><br><span class="line">1382 Jps</span><br><span class="line">[root@xxo10 ~]<span class="comment"># cd /opt/kafka</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################4、再来看一下topic 就会发现平衡机制已经重启分配partitoin######</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 1Replicas: 2,1,0Isr: 1,0</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0</span><br><span class="line">Topic: worldPartition: 3Leader: 0Replicas: 2,0,1Isr: 0,1</span><br></pre></td></tr></table></figure></li></ul><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>对于扩容，是公司中使用教多的，比如集群不够了，重新购买了服务器，需要把这台服务器加入到kafak集群中。新加入的这个节点<strong>zk会自动识别</strong>并让它在适当的机会选择此节点提供服务。</p><ol><li>新加入的节点，<strong>配置信息(<em>server.properties</em>)记得保持相对一致</strong>。</li><li>修改<strong>broker.id</strong>、<strong>log.dirs</strong>、<strong>zookeeper.connect</strong></li><li>如果直接拷贝kafka,记得拷贝后新节点<strong>zk和kafka的存储路径</strong>应该把数据都删掉，防止数据不一致问题。因为<strong>zk的dataDir里面存储了zk和kafka的元数据</strong>信息，<strong>kafka的数据在kafka的Data目录</strong>就会多出一下奇怪的数据。</li></ol><ul><li><strong>下面我们就假如新加入了一个节点就是xxo10(brokerId=2)，先来启动该节点</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo10 kafka]<span class="comment"># nohup bin/kafka-server-start.sh config/server.properties &gt;&gt; ../logs/kafka-server.log 2&gt;</span></span><br><span class="line">&amp;1 &amp;</span><br><span class="line">[1] 1412</span><br><span class="line"><span class="comment">##########1、启动后会发现这个节点不会是任何分区的leader，在Isr能看见它以存活########</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 1Replicas: 2,1,0Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1,2</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 0Replicas: 2,0,1Isr: 0,1,2</span><br><span class="line"></span><br><span class="line"><span class="comment">##########2、怎么重新均匀分配？########</span></span><br><span class="line"><span class="comment">##########2.1、Broker配置中的自动均衡策略######################################</span></span><br><span class="line"><span class="comment">#####Auto.leader.rebalance.enable=true######################################</span></span><br><span class="line"><span class="comment">#####leader.imbalance.check.interval.seconds 默认值：300#####################</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##########2.2、手动配置执行###################################################</span></span><br><span class="line"><span class="comment">##########下面我们手动配置一下#################################################</span></span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-preferred-replica-election.sh --zookeeper xxo08:2181,xxo09:2181,xxo10:2181</span></span><br><span class="line">Successfully started preferred replica election <span class="keyword">for</span> partitions Set([world,0], [world,2], [world,3], [world,1])</span><br><span class="line">[root@xxo10 kafka]<span class="comment"># bin/kafka-topics.sh --describe --zookeeper xxo08:2181,xxo09:2181,xxo10:2181 --topic world</span></span><br><span class="line">Topic:worldPartitionCount:4ReplicationFactor:3Configs:</span><br><span class="line">Topic: worldPartition: 0Leader: 2Replicas: 2,1,0Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 1Leader: 0Replicas: 0,2,1Isr: 0,1,2</span><br><span class="line">Topic: worldPartition: 2Leader: 1Replicas: 1,0,2Isr: 1,0,2</span><br><span class="line">Topic: worldPartition: 3Leader: 2Replicas: 2,0,1Isr: 0,1,2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####负载均衡，Kafka提供了一个 metadata API来管理broker之间的负载（对于0.7.x主要靠zookeeper来实现负载均衡）。</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="API操作"><a href="#API操作" class="headerlink" title="API操作"></a>API操作</h2><p>kafka使用了scala编写，但是提供了很多语言的API接口。比如scala、java、python、R、PHP等。<br>这里我就<strong>使用java来模拟一个网页流量的实时统计处理</strong>：</p><ul><li><p><strong>项目结构</strong>：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514162644.png" alt="项目结构"></p></li><li><p>一、<strong>配置文件</strong></p></li></ul><hr><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">###############<span class="meta">#producer.properties##########################</span></span><br><span class="line">metadata.broker.<span class="built_in">list</span>=xxo08:<span class="number">9092</span>,xxo09:<span class="number">9092</span>,xxo10:<span class="number">9092</span></span><br><span class="line">partitioner.class=com.xxo.kafka.MyPartition</span><br><span class="line">producer.type=sync</span><br><span class="line">compression.codec=none</span><br><span class="line">serializer.class=kafka.serializer.StringEncoder</span><br><span class="line"></span><br><span class="line">################consumer.properties##########################</span><br><span class="line">zookeeper.connect=xxo08:<span class="number">2181</span>,xxo08:<span class="number">2181</span>,xxo08:<span class="number">2181</span></span><br><span class="line">zookeeper.connection.timeout.ms=<span class="number">6000</span></span><br><span class="line">group.id=xiaoxiaomo  ###组ID</span><br></pre></td></tr></table></figure><ul><li><p>二、<strong>生产者，模拟用户访问数据</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> kafka.producer.KeyedMessage;</span><br><span class="line"><span class="keyword">import</span> kafka.producer.ProducerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 模拟生产用户访问数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProduceUserData</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> Map&lt;Integer,String&gt; path = <span class="keyword">new</span> HashMap&lt;Integer, String&gt;();</span><br><span class="line">    <span class="keyword">static</span> Map&lt;Integer,Integer&gt; userId = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建一个生产者对象</span></span><br><span class="line">        Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">        prop.load( ProduceUserData.class.getClassLoader().getResourceAsStream(<span class="string">"producer.properties"</span>) );</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> Producer&lt;String, String&gt;(<span class="keyword">new</span> ProducerConfig( prop ));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 构造message</span></span><br><span class="line">        String topic = <span class="string">"world"</span> ;  <span class="comment">//world 主题</span></span><br><span class="line">        List&lt;KeyedMessage&lt;String,String&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;KeyedMessage&lt;String, String&gt;&gt;() ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//用户数据</span></span><br><span class="line">        <span class="comment">//init path</span></span><br><span class="line">        path.put(<span class="number">0</span>,<span class="string">"http://xiaoxiaomo.com/"</span>);</span><br><span class="line">        path.put(<span class="number">1</span>,<span class="string">"http://blog.xiaoxiaomo.com/"</span>);</span><br><span class="line">        path.put(<span class="number">2</span>,<span class="string">"http://blog.xiaoxiaomo.com/archives/"</span>);</span><br><span class="line">        path.put(<span class="number">3</span>,<span class="string">"http://blog.xiaoxiaomo.com/photo/"</span>);</span><br><span class="line">        path.put(<span class="number">4</span>,<span class="string">"http://blog.xiaoxiaomo.com/about/"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//init userId</span></span><br><span class="line">        userId.put(<span class="number">0</span>,<span class="number">2010</span>);</span><br><span class="line">        userId.put(<span class="number">1</span>,<span class="number">1001</span>);</span><br><span class="line">        userId.put(<span class="number">2</span>,<span class="number">1002</span>);</span><br><span class="line">        userId.put(<span class="number">3</span>,<span class="number">2001</span>);</span><br><span class="line">        userId.put(<span class="number">4</span>,<span class="number">2002</span>);</span><br><span class="line">        userId.put(<span class="number">5</span>,<span class="number">3003</span>);</span><br><span class="line">        userId.put(<span class="number">6</span>,<span class="number">4004</span>);</span><br><span class="line">        userId.put(<span class="number">7</span>,<span class="number">1007</span>);</span><br><span class="line">        userId.put(<span class="number">8</span>,<span class="number">1008</span>);</span><br><span class="line">        userId.put(<span class="number">9</span>,<span class="number">1009</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">while</span> ( <span class="keyword">true</span> )&#123;</span><br><span class="line">            <span class="comment">//随机产生数据</span></span><br><span class="line">            <span class="keyword">int</span> pathIndex=random.nextInt(<span class="number">5</span>);</span><br><span class="line">            <span class="keyword">int</span> userIndex=random.nextInt(<span class="number">10</span>);</span><br><span class="line">            <span class="keyword">int</span> isVip=random.nextInt(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//构造一个用户访问数据</span></span><br><span class="line">            String visData = String.format(<span class="string">"%s\t%s\t%s\t%s"</span>,</span><br><span class="line">                    userId.get(userIndex),</span><br><span class="line">                    path.get(pathIndex),</span><br><span class="line">                    <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>).format(<span class="keyword">new</span> Date()), isVip) ;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//使用了pathIndex作为一个Key分区用</span></span><br><span class="line">            list.add( <span class="keyword">new</span> KeyedMessage&lt;String, String&gt;( topic ,String.valueOf(pathIndex) , visData ) );</span><br><span class="line"></span><br><span class="line">            <span class="comment">//3. 发送</span></span><br><span class="line">            producer.send(list);</span><br><span class="line"></span><br><span class="line">            Thread.sleep( random.nextInt(<span class="number">2000</span>) );</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭</span></span><br><span class="line">        <span class="comment">//producer.close();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>三、<strong>消费者，处理用户访问日志信息</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.consumer.Consumer;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.ConsumerIterator;</span><br><span class="line"><span class="keyword">import</span> kafka.consumer.KafkaStream;</span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.consumer.ConsumerConnector;</span><br><span class="line"><span class="keyword">import</span> kafka.message.MessageAndMetadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> * 处理用户访问日志信息</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerUserVisit</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> times = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> Map&lt;String,Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建消费者</span></span><br><span class="line">        Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">        prop.load( ConsumerUserVisit.class.getClassLoader().getResourceAsStream( <span class="string">"consumer.properties"</span> ) );</span><br><span class="line">        ConsumerConnector connector = Consumer.createJavaConsumerConnector(<span class="keyword">new</span> ConsumerConfig(prop));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.</span></span><br><span class="line">        String topic = <span class="string">"world"</span> ;</span><br><span class="line">        Map&lt;String, Integer&gt; topicCountMap =  <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">        topicCountMap.put( topic , <span class="number">3</span> ) ; <span class="comment">//这里启用了三个消费者线程</span></span><br><span class="line"></span><br><span class="line">        Map&lt;String, List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; streams = connector.createMessageStreams(topicCountMap);</span><br><span class="line">        List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt; streamList = streams.get(topic);</span><br><span class="line">        <span class="keyword">for</span> (KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; stream : streamList) &#123;</span><br><span class="line">            ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator = stream.iterator();</span><br><span class="line">            <span class="keyword">new</span> Thread( <span class="keyword">new</span> RunConsumer(  iterator ) ).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//处理访问数据</span></span><br><span class="line">        Timer timer = <span class="keyword">new</span> Timer(); <span class="comment">//定时来打印一下信息</span></span><br><span class="line">        timer.schedule(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (map) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (String key:map.keySet())&#123;</span><br><span class="line">                        System.out.println(String.format(<span class="string">"访问path： %s, 的次数： %s"</span>,key,map.get(key)));</span><br><span class="line">                    &#125;</span><br><span class="line">                    System.out.println(<span class="string">"总访问次数： "</span>+times);</span><br><span class="line">                    map.clear();</span><br><span class="line">                    times=<span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; , <span class="number">0</span> ,<span class="number">5</span>*<span class="number">1000</span> );</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 多线程处理数据，防阻塞</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RunConsumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator ;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">RunConsumer</span><span class="params">(ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; iterator)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.iterator = iterator ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> ( iterator.hasNext() )&#123;</span><br><span class="line">                MessageAndMetadata&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; next = iterator.next();</span><br><span class="line">                String str = <span class="keyword">new</span> String(next.message());</span><br><span class="line">                String[] strs = str.split(<span class="string">"\t"</span>);</span><br><span class="line">                Integer key = map.get(strs[<span class="number">1</span>]);</span><br><span class="line">                <span class="keyword">synchronized</span> ( map ) &#123;</span><br><span class="line">                    <span class="keyword">int</span> count = <span class="number">1</span> ;</span><br><span class="line">                    <span class="keyword">if</span>( key != <span class="keyword">null</span>  )&#123;</span><br><span class="line">                        count += key ;</span><br><span class="line">                    &#125;</span><br><span class="line">                    map.put( strs[<span class="number">1</span>] , count ) ;</span><br><span class="line">                    times ++ ;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>四、自定义Partition</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> kafka.utils.VerifiableProperties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义partition</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartition</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyPartition</span><span class="params">(VerifiableProperties verifiableProperties)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//记得要有这个构造函数，不然会报错！</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Object key, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>( key == <span class="keyword">null</span> ) <span class="keyword">return</span> <span class="number">0</span> ;</span><br><span class="line">        Integer k = Integer.parseInt(key+<span class="string">""</span>) ;</span><br><span class="line">        <span class="keyword">return</span> k % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>输出结果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">总访问次数： <span class="number">0</span></span><br><span class="line">总访问次数： <span class="number">0</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 5</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 2</span></span><br><span class="line">总访问次数： <span class="number">10</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 6</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 6</span></span><br><span class="line">总访问次数： <span class="number">18</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 6</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/, 的次数： 4</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 3</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 5</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 9</span></span><br><span class="line">总访问次数： <span class="number">27</span></span><br><span class="line">访问path： http:<span class="comment">//xiaoxiaomo.com/, 的次数： 24</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/, 的次数： 23</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/about/, 的次数： 16</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/photo/, 的次数： 21</span></span><br><span class="line">访问path： http:<span class="comment">//blog.xiaoxiaomo.com/archives/, 的次数： 32</span></span><br><span class="line">总访问次数： <span class="number">116</span></span><br></pre></td></tr></table></figure></li><li><p>本博客所用源码下载地址：<a href="http://download.csdn.net/detail/tang__xuandong/9520209" target="_blank" rel="noopener">http://download.csdn.net/detail/tang__xuandong/9520209</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka--分布式消息队列</title>
      <link href="/2016/05/13/Kafka-%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
      <url>/2016/05/13/Kafka-%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</url>
      <content type="html"><![CDATA[<p>　　<code>Kafka</code> <strong>分布式的发布-订阅消息系统</strong>。最初由 <strong>LinkedIn</strong> 公司开发，使用 <strong>Scala</strong> 语言编写，2010年12月份开源成为 Apache 项目的一部分。<strong>Kafka 是一个高吞吐量的、持久性的、分布式发布订阅消息系统</strong>。<strong>它主要用于处理活跃的数据（登录、浏览、点击、分享、喜欢等用户行为产生的数据）。</strong></p><h2 id="Kafka概述"><a href="#Kafka概述" class="headerlink" title="Kafka概述"></a>Kafka概述</h2><h3 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h3><ul><li><strong><a href="http://kafka.apache.org/documentation.html#design" target="_blank" rel="noopener">主要的设计元素</a>：</strong><blockquote><ol><li>Kafka在设计之时为就将<strong>持久化消息</strong>作为通常的使用情况进行了考虑。</li><li>主要的设计约束是<strong>吞吐量</strong>而不是功能。</li><li>有关哪些数据<strong>已经被使用了的状态信息保存为数据使用者（consumer）的一部分</strong>，而不是保存在服务器之上。</li><li>Kafka是<strong>一种显式的分布式系统</strong>。它假设，数据生产者（producer）、代理（brokers）和数据使用者（consumer）分散于多台机器之上。</li></ol></blockquote></li></ul><ul><li><strong>在对消息进行存储和缓存时，Kafka严重地依赖于文件系统。所有数据都要立即写入文件系统持久化的日志中但不进行刷新数据的任何调用（<em>有刷新策略，可以配置</em>）</strong>。就意味着，数据被传输到OS内核的页面缓存中了，OS随后会将这些数据刷新到磁盘的。</li></ul><a id="more"></a><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li><strong>高吞吐量、低延迟</strong>：可以满足每秒百万级别消息的生产和消费、延迟最低只有几毫秒。</li><li><strong>持久性</strong>：有一套完善的消息存储机制，确保数据的高效安全的持久化。</li><li><strong>容错性</strong>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li><li><strong>可扩展性</strong>：kafka集群支持热扩展。</li><li><strong>高并发</strong>：支持数千个客户端同时读写。</li></ul><h3 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h3><p>　　　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160513222806.png" alt="Kafka集群分布"></p><ul><li><strong>broker</strong>： 缓存代理，<strong>kafka集群中的一个kafka服务节点称为一个broker，主要存储消息数据</strong>。不是主从关系，各个broker在集群中地位一样，可以随意的增删broker节点。</li><li><strong>topic</strong>： kafka 处理的<strong>消息的分类</strong>。</li><li><strong>partition</strong>： <strong>一个topic在broker中被分为1个或者多个partition，分区在创建topic的时候指定。</strong></li><li><strong>message</strong>： 消息（<em>offset，MessageSize，data</em>），是<strong>通信的基本单位</strong>，每个消息都属于一个<strong>partition</strong>。</li><li><strong>producer</strong>： <strong>生产者，向kafka的一个topic发布消息</strong>。</li><li><strong>consumer</strong>： <strong>消费者，订阅topic并处理其发布的消息</strong>。</li><li><strong>zookeeper</strong>： <strong>协调kafka的正常运行</strong>。</li><li><strong>push-and-pull</strong> : Kafka中的Producer和consumer采用的是push-and-pull模式，即<strong>Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的</strong>。<h3 id="消息发送流程"><a href="#消息发送流程" class="headerlink" title="消息发送流程"></a>消息发送流程</h3></li></ul><p>　　　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160513221804.png" alt="Kafka消息发送流程"></p><ul><li><strong>1、Producer：</strong> 可以根据用户<strong>自定义算法</strong>来根据消息的key来计算输入到哪个partition。可以指定<strong>同步异步</strong>（producer.type），异步发送模式允许进行批量发送，先将消息缓存在内存中，然后一次请求<strong>批量发送</strong>出去。（<em>queue.buffering.max.ms=5000、queue.buffering.max.messages=10000</em>）。</li><li><strong>2、broker</strong> 为了减少磁盘写入的次数,broker会将消息暂时<strong>buffer</strong>起来,当消息的个数达到<strong>一定阀值或者过了一定的时间间隔时</strong>,再flush到磁盘,这样减少了磁盘IO调用的次数。配置（<em>log.flush.interval…、log.retention…默认7天</em>）。</li><li><strong>3、kafka：</strong> 集群接收到Producer发过来的消息后，将其持久化到硬盘，并保留消息指定时长(可配置)，不关注消息是否被消费。</li><li><strong>4、Consumer：</strong> 从kafka集群pull数据，并控制获取消息的offset。<strong>每个consumer属于一个consumer group，可以指定组id。Group.id</strong>。</li></ul><h2 id="Kafka安装"><a href="#Kafka安装" class="headerlink" title="Kafka安装"></a>Kafka安装</h2><ol><li><p><a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz" target="_blank" rel="noopener"><strong>下载</strong></a> <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz" target="_blank" rel="noopener">https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz</a></p></li><li><p><strong>解压并修改目录 </strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 ~]<span class="comment"># tar -zxvf kafka_2.11-0.8.2.2.tgz -C /opt/  ##解压到指定目录</span></span><br><span class="line">[root@xxo07 ~]<span class="comment"># mv /opt/kafka_2.11-0.8.2.2/ /opt/kafka     ##改一下目录名</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置和启动zookeeper服务</strong>（使用kafka内置zk）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###################启用zk服务 #############################</span></span><br><span class="line">[root@xxo07 ~]<span class="comment"># mkdir /opt/logs       ##创建一个logs目录，用于存放日子文件</span></span><br><span class="line">[root@xxo07 ~]<span class="comment"># nohup /opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties &gt; /opt/logs/kafka-zk.log 2&gt;&amp;1 &amp;   ##后台启动zk服务</span></span><br><span class="line">[1] 1212</span><br><span class="line">[root@xxo07 ~]<span class="comment"># jps   ##查看进程</span></span><br><span class="line">1234 Jps</span><br><span class="line">1212 QuorumPeerMain   <span class="comment">##zk已经启动</span></span><br><span class="line"><span class="comment">###################查看日志：more /opt/logs/kafka-zk.log ######</span></span><br></pre></td></tr></table></figure></li><li><p><strong>启动 Kafka-server</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 ~]<span class="comment"># nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt; /opt/logs/kafka-server.log 2&gt;&amp;1 &amp;</span></span><br><span class="line">[2] 1244</span><br><span class="line">[root@xxo07 ~]<span class="comment"># jps   ##查看进程</span></span><br><span class="line">1289 Jps</span><br><span class="line">1244 Kafka            <span class="comment">##Kafka服务</span></span><br><span class="line">1212 QuorumPeerMain</span><br><span class="line"><span class="comment">###################查看日志： more /opt/logs/kafka-server.log ######</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="kafka操作"><a href="#kafka操作" class="headerlink" title="kafka操作"></a>kafka操作</h2><h3 id="主题topic"><a href="#主题topic" class="headerlink" title="主题topic"></a>主题topic</h3><ul><li><p><strong>kafka-topics.sh</strong> 操作 如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo08 kafka]<span class="comment"># bin/kafka-topics.sh        ##看一下怎么使用，需要什么参数</span></span><br><span class="line">Create, delete, describe, or change a topic.</span><br><span class="line">Option                                  Description                            </span><br><span class="line">------                                  -----------                            </span><br><span class="line">--alter                                 Alter the configuration <span class="keyword">for</span> the topic. </span><br><span class="line">--config &lt;name=value&gt;                   A topic configuration override <span class="keyword">for</span> the </span><br><span class="line">                                          topic being created or altered.The   </span><br><span class="line">                                          following is a list of valid         </span><br><span class="line">                                          configurations:                      </span><br><span class="line">                                        unclean.leader.election.enable        </span><br><span class="line">                                        delete.retention.ms                   </span><br><span class="line">                                        segment.jitter.ms                     </span><br><span class="line">                                        retention.ms                          </span><br><span class="line">                                        flush.ms                              </span><br><span class="line">                                        segment.bytes                         </span><br><span class="line">                                        flush.messages                        </span><br><span class="line">                                        segment.ms                            </span><br><span class="line">                                        retention.bytes                       </span><br><span class="line">                                        cleanup.policy                        </span><br><span class="line">                                        segment.index.bytes                   </span><br><span class="line">                                        min.cleanable.dirty.ratio             </span><br><span class="line">                                        max.message.bytes                     </span><br><span class="line">                                        file.delete.delay.ms                  </span><br><span class="line">                                        min.insync.replicas                   </span><br><span class="line">                                        index.interval.bytes                  </span><br><span class="line">                                        See the Kafka documentation <span class="keyword">for</span> full   </span><br><span class="line">                                          details on the topic configs.        </span><br><span class="line">--create                                Create a new topic.                    </span><br><span class="line">--delete                                Delete a topic                         </span><br><span class="line">--delete-config &lt;name&gt;                  A topic configuration override to be   </span><br><span class="line">                                          removed <span class="keyword">for</span> an existing topic (see   </span><br><span class="line">                                          the list of configurations under the </span><br><span class="line">                                          --config option).                    </span><br><span class="line">--describe                              List details <span class="keyword">for</span> the given topics.     </span><br><span class="line">--<span class="built_in">help</span>                                  Print usage information.               </span><br><span class="line">--list                                  List all available topics.             </span><br><span class="line">--partitions &lt;Integer: <span class="comment"># of partitions&gt; The number of partitions for the topic </span></span><br><span class="line">                                          being created or altered (WARNING:   </span><br><span class="line">                                          If partitions are increased <span class="keyword">for</span> a    </span><br><span class="line">                                          topic that has a key, the partition  </span><br><span class="line">                                          logic or ordering of the messages    </span><br><span class="line">                                          will be affected                     </span><br><span class="line">--replica-assignment                    A list of manual partition-to-broker   </span><br><span class="line">  &lt;broker_id_for_part1_replica1 :         assignments <span class="keyword">for</span> the topic being      </span><br><span class="line">  broker_id_for_part1_replica2 ,          created or altered.                  </span><br><span class="line">  broker_id_for_part2_replica1 :                                               </span><br><span class="line">  broker_id_for_part2_replica2 , ...&gt;                                          </span><br><span class="line">--replication-factor &lt;Integer:          The replication factor <span class="keyword">for</span> each        </span><br><span class="line">  replication factor&gt;                     partition <span class="keyword">in</span> the topic being created.</span><br><span class="line">--topic &lt;topic&gt;                         The topic to be create, alter or       </span><br><span class="line">                                          describe. Can also accept a regular  </span><br><span class="line">                                          expression except <span class="keyword">for</span> --create option</span><br><span class="line">--topics-with-overrides                 <span class="keyword">if</span> <span class="built_in">set</span> when describing topics, only    </span><br><span class="line">                                          show topics that have overridden     </span><br><span class="line">                                          configs                              </span><br><span class="line">--unavailable-partitions                <span class="keyword">if</span> <span class="built_in">set</span> when describing topics, only    </span><br><span class="line">                                          show partitions whose leader is not  </span><br><span class="line">                                          available                            </span><br><span class="line">--under-replicated-partitions           <span class="keyword">if</span> <span class="built_in">set</span> when describing topics, only    </span><br><span class="line">                                          show under replicated partitions     </span><br><span class="line">--zookeeper &lt;urls&gt;                      REQUIRED: The connection string <span class="keyword">for</span>    </span><br><span class="line">                                          the zookeeper connection <span class="keyword">in</span> the form </span><br><span class="line">                                          host:port. Multiple URLS can be      </span><br><span class="line">                                          given to allow fail-over.</span><br></pre></td></tr></table></figure></li><li><p><strong>新增</strong> 一个topic</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 ~]<span class="comment"># cd /opt/kafka/bin/   ##这里进入一下kafka/bin目录</span></span><br><span class="line"></span><br><span class="line"><span class="comment">################新增一个topic："hello"，为它分配一个分区，保存一个副本############</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic hello</span></span><br><span class="line">Created topic <span class="string">"hello"</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment">################replication-factor不能大于broker数（这里我们只有一个partitions）#</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic world</span></span><br><span class="line">Error <span class="keyword">while</span> executing topic <span class="built_in">command</span> replication factor: 2 larger than available brokers: 1</span><br><span class="line">kafka.admin.AdminOperationException: replication factor: 2 larger than available brokers: 1</span><br><span class="line">at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)</span><br><span class="line">at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)</span><br><span class="line">at kafka.admin.TopicCommand$.createTopic(TopicCommand.scala:93)</span><br><span class="line">at kafka.admin.TopicCommand$.main(TopicCommand.scala:55)</span><br><span class="line">at kafka.admin.TopicCommand.main(TopicCommand.scala)</span><br></pre></td></tr></table></figure></li><li><p><strong>查询</strong> topic</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --describe --zookeeper localhost:2181 --topic hello</span></span><br><span class="line">Topic:helloPartitionCount:2ReplicationFactor:1Configs:</span><br><span class="line">Topic: helloPartition: 0Leader: 0Replicas: 0Isr: 0</span><br><span class="line">Topic: helloPartition: 1Leader: 0Replicas: 0Isr: 0</span><br><span class="line"></span><br><span class="line"><span class="comment">#########################查询所有可以使用的topic######################</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --list --zookeeper localhost:2181</span></span><br><span class="line">hello</span><br><span class="line">world</span><br></pre></td></tr></table></figure></li><li><p><strong>修改</strong> topic</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################修改hello为2个分区#########################   </span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --alter --zookeeper localhost:2181 -partitions 3 --topic hello</span></span><br><span class="line">WARNING: If partitions are increased <span class="keyword">for</span> a topic that has a key, the partition logic or ordering of the messages will be affected</span><br><span class="line">Adding partitions succeeded!</span><br><span class="line"></span><br><span class="line"><span class="comment">########################修改partition数（只能增加）#################</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --alter --zookeeper localhost:2181 -partitions 2 --topic hello</span></span><br><span class="line">WARNING: If partitions are increased <span class="keyword">for</span> a topic that has a key, the partition logic or ordering of the messages will be affected</span><br><span class="line">Error <span class="keyword">while</span> executing topic <span class="built_in">command</span> The number of partitions <span class="keyword">for</span> a topic can only be increased</span><br><span class="line">kafka.admin.AdminOperationException: The number of partitions <span class="keyword">for</span> a topic can only be increased</span><br><span class="line">at kafka.admin.AdminUtils$.addPartitions(AdminUtils.scala:114)</span><br><span class="line">at kafka.admin.TopicCommand$<span class="variable">$anonfun</span><span class="variable">$alterTopic</span><span class="variable">$1</span>.apply(TopicCommand.scala:119)</span><br><span class="line">at kafka.admin.TopicCommand$<span class="variable">$anonfun</span><span class="variable">$alterTopic</span><span class="variable">$1</span>.apply(TopicCommand.scala:100)</span><br><span class="line">at scala.collection.mutable.ResizableArray<span class="variable">$class</span>.foreach(ResizableArray.scala:59)</span><br><span class="line">at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)</span><br><span class="line">at kafka.admin.TopicCommand$.alterTopic(TopicCommand.scala:100)</span><br><span class="line">at kafka.admin.TopicCommand$.main(TopicCommand.scala:57)</span><br><span class="line">at kafka.admin.TopicCommand.main(TopicCommand.scala)</span><br></pre></td></tr></table></figure></li><li><p><strong>删除</strong> topic</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################删除world topic ############################</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --delete --zookeeper localhost:2181 --topic world</span></span><br><span class="line">Topic world is marked <span class="keyword">for</span> deletion.</span><br><span class="line">Note: This will have no impact <span class="keyword">if</span> delete.topic.enable is not <span class="built_in">set</span> to <span class="literal">true</span>.</span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --list --zookeeper localhost:2181</span></span><br><span class="line">hello</span><br><span class="line">world - marked <span class="keyword">for</span> deletion   <span class="comment">##可以看见还在，如果重启可以删除</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###是否开启topic的删除功能:默认为false 修改delete.topic.enable=true可以不用重启</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># vim ../config/server.properties  ###修改配置如下图</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-server-stop.sh             ###关闭kafka</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># jps</span></span><br><span class="line">1645 Jps</span><br><span class="line">1212 QuorumPeerMain</span><br><span class="line">[root@xxo07 bin]<span class="comment"># nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt; /opt/logs/kafka-server.log 2&gt;&amp;1 &amp;</span></span><br><span class="line">[2] 1665</span><br><span class="line">[root@xxo07 bin]<span class="comment"># jps    #####################已经重新启动</span></span><br><span class="line">1665 Kafka</span><br><span class="line">1710 Jps</span><br><span class="line">1212 QuorumPeerMain</span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --list --zookeeper localhost:2181  ########查看，已经被删除了</span></span><br><span class="line">hello</span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic world</span></span><br><span class="line">Created topic <span class="string">"world"</span>.   <span class="comment">######################重新创建了一个</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --delete --zookeeper localhost:2181 --topic world ###再次删除</span></span><br><span class="line">Topic world is marked <span class="keyword">for</span> deletion.</span><br><span class="line">Note: This will have no impact <span class="keyword">if</span> delete.topic.enable is not <span class="built_in">set</span> to <span class="literal">true</span>.  <span class="comment">######这个为提示信息</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-topics.sh --list --zookeeper localhost:2181  ########查看，已经被删除了</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160513234642.png" alt="修改server.properties"></p><h3 id="生产-消费"><a href="#生产-消费" class="headerlink" title="生产/消费"></a>生产/消费</h3><ul><li><p><strong>创建生产者 producer</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############broker-list：必须的参数，kafka的服务地址[多个用逗号隔开]#############</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># bin/kafka-console-producer.sh --broker-list localhost:9092 --topic hello</span></span><br></pre></td></tr></table></figure></li><li><p><strong>创建消费者 consumer</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###################Zookeeper：必须的参数，kafka的zk集群地址####################</span></span><br><span class="line"><span class="comment">############Topic\whitelist\blacklist：</span></span><br><span class="line"><span class="comment">############1、具体的单个topic</span></span><br><span class="line"><span class="comment">############2、多个白名单topic字符串[逗号隔开]。</span></span><br><span class="line"><span class="comment">############3、多个黑名单topic字符串[逗号隔开]。</span></span><br><span class="line">[root@xxo07 bin]<span class="comment"># kafka-console-consumer.sh --zookeeper localhost:2181 --topic hello --from-beginning</span></span><br><span class="line"><span class="comment">##################标记删除的topic也可以使用###################################</span></span><br></pre></td></tr></table></figure></li><li><p><strong>实例</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514001613.png" alt="producer 生产一个消息"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160514001501.png" alt="consumer 消费者该消息"></p></li></ul><ul><li><strong>概念理解</strong>：<blockquote><p><strong>消费者组理解</strong>：很多consumer可以组成一个组，一个消息在<strong>组中</strong>只能被一个consumer消费，可以被<strong>不同的组</strong>消费。<br><strong>消息持久化</strong>：Kafka中会把消息持久化到本地文件系统中，并且保持极高的效率。<br><strong>消息状态</strong>：在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置）。<br><strong>消息有效期</strong>：Kafka会长久（<em>默认七天，一般公司生产环境中会设置很长</em>）保留其中的消息，以便consumer可以多次消费。<br><strong>批量发送</strong>：Kafka支持以消息集合为单位进行批量发送，以<strong>提高push效率</strong>。<br><strong>同步异步</strong>：<strong>Producer采用异步push方式，极大提高Kafka系统的吞吐率</strong>（可以通过参数控制）。<br>分区机制partition：Kafka的broker端支持消息分区，Producer可以决定把消息发到哪个分区，在一个分区中消息的顺序就是Producer发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现。<br><strong>离线数据装载</strong>：Kafka由于对可拓展的数据持久化的支持，它也非常适合向Hadoop或者数据仓库中进行数据装载。<br><strong>插件支持</strong>：现在不少活跃的社区已经开发出不少插件来拓展Kafka的功能，如用来配合Storm、Hadoop、flume相关的插件。</p></blockquote></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--Ganglia集群监控</title>
      <link href="/2016/05/09/Hadoop-Ganglia%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/"/>
      <url>/2016/05/09/Hadoop-Ganglia%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<p>　　Ganglia 是 UC Berkeley 发起的一个开源监视项目，设计用于测量数以千计的节点。<strong>每台计算机都运行一个收集和发送度量数据（如处理器速度、内存使用量等）的名为 gmond 的守护进程，</strong>gmond 带来的系统负载非常少，不会影响用户性能。</p><h2 id="Ganglia简介"><a href="#Ganglia简介" class="headerlink" title="Ganglia简介"></a>Ganglia简介</h2><ul><li><strong>Ganglia</strong> 监控套件包括<strong>三</strong>个主要部分：<strong>gmetad</strong>，<strong>gmond</strong>，和<strong>网页接口(ganglia-web)</strong>。</li><li><strong>Gmetad</strong> ：也是一个守护进程，他定期检查gmonds，从那里拉取数据，并将他们的指标存储在RRD存储引擎中。他可以查询多个集群并聚合指标。</li><li><strong>Gmond</strong> ：是一个守护进程，<strong>他运行在每一个需要监测的节点上</strong>，<strong>发送和接受在同一个组播或单播通道上的统计信息</strong> 。<code>发送</code>-收集基本指标，比如系统负载、CPU利用率等。 <code>接收者</code>-聚合所有从别的主机上发来的指标，并把它们都保存在内存缓冲区中。</li><li><strong>Ganglia-web</strong> ：安装在有<code>gmetad</code>运行的机器上，以便读取RRD文件。</li><li><strong>一般集群中每个节点需要一个接收的gmond，每个网站需要一个gmetad</strong>。</li></ul><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li>一、安装依赖<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############## 注：建议使用超级用户安装</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># yum install –y gcc gcc-c++ libpng freetype zlib libdbi apr* libxml2-devel pkg-config glib pixman pango pango-devel freetye-devel fontconfig cairo cairo-devel libart_lgpl libart_lgpl-devel pcre* rrdtool*</span></span><br></pre></td></tr></table></figure></li></ul><p>三、安装expat依赖<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># cd /root</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># wget http://jaist.dl.sourceforge.net/project/expat/expat/2.1.0/expat-2.1.0.tar.gz</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># tar -xf expat-2.1.0.tar.gz &amp;&amp; cd expat-2.1.0 &amp;&amp; ./configure --prefix=/usr/local/expat &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###### 对于64位操作系统，需要手动的拷贝下动态链接库到lib64下 ######</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># mkdir /usr/local/expat/lib64 &amp;&amp; cp -a /usr/local/expat/lib/* /usr/local/expat/lib64/</span></span><br></pre></td></tr></table></figure></p><p>四、安装confuse<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># wget http://ftp.twaren.net/Unix/NonGNU//confuse/confuse-2.7.tar.gz</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># tar -xf confuse-2.7.tar.gz &amp;&amp; cd confuse-2.7 &amp;&amp; ./configure CFLAGS=-fPIC --disable-nls --prefix=/usr/local/confuse &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####### 64bit机器需要拷贝动态链接库： #########################</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># mkdir -p /usr/local/confuse/lib64 &amp;&amp; cp -a -f /usr/local/confuse/lib/* /usr/local/confuse/lib64/</span></span><br></pre></td></tr></table></figure></p><p>五、安装ganglia<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># wget http://jaist.dl.sourceforge.net/project/ganglia/ganglia%20monitoring%20core/3.6.0/ganglia-3.6.0.tar.gz</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># tar -xf ganglia-3.6.0.tar.gz &amp;&amp; cd ganglia-3.6.0 &amp;&amp; ./configure --with-gmetad --enable-gexec --with-libconfuse=/usr/local/confuse --with-libexpat=/usr/local/expat --prefix=/usr/local/ganglia --sysconfdir=/etc/ganglia &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..</span></span><br></pre></td></tr></table></figure></p><p>六、服务端配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########创建rrdtool数据目录，看$ganglia-3.2.0/web/conf.php里面的gmetad_root变量######</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># mkdir -p /var/lib/ganglia/rrds &amp;&amp; mkdir -p /var/lib/ganglia/dwoo &amp;&amp; chown -R root:root /var/lib/ganglia</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">########配置一个数据源，修改/etc/ganglia/gmetad.conf文件，同时将运行用户设置为rrdtool的目录权限用户，例如root用户</span></span><br><span class="line">data_source <span class="string">"Hadoop"</span> xxo04:8649   <span class="comment">#### 44行</span></span><br><span class="line">setuid_username <span class="string">"root"</span>            <span class="comment">#### 102行</span></span><br><span class="line">说明：这里的 <span class="string">" hadoop "</span> 表示的是集群的名称，后面的内容是这个集群中所包含的主机信息，也就是要监控的主机（ip或主机名）。</span><br><span class="line"></span><br><span class="line"><span class="comment">########添加自启动脚本</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># cp -f ganglia-3.6.0/gmetad/gmetad.init /etc/init.d/gmetad &amp;&amp; cp -f /usr/local/ganglia/sbin/gmetad /usr/sbin/gmetad &amp;&amp; chkconfig --add gmetad</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########启动gmetad服务</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># service gmetad start</span></span><br><span class="line">Starting GANGLIA gmetad:       [  OK  ] <span class="comment">##代表运行正常</span></span><br></pre></td></tr></table></figure></p><p>七、客户端配置（gmond节点）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># cp -f ganglia-3.6.0/gmond/gmond.init /etc/init.d/gmond &amp;&amp; cp -f /usr/local/ganglia/sbin/gmond /usr/sbin/gmond &amp;&amp; chkconfig --add gmond &amp;&amp; gmond --default_config &gt; /etc/ganglia/gmond.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###############修改 /etc/ganglia/gmond.conf ######################</span></span><br><span class="line">globals &#123;</span><br><span class="line">  user = root     <span class="comment">### 6行 运行Ganglia的用户</span></span><br><span class="line">  host_dmax = 120 <span class="comment">### 12行 secs</span></span><br><span class="line">  send_metadata_interval = 15 <span class="comment">###21行  /*发送数据的时间间隔*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cluster &#123;</span><br><span class="line">  name = <span class="string">"Hadoop"</span> <span class="comment">### 30行  /*集群名称*/</span></span><br><span class="line">  owner = <span class="string">"root"</span>  <span class="comment">### 31行  /*运行Ganglia的用户*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">udp_send_channel &#123;</span><br><span class="line">  <span class="comment"># mcast_join = 239.2.11.71 ### 50行 /*注释掉组播*/</span></span><br><span class="line">  host = xxo04               <span class="comment">### 51行 新增行/*发送给安装gmetad的机器*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">udp_recv_channel &#123; <span class="comment">#接受UDP包配置</span></span><br><span class="line">  <span class="comment"># mcast_join = 239.2.11.71 ### 58行 /*注释掉*/</span></span><br><span class="line">  <span class="comment"># bind = 239.2.11.71       ### 60行 /*注释掉*/</span></span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">############### 开启服务 #####################################</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># service gmond start</span></span><br><span class="line">Starting GANGLIA gmond:     [  OK  ]  <span class="comment">##成功</span></span><br></pre></td></tr></table></figure></p><p>八、服务端的WEB配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################ PHP程序需要依赖Apache来运行，因此需要安装如下依赖</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># yum -y install php httpd</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># service httpd start ####启动httpd 服务</span></span><br></pre></td></tr></table></figure></p><ul><li>浏览器检查：<a href="http://xxo04/" target="_blank" rel="noopener">http://xxo04/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160509013146.png" alt="运行Apache"></li></ul><p>九、生成了ganglia-web目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># cd /root</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># wget http://jaist.dl.sourceforge.net/project/ganglia/ganglia-web/3.5.10/ganglia-web-3.5.10.tar.gz</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># tar -xf ganglia-web-3.5.10.tar.gz &amp;&amp; cd ganglia-web-3.5.10 &amp;&amp; make install &amp;&amp; cd ..</span></span><br><span class="line">rsync --exclude <span class="string">"rpmbuild"</span> --exclude <span class="string">"*.gz"</span> --exclude <span class="string">"Makefile"</span> --exclude <span class="string">"*debian*"</span> --exclude <span class="string">"ganglia-web-3.5.10"</span> --exclude <span class="string">".git*"</span> --exclude <span class="string">"*.in"</span> --exclude <span class="string">"*~"</span> --exclude <span class="string">"#*#"</span> --exclude <span class="string">"ganglia-web.spec"</span> -a . ganglia-web-3.5.10</span><br><span class="line">mkdir -p //var/lib/ganglia-web/dwoo/compiled &amp;&amp; \</span><br><span class="line">mkdir -p //var/lib/ganglia-web/dwoo/cache &amp;&amp; \</span><br><span class="line">mkdir -p //var/lib/ganglia-web &amp;&amp; \</span><br><span class="line">rsync -a ganglia-web-3.5.10/conf //var/lib/ganglia-web &amp;&amp; \</span><br><span class="line">mkdir -p //var/www/html/ganglia &amp;&amp; \</span><br><span class="line">rsync --exclude <span class="string">"conf"</span> -a ganglia-web-3.5.10/* //var/www/html/ganglia &amp;&amp; \</span><br><span class="line">chown -R apache:apache //var/lib/ganglia-web</span><br><span class="line"></span><br><span class="line"><span class="comment">################### 这样 在/var/www/html/下 生成了 ganglia 目录</span></span><br><span class="line">注： Ganglia访问失败：</span><br><span class="line">There was an error collecting ganglia data (127.0.0.1:8652): fsockopen error: Permission denied</span><br><span class="line">解决：</span><br><span class="line">1. 需要关闭selinux：vi /etc/selinux/config，把SELINUX=enforcing改成SELINUX=disabled；需要重启（永久）。</span><br><span class="line">2. 命令setenforce 0来关闭selinux;不需要重启（临时） </span><br><span class="line">    </span><br><span class="line"><span class="comment">#################### 重启httpd服务器</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># service httpd restart</span></span><br></pre></td></tr></table></figure></p><ul><li>查看：<a href="http://xxo04/ganglia" target="_blank" rel="noopener">http://xxo04/ganglia</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160509015500.png" alt="运行Apache"></li></ul><h2 id="监控hadoop集群"><a href="#监控hadoop集群" class="headerlink" title="监控hadoop集群"></a>监控hadoop集群</h2><p>在博客<a href="http://blog.xiaoxiaomo.com/2016/05/09/Hadoop-2-0集群/">Hadoop2.0集群</a>中我们搭建了hadoop集群，分别是<code>xxo04</code>、<code>xxo05</code>、<code>xxo06</code>。<strong>上述中我们已经在xx04安装好了ganglia的gmetad、gmond和web</strong>。<br>如果我们要监控xxo04、xxo05、xxo06的状态，所以还<strong>需要在xxo05、xxo06中安装gmond</strong>。<strong>注意：只需要安装gmond，请重复上述步骤（不需要第六、第八、第九步骤）。</strong></p><ul><li><p>启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># service httpd status</span></span><br><span class="line">httpd is stopped</span><br><span class="line">[root@xxo04 ~]<span class="comment"># service httpd start</span></span><br><span class="line">Starting httpd: httpd: Could not reliably determine the server<span class="string">'s fully qualified domain name, using 192.168.33.69 for ServerName</span></span><br></pre></td></tr></table></figure></li><li><p>查看ganglia集群监控：<a href="http://xxo04/ganglia/" target="_blank" rel="noopener">http://xxo04/ganglia/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160509112421.png" alt="运行Apache"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--2.0集群</title>
      <link href="/2016/05/09/Hadoop-2-0%E9%9B%86%E7%BE%A4/"/>
      <url>/2016/05/09/Hadoop-2-0%E9%9B%86%E7%BE%A4/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解<code>Hadoop2.0集群</code>的安装配置(以<code>hadoop-2.6.0.tar.gz</code>为例)，使用centsos6.5，jdk使用1.7。由于前面几篇博客已经讲解<a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-1-0伪分布式安装/">hadoop1.0</a>、<a href="http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0伪分布式安装/">hadoop2.0</a>的伪分布式安装了，所以该篇博文就不一一贴步骤了（会省略基本的环境准备）。</p><ul><li><p><strong>注意</strong>：对基本的环境还不了解的可以查看博客<a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-安装前环境准备/">Hadoop-安装前环境准备</a>。</p></li><li><p><strong>该博客省略基本环境搭建</strong></p></li></ul><ol><li>设置ip地址</li><li>关闭防火墙</li><li>设置主机名</li><li>绑定Hostname</li><li>设置ssh</li><li>安装JDK</li><li>上传<a href="http://pan.baidu.com/s/1c1H8xyw" target="_blank" rel="noopener">hadoop-2.6.0.tar.gz</a></li></ol><a id="more"></a><h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><ul><li><p>主机　　　　　　主机名<br>192.168.33.69　　xxo04（主）<br>192.168.33.70　　xxo05<br>192.168.33.71　　xxo06</p></li><li><p>节点分布： </p><blockquote><p>hdfs<br>xxo04 ： NameNode|DataNode<br>xxo05 ： DataNode<br>xxo06 ： SecondaryNameNode|DataNode<br>yarn<br>xxo04 ： NodeManager<br>xxo05 ： ResourceManager|NodeManager<br>xxo06 ： NodeManager</p></blockquote></li><li><p>在xxo04中配置，hosts</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># vim /etc/hosts</span></span><br><span class="line">192.168.33.69 xxo04</span><br><span class="line">192.168.33.70 xxo05</span><br><span class="line">192.168.33.71 xxo06</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><ul><li><p>一、<strong>上传hadoop后解压文件到/use/local/目录下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 up]<span class="comment"># tar -zxvf hadoop-2.6.0.tar.gz -C /usr/local/</span></span><br><span class="line">[root@xxo04 up]<span class="comment"># cd /usr/local/hadoop-2.6.0/</span></span><br><span class="line">[root@xxo04 hadoop-2.6.0]<span class="comment"># ll</span></span><br><span class="line">total 52</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 bin</span><br><span class="line">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 etc</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 include</span><br><span class="line">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 lib</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 libexec</span><br><span class="line">-rw-r--r--. 1 20000 20000 15429 Nov 14  2014 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 20000 20000   101 Nov 14  2014 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1 20000 20000  1366 Nov 14  2014 README.txt</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 sbin</span><br><span class="line">drwxr-xr-x. 4 20000 20000  4096 Nov 14  2014 share</span><br></pre></td></tr></table></figure></li><li><p>二、 配置hadoop环境变量(详情见<a href="http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0伪分布式安装/">hadoop2.0</a>)</p></li><li><p>三、<strong>修改配置文件</strong><br>修改/usr/local/hadoop-2.6.0/etc/hadoop/下的配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 hadoop-2.6.0]<span class="comment"># cd /usr/local/hadoop-2.6.0/etc/hadoop/</span></span><br><span class="line"><span class="comment">##############修改如下8个配置文件##############################</span></span><br><span class="line"><span class="comment">############### 一. 2个sh文件、1个日志文件、1个主从文件##########</span></span><br><span class="line">hadoop-env.sh</span><br><span class="line">yarn-env.sh</span><br><span class="line">log4j.properties</span><br><span class="line">slaves</span><br><span class="line"><span class="comment">############## 二. 4个xml文件#################################</span></span><br><span class="line">core-site.xml</span><br><span class="line">hdfs-site.xml</span><br><span class="line">mapred-site.xml</span><br><span class="line">yarn-site.xml</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/hadoop/cluster" target="_blank" rel="noopener">修改后配置文件，点击可<strong>查看</strong>，这里就不一一贴出了（<strong>注</strong>：主机名的修改</a></p><ul><li><p>四、在xxo05\xxo06 重复上面操作（记得配置ssh免密码登录）</p></li><li><p>五、格式化<br>我们需要在xx04中执行格式化命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 ~]<span class="comment"># hdfs namenode -format</span></span><br><span class="line">Formatting using clusterid: CID-e59cc833-b618-4186-9158-1ddb3f15dd10</span><br></pre></td></tr></table></figure></li><li><p>六、启动HDFS</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo04 hadoop]<span class="comment"># start-dfs.sh</span></span><br><span class="line">Starting namenodes on [xxo04]</span><br><span class="line">xxo04: starting namenode, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/hadoop-root-namenode-xxo04.out</span><br><span class="line">xxo05: starting datanode, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/hadoop-root-datanode-xxo05.out</span><br><span class="line">xxo06: starting datanode, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/hadoop-root-datanode-xxo06.out</span><br><span class="line">xxo04: starting datanode, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/hadoop-root-datanode-xxo04.out</span><br><span class="line">Starting secondary namenodes [xxo06]</span><br><span class="line">xxo06: starting secondarynamenode, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/hadoop-root-secondarynamenode-xxo06.out</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo04进程 ###############################</span></span><br><span class="line">[root@xxo04 hadoop]<span class="comment"># jps</span></span><br><span class="line">2097 DataNode</span><br><span class="line">2308 Jps</span><br><span class="line">2008 NameNode</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo05进程 ###############################</span></span><br><span class="line">[root@xxo05 logs]<span class="comment"># jps</span></span><br><span class="line">1325 Jps</span><br><span class="line">1257 DataNode</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo06进程 ###############################</span></span><br><span class="line">[root@xxo06 logs]<span class="comment"># jps</span></span><br><span class="line">1495 SecondaryNameNode</span><br><span class="line">1408 DataNode</span><br><span class="line">1535 Jps</span><br></pre></td></tr></table></figure></li><li><p>测试，hdfs的集群：<a href="http://xxo04:50070/" target="_blank" rel="noopener">http://xxo04:50070/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160509111051.png" alt="hdfs的集群"></p></li><li><p>六、启动YARN ，我们需要在xx05中启动yarn</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo05 logs]<span class="comment"># start-yarn.sh </span></span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-resourcemanager-xxo05.out</span><br><span class="line">xxo04: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-nodemanager-xxo04.out</span><br><span class="line">xxo06: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-nodemanager-xxo06.out</span><br><span class="line">xxo05: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-nodemanager-xxo05.out</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo05进程 ###############################</span></span><br><span class="line">[root@xxo05 logs]<span class="comment"># jps</span></span><br><span class="line">2808 NodeManager       <span class="comment">##start-yarn.sh</span></span><br><span class="line">2714 ResourceManager   <span class="comment">##start-yarn.sh</span></span><br><span class="line">2842 Jps</span><br><span class="line">1257 DataNode</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo04进程 ###############################</span></span><br><span class="line">[root@xxo04 ~]<span class="comment"># jps</span></span><br><span class="line">2097 DataNode</span><br><span class="line">2008 NameNode</span><br><span class="line">4325 Jps</span><br><span class="line">4203 NodeManager       <span class="comment">##start-yarn.sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################### 查看xxo06进程 ###############################</span></span><br><span class="line">[root@xxo06 ~]<span class="comment"># jps</span></span><br><span class="line">1495 SecondaryNameNode</span><br><span class="line">1408 DataNode</span><br><span class="line">2930 NodeManager       <span class="comment">##start-yarn.sh</span></span><br><span class="line">3059 Jps</span><br></pre></td></tr></table></figure></li><li><p>测试，hdfs的集群：<a href="http://xxo05:8088/" target="_blank" rel="noopener">http://xxo05:8088/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160509180956.png" alt="hdfs的集群"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--2.0伪分布式安装</title>
      <link href="/2016/05/08/Hadoop-2-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2016/05/08/Hadoop-2-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解<code>Hadoop2.0伪分布式</code>的安装配置(以<code>hadoop-2.6.0.tar.gz</code>为例)，使用centsos6.5，jdk使用1.7。安装环境比较简单我就直接贴步骤了。如想安装<code>1.0</code>可查看博客<a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-1-0伪分布式安装/">http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-1-0伪分布式安装/</a></p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li><p>一、使用root用户，<a href="http://pan.baidu.com/s/1geL6dNX" target="_blank" rel="noopener">jdk-7u79-linux-x64.tar.gz</a>和<a href="http://pan.baidu.com/s/1c1H8xyw" target="_blank" rel="noopener">hadoop-2.6.0.tar.gz</a>，安装在/usr/local/目录下。</p></li><li><p>二、<strong>准备环境</strong><br>可查看博客：<a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/">Hadoop-安装前环境准备</a><br>1.2.1. 设置ip地址<br>1.2.2. 关闭防火墙<br>1.2.3. 设置主机名<br>1.2.4. 绑定Hostname<br>1.2.5. 设置ssh<br>1.2.6. 安装JDK（这里我们使用了1.7替换成1.7的jdk版本即可）</p></li></ul><a id="more"></a><h2 id="安装-配置"><a href="#安装-配置" class="headerlink" title="安装/配置"></a>安装/配置</h2><ul><li><p>三、<strong>上传hadoop后解压文件到/use/local/目录下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo03 up]<span class="comment"># tar -zxvf hadoop-2.6.0.tar.gz -C /usr/local/</span></span><br><span class="line">[root@xxo03 up]<span class="comment"># cd /usr/local/hadoop-2.6.0/</span></span><br><span class="line">[root@xxo03 hadoop-2.6.0]<span class="comment"># ll</span></span><br><span class="line">total 52</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 bin</span><br><span class="line">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 etc</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 include</span><br><span class="line">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 lib</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 libexec</span><br><span class="line">-rw-r--r--. 1 20000 20000 15429 Nov 14  2014 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 20000 20000   101 Nov 14  2014 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1 20000 20000  1366 Nov 14  2014 README.txt</span><br><span class="line">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 sbin</span><br><span class="line">drwxr-xr-x. 4 20000 20000  4096 Nov 14  2014 share</span><br></pre></td></tr></table></figure></li><li><p>四、<strong>修改配置文件</strong><br>修改/usr/local/hadoop-2.6.0/etc/hadoop/下的配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo03 hadoop-2.6.0]<span class="comment"># cd /usr/local/hadoop-2.6.0/etc/hadoop/</span></span><br><span class="line"><span class="comment">##############修改如下8个配置文件##############################</span></span><br><span class="line"><span class="comment">############### 一. 2个sh文件、1个日志文件、1个主从文件##########</span></span><br><span class="line">hadoop-env.sh</span><br><span class="line">yarn-env.sh</span><br><span class="line">log4j.properties</span><br><span class="line">slaves</span><br><span class="line"><span class="comment">############## 二. 4个xml文件#################################</span></span><br><span class="line">core-site.xml</span><br><span class="line">hdfs-site.xml</span><br><span class="line">mapred-site.xml</span><br><span class="line">yarn-site.xml</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/jasonTangxd/Blog_Resources_20160508/tree/master/resources/hadoop/pretend_cluster" target="_blank" rel="noopener">修改后配置文件，点击可<strong>查看</strong>，这里就不一一贴出了（<strong>注</strong>：我主机为xxo03,请把所有xxo03修改为你的主机名）</a></p><ul><li><p>五、<strong>创建目录，为了存放数据文件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################### 创建目录 ##########################</span></span><br><span class="line">[root@xxo03 hadoop-2.6.0]<span class="comment"># cd /usr/local/</span></span><br><span class="line">[root@xxo03 <span class="built_in">local</span>]<span class="comment"># mkdir -p /usr/local/hadoop_repo/name    </span></span><br><span class="line">[root@xxo03 <span class="built_in">local</span>]<span class="comment"># cd hadoop_repo/</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># mkdir data</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># mkdir namesecondary</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># mkdir logs</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># mkdir tmp</span></span><br><span class="line"></span><br><span class="line"><span class="comment">################### 查看创建结果 ######################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># ll</span></span><br><span class="line">total 20</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May  9 05:21 data</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May  9 05:21 logs</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May  9 05:20 name</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May  9 05:21 namesecondary</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May  9 05:21 tmp</span><br></pre></td></tr></table></figure></li><li><p>六、<strong>配置环境变量，把bin和sbin目录配置到PATH路径下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################### 修改文件 ##########################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># vim /etc/profile</span></span><br><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.7.0_79</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$&#123;JAVA_HOME&#125;</span>/lib:<span class="variable">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop-2.6.0</span><br><span class="line">PATH=.:<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/sbin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment">################### 加载配置 ##########################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># source /etc/profile</span></span><br></pre></td></tr></table></figure></li><li><p>七.<strong>格式化文件系统</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># hdfs namenode -format</span></span><br><span class="line">Formatting using clusterid: CID-c80f2abf-fc78-48fc-b1b3-84476587cce4</span><br></pre></td></tr></table></figure></li><li><p>八、<strong>启动HDFS</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################### 启动HDFS ##########################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># start-dfs.sh</span></span><br><span class="line">Starting namenodes on [xxo03]</span><br><span class="line">The authenticity of host <span class="string">'xxo03 (192.168.33.68)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is 3c:55:d3:bb:e9:15:5a:48:07:c4:22:6a:01:a5:45:cc.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">xxo03: Warning: Permanently added '</span>xxo03,192.168.33.68<span class="string">' (RSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">xxo03: starting namenode, logging to /usr/local/hadoop_repo/logs/hadoop-root-namenode-xxo03.out</span></span><br><span class="line"><span class="string">xxo03: starting datanode, logging to /usr/local/hadoop_repo/logs/hadoop-root-datanode-xxo03.out</span></span><br><span class="line"><span class="string">Starting secondary namenodes [xxo03]</span></span><br><span class="line"><span class="string">xxo03: starting secondarynamenode, logging to /usr/local/hadoop_repo/logs/hadoop-root-secondarynamenode-xxo03.out</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">################### JPS测试 ##########################</span></span><br><span class="line"><span class="string">[root@xxo03 hadoop_repo]# jps</span></span><br><span class="line"><span class="string">1551 SecondaryNameNode</span></span><br><span class="line"><span class="string">1391 DataNode</span></span><br><span class="line"><span class="string">1663 Jps</span></span><br><span class="line"><span class="string">1312 NameNode</span></span><br></pre></td></tr></table></figure></li><li><p>浏览器测试：<a href="http://xxo03:50070/" target="_blank" rel="noopener">http://xxo03:50070/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160508233202.png" alt="测试hadoop HDFS"></p></li></ul><ul><li><p>九、<strong>启动YARN</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################### 启动YARN ##########################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># start-yarn.sh</span></span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-resourcemanager-xxo03.out</span><br><span class="line">xxo03: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop_repo/logs/yarn-root-nodemanager-xxo03.out</span><br><span class="line"></span><br><span class="line"><span class="comment">################### JPS测试 ##########################</span></span><br><span class="line">[root@xxo03 hadoop_repo]<span class="comment"># jps</span></span><br><span class="line">2132 Jps</span><br><span class="line">1551 SecondaryNameNode  <span class="comment">##start-yarn</span></span><br><span class="line">1391 DataNode</span><br><span class="line">1747 ResourceManager    <span class="comment">##start-yarn</span></span><br><span class="line">1312 NameNode</span><br><span class="line">1830 NodeManager</span><br></pre></td></tr></table></figure></li><li><p>浏览器测试：<a href="http://xxo03:8088/" target="_blank" rel="noopener">http://xxo03:8088/</a><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160508234009.png" alt="测试hadoop HDFS"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper--概述及应用</title>
      <link href="/2016/05/05/Zookeeper-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
      <url>/2016/05/05/Zookeeper-%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>　　<strong>Zookeeper</strong> 是 <code>Hadoop</code> 的分布式协调服务，起源于Google的Chubby。分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。<strong>Zookeeper</strong> 可以保证数据在Zookeeper 集群之间的数据的事务性一致。</p><h2 id="总体概述"><a href="#总体概述" class="headerlink" title="总体概述"></a>总体概述</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160505224003.png" alt="ZooKeeper总体架构"></p><ol><li><strong>组成：</strong> <strong>ZooKeeper集群即多个Server节点</strong>，<strong>其中有一个Leader的节点，和多个Follower组成</strong>。</li><li><strong>写请求：</strong> <strong>当客户端Client执行写请求时，会发送到Leader节点上，然后Leader节点上数据变更会同步到集群中其他的Follower节点</strong>。Leader节点在接收到数据变更请求后，首先将变更写入本地磁盘，以作恢复之用。当所有的写请求持久化到磁盘以后，才会将变更应用到内存中。</li><li><strong>协议：</strong> ZooKeeper使用了一种自定义的<strong>原子消息协议</strong>，在消息层的这种原子特性，保证了整个协调系统中的节点数据或状态的一致性和本地的ZooKeeper数据与Leader节点同步。</li><li><strong>选举：</strong> 当Leader节点发生故障，消息层负责<strong>重新选举出Leader</strong>，继续作为协调服务集群的中心，处理客户端写请求。</li></ol><a id="more"></a><h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160505225608.png" alt="Zookeeper数据模型"></p><ol><li><strong>ZooKeeper数据模型的结构与Linux文件系统很类似</strong>，树结构，每个节点称做一个<strong>ZNode</strong>。</li><li>每个ZNode都可以通过其路径唯一标识，每个ZNode上可存储少量数据(<em>默认是1M, 可以通过配置修改, 通常不建议在ZNode上存储大量的数据</em>)。</li><li><strong>每个ZNode还拥有自身的一些信息，包括：数据、数据长度、创建时间、修改时间等</strong>Znode中的数据可以有多个版本，比如某一个路径下存有多个数据版本，那么查询这个路径下的数据就需要带上版本。</li><li><strong>每当Znode中的数据更新后它所维护的版本号将增加</strong>，每一个Znode的数据将被<strong>原子地读写</strong>。读操作将读取与Znode相关的所有数据，写操作将替换掉所有的数据。</li><li><strong>znode 的目录名可以自动编号</strong>，如 ZK_1 已经存在，再创建的话，将会自动命名为 ZK_2 </li></ol><ul><li><p><strong>永久节点</strong><br><strong>永久节点一经创建就永久保留了</strong>，就像我们在文件系统上创建一个普通文件，这个文件的生命周期跟创建它的应用没有任何关系。</p></li><li><p><strong>临时节点</strong><br><strong>一个session回话创建临时节点后，该会话过期之后，临时节点就会被zookeeper自动删除。</strong>我们可以很好的利用该特性，做一些集群感知。</p></li></ul><h3 id="ZooKeeper特性"><a href="#ZooKeeper特性" class="headerlink" title="ZooKeeper特性"></a>ZooKeeper特性</h3><ol><li><p>读、写(更新)模式<br>在<code>ZooKeeper集群</code>中，<strong>读可以从任意一个ZooKeeper Server读</strong>，这一点是保证ZooKeeper比较好的读性能的关键；<strong>写的请求会先Forwarder到Leader，然后由Leader来通过ZooKeeper中的原子广播协议，将请求广播给所有的Follower</strong>，Leader收到一半以上的写成功的Ack后，就认为该写成功了，就会将该写进行持久化，并告诉客户端写成功了。</p></li><li><p>WAL和Snapshot<br>和大多数分布式系统一样，ZooKeeper也有WAL(<em>Write-Ahead-Log</em>)，对于每一个更新操作，<strong>ZooKeeper都会先写WAL, 然后再对内存中的数据做更新，然后向Client通知更新结果</strong>。另外，ZooKeeper还会定期将内存中的目录树进行Snapshot，落地到磁盘上，这个跟HDFS中的FSImage是比较类似的。这么做的主要目的，一当然是数据的持久化，二是加快重启之后的恢复速度，如果全部通过Replay WAL的形式恢复的话，会比较慢。</p></li><li><p>FIFO<br>对于每一个ZooKeeper客户端而言，所有的操作都是遵循FIFO顺序的，这一特性是由下面两个基本特性来保证的：一是ZooKeeper Client与Server之间的网络通信是基于TCP，TCP保证了Client/Server之间传输包的顺序；二是ZooKeeper Server执行客户端请求也是严格按照FIFO顺序的。</p></li><li><p>Linearizability<br>在ZooKeeper中，所有的更新操作都有严格的偏序关系，更新操作都是串行执行的，这一点是保证ZooKeeper功能正确性的关键。</p></li></ol><h3 id="Client-API"><a href="#Client-API" class="headerlink" title="Client API"></a>Client API</h3><blockquote><ol><li><strong>create</strong>(path, data, flags):  创建一个ZNode, path是其路径，data是要存储在该ZNode上的数据，flags常用的有: PERSISTEN,PERSISTENT_SEQUENTAIL, EPHEMERAL, EPHEMERAL_SEQUENTAIL。</li><li><strong>delete</strong>(path, version):  删除一个ZNode，可以通过version删除指定的版本, 如果version是-1的话，表示删除所有的版本。</li><li><strong>exists</strong>(path, watch):  判断指定ZNode是否存在，并设置是否Watch这个ZNode。这里如果要设置Watcher的话，Watcher是在创建ZooKeeper实例时指定的，如果要设置特定的Watcher的话，可以调用另一个重载版本的exists(path, watcher)。以下几个带watch参数的API也都类似。</li><li><strong>getData</strong>(path, watch):  读取指定ZNode上的数据，并设置是否watch这个ZNode。</li><li><strong>setData</strong>(path, watch):  更新指定ZNode的数据，并设置是否Watch这个ZNode。</li><li><strong>getChildren</strong>(path, watch):  获取指定ZNode的所有子ZNode的名字，并设置是否Watch这个ZNode。</li><li><strong>sync</strong>(path):  把所有在sync之前的更新操作都进行同步，达到每个请求都在半数以上的ZooKeeper Server上生效。path参数目前没有用。</li><li>setAcl(path, acl):  设置指定ZNode的Acl信息。</li><li>getAcl(path):  获取指定ZNode的Acl信息。</li></ol></blockquote><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><h3 id="Curator"><a href="#Curator" class="headerlink" title="Curator"></a>Curator</h3><ul><li><a href="http://mvnrepository.com/artifact/org.apache.curator/curator-recipes" target="_blank" rel="noopener">Curator</a>框架，一个流行的zookeeper的客户端，提供了一套高级的API，简化了ZooKeeper的操作。 它增加了很多使用ZooKeeper开发的特性，可以处理ZooKeeper集群复杂的连接管理和重试机制。下面示例代码将使用Curator。官方文档：<a href="http://curator.apache.org/" target="_blank" rel="noopener">http://curator.apache.org/</a></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160506003506.png" alt="Curator"></p><p>详细讲解可查看该博客<a href="http://supben.iteye.com/blog/2094077" target="_blank" rel="noopener">http://supben.iteye.com/blog/2094077</a></p><h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><ul><li><p>示例代码： 创建节点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createNode</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 指定zk集群的地址</span></span><br><span class="line">String connectString = <span class="string">"192.168.3.220:2181,192.168.3.221:2181,192.168.3.222:2181"</span>;</span><br><span class="line"><span class="comment">//1000 ：代表是重试时间间隔  3：表示是重试次数</span></span><br><span class="line">RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 使用curator创建一个zk链接</span></span><br><span class="line"><span class="keyword">int</span> sessionTimeoutMs = <span class="number">5000</span>;<span class="comment">//这个值必须在4s--40s之间，表示是链接失效的时间</span></span><br><span class="line"><span class="keyword">int</span> connectionTimeoutMs = <span class="number">1000</span>;<span class="comment">//链接超时时间</span></span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.</span><br><span class="line">newClient(connectString, sessionTimeoutMs , connectionTimeoutMs , retryPolicy);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. 启动链接</span></span><br><span class="line">client.start();</span><br><span class="line"></span><br><span class="line">InetAddress localHost = InetAddress.getLocalHost();</span><br><span class="line">String ip = localHost.getHostAddress();</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 4. 创建节点</span></span><br><span class="line"><span class="comment"> * EPHEMERAL 临时节点</span></span><br><span class="line"><span class="comment"> * EPHEMERAL_SEQUENTIAL 临时有序</span></span><br><span class="line"><span class="comment"> * PERSISTENT 永久节点</span></span><br><span class="line"><span class="comment"> * PERSISTENT_SEQUENTIAL 永久有序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">client.create()</span><br><span class="line">.creatingParentsIfNeeded()<span class="comment">//如果父节点不存在，则创建,这时创建的父节点是永久节点</span></span><br><span class="line">.withMode(CreateMode.EPHEMERAL)<span class="comment">//指定节点类型</span></span><br><span class="line">.withACL(Ids.OPEN_ACL_UNSAFE)<span class="comment">//指定节点的权限信息</span></span><br><span class="line">.forPath(<span class="string">"/spider/"</span>+ip);<span class="comment">//指定节点名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//这里只是避免创建临时节点时，程序一结束很快就消失了，看不了效果</span></span><br><span class="line">Thread.sleep(<span class="number">10000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//当创建一个临时节点时，如果程序结果，该节点会过sessionTimeoutMs的时间后消失！</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>示例代码：监视器,在这里主要举例一个zookeeper通过利用临时节点session失效特性做一个监控功能。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建一个监视器，这个监视器需要实现watcher接口</span></span><br><span class="line"><span class="comment"> * 接口中有一个process方法。</span></span><br><span class="line"><span class="comment"> * 当监视器发现监视的节点发生变化的时候，这个process方法会被调用</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 所以这个监视器是一个守护进程，也就是说一个永远不会停止的进程，类似于死循环</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/5/5.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpiderWatcher</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    CuratorFramework client ;</span><br><span class="line">    List&lt;String&gt; chiList ;</span><br><span class="line">    List&lt;String&gt; newChiList ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SpiderWatcher</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定zk集群的地址</span></span><br><span class="line">        String connectStr = <span class="string">"192.168.3.220:2181,192.168.3.221:2181,192.168.3.222:2181"</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1000 ：代表是重试时间间隔     3：表示是重试次数</span></span><br><span class="line">        RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>) ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用curator创建一个zk链接</span></span><br><span class="line">        <span class="keyword">int</span> sessionTimeoutMs = <span class="number">3000</span> ;   <span class="comment">//这个值必须在4s--40s之间，表示是链接失效的时间</span></span><br><span class="line">        <span class="keyword">int</span> connectionTimeoutMs = <span class="number">4000</span> ;<span class="comment">//链接超时时间</span></span><br><span class="line">        client = CuratorFrameworkFactory.</span><br><span class="line">newClient(connectStr, sessionTimeoutMs, connectionTimeoutMs, retryPolicy);</span><br><span class="line"></span><br><span class="line">        client.start(); <span class="comment">//开启这个链接</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//使用SpiderWater监视Spider节点下面节点的所有变化</span></span><br><span class="line">            <span class="comment">//(想spider节点注册监视器，监视器需要重复注册)</span></span><br><span class="line">            chiList =  client.getChildren().usingWatcher(<span class="keyword">this</span>).forPath(<span class="string">"/spider"</span>);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//重复注册监视器</span></span><br><span class="line">            newChiList = client.getChildren().usingWatcher(<span class="keyword">this</span>).forPath(<span class="string">"/spider"</span>);</span><br><span class="line">            <span class="keyword">for</span> (String s : chiList) &#123;</span><br><span class="line">                <span class="keyword">if</span>( !newChiList.contains(s) )&#123;</span><br><span class="line">                    System.out.println(<span class="string">"节点消失："</span>+s);</span><br><span class="line">                    <span class="comment">//给管理员发送短信，或者邮件</span></span><br><span class="line">                    <span class="comment">//发短信的话可以使用一些第三方平台 云片网</span></span><br><span class="line">                    <span class="comment">//发邮件的话使用  javamail</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String s : chiList) &#123;</span><br><span class="line">                <span class="keyword">if</span>( !chiList.contains(s) )&#123;</span><br><span class="line">                    System.out.println(<span class="string">"节点新增："</span>+s);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.chiList = newChiList ;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//        System.out.println("节点发生变化，"+event);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//为了保证让这个方法一直运行</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line">            ;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpiderWatcher spiderWatcher = <span class="keyword">new</span> SpiderWatcher();</span><br><span class="line">        spiderWatcher.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>参考资料<br><a href="http://curator.apache.org/" target="_blank" rel="noopener">http://curator.apache.org/</a><br><a href="http://www.blogjava.net/BucketLi/archive/2010/12/21/341268.html" target="_blank" rel="noopener">http://www.blogjava.net/BucketLi/archive/2010/12/21/341268.html</a><br><a href="http://blog.csdn.net/xinguan1267/article/details/38422149" target="_blank" rel="noopener">http://blog.csdn.net/xinguan1267/article/details/38422149</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper--集群启动报错记录</title>
      <link href="/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/"/>
      <url>/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url>
      <content type="html"><![CDATA[<p>　　记录一个Zookeeper集群启动报错的问题，虽然是小问题，但让我找了一个多小时才解决。检查了配置、版本、ip、集群映射都没问题。</p><ul><li><p>启动客服端，一直报错，信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2016-05-06 01:58:23,980 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@975] - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">2016-05-06 01:58:23,983 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@852] - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session</span><br><span class="line">2016-05-06 01:58:23,987 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@1098] - Unable to <span class="built_in">read</span> additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect</span><br><span class="line">2016-05-06 01:58:25,062 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@975] - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">2016-05-06 01:58:25,066 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@852] - Socket connection established to localhost/127.0.0.1:2181, initiating session</span><br><span class="line">2016-05-06 01:58:25,070 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@1098] - Unable to <span class="built_in">read</span> additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect</span><br><span class="line">2016-05-06 01:58:27,075 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@975] - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">2016-05-06 02:09:01,225 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@852] - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session</span><br><span class="line">2016-05-06 02:09:01,231 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn<span class="variable">$SendThread</span>@1098] - Unable to <span class="built_in">read</span> additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect</span><br></pre></td></tr></table></figure></li><li><p>最后结局办法：<br>发现是<strong>自己修改了hosts，然后没有重启</strong>。<strong>重启后问题解决</strong>。（还有记得关掉防火墙）</p></li></ul>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper--集群搭建</title>
      <link href="/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/2016/05/05/Zookeeper-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>　　<code>zookeeper</code>集群搭建，是非常简单的。本博客就简单的记录一下，不详细的说每一个步骤了。主要就是下载后解压，修改配置，拷贝到其他节点，该一下myid中的编号后启动即可。</p><h2 id="单机模式："><a href="#单机模式：" class="headerlink" title="单机模式："></a>单机模式：</h2><ol><li><strong>下载</strong><a href="http://apache.fayea.com/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">zookeeper-3.4.6.tar.gz</a>：上传到服务器目录</li><li><strong>解压到指定目录</strong>：tar -zxvf zookeeper-3.4.6.tar.gz -C /usr/local/zookeeper</li><li>cd zookeeper/conf</li><li><strong>修改配置文件名称</strong>：mv zoo_sample.cfg  zoo.cfg</li><li>cd ..</li><li><strong>启动zookeeper</strong>：bin/zkServer.sh start</li><li><strong>验证</strong>：jps，看到有这个<em>（QuorumPeerMain）</em>进程就表示zookeeper已经正常启动。</li></ol><a id="more"></a><h2 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h2><p>需要使用多台服务器，建议使用奇数台服务器，在这使用三台，服务器的ip分别是：192.168.3.220 192.168.3.221 192.168.3.222</p><ol><li>在192.168.3.220服务器上执行这些操作，把这个<a href="http://apache.fayea.com/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">zookeeper-3.4.6.tar.gz</a>文件上传到服务器目录</li><li><strong>解压</strong>：tar -zxvf zookeeper-3.4.6.tar.gz -C /usr/local/zookeeper</li><li><strong>重命名</strong>：mv zookeeper-3.4.5 zookeeper</li><li>cd zookeeper/conf</li><li><strong>修改配置文件名称</strong>：mv zoo_sample.cfg  zoo.cfg</li><li>vi zoo.cfg<br> 修改配置文件中的datadir:/usr/local/zookeeper-3.4.6/data<br> 添加下面配置：（ip可以改为主机名）<br> server.0=192.168.3.220:2888:3888<br> server.1=192.168.3.220:2888:3888<br> server.2=192.168.3.220:2888:3888</li><li>cd ..</li><li><strong>创建目录</strong>：mkdir data</li><li><strong>在data目录下创建文件</strong>：vi myid，在里面保存当前节点的编号<br> 注意：在192.168.3.220服务器上面保存的编号是0</li><li>cd /usr/local</li><li><strong>把220服务器上的zookeeper目录拷贝到其他两个节点</strong><br>scp -rq zookeeper 192.168.3.221:/usr/local<br>scp -rq zookeeper 192.168.3.222:/usr/local</li><li><strong>连接到192.168.3.221</strong>，cd /usr/local/zookeeper/data  修改myid中的编号为1</li><li><strong>连接到192.168.3.222</strong>，cd /usr/local/zookeeper/data  修改myid中的编号为2</li><li><strong>启动这三个节点</strong>：<br>在170上的/usr/local/zookeeper目录下执行命令：bin/zkServer.sh start<br>在171上的/usr/local/zookeeper目录下执行命令：bin/zkServer.sh start<br>在172上的/usr/local/zookeeper目录下执行命令：bin/zkServer.sh start</li><li><strong>最后jps验证即可</strong>。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo zookeeper]<span class="comment"># jps</span></span><br><span class="line">1245 QuorumPeerMain</span><br><span class="line">1518 Jps</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--优化详解</title>
      <link href="/2016/05/02/Redis-%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3/"/>
      <url>/2016/05/02/Redis-%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　本片博客，刚开始会讲解一下redis的<strong>基本优化</strong>，然后会举一些优化<strong>示例代码或实例</strong>。最后讲解一下，默认启动redis时，所报的一些<strong>警示错误</strong>。</p><h2 id="优化的一些建议"><a href="#优化的一些建议" class="headerlink" title="优化的一些建议"></a>优化的一些建议</h2><ol><li><p><strong>尽量使用短的key</strong><br>当然在精简的同时，不要完了key的“见名知意”。对于value有些也可精简，比如性别使用0、1。</p></li><li><p><strong>避免使用keys *</strong><br><code>keys *</code>, 这个命令是阻塞的，即操作执行期间，其它任何命令在你的实例中都无法执行。当redis中key数据量小时到无所谓，数据量大就很糟糕了。所以我们应该避免去使用这个命令。可以去使用<a href="http://www.redis.cn/commands/scan.html" target="_blank" rel="noopener">SCAN</a>,来代替。</p></li><li><p><strong>在存到Redis之前先把你的数据压缩下</strong><br>redis为每种数据类型都提供了两种内部编码方式，在不同的情况下redis会自动调整合适的编码方式。</p></li><li><p><strong>设置 </strong>key<strong> 有效期</strong><br>我们应该尽可能的利用key有效期。比如一些临时数据（短信校验码），过了有效期Redis就会自动为你清除！</p><a id="more"></a></li><li><p><strong>选择回收策略(maxmemory-policy)</strong><br><strong>当 Redis 的实例空间被填满了之后，将会尝试回收一部分key</strong>。根据你的使用方式，强烈建议使用 <strong>volatile-lru（默认）</strong> 策略——前提是你对key已经设置了超时。但如果你运行的是一些类似于 cache 的东西，并且没有对 key 设置超时机制，可以考虑使用 <strong>allkeys-lru</strong> 回收机制，<a href="http://redis.io/topics/lru-cache#eviction-policies" target="_blank" rel="noopener">具体讲解查看</a> 。maxmemory-samples 3 是说每次进行淘汰的时候 会随机抽取3个key 从里面淘汰最不经常使用的（默认选项）</p><blockquote><p>maxmemory-policy 六种方式 :<br>volatile-lru：只对设置了过期时间的key进行LRU（默认值）<br>allkeys-lru ： 是从所有key里 删除 不经常使用的key<br>volatile-random：随机删除即将过期key<br>allkeys-random：随机删除<br>volatile-ttl ： 删除即将过期的<br>noeviction ： 永不过期，返回错误</p></blockquote></li><li><p>使用bit位级别操作和byte字节级别操作来减少不必要的内存使用。</p><blockquote><p><strong>bit位级别操作</strong>：GETRANGE, SETRANGE, GETBIT and SETBIT<br><strong>byte字节级别操作</strong>：GETRANGE and SETRANGE</p></blockquote></li><li><p>尽可能地使用hashes哈希存储。</p></li><li><p>当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能。</p></li><li><p>想要一次添加多条数据的时候可以使用管道。</p></li><li><p><strong>限制redis的内存大小</strong>（64位系统不限制内存，32位系统默认最多使用3GB内存）<br>数据量不可预估，并且内存也有限的话，尽量限制下redis使用的内存大小，这样可以避免redis使用swap分区或者出现OOM错误。（使用swap分区，性能较低，如果限制了内存，当到达指定内存之后就不能添加数据了，否则会报OOM错误。可以设置maxmemory-policy，内存不足时删除数据。）</p></li><li><p>SLOWLOG [get/reset/len]</p><blockquote><p>slowlog-log-slower-than 它决定要对执行时间大于多少微秒(microsecond，1秒 = 1,000,000 微秒)的命令进行记录。<br>slowlog-max-len 它决定 slowlog 最多能保存多少条日志，当发现redis性能下降的时候可以查看下是哪些命令导致的。</p></blockquote></li></ol><h2 id="优化实例分析"><a href="#优化实例分析" class="headerlink" title="优化实例分析"></a>优化实例分析</h2><h3 id="管道性能测试"><a href="#管道性能测试" class="headerlink" title="管道性能测试"></a>管道性能测试</h3><p><strong>redis的管道功能在命令行中没有，但是redis是支持管道的，在java的客户端(jedis)中是可以使用的</strong>：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160427172349.png" alt="redis管道"></p><ul><li>示例代码<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//注：具体耗时，和自身电脑有关(博主是在虚拟机中运行的数据)</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 不使用管道初始化1W条数据</span></span><br><span class="line"><span class="comment"> * 耗时：3079毫秒</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">NOTUsePipeline</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Jedis jedis = JedisUtil.getJedis();</span><br><span class="line">    <span class="keyword">long</span> start_time = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        jedis.set(<span class="string">"aa_"</span>+i, i+<span class="string">""</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(System.currentTimeMillis()-start_time);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用管道初始化1W条数据</span></span><br><span class="line"><span class="comment"> * 耗时：255毫秒</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">usePipeline</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Jedis jedis = JedisUtil.getJedis();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> start_time = System.currentTimeMillis();</span><br><span class="line">    Pipeline pipelined = jedis.pipelined();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        pipelined.set(<span class="string">"cc_"</span>+i, i+<span class="string">""</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    pipelined.sync();<span class="comment">//执行管道中的命令</span></span><br><span class="line">    System.out.println(System.currentTimeMillis()-start_time);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="hash的应用"><a href="#hash的应用" class="headerlink" title="hash的应用"></a>hash的应用</h3><p>　　<strong>示例</strong>：我们要存储一个用户信息对象数据，包含以下信息：<br>key为用户ID，value为用户对象（姓名，年龄，生日等）如果用普通的key/value结构来存储，主要有以下2种存储方式：</p><ol><li><p>将用户ID作为查找key,把其他信息封装成一个对象以<strong>序列化的方式存储</strong><br>缺点：增加了序列化/反序列化的开销，引入复杂适应系统（Complex adaptive system，简称<a href="https://www.douban.com/group/topic/19342736/" target="_blank" rel="noopener">CAS</a>）修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160502234207.png" alt="方法一"></p></li><li><p>用户信息<strong>对象有多少成员就存成多少个key-value对</strong><br>虽然省去了序列化开销和并发问题，但是用户ID为重复存储。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160502234523.png" alt="方法二"></p></li></ol><ul><li>Redis提供的Hash很好的解决了这个问题，<strong>提供了直接存取这个Map成员的接口</strong>。<strong>Key仍然是用户ID, value是一个Map</strong>，这个Map的key是成员的属性名，value是属性值。(<em> <strong>内部实现</strong>：Redis Hashd的Value内部有2种不同实现，Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht</em> )。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160502235040.png" alt="hash存储"></li></ul><h3 id="Instagram内存优化"><a href="#Instagram内存优化" class="headerlink" title="Instagram内存优化"></a>Instagram内存优化</h3><p><code>Instagram</code>可能大家都已熟悉，当前火热的拍照App，月活跃用户3亿。四年前Instagram所存图片3亿多时需要解决一个问题：想知道每一张照片的作者是谁（通过图片ID反查用户UID），并且要求查询速度要相当的块，如果把它放到内存中使用String结构做key-value:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HSET <span class="string">"mediabucket:1155"</span> <span class="string">"1155315"</span> <span class="string">"939"</span></span><br><span class="line">HGET <span class="string">"mediabucket:1155"</span> <span class="string">"1155315"</span></span><br><span class="line"><span class="string">"939"</span></span><br></pre></td></tr></table></figure><p><strong>测试</strong>：1百万数据会用掉70MB内存，3亿张照片就会用掉21GB的内存。当时(四年前)最好是一台EC2的 high-memory 机型就能存储（17GB或者34GB的，68GB的太浪费了）,想把它放到16G机型中还是不行的。</p><ul><li>Instagram的开发者向Redis的开发者之一Pieter Noordhuis询问优化方案，得到的回复是<strong>使用Hash结构</strong>。具体的做法就是将数据分段，每一段使用一个Hash结构存储.<br>由于Hash结构会在单个Hash元素在不足一定数量时进行压缩存储，所以可以大量节约内存。这一点在上面的String结构里是不存在的。而这个一定数量是由配置文件中的hash-zipmap-max-entries参数来控制的。<strong>经过实验，将hash-zipmap-max-entries设置为1000时，性能比较好，超过1000后HSET命令就会导致CPU消耗变得非常大</strong>。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HSET <span class="string">"mediabucket:1155"</span> <span class="string">"1155315"</span> <span class="string">"939"</span></span><br><span class="line">HGET <span class="string">"mediabucket:1155"</span> <span class="string">"1155315"</span></span><br><span class="line"><span class="string">"939"</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>测试</strong>：1百万消耗16MB的内存。总内存使用也降到了5GB。当然我们还可以优化，去掉<code>mediabucket:</code>key长度减少了12个字节。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HSET <span class="string">"1155"</span> <span class="string">"315"</span> <span class="string">"939"</span></span><br><span class="line">HGET <span class="string">"1155"</span> <span class="string">"315"</span></span><br><span class="line"><span class="string">"939"</span></span><br></pre></td></tr></table></figure></p><h2 id="启动时WARNING优化"><a href="#启动时WARNING优化" class="headerlink" title="启动时WARNING优化"></a>启动时WARNING优化</h2><p>在我们启动redis时，默认会出现如下三个警告：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160502211355.png" alt="启动redis"></p><ul><li>一、修改<strong>linux</strong>中<strong>TCP</strong>监听的最大容纳数量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WARNING: The TCP backlog setting of 511 cannot be enforced because </span><br><span class="line">/proc/sys/net/core/somaxconn is <span class="built_in">set</span> to the lower value of 128.</span><br></pre></td></tr></table></figure></li></ul><p><strong>在高并发环境下你需要一个高backlog值来避免慢客户端连接问题</strong>。注意Linux内核默默地将这个值减小到<code>/proc/sys/net/core/somaxconn</code>的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果。<br>echo 511 &gt; /proc/sys/net/core/somaxconn<br><strong>注意</strong>：这个参数并不是限制redis的最大链接数。如果想限制redis的最大连接数需要修改maxclients，默认最大连接数为10000</p><ul><li>二、修改linux内核内存分配策略<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">错误日志：WARNING overcommit_memory is <span class="built_in">set</span> to 0! Background save may fail under low memory condition. </span><br><span class="line">To fix this issue add <span class="string">'vm.overcommit_memory = 1'</span> to /etc/sysctl.conf and <span class="keyword">then</span> reboot or </span><br><span class="line">run the <span class="built_in">command</span> <span class="string">'sysctl vm.overcommit_memory=1'</span></span><br></pre></td></tr></table></figure></li></ul><p>原因：<br><strong>redis在备份数据的时候，会fork出一个子进程，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为8G，这个时候也要同样分配8G的内存给child,如果内存无法负担，往往会造成redis服务器的down机或者IO负载过高，效率下降</strong>。所以内存分配策略应该设置为 1（表示内核允许分配所有的物理内存，而不管当前的内存状态如何）。<br>内存分配策略有三种<br>可选值：0、1、2。<br>0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。<br>1， 不管需要多少内存，都允许申请。<br>2， 只允许分配物理内存和交换内存的大小(交换内存一般是物理内存的一半)。</p><ul><li>三、关闭Transparent Huge Pages(THP)<br>THP会造成内存锁影响redis性能，建议关闭<blockquote><p>Transparent HugePages ：用来提高内存管理的性能<br>Transparent Huge Pages在32位的RHEL 6中是不支持的<br>执行命令 <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code><br>把这条命令添加到这个文件中/etc/rc.local</p></blockquote></li></ul><ul><li>参考资料<br><a href="http://www.infoq.com/cn/articles/tq-redis-memory-usage-optimization-storage" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/tq-redis-memory-usage-optimization-storage</a><br><a href="http://blog.nosqlfan.com/html/3379.html" target="_blank" rel="noopener">http://blog.nosqlfan.com/html/3379.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--集群</title>
      <link href="/2016/04/28/Redis-%E9%9B%86%E7%BE%A4/"/>
      <url>/2016/04/28/Redis-%E9%9B%86%E7%BE%A4/</url>
      <content type="html"><![CDATA[<p>　　<code>redis集群</code>是一个<strong>无中心的分布式</strong>Redis存储架构，<strong>可以在多个节点之间进行数据共享</strong>，解决了Redis高可用、可扩展等问题。redis集群提供了以下两个好处：</p><ol><li><strong>将数据自动切分(split)到多个节点</strong></li><li>当集群中的某一个节点故障时，redis还可以继续处理客户端的请求。</li><li>一个 Redis 集群包含 <code>16384</code> 个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽。<strong>集群中的每一个节点负责处理一部分哈希槽</strong>。</li></ol><ul><li><p><strong>集群中的主从复制：</strong><br><strong>集群中的每个节点都有1个至N个复制品，其中一个为主节点，其余的为从节点</strong>，<em>如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点，继续工作</em>。<strong>这样集群就不会因为一个主节点的下线而无法正常工作</strong>。</p></li><li><p><strong>注意：</strong><br><strong>如果某一个主节点和他所有的从节点都下线的话，redis集群就会停止工作了</strong>。<br><strong>redis集群不保证数据的强一致性</strong>，在<strong>特定的情况下</strong>，<em>redis集群会丢失已经被执行过的写命令使用异步复制（asynchronous replication）是 Redis 集群可能会丢失写命令的其中一个原因，有时候由于网络原因，如果网络断开时间太长，redis集群就会启用新的主节点，之前发给主节点的数据就会丢失</em>。</p></li></ul><a id="more"></a><h2 id="redis集群安装配置"><a href="#redis集群安装配置" class="headerlink" title="redis集群安装配置"></a>redis集群安装配置</h2><ol><li><p>修改配置文件redis.conf </p><blockquote><ol><li>daemonize yes</li><li>port 7000</li><li>cluster-enabled yes</li><li>cluster-config-file nodes.conf</li><li>cluster-node-timeout 5000<br>要让集群正常运作至少需要三个主节点</li></ol></blockquote></li><li><p>创建集群命令<br>./redis-trib.rb  create –replicas 1 192.168.1.160:7000 192.168.1.160:7001 192.168.1.160:7002 192.168.1.160:7003 192.168.1.160:7004 192.168.1.160:7005</p></li></ol><ul><li>示例代码 ： 这里我们在单机上模拟集群搭建<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########0. 准备服务器################################</span></span><br><span class="line">ip:  这里我们使用192.168.33.88搭建六个redis</span><br><span class="line">port:使用7000、7001、7002、7003、7004、7005</span><br><span class="line"></span><br><span class="line"><span class="comment">########1. 在/usr/local/创建一个cluster目录###########</span></span><br><span class="line"><span class="comment">########2. 复制配置文件到cluster/目录##################</span></span><br><span class="line"><span class="comment">########3. 创建7001-7005目录##########################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># ll</span></span><br><span class="line">总用量 68</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:27 7000</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:30 7001</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:29 7002</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:28 7003</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:28 7004</span><br><span class="line">drwxr-xr-x. 2 root root  4096 4月  29 01:28 7005</span><br><span class="line">-rw-r--r--. 1 root root 41550 4月  29 01:27 redis.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">########4. 复制redis.conf文件到每个目录################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7000</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7001</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7002</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7003</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7004</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp ./redis.conf 7005</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########4. 修改配置文件端口号##########################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># vim ./redis.conf ##查看行号</span></span><br><span class="line">49 <span class="comment"># If port 0 is specified Redis will not listen on a TCP socket.</span></span><br><span class="line">50 port 7000</span><br><span class="line">51 </span><br><span class="line">52 <span class="comment"># TCP listen() backlog.</span></span><br><span class="line"></span><br><span class="line">查看到端口号在50行于是使用sed命令修改</span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7001/" 7001/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7002/" 7002/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7003/" 7003/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7004/" 7004/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7005/" 7005/redis.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########5. 分别启动这6个redis实例######################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cd 7000/</span></span><br><span class="line">[root@momo1 7000]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7000]<span class="comment"># cd ../7001/</span></span><br><span class="line">[root@momo1 7001]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7001]<span class="comment"># cd ../7002/</span></span><br><span class="line">[root@momo1 7002]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7002]<span class="comment"># cd ../7003/</span></span><br><span class="line">[root@momo1 7003]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7003]<span class="comment"># cd ../7004/</span></span><br><span class="line">[root@momo1 7004]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7004]<span class="comment"># cd ../7005/</span></span><br><span class="line">[root@momo1 7005]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 7005]<span class="comment"># ps -ef|grep redis</span></span><br><span class="line">root       7694      1  0 06:30 ?        00:00:00 redis-server *:7000 [cluster]</span><br><span class="line">root       7698      1  0 06:31 ?        00:00:00 redis-server *:7001 [cluster]</span><br><span class="line">root       7702      1  0 06:31 ?        00:00:00 redis-server *:7002 [cluster]</span><br><span class="line">root       7712      1  0 06:31 ?        00:00:00 redis-server *:7003 [cluster]</span><br><span class="line">root       7716      1  0 06:31 ?        00:00:00 redis-server *:7004 [cluster]</span><br><span class="line">root       7720      1  0 06:31 ?        00:00:00 redis-server *:7005 [cluster]</span><br><span class="line">root       7726   5794  0 06:32 pts/2    00:00:00 grep redis</span><br><span class="line"></span><br><span class="line"><span class="comment">########6. 执行redis的创建集群命令创建集群################</span></span><br><span class="line">[root@momo1 src]<span class="comment"># ./redis-trib.rb create --replicas 1 192.168.33.88:7000 192.168.33.88:7001 192.168.33.88:7002 192.168.33.88:7003 192.168.33.88:7004 192.168.33.88:7005</span></span><br><span class="line"></span><br><span class="line">如报错：/usr/bin/env: ruby: 没有那个文件或目录 ，安装ruby:yum -y install ruby</span><br><span class="line">如报错：./redis-trib.rb:24:<span class="keyword">in</span> `require<span class="string">': no such file to load -- rubygems (LoadError)</span></span><br><span class="line"><span class="string">from ./redis-trib.rb:24  安装ruby:yum -y install rubygems</span></span><br><span class="line"><span class="string">错误内容：</span></span><br><span class="line"><span class="string">/usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'</span>: no such file to load -- redis (LoadError)</span><br><span class="line">from /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:<span class="keyword">in</span> `require<span class="string">'</span></span><br><span class="line"><span class="string">from ./redis-trib.rb:25  使用gem 安装:gem install redis</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#####正常运行，输入yes</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Creating cluster</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...</span></span><br><span class="line"><span class="string">Using 3 masters:</span></span><br><span class="line"><span class="string">192.168.33.88:7000</span></span><br><span class="line"><span class="string">192.168.33.88:7001</span></span><br><span class="line"><span class="string">192.168.33.88:7002</span></span><br><span class="line"><span class="string">Adding replica 192.168.33.88:7003 to 192.168.33.88:7000</span></span><br><span class="line"><span class="string">Adding replica 192.168.33.88:7004 to 192.168.33.88:7001</span></span><br><span class="line"><span class="string">Adding replica 192.168.33.88:7005 to 192.168.33.88:7002</span></span><br><span class="line"><span class="string">M: 7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000</span></span><br><span class="line"><span class="string">   slots:0-5460 (5461 slots) master</span></span><br><span class="line"><span class="string">M: 433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001</span></span><br><span class="line"><span class="string">   slots:5461-10922 (5462 slots) master</span></span><br><span class="line"><span class="string">M: c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002</span></span><br><span class="line"><span class="string">   slots:10923-16383 (5461 slots) master</span></span><br><span class="line"><span class="string">S: 054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003</span></span><br><span class="line"><span class="string">   replicates 7a869b7e7b55094949c060bd5f2f99174c79be59</span></span><br><span class="line"><span class="string">S: fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004</span></span><br><span class="line"><span class="string">   replicates 433d5052db72f7915bfe491f3afefcfd636da285</span></span><br><span class="line"><span class="string">S: 7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005</span></span><br><span class="line"><span class="string">   replicates c7820416485d4af315146266bb42abd171099934</span></span><br><span class="line"><span class="string">Can I set the above configuration? (type '</span>yes<span class="string">' to accept): yes</span></span><br><span class="line"><span class="string">//......</span></span><br><span class="line"><span class="string">[OK] All nodes agree about slots configuration.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Check for open slots...</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Check slots coverage...</span></span><br><span class="line"><span class="string">[OK] All 16384 slots covered.</span></span><br><span class="line"><span class="string">[root@momo1 ~]# ps -ef|grep redis</span></span><br><span class="line"><span class="string">root       7694      1  0 06:30 ?        00:00:01 redis-server *:7000 [cluster]</span></span><br><span class="line"><span class="string">root       7698      1  0 06:31 ?        00:00:01 redis-server *:7001 [cluster]</span></span><br><span class="line"><span class="string">root       7702      1  0 06:31 ?        00:00:01 redis-server *:7002 [cluster]</span></span><br><span class="line"><span class="string">root       7712      1  0 06:31 ?        00:00:01 redis-server *:7003 [cluster]</span></span><br><span class="line"><span class="string">root       7716      1  0 06:31 ?        00:00:01 redis-server *:7004 [cluster]</span></span><br><span class="line"><span class="string">root       7720      1  0 06:31 ?        00:00:01 redis-server *:7005 [cluster]</span></span><br><span class="line"><span class="string">root       8377   8355  0 06:52 pts/1    00:00:00 grep redis</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">########7. redis-cli命令进入集群环境################</span></span><br><span class="line"><span class="string">redis-cli -c -p 7000 ##可任意进入其他节点</span></span><br><span class="line"><span class="string">redis-cli -c -p 7000 cluster nodes [| grep master] ##查看</span></span><br><span class="line"><span class="string">[root@momo1 src]# redis-cli -c -p 7000 cluster nodes</span></span><br><span class="line"><span class="string">fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004 slave 433d5052db72f7915bfe491f3afefcfd636da285 0 1461883595276 5 connected</span></span><br><span class="line"><span class="string">c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002 master - 0 1461883592754 3 connected 10923-16383</span></span><br><span class="line"><span class="string">7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005 slave c7820416485d4af315146266bb42abd171099934 0 1461883596285 6 connected</span></span><br><span class="line"><span class="string">054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003 slave 7a869b7e7b55094949c060bd5f2f99174c79be59 0 1461883593258 4 connected</span></span><br><span class="line"><span class="string">433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001 master - 0 1461883594266 2 connected 5461-10922</span></span><br><span class="line"><span class="string">7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000 myself,master - 0 0 1 connected 0-5460</span></span><br><span class="line"><span class="string">====&gt;可以看见id ip:端口 主/从 主id 哈希槽区域</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">127.0.0.1:7000&gt; set ab momo</span></span><br><span class="line"><span class="string">-&gt; Redirected to slot [13567] located at 192.168.33.88:7002</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">192.168.33.88:7002&gt; get ab  ##key通过哈希槽分配到7002中</span></span><br><span class="line"><span class="string">"momo"</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="redis集群操作"><a href="#redis集群操作" class="headerlink" title="redis集群操作"></a>redis集群操作</h2><h3 id="添加节点"><a href="#添加节点" class="headerlink" title="添加节点"></a>添加节点</h3><p>根据<strong>添加节点</strong>类型的不同，有<strong>两种方法</strong>来添加新节点</p><ul><li>主节点：如果添加的是主节点，那么我们需要创建一个空节点，然后将某些哈希槽移动到这个空节点里面</li><li><p>从节点：如果添加的是从节点，我们也需要创建一个空节点，然后把这个新节点设置成集群中某个主节点的复制品。<br>命令</p></li><li><p><strong>添加节点到集群</strong>：redis-trib.rb add-node 192.168.33.88:7006 192.168.33.88:7000</p></li><li><p><strong>(添加主节点)重新分片</strong>：重新分片操作基本上就是将某些节点上的哈希槽移动到另外一些节点上面.</p></li></ul><ol><li>使用命令./redis-trib.rb reshard 192.168.1.160:7000</li><li>执行 redis-trib 的第一步就是设定你打算移动的哈希槽的数量：</li><li>第二部是输入接收solts的节点ID</li><li>redis-trib 会向你询问重新分片的源节点（source node），也就是需要从哪个节点中转移哈希槽（可以使用all）最后输入 yes 并使用按下回车之后， redis-trib 就会正式开始执行重新分片操作</li></ol><ul><li><strong>(添加从节点)把集群中的某个节点设置为从节点</strong>：</li></ul><ol><li>redis-cli -c -p 7007 #进入7007为要修改为从节点的端口号</li><li>cluster replicate 0b00721a509444db793d28448d8f02168b94bd38 #后面为主节点id</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">########一. 添加一个主节点########################</span></span><br><span class="line"><span class="comment">########1. 首先把需要添加的节点启动################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># mkdir 7006</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp redis.conf 7006/</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7006/" 7006/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cd 7006/</span></span><br><span class="line">[root@momo1 7006]<span class="comment"># redis-server ./redis.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########2. 将这个新节点添加到集群中################</span></span><br><span class="line">[root@momo1 7007]<span class="comment"># cd /usr/local/redis/src/</span></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-</span></span><br><span class="line">redis-benchmark   redis-check-dump  redis-sentinel    redis-trib.rb</span><br><span class="line">redis-check-aof   redis-cli         redis-server      </span><br><span class="line">[root@momo1 src]<span class="comment"># redis-trib.rb add-node 192.168.33.88:7006 192.168.33.88:7000 </span></span><br><span class="line"><span class="comment">#最后这个ip:port六选一都行</span></span><br><span class="line">&gt;&gt;&gt; Adding node 192.168.33.88:7006 to cluster 192.168.33.88:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 192.168.33.88:7000)</span><br><span class="line">M: 7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 433d5052db72f7915bfe491f3afefcfd636da285</span><br><span class="line">M: c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates c7820416485d4af315146266bb42abd171099934</span><br><span class="line">S: 054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 7a869b7e7b55094949c060bd5f2f99174c79be59</span><br><span class="line">M: 433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check <span class="keyword">for</span> open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 192.168.33.88:7006 to make it join the cluster.</span><br><span class="line">[OK] New node added correctly.</span><br><span class="line"></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-cli -c -p 7000 cluster nodes #查看7006为master</span></span><br><span class="line">fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004 slave 433d5052db72f7915bfe491f3afefcfd636da285 0 1461884624785 5 connected</span><br><span class="line">c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002 master - 0 1461884620748 3 connected 10923-16383</span><br><span class="line">7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005 slave c7820416485d4af315146266bb42abd171099934 0 1461884625810 6 connected</span><br><span class="line">054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003 slave 7a869b7e7b55094949c060bd5f2f99174c79be59 0 1461884623775 4 connected</span><br><span class="line">ea2b724ca7603e0a2036cf97781553dec1b0fad2 192.168.33.88:7006 master - 0 1461884621758 0 connected</span><br><span class="line">433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001 master - 0 1461884622768 2 connected 5461-10922</span><br><span class="line">7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000 myself,master - 0 0 1 connected 0-5460</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">########3. 这个新的节点可以成为主节点或者是从节点################</span></span><br><span class="line">把这个节点变成主节点，使用redis-trib程序，将集群中的某些哈希槽移动到新节点里面，这个新节点就成为真正的主节点了。</span><br><span class="line">执行下面的命令对集群中的哈希槽进行移动:</span><br><span class="line">[root@momo1 src]<span class="comment"># cd /usr/local/redis/src/</span></span><br><span class="line">[root@momo1 src]<span class="comment"># ./redis-trib.rb reshard 192.168.33.88:7006</span></span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 192.168.33.88:7006)</span><br><span class="line">M: ea2b724ca7603e0a2036cf97781553dec1b0fad2 192.168.33.88:7006</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">S: fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 433d5052db72f7915bfe491f3afefcfd636da285</span><br><span class="line">M: 7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates c7820416485d4af315146266bb42abd171099934</span><br><span class="line">M: c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 7a869b7e7b55094949c060bd5f2f99174c79be59</span><br><span class="line">M: 433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check <span class="keyword">for</span> open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">How many slots <span class="keyword">do</span> you want to move (from 1 to 16384)? 2000 <span class="comment">#提示移动多少哈希槽，这移动2000</span></span><br><span class="line">What is the receiving node ID?ea2b724ca7603e0a203..........<span class="comment">#移到那个节点，这里为新增的</span></span><br><span class="line">Please enter all the <span class="built_in">source</span> node IDs.</span><br><span class="line">  Type <span class="string">'all'</span> to use all the nodes as <span class="built_in">source</span> nodes <span class="keyword">for</span> the <span class="built_in">hash</span> slots.</span><br><span class="line">  Type <span class="string">'done'</span> once you entered all the <span class="built_in">source</span> nodes IDs.</span><br><span class="line">Source node <span class="comment">#1:all #输入all 表示从所有的主节点中随机转移，凑够2000个哈希槽</span></span><br><span class="line"></span><br><span class="line">....然后输入：yes</span><br><span class="line"></span><br><span class="line">//<span class="comment">######这样我们就分配好了，然后查看一下</span></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-cli -c -p 7000 cluster nodes</span></span><br><span class="line">fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004 slave 433d5052db72f7915bfe491f3afefcfd636da285 0 1461885154660 5 connected</span><br><span class="line">c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002 master - 0 1461885150120 3 connected 11589-16383</span><br><span class="line">7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005 slave c7820416485d4af315146266bb42abd171099934 0 1461885154157 6 connected</span><br><span class="line">054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003 slave 7a869b7e7b55094949c060bd5f2f99174c79be59 0 1461885155165 4 connected</span><br><span class="line">ea2b724ca7603e0a2036cf97781553dec1b0fad2 192.168.33.88:7006 master - 0 1461885156172 7 connected 0-665 5461-6127 10923-11588</span><br><span class="line">433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001 master - 0 1461885152140 2 connected 6128-10922</span><br><span class="line">7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000 myself,master - 0 0 1 connected 666-5460</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">########二. 添加一个从节点########################</span></span><br><span class="line"><span class="comment">########1. 首先把需要添加的节点启动################</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># mkdir 7007</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cp redis.conf 7007/</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># sed -i "50s/7000/7007/" 7007/redis.conf</span></span><br><span class="line">[root@momo1 cluster]<span class="comment"># cd 7007/</span></span><br><span class="line">[root@momo1 7007]<span class="comment"># redis-server ./redis.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########2. 将这个新节点添加到集群中################</span></span><br><span class="line">[root@momo1 7007]<span class="comment"># cd /usr/local/redis/src/</span></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-trib.rb add-node 192.168.33.88:7007 192.168.33.88:7000  //添加</span></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-cli -c -p 7000 cluster nodes</span></span><br><span class="line">fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004 slave 433d5052db72f7915bfe491f3afefcfd636da285 0 1461886668520 5 connected</span><br><span class="line">c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002 master - 0 1461886665997 3 connected 11589-16383</span><br><span class="line">7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005 slave c7820416485d4af315146266bb42abd171099934 0 1461886666503 6 connected</span><br><span class="line">08908d24194bcbeeb7a6bca3024eb20d2f43b6cb 192.168.33.88:7007 master - 0 1461886667511 0 connected</span><br><span class="line">054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003 slave 7a869b7e7b55094949c060bd5f2f99174c79be59 0 1461886665494 4 connected</span><br><span class="line">ea2b724ca7603e0a2036cf97781553dec1b0fad2 192.168.33.88:7006 master - 0 1461886667007 7 connected 0-665 5461-6127 10923-11588</span><br><span class="line">433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001 master - 0 1461886664487 2 connected 6128-10922</span><br><span class="line">7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000 myself,master - 0 0 1 connected 666-5460</span><br><span class="line"></span><br><span class="line">[root@momo1 ~]<span class="comment"># redis-cli -c -p 7007</span></span><br><span class="line">127.0.0.1:7007&gt; cluster replicate ea2b724ca7603e0a2036cf97781553dec1b0fad2</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h3 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h3><ul><li><p>如果是<strong>主节点</strong>，先把主节点中的哈希槽转移到其他节点中，然后删除这个节点。<br>redis-trib.rb reshard 192.168.33.88:7000<br>redis-trib.rb del-node 192.168.33.88:7000 08908d24194bcbeeb7a6bca3024eb20d2f43b6cb</p></li><li><p>如果是<strong>从节点</strong>，直接删除即可。<br>redis-trib.rb del-node 192.168.33.88:7000  7002e2b66b9d3b384981bcbe7d09954638ed82fb</p></li><li><p>示例代码：删除主从节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##############这里演示删除主节点7006############################</span></span><br><span class="line">[root@momo1 src]<span class="comment">#redis-trib.rb reshard 192.168.33.88:7000  ##进入分配哈希槽</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">How many slots <span class="keyword">do</span> you want to move (from 1 to 16384)? 4000 <span class="comment">##这里之前7006的4000哈希</span></span><br><span class="line">What is the receiving node ID? 433d5052db72f7915bfe491f3afefcfd636da285 <span class="comment">##这里一到7001指定它的id</span></span><br><span class="line">Please enter all the <span class="built_in">source</span> node IDs.</span><br><span class="line">  Type <span class="string">'all'</span> to use all the nodes as <span class="built_in">source</span> nodes <span class="keyword">for</span> the <span class="built_in">hash</span> slots.</span><br><span class="line">  Type <span class="string">'done'</span> once you entered all the <span class="built_in">source</span> nodes IDs.</span><br><span class="line">Source node <span class="comment">#1:ea2b724ca7603e0a2036cf97781553dec1b0fad2    ##我们要删除7006这里一定是7006</span></span><br><span class="line">Source node <span class="comment">#2:done</span></span><br><span class="line"></span><br><span class="line">//......yes</span><br><span class="line"><span class="comment">#####删除</span></span><br><span class="line">./redis-trib.rb del-node 192.168.33.88:7006 ea2b724ca7603e0a2036cf97781553dec1b0fad2 <span class="comment">#7006ID</span></span><br><span class="line"></span><br><span class="line">注意：分配哈希槽顺序，先是指定分给某节点，然后是被分配的节点id（博主顺序就错错过，所以上面为4000）</span><br><span class="line"></span><br><span class="line"><span class="comment">###############删除从节点，7007##################</span></span><br><span class="line">./redis-trib.rb del-node 192.168.33.88:7007 ea2b724ca7603e0a2036cf97781553dec1b0fad2 <span class="comment">#7007ID</span></span><br><span class="line"></span><br><span class="line">[root@momo1 src]<span class="comment"># redis-cli -c -p 7000 cluster nodes   ####查看</span></span><br><span class="line">fcd2e21a9bd0785a27f6c356d670f378df679547 192.168.33.88:7004 slave 433d5052db72f7915bfe491f3afefcfd636da285 0 1461888018505 8 connected</span><br><span class="line">c7820416485d4af315146266bb42abd171099934 192.168.33.88:7002 master - 0 1461888017497 3 connected 12589-16383</span><br><span class="line">7e1d4056265d38b9ce419bcd6017534356bfcec0 192.168.33.88:7005 slave c7820416485d4af315146266bb42abd171099934 0 1461888017497 6 connected</span><br><span class="line">054f970416643f34a5c9472348097ff186629230 192.168.33.88:7003 slave 7a869b7e7b55094949c060bd5f2f99174c79be59 0 1461888019513 4 connected</span><br><span class="line">433d5052db72f7915bfe491f3afefcfd636da285 192.168.33.88:7001 master - 0 1461888016486 8 connected 0-665 5461-12588</span><br><span class="line">7a869b7e7b55094949c060bd5f2f99174c79be59 192.168.33.88:7000 myself,master - 0 0 1 connected 666-5460</span><br></pre></td></tr></table></figure></li></ul><h2 id="java操作redis集群"><a href="#java操作redis集群" class="headerlink" title="java操作redis集群"></a>java操作redis集群</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 集群操作</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cluster</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">    <span class="comment">//TODO--</span></span><br><span class="line">    Set&lt;HostAndPort&gt; nodes = <span class="keyword">new</span> HashSet&lt;HostAndPort&gt;();</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7000</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7001</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7002</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7003</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7004</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.33.88"</span>, <span class="number">7005</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 创建JedisCluster对象</span></span><br><span class="line">    JedisCluster jedisCluster = <span class="keyword">new</span> JedisCluster(nodes , poolConfig );</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 直接可以操作reidsi了</span></span><br><span class="line">    jedisCluster.set(<span class="string">"blog"</span>, <span class="string">"blog.xiaoxiaomo.com"</span>);</span><br><span class="line">    System.out.println( jedisCluster.get(<span class="string">"blog"</span>) );</span><br><span class="line">    </span><br><span class="line"><span class="comment">//3. 不需要关闭</span></span><br><span class="line"><span class="comment">//这个close表示把jedisCluster给关闭了</span></span><br><span class="line">    <span class="comment">//jedisCluster.close();</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>查看结果 : </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@momo1 home]<span class="comment"># redis-cli -c -p 7000</span></span><br><span class="line">127.0.0.1:7000&gt; get blog</span><br><span class="line">-&gt; Redirected to slot [7653] located at 192.168.33.88:7001</span><br><span class="line"><span class="string">"blog.xiaoxiaomo.com"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--主从复制</title>
      <link href="/2016/04/28/Redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>/2016/04/28/Redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      <content type="html"><![CDATA[<p>　　<strong>redis的复制功能是支持多个数据库之间的数据同步</strong>。一类是<code>主数据库（master）</code>一类是从<code>数据库（slave）</code>，主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，<strong>一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库</strong>。</p><ul><li>通过redis的复制功能可以很好的<strong>实现数据库的读写分离，提高服务器的负载能力</strong>。<strong>主数据库主要进行写操作，而从数据库负责读操作</strong>。</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428142555.png" alt="redis主从复制"></p><a id="more"></a><ul><li>主从复制过程：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428205645.png" alt="主从复制过程"></p><h2 id="配置redis主从"><a href="#配置redis主从" class="headerlink" title="配置redis主从"></a>配置redis主从</h2><ul><li><p>修改配置文件redis.conf，<strong>只修改从数据库</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slaveof ip port</span><br><span class="line">slaveof no one 可以把从数据库转为主数据库</span><br></pre></td></tr></table></figure></li><li><p>示例代码：配置主从</p></li><li>节点分配</li></ul><ol><li>192.168.33.88 端口6379为主节点</li><li>192.168.33.89 为从节点<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428210750.png" alt="在从节点配置"></li></ol><ul><li><p>192.168.33.88</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############启动后info查看#################</span></span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; info</span><br><span class="line">//......</span><br><span class="line"><span class="comment"># Replication</span></span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=192.168.33.89,port=6379,state=online,offset=7979,lag=1</span><br><span class="line">master_repl_offset:7979</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:7978</span><br><span class="line">//......</span><br></pre></td></tr></table></figure></li><li><p>192.168.33.89</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############启动后info查看##################</span></span><br><span class="line">//.......</span><br><span class="line"><span class="comment"># Replication</span></span><br><span class="line">role:slave</span><br><span class="line">master_host:192.168.33.88</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:8</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:7965</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">//......</span><br></pre></td></tr></table></figure></li><li><p>注意：<br>如果你使用主从复制，那么要<strong>确保你的master激活了持久化</strong>，<strong>或者确保它不会在当掉后自动重启</strong>。<br>slave是master的完整备份，因此如果master通过一个空数据集重启，slave也会被清掉。</p></li></ul><h2 id="redis的Sentinel"><a href="#redis的Sentinel" class="headerlink" title="redis的Sentinel"></a>redis的Sentinel</h2><p>redis的sentinel系统用于管理多个redis服务器，该系统主要执行三个任务:</p><ol><li><strong>监控（Monitoring）</strong>： Redis Sentinel实时监控主服务器和从服务器运行状态。</li><li><strong>提醒（Notification）</strong>：当被监控的某个 Redis 服务器出现问题时， Redis Sentinel 可以向系统管理员发送通知， 也可以通过 API 向其他程序发送通知。</li><li><strong>自动故障转移（Automatic failover）</strong>：当一个主服务器不能正常工作时，Redis Sentinel 可以将一个从服务器升级为主服务器， 并对其他从服务器进行配置，让它们使用新的主服务器。当应用程序连接Redis 服务器时， Redis Sentinel会告之新的主服务器地址和端口。</li></ol><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428215417.png" alt="sentinel"></p><ul><li><strong>配置sentinel</strong></li></ul><ol><li><p><strong>修改sentinel.conf文件</strong><br>sentinel monitor mymaster 192.168.1.170 6379 2  ##指定到主节点ip和端口</p></li><li><p><strong>启动sentinel</strong><br>redis-sentinel sentinel.conf</p></li></ol><ul><li><p><strong>sentinel日志明细说明</strong><br><a href="http://redisdoc.com/topic/sentinel.html" target="_blank" rel="noopener">http://redisdoc.com/topic/sentinel.html</a></p></li><li><p><strong>主观下线和客观下线</strong></p></li></ul><p>通过订阅指定的频道信息，当服务器出现故障得时候通知管理员<br>客户端可以将 Sentinel 看作是一个只提供了订阅功能的 Redis 服务器，你不可以使用 PUBLISH 命令向这个服务器发送信息，但你可以用 SUBSCRIBE 命令或者 PSUBSCRIBE 命令， 通过订阅给定的频道来获取相应的事件提醒。<br>一个频道能够接收和这个频道的名字相同的事件。 比如说， 名为 +sdown 的频道就可以接收所有实例进入主观下线（SDOWN）状态的事件。</p><ul><li>示例代码 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############这里配置两个sentinel，同时修改配置###########</span></span><br><span class="line">1. 在安装目录下复制文件到/etc/ 即<span class="comment"># cp sentinel.conf /etc/</span></span><br><span class="line">2. vim 修改 sentinel monitor mymaster 192.168.33.88 6379 2</span><br><span class="line">3. 重启配置<span class="comment">#redis-sentinel /etc/sentinel.conf </span></span><br><span class="line"></span><br><span class="line">第一步：启动momo1==》192.168.33.88</span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-sentinel /etc/sentinel.conf </span></span><br><span class="line">6971:X 29 Apr 05:26:07.499 * Increased maximum number of open files to 10032 (it was originally <span class="built_in">set</span> to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-``__ <span class="string">''</span>-._                                             </span><br><span class="line">      _.-``    `.  `_.  <span class="string">''</span>-._           Redis 3.0.6 (00000000/0) 64 bit</span><br><span class="line">  .-`` .-```.  ```\/    _.,_ <span class="string">''</span>-._                                   </span><br><span class="line"> (    <span class="string">'      ,       .-`  | `,    )     Running in sentinel mode</span></span><br><span class="line"><span class="string"> |`-._`-...-` __...-.``-._|'</span>` _.-<span class="string">'|     Port: 26379</span></span><br><span class="line"><span class="string"> |    `-._   `._    /     _.-'</span>    |     PID: 6971</span><br><span class="line">  `-._    `-._  `-./  _.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |           http://redis.io        </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |                                  </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line">      `-._    `-.__.-<span class="string">'    _.-'</span>                                       </span><br><span class="line">          `-._        _.-<span class="string">'                                           </span></span><br><span class="line"><span class="string">              `-.__.-'</span>                                               </span><br><span class="line"></span><br><span class="line">6971:X 29 Apr 05:26:07.881 <span class="comment"># WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.</span></span><br><span class="line">6971:X 29 Apr 05:26:07.881 <span class="comment"># Sentinel runid is c24c259a092430387b2a8f2ad03b1b0bd4e0abd2</span></span><br><span class="line">6971:X 29 Apr 05:26:07.881 <span class="comment"># +monitor master mymaster 192.168.33.88 6379 quorum 2</span></span><br><span class="line"></span><br><span class="line">第二步：启动momo2==》192.168.33.89</span><br><span class="line">[root@momo2 redis-3.0.6]<span class="comment"># redis-sentinel /etc/sentinel.conf </span></span><br><span class="line">9694:X 29 Apr 05:27:07.226 * Increased maximum number of open files to 10032 (it was originally <span class="built_in">set</span> to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-``__ <span class="string">''</span>-._                                             </span><br><span class="line">      _.-``    `.  `_.  <span class="string">''</span>-._           Redis 3.0.6 (00000000/0) 64 bit</span><br><span class="line">  .-`` .-```.  ```\/    _.,_ <span class="string">''</span>-._                                   </span><br><span class="line"> (    <span class="string">'      ,       .-`  | `,    )     Running in sentinel mode</span></span><br><span class="line"><span class="string"> |`-._`-...-` __...-.``-._|'</span>` _.-<span class="string">'|     Port: 26379</span></span><br><span class="line"><span class="string"> |    `-._   `._    /     _.-'</span>    |     PID: 9694</span><br><span class="line">  `-._    `-._  `-./  _.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |           http://redis.io        </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |                                  </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line">      `-._    `-.__.-<span class="string">'    _.-'</span>                                       </span><br><span class="line">          `-._        _.-<span class="string">'                                           </span></span><br><span class="line"><span class="string">              `-.__.-'</span>                                               </span><br><span class="line"></span><br><span class="line">9694:X 29 Apr 05:27:07.252 <span class="comment"># WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.</span></span><br><span class="line">9694:X 29 Apr 05:27:07.252 <span class="comment"># Sentinel runid is 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1</span></span><br><span class="line">9694:X 29 Apr 05:27:07.252 <span class="comment"># +monitor master mymaster 192.168.33.88 6379 quorum 2</span></span><br><span class="line">9694:X 29 Apr 05:27:08.847 * -dup-sentinel master mymaster 192.168.33.88 6379 <span class="comment">#duplicate of 192.168.33.88:26379 or c24c259a092430387b2a8f2ad03b1b0bd4e0abd2</span></span><br><span class="line">9694:X 29 Apr 05:27:08.847 * +sentinel sentinel 192.168.33.88:26379 192.168.33.88 26379 @ mymaster 192.168.33.88 6379</span><br><span class="line">9694:X 29 Apr 05:27:09.304 * -dup-sentinel master mymaster 192.168.33.88 6379 <span class="comment">#duplicate of 127.0.0.1:26379 or 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1</span></span><br><span class="line">9694:X 29 Apr 05:27:09.304 * +sentinel sentinel 127.0.0.1:26379 127.0.0.1 26379 @ mymaster 192.168.33.88 6379</span><br><span class="line"></span><br><span class="line">第三步：如果在主节点192.168.33.88（momo1）设置值在89（momo2）中获取</span><br><span class="line">192.168.33.88:6379&gt; <span class="built_in">set</span> momo1 88</span><br><span class="line">OK</span><br><span class="line">192.168.33.89:6379&gt; get momo1</span><br><span class="line"><span class="string">"88"</span></span><br><span class="line"></span><br><span class="line">第四步：如果我们<span class="built_in">kill</span>掉主节点</span><br><span class="line">默认30s后</span><br><span class="line"></span><br><span class="line"><span class="comment">##momo1</span></span><br><span class="line">6971:X 29 Apr 05:35:36.799 <span class="comment"># +sdown master mymaster 192.168.33.88 6379</span></span><br><span class="line">6971:X 29 Apr 05:35:36.930 <span class="comment"># +new-epoch 1</span></span><br><span class="line">6971:X 29 Apr 05:35:36.933 <span class="comment"># +vote-for-leader 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1 1</span></span><br><span class="line">6971:X 29 Apr 05:35:38.045 <span class="comment"># +config-update-from sentinel 192.168.33.89:26379 192.168.33.89 26379 @ mymaster 192.168.33.88 6379</span></span><br><span class="line">6971:X 29 Apr 05:35:38.045 <span class="comment"># +switch-master mymaster 192.168.33.88 6379 192.168.33.89 6379</span></span><br><span class="line">6971:X 29 Apr 05:35:38.046 * +slave slave 192.168.33.88:6379 192.168.33.88 6379 @ mymaster 192.168.33.89 6379</span><br><span class="line"></span><br><span class="line"><span class="comment">##momo2</span></span><br><span class="line">9694:X 29 Apr 05:35:36.868 <span class="comment"># +sdown master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:36.926 <span class="comment"># +odown master mymaster 192.168.33.88 6379 #quorum 3/2</span></span><br><span class="line">9694:X 29 Apr 05:35:36.926 <span class="comment"># +new-epoch 1</span></span><br><span class="line">9694:X 29 Apr 05:35:36.926 <span class="comment"># +try-failover master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:36.952 <span class="comment"># +vote-for-leader 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1 1</span></span><br><span class="line">9694:X 29 Apr 05:35:36.952 <span class="comment"># 127.0.0.1:26379 voted for 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1 1</span></span><br><span class="line">9694:X 29 Apr 05:35:36.969 <span class="comment"># 192.168.33.88:26379 voted for 271dc5b6ca168ffcbdaafc95aa298bffb9ddbfd1 1</span></span><br><span class="line">9694:X 29 Apr 05:35:37.019 <span class="comment"># +elected-leader master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:37.019 <span class="comment"># +failover-state-select-slave master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:37.079 <span class="comment"># +selected-slave slave 192.168.33.89:6379 192.168.33.89 6379 @ mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:37.079 * +failover-state-send-slaveof-noone slave 192.168.33.89:6379 192.168.33.89 6379 @ mymaster 192.168.33.88 6379</span><br><span class="line">9694:X 29 Apr 05:35:37.156 * +failover-state-wait-promotion slave 192.168.33.89:6379 192.168.33.89 6379 @ mymaster 192.168.33.88 6379</span><br><span class="line">9694:X 29 Apr 05:35:37.990 <span class="comment"># +promoted-slave slave 192.168.33.89:6379 192.168.33.89 6379 @ mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:37.991 <span class="comment"># +failover-state-reconf-slaves master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:38.075 <span class="comment"># +failover-end master mymaster 192.168.33.88 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:38.075 <span class="comment"># +switch-master mymaster 192.168.33.88 6379 192.168.33.89 6379</span></span><br><span class="line">9694:X 29 Apr 05:35:38.076 * +slave slave 192.168.33.88:6379 192.168.33.88 6379 @ mymaster 192.168.33.89 6379</span><br><span class="line"></span><br><span class="line"><span class="comment">###这一句话就表示了选择了新的主节点192.168.33.89 6379</span></span><br><span class="line">+switch-master mymaster 192.168.33.88 6379 192.168.33.89 6379</span><br><span class="line"></span><br><span class="line">第五步：如果我们再次启动88这台服务器，他将不再是master而是slave</span><br><span class="line">9694:X 29 Apr 05:36:08.160 <span class="comment"># +sdown slave 192.168.33.88:6379 192.168.33.88 6379 @ mymaster 192.168.33.89 6379</span></span><br><span class="line">9694:X 29 Apr 05:38:54.076 <span class="comment"># -sdown slave 192.168.33.88:6379 192.168.33.88 6379 @ mymaster 192.168.33.89 6379</span></span><br><span class="line">9694:X 29 Apr 05:39:04.021 * +convert-to-slave slave 192.168.33.88:6379 192.168.33.88 6379 @ mymaster 192.168.33.89 6379</span><br></pre></td></tr></table></figure></li></ul><h2 id="java操作sentinel"><a href="#java操作sentinel" class="headerlink" title="java操作sentinel"></a>java操作sentinel</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用sentinel操作主从架构中的数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TestSentinel</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">    <span class="comment">//TODO--</span></span><br><span class="line">    String masterName = <span class="string">"mymaster"</span>; <span class="comment">//名称</span></span><br><span class="line"></span><br><span class="line">    Set&lt;String&gt; sentinels = <span class="keyword">new</span> HashSet&lt;String&gt;();;</span><br><span class="line">    sentinels.add(<span class="string">"192.168.33.88:26379"</span>);</span><br><span class="line">    sentinels.add(<span class="string">"192.168.33.89:26379"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//SentinelPool</span></span><br><span class="line">    JedisSentinelPool jsp = <span class="keyword">new</span> JedisSentinelPool(masterName , sentinels, poolConfig );</span><br><span class="line"></span><br><span class="line"><span class="comment">//可以获取主节点信息</span></span><br><span class="line">    HostAndPort currentHostMaster = jsp.getCurrentHostMaster();</span><br><span class="line">    System.out.println(currentHostMaster.getHost()+<span class="string">"--"</span>+currentHostMaster.getPort());</span><br><span class="line"></span><br><span class="line">    Jedis jedis = jsp.getResource();<span class="comment">//获取Jedis</span></span><br><span class="line">    String value = jedis.set(<span class="string">"xiaoxiao"</span>,<span class="string">"momo"</span>);</span><br><span class="line">    System.out.println(value);</span><br><span class="line">    jedis.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回结果</span></span><br><span class="line"><span class="number">192.168</span>.33.89--<span class="number">6379</span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--安全策略</title>
      <link href="/2016/04/28/Redis-%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/"/>
      <url>/2016/04/28/Redis-%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/</url>
      <content type="html"><![CDATA[<p>　　<strong>可信环境下的可信用户才可访问redis</strong>。这意味着，<strong>将redis服务器直接暴露在Internet或者不可信用户可直接访问Redis的tcp端口或Unix套接字的环境，是不安全的</strong>。redis着重于高性能和简单易用，在安全方面做得并不好。</p><h2 id="网络安全"><a href="#网络安全" class="headerlink" title="网络安全"></a>网络安全</h2><p><strong>bind参数</strong>（在redis.conf配置文件，添加bind可以让数据库只能在指定IP下访问）。<br>bind 127.0.0.1 [192.168.3.1 ……]<br>注意：bind后面指定的ip只能是本机的ip。</p><h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><p><strong>设置数据库密码</strong></p><ol><li>修改配置requirepass password</li><li>验证密码auth password</li></ol><ul><li>实例 ： 修改密码为xiaoxiaomo<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#requirepass foobared</span></span><br><span class="line">requirepass xiaoxiaomo</span><br><span class="line"></span><br><span class="line"><span class="comment"># Command renaming.</span></span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h2 id="命令重命名"><a href="#命令重命名" class="headerlink" title="命令重命名"></a>命令重命名</h2><p><strong>修改命令的名称</strong> ： rename-command flushall cleanall<br><strong>禁用命令</strong> ： rename-command flushall “”</p><h2 id="调试命令"><a href="#调试命令" class="headerlink" title="调试命令"></a>调试命令</h2><p>monitor，可以监控当前操作<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@momo2 momo2]<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; monitor</span><br><span class="line">OK</span><br><span class="line">1461856075.682226 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br><span class="line">1461856085.788001 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br><span class="line">1461856086.421633 [0 192.168.33.88:6379] <span class="string">"set"</span> <span class="string">"b"</span> <span class="string">"123"</span></span><br><span class="line">1461856095.887983 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br><span class="line">1461856105.986328 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br><span class="line">1461856106.884941 [0 192.168.33.88:6379] <span class="string">"set"</span> <span class="string">"d"</span> <span class="string">"999"</span></span><br><span class="line">1461856116.086099 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br><span class="line">1461856126.187827 [0 192.168.33.88:6379] <span class="string">"PING"</span></span><br></pre></td></tr></table></figure></p><ul><li>附：一次redis漏洞事件<br><a href="http://www.wooyun.org/bugs/wooyun-2015-0152710" target="_blank" rel="noopener">http://www.wooyun.org/bugs/wooyun-2015-0152710</a><br><a href="http://www.cnblogs.com/yangecnu/archive/2015/11/12/4957823.html" target="_blank" rel="noopener">http://www.cnblogs.com/yangecnu/archive/2015/11/12/4957823.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--持久化方案及备份</title>
      <link href="/2016/04/28/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E6%A1%88%E5%8F%8A%E5%A4%87%E4%BB%BD/"/>
      <url>/2016/04/28/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E6%A1%88%E5%8F%8A%E5%A4%87%E4%BB%BD/</url>
      <content type="html"><![CDATA[<p>　　<strong>redis支持两种方式的持久化，可以单独使用或者结合起来使用</strong>。第一种：<strong>RDB方式</strong>redis默认的持久化方式，第二种：<strong>AOF方式</strong>，需要手动修改配置。下面我们来看一下两种持久化方式以及持久化中所注意的一些问题。</p><h2 id="持久化之RDB"><a href="#持久化之RDB" class="headerlink" title="持久化之RDB"></a>持久化之RDB</h2><p><strong>rdb方式的持久化是通过快照完成的，当符合一定条件时redis会自动将内存中的所有数据执行快照操作并存储到硬盘上</strong>。默认存储在dump.rdb文件中(文件名在配置文件中dbfilename)，默认打开可以到启动的目录去查看，注意： <strong>dump.rdb是在哪儿启动redis，就会在哪儿生成rdb文件</strong>。</p><ul><li><strong>dump.rdb</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@momo1 ~]<span class="comment"># cd /usr/local/redis/</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># ll</span></span><br><span class="line">总用量 156</span><br><span class="line">-rw-rw-r--.  1 root root 34339 12月 18 23:19 00-RELEASENOTES</span><br><span class="line">-rw-rw-r--.  1 root root    53 12月 18 23:19 BUGS</span><br><span class="line">-rw-rw-r--.  1 root root  1805 12月 18 23:19 CONTRIBUTING</span><br><span class="line">-rw-rw-r--.  1 root root  1487 12月 18 23:19 COPYING</span><br><span class="line">drwxrwxr-x.  6 root root  4096 4月  27 19:40 deps</span><br><span class="line">-rw-r--r--.  1 root root    36 4月  29 01:20 dump.rdb   <span class="comment">##dump.rdb</span></span><br><span class="line">-rw-rw-r--.  1 root root    11 12月 18 23:19 INSTALL</span><br><span class="line">-rw-rw-r--.  1 root root   151 12月 18 23:19 Makefile</span><br><span class="line">-rw-rw-r--.  1 root root  4223 12月 18 23:19 MANIFESTO</span><br><span class="line">-rw-rw-r--.  1 root root  5201 12月 18 23:19 README</span><br><span class="line">-rw-rw-r--.  1 root root 41561 4月  27 19:53 redis.conf</span><br><span class="line">-rwxrwxr-x.  1 root root   271 12月 18 23:19 runtest</span><br><span class="line">-rwxrwxr-x.  1 root root   280 12月 18 23:19 runtest-cluster</span><br><span class="line">-rwxrwxr-x.  1 root root   281 12月 18 23:19 runtest-sentinel</span><br><span class="line">-rw-rw-r--.  1 root root  7113 4月  29 00:26 sentinel.conf</span><br><span class="line">drwxrwxr-x.  2 root root  4096 4月  27 19:41 src</span><br><span class="line">drwxrwxr-x. 10 root root  4096 12月 18 23:19 tests</span><br><span class="line">drwxrwxr-x.  5 root root  4096 12月 18 23:19 utils</span><br></pre></td></tr></table></figure></li></ul><ol><li><p><strong>redis进行快照的时机</strong>（在配置文件redis.conf中）</p><blockquote><ol><li>save 900 1：表示900秒内至少一个键被更改则进行快照。</li><li>save 300 10</li><li>save 60 10000</li></ol></blockquote></li><li><p><strong>redis实现快照的过程</strong></p><blockquote><ol><li>redis使用fork函数复制一份当前进程的副本(子进程)</li><li>父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件</li><li>当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。</li></ol></blockquote></li><li><p><strong>手动执行save或者bgsave命令让redis执行快照</strong>。</p><blockquote><ol><li><code>save</code>是由主进程进行快照操作，会阻塞其它请求。</li><li><code>bgsave</code>是由redis执行fork函数复制出一个子进程来进行快照操作。</li></ol></blockquote></li><li><p><strong>文件修复</strong>：redis-check-dump</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># redis-check-dump dump.rdb </span></span><br><span class="line">==== Processed 5 valid opcodes (<span class="keyword">in</span> 45 bytes) ===================================</span><br><span class="line">CRC64 checksum is OK</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><ul><li><p><strong>rdb的优缺点</strong><br><strong>优点</strong>：由于存储的有数据快照文件，恢复数据很方便。<br><strong>缺点</strong>：会丢失最后一次快照以后更改的所有数据。</p></li><li><p><strong>注意</strong></p></li></ul><ol><li>redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说<strong>任何时候RDB文件都是完整的</strong>。</li><li>我们可以通过定时备份RDB文件来实现redis数据库的备份。</li><li>RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。</li></ol><ul><li>示例代码：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> a 123</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> b 456</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">"b"</span></span><br><span class="line">2) <span class="string">"a"</span></span><br><span class="line">127.0.0.1:6379&gt; shutdown</span><br><span class="line">not connected&gt; <span class="built_in">exit</span></span><br><span class="line"><span class="comment">###注意此时有值，关掉退出然后我们切换一下目录后再启动，就会是一个新的rdb文件，无值</span></span><br><span class="line"></span><br><span class="line">[root@momo1 redis]<span class="comment"># cd /home/up/</span></span><br><span class="line">[root@momo1 up]<span class="comment"># redis-server /etc/redis.conf </span></span><br><span class="line">[root@momo1 up]<span class="comment"># redis-cli </span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line">127.0.0.1:6379&gt; shutdown</span><br><span class="line">not connected&gt; <span class="built_in">exit</span></span><br><span class="line">[root@momo1 up]<span class="comment"># ll</span></span><br><span class="line">总用量 1348</span><br><span class="line">-rw-r--r--. 1 root root      18 4月  29 04:04 dump.rdb</span><br></pre></td></tr></table></figure></li></ul><h2 id="持久化之AOF"><a href="#持久化之AOF" class="headerlink" title="持久化之AOF"></a>持久化之AOF</h2><p><strong>aof方式的持久化是通过日志文件的方式</strong>。默认情况下redis没有开启aof，可以通过参数appendonly参数开启。<code>appendonly yes</code><br>aof文件的保存位置和rdb文件的位置相同，都是dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改<br>appendfilename appendonly.aof</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428202257.png" alt="appendonly.aof"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160428202509.png" alt="aof同步的时机"></p><ol><li><p><strong>redis写命令同步的时机</strong></p><blockquote><ol><li>appendfsync always 每次都会执行</li><li>appendfsync everysec 默认 每秒执行一次同步操作（推荐，默认）</li><li>appendfsync no不主动进行同步，由操作系统来做，30秒一次</li></ol></blockquote></li><li><p><strong>aof日志文件重写</strong></p><blockquote><ol><li>auto-aof-rewrite-percentage 100(当目前aof文件大小超过上一次重写时的aof文件大小的百分之多少时会再次进行重写，如果之前没有重写，则以启动时的aof文件大小为依据)</li><li>auto-aof-rewrite-min-size 64mb</li></ol></blockquote></li><li><p><strong>手动执行bgrewriteaof进行重写</strong></p><blockquote><p>重写的过程只和内存中的数据有关，和之前的aof文件无关。<strong>即针对数据库中当前数据进行重新整理成redis语句</strong></p></blockquote></li><li><p><strong>文件修复</strong>：redis-check-aof</p></li></ol><ul><li>示例代码：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 在rdb是持久化下游三个keys</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">"d"</span></span><br><span class="line">2) <span class="string">"a"</span></span><br><span class="line">3) <span class="string">"b"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## </span></span><br><span class="line">[root@momo1 redis]<span class="comment"># vim redis.conf #修改appendonly yes</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-server ./redis.conf </span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="动态切换redis持久方式"><a href="#动态切换redis持久方式" class="headerlink" title="动态切换redis持久方式"></a>动态切换redis持久方式</h2><blockquote><p>从 <strong><code>RDB</code></strong> 切换到 <strong><code>AOF</code></strong>（<em>支持Redis 2.2及以上</em>）</p></blockquote><ul><li><p><strong>问题</strong>： 在很多情况下，默认使用了rdb持久化方式，如果我们再开启aof持久化方式，就会发现一个问题 ： 原先的redis数据丢失了!</p></li><li><p><strong>主要原因</strong>： redis的aof持久化方式是最安全的，如果开启aof之后，<strong>redis会优先选择aof的方式</strong>，而appendonly.aof文件此时还是空文件于是之前的数据就丢失了。</p></li><li><p><strong>解决办法</strong>： 使用config命令，<strong>首先动态修改配置，然后再修改配置文件！</strong></p><blockquote><ol><li>cinfig set appendonly yes</li><li>config set save “”（可选，如果开启了aof可以选择关闭rdb）</li></ol></blockquote></li><li><p><strong>总结：</strong></p></li></ul><ol><li>当redis启动时，如果rdb持久化和aof持久化都打开了，那么程序会优先使用aof方式来恢复数据集，因为aof方式所保存的数据通常是最完整的。如果aof文件丢失了，则启动之后数据库内容为空。</li><li>如果想把正在运行的redis数据库，从RDB切换到AOF，<strong>先使用动态切换方式，再修改配置文件，重启数据库</strong>。(不能自己修改配置文件，重启数据库，否则数据库中数据就为空了。)</li><li><strong>如果我们失误操作，没有动态切换数据为空了，我们应该尽快手动kill掉redis进程，然后删掉aof备份文件改掉配置后重新动态切换。</strong></li></ol><ul><li><p>示例代码：动态切换</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config <span class="built_in">set</span> appendonly yes</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; mget a b d</span><br><span class="line">1) <span class="string">"123"</span></span><br><span class="line">2) <span class="string">"123"</span></span><br><span class="line">3) <span class="string">"999"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####然后我们来看一下appendonly.aof文件内容</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># vim appendonly.aof </span></span><br><span class="line">*2</span><br><span class="line"><span class="variable">$6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="variable">$1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="variable">$3</span></span><br><span class="line">SET</span><br><span class="line"><span class="variable">$1</span></span><br><span class="line">d   <span class="comment">##d的值</span></span><br><span class="line"><span class="variable">$3</span>  <span class="comment">##长度为3</span></span><br><span class="line">999 <span class="comment">##值为999</span></span><br><span class="line">*3</span><br><span class="line"><span class="variable">$3</span></span><br><span class="line">SET</span><br><span class="line"><span class="variable">$1</span></span><br><span class="line">b</span><br><span class="line"><span class="variable">$3</span></span><br><span class="line">123</span><br><span class="line">*3</span><br><span class="line"><span class="variable">$3</span></span><br><span class="line">SET</span><br><span class="line"><span class="variable">$1</span></span><br><span class="line">a</span><br><span class="line"><span class="variable">$3</span></span><br><span class="line">123</span><br></pre></td></tr></table></figure></li><li><p>示例代码：如果我们失误操作，没有动态切换数据为空了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@momo1 redis]<span class="comment"># vim redis.conf #修改appendonly yes此时没有动态切换</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-server ./redis.conf ##启动</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-cli      ##此时有数据</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line"></span><br><span class="line">[root@momo1 redis]<span class="comment"># ps -ef|grep redis  ##重开一个端口kill进程</span></span><br><span class="line">root       6399      1  0 04:20 ?        00:00:00 redis-server *:6379      </span><br><span class="line">root       6402   5794  0 04:20 pts/2    00:00:00 redis-cli</span><br><span class="line">root       6413   6113  0 04:21 pts/3    00:00:00 grep redis</span><br><span class="line">[root@momo1 redis]<span class="comment"># kill -9 6399   </span></span><br><span class="line">[root@momo1 redis]<span class="comment"># rm -rf appendonly.aof ##删掉appendonly.aof</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># vim redis.conf   ##再次改回no</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-server ./redis.conf ##启动</span></span><br><span class="line">[root@momo1 redis]<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; keys *               <span class="comment">##数据还在，万幸</span></span><br><span class="line">1) <span class="string">"d"</span></span><br><span class="line">2) <span class="string">"b"</span></span><br><span class="line">3) <span class="string">"a"</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="config命令"><a href="#config命令" class="headerlink" title="config命令"></a>config命令</h2><ul><li><p>1、使用<code>config set</code>可以动态设置参数信息，服务器重启之后就失效了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config <span class="built_in">set</span> appendonly yes</span><br><span class="line">config <span class="built_in">set</span> save <span class="string">"90 1 30 10 60 100"</span></span><br></pre></td></tr></table></figure></li><li><p>2、使用config get可以查看所有可以使用config set命令设置的参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config get *  <span class="comment">##这里我省略了很多</span></span><br><span class="line">  1) <span class="string">"dbfilename"</span>      <span class="comment">##rdb存储文件</span></span><br><span class="line">  2) <span class="string">"dump.rdb"</span></span><br><span class="line">  9) <span class="string">"logfile"</span>         <span class="comment">##日志文件</span></span><br><span class="line"> 10) <span class="string">""</span>                <span class="comment">##可重新配置</span></span><br><span class="line"> 11) <span class="string">"pidfile"</span>         <span class="comment">##pid文件</span></span><br><span class="line"> 12) <span class="string">"/var/run/redis.pid"</span></span><br><span class="line"> 13) <span class="string">"maxmemory"</span></span><br><span class="line"> 14) <span class="string">"0"</span></span><br><span class="line"> 15) <span class="string">"maxmemory-samples"</span></span><br><span class="line"> 16) <span class="string">"5"</span></span><br><span class="line"> 17) <span class="string">"timeout"</span></span><br><span class="line"> 18) <span class="string">"0"</span></span><br><span class="line"> 40) <span class="string">"3000"</span></span><br><span class="line"> 41) <span class="string">"lua-time-limit"</span></span><br><span class="line"> 42) <span class="string">"5000"</span></span><br><span class="line"> 43) <span class="string">"slowlog-log-slower-than"</span> </span><br><span class="line"> 44) <span class="string">"10000"</span></span><br><span class="line"> 45) <span class="string">"latency-monitor-threshold"</span></span><br><span class="line"> 46) <span class="string">"0"</span></span><br><span class="line"> 47) <span class="string">"slowlog-max-len"</span></span><br><span class="line"> 48) <span class="string">"128"</span></span><br><span class="line"> 49) <span class="string">"port"</span>         <span class="comment">##端口</span></span><br><span class="line"> 50) <span class="string">"6379"</span></span><br><span class="line"> 51) <span class="string">"tcp-backlog"</span></span><br><span class="line"> 52) <span class="string">"511"</span></span><br><span class="line"> 53) <span class="string">"databases"</span>   <span class="comment">##支持数据库</span></span><br><span class="line"> 54) <span class="string">"16"</span></span><br><span class="line"> 75) <span class="string">"cluster-node-timeout"</span>  <span class="comment">##集群的一些信息</span></span><br><span class="line"> 76) <span class="string">"15000"</span></span><br><span class="line"> 77) <span class="string">"cluster-migration-barrier"</span></span><br><span class="line"> 78) <span class="string">"1"</span></span><br><span class="line"> 79) <span class="string">"cluster-slave-validity-factor"</span></span><br><span class="line"> 80) <span class="string">"10"</span></span><br><span class="line"> 81) <span class="string">"repl-diskless-sync-delay"</span></span><br><span class="line"> 82) <span class="string">"5"</span></span><br><span class="line"> 83) <span class="string">"cluster-require-full-coverage"</span></span><br><span class="line"> 84) <span class="string">"yes"</span></span><br><span class="line"> 85) <span class="string">"no-appendfsync-on-rewrite"</span></span><br><span class="line"> 86) <span class="string">"no"</span></span><br><span class="line"> 87) <span class="string">"slave-serve-stale-data"</span></span><br><span class="line"> 88) <span class="string">"yes"</span></span><br><span class="line"> 89) <span class="string">"slave-read-only"</span></span><br><span class="line"> 90) <span class="string">"yes"</span></span><br><span class="line"> 91) <span class="string">"stop-writes-on-bgsave-error"</span></span><br><span class="line"> 92) <span class="string">"yes"</span></span><br><span class="line"> 93) <span class="string">"daemonize"</span>     <span class="comment">##是否开启daemonize</span></span><br><span class="line"> 94) <span class="string">"yes"</span></span><br><span class="line"> 95) <span class="string">"rdbcompression"</span></span><br><span class="line"> 96) <span class="string">"yes"</span></span><br><span class="line"> 97) <span class="string">"rdbchecksum"</span></span><br><span class="line"> 98) <span class="string">"yes"</span></span><br><span class="line"> 99) <span class="string">"activerehashing"</span></span><br><span class="line">100) <span class="string">"yes"</span></span><br><span class="line">101) <span class="string">"repl-disable-tcp-nodelay"</span></span><br><span class="line">102) <span class="string">"no"</span></span><br><span class="line">103) <span class="string">"repl-diskless-sync"</span></span><br><span class="line">104) <span class="string">"no"</span></span><br><span class="line">105) <span class="string">"aof-rewrite-incremental-fsync"</span></span><br><span class="line">106) <span class="string">"yes"</span></span><br><span class="line">107) <span class="string">"aof-load-truncated"</span></span><br><span class="line">108) <span class="string">"yes"</span></span><br><span class="line">109) <span class="string">"appendonly"</span>    <span class="comment">##</span></span><br><span class="line">110) <span class="string">"no"</span></span><br><span class="line">111) <span class="string">"dir"</span>           <span class="comment">##dir 目录,可修改</span></span><br><span class="line">112) <span class="string">"/root"</span></span><br><span class="line">117) <span class="string">"save"</span>         <span class="comment">##rdb持久化点</span></span><br><span class="line">118) <span class="string">"900 1 300 10 60 10000"</span></span><br><span class="line">119) <span class="string">"loglevel"</span>     <span class="comment">##日志级别</span></span><br><span class="line">120) <span class="string">"notice"</span></span><br><span class="line">124) <span class="string">"0"</span></span><br><span class="line">125) <span class="string">"slaveof"</span>　　<span class="comment">##主从</span></span><br><span class="line">129) <span class="string">"bind"</span>　     <span class="comment">##bind ip</span></span><br><span class="line">130) <span class="string">""</span></span><br></pre></td></tr></table></figure></li><li><p>3、 使用config rewrite命令对启动 Redis 服务器时所指定的 redis.conf 文件进行改写(Redis 2.8 及以上版本才可以使用)，主要是把使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config <span class="built_in">set</span>动态指定的命令保存到配置文件中。</span><br><span class="line">config rewrite</span><br></pre></td></tr></table></figure></li><li><p>注意：</p></li></ul><p>　　config rewrite命令对 redis.conf 文件的重写是<code>原子性的</code>， 并且是一致的：<em>如果重写出错或重写期间服务器崩溃， 那么重写失败， 原有 redis.conf 文件不会被修改。 如果重写成功， 那么 redis.conf 文件为重写后的新文件</em>。</p><h2 id="修改持久化、日志路径"><a href="#修改持久化、日志路径" class="headerlink" title="修改持久化、日志路径"></a>修改持久化、日志路径</h2><p>现在我们知道（<a href="http://blog.xiaoxiaomo.com/2016/03/23/Linux-软件安装之Redis/">如不清楚下面安装方式，点击阅读博客</a>），持久化的目录默认为<code>./</code> ， logfile “”没有开启：</p><ul><li><strong>如果我们通过注册服务方式安装</strong>： 然后<code>service redis start</code>启动，持久化文件默认为更目录<code>“/”</code>；</li><li><p><strong>如果我们通过快速安装</strong>： 然后<code>直接启动或指定配置文件</code>启动，持久化文件是和你启动时目录有关，即在哪儿启动就在那儿生成文件，这样有可能出现数据丢失！</p></li><li><p><strong>修改持久化、日志路径：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###########1、创建目录存储redis，博主在/data/创建redis目录来存放数据###</span></span><br><span class="line">mkdir /data/redis </span><br><span class="line"><span class="built_in">kill</span> -9 redis进程号或shutdown redis<span class="comment">#关掉redis进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###########2、修改日志文件、dump文件路径###########</span></span><br><span class="line">logfile <span class="string">"/data/redis/redis.log"</span></span><br><span class="line">dir /data/redis/</span><br><span class="line"></span><br><span class="line"><span class="comment">###########3、移动之前dump文件到新目录##########</span></span><br><span class="line">mv /dump.rdb /data/redis/ <span class="comment">#我这里之前dump文件在根目录下</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###########4、启动redis、查看数据正常##########</span></span><br><span class="line">[root@iZ94r8hgrjcZ usr]<span class="comment"># service redis start ##启动redis</span></span><br><span class="line">Starting Redis server...</span><br><span class="line">[root@iZ94r8hgrjcZ redis]<span class="comment"># pwd  </span></span><br><span class="line">/data/redis</span><br><span class="line">[root@iZ94r8hgrjcZ redis]<span class="comment"># ll         ##以生成日志文件</span></span><br><span class="line">total 8</span><br><span class="line">-rw-r--r-- 1 root root   62 Apr 30 11:51 dump.rdb</span><br><span class="line">-rw-r--r-- 1 root root 2206 Apr 30 13:04 redis.log</span><br><span class="line">[root@iZ94r8hgrjcZ redis]<span class="comment"># redis-cli  ##数据正常</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">//......</span><br><span class="line"></span><br><span class="line">////////<span class="comment">##########如果还想测试aof#############</span></span><br><span class="line">127.0.0.1:6379&gt; config <span class="built_in">set</span> appendonly yes <span class="comment">##1、动态修改持久化</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">[root@iZ94r8hgrjcZ redis]<span class="comment"># vim /etc/redis/6379.conf ##2、修改配置appendonly yes</span></span><br><span class="line">[root@iZ94r8hgrjcZ redis]<span class="comment"># ll   ##3、查看数据正常</span></span><br><span class="line">total 12</span><br><span class="line">-rw-r--r-- 1 root root  132 Apr 30 13:20 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 root root   62 Apr 30 11:51 dump.rdb</span><br><span class="line">-rw-r--r-- 1 root root 2937 Apr 30 13:20 redis.log</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis--基本命令及Java操作</title>
      <link href="/2016/04/27/Redis-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E5%8F%8AJava%E6%93%8D%E4%BD%9C/"/>
      <url>/2016/04/27/Redis-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E5%8F%8AJava%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>　　本篇博文主要讲解，Redis的<strong>基本使用</strong>、<strong>基本命令</strong>、<strong>数据类型</strong>以及<strong>通过java操作Redis数据库（Jredis）</strong>。内容命令过多，不会一一演示，建议读者联想记忆。如果还没有搭建好环境请参考上篇博文：<a href="http://blog.xiaoxiaomo.com/2016/02/23/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BRedis/">http://blog.xiaoxiaomo.com/2016/02/23/Linux-软件安装之Redis/</a>。</p><h2 id="redis基础命令"><a href="#redis基础命令" class="headerlink" title="redis基础命令"></a>redis基础命令</h2><ol><li><p><strong>获得符合规则的键名称</strong><br>keys 表达式<code>（?,* ,[],\?）</code></p></li><li><p><strong>判断一个键是否存在</strong><br>exists key</p></li><li><p><strong>删除键</strong><br>del key<br>del key1 key2</p></li><li><p><strong>获得键值的数据类型type</strong><br>返回值可能是这五种类型<em>（string,hash,list,set,zset）</em>。</p></li></ol><p><strong>注意：redis的命令不区分大小写</strong></p><a id="more"></a><ul><li>实例代码：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; exists blog</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; exists blogs</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> blogs momo</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">"blogs"</span></span><br><span class="line">2) <span class="string">"blog"</span></span><br><span class="line">127.0.0.1:6379&gt; del blogs</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">"blog"</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="redis的help命令"><a href="#redis的help命令" class="headerlink" title="redis的help命令"></a>redis的help命令</h2><ul><li>help command<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">help</span></span><br><span class="line">redis-cli 3.0.6</span><br><span class="line">Type: <span class="string">"help @&lt;group&gt;"</span> to get a list of commands <span class="keyword">in</span> &lt;group&gt;</span><br><span class="line">      <span class="string">"help &lt;command&gt;"</span> <span class="keyword">for</span> <span class="built_in">help</span> on &lt;<span class="built_in">command</span>&gt;</span><br><span class="line">      <span class="string">"help &lt;tab&gt;"</span> to get a list of possible <span class="built_in">help</span> topics</span><br><span class="line">      <span class="string">"quit"</span> to <span class="built_in">exit</span></span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">help</span> del</span><br><span class="line"></span><br><span class="line">  DEL key [key ...]</span><br><span class="line">  summary: Delete a key</span><br><span class="line">  since: 1.0.0</span><br><span class="line">  group: generic</span><br></pre></td></tr></table></figure></li></ul><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p><strong>字符串类型是redis中最基本的数据类型</strong>，它能存储任何形式的内容，包含二进制数据，甚至是一张图片(二进制内容)。<strong>在实际生产环境中我们存放json字符串比较常用</strong>，<em>一个字符串类型的值存储的最大容量是1GB</em>。</p><ul><li>命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>/get(setnx)</span><br><span class="line">mset/mget   <span class="comment">##返回/设置(一个或多个)给定 key 的值。</span></span><br><span class="line">incr/decr/incrby/decrby/incrbyfloat</span><br><span class="line">append <span class="comment">##append key value，将 value 追加到 key 原来的值的末尾，如果 key 不存在,key 设为 value</span></span><br><span class="line">strlen <span class="comment">##字符串长度</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p><strong>hash类型的值存储了字段和字段值的映射</strong>，字段和字段值只能是<strong>字符串</strong>，<em>不支持其他数据类型</em>。hash类型的键至多可以存储       （<em>2的32次方-1</em>）个字段。<strong>hash类型适合存储对象</strong>，redis可以为任何键增减字段而不影响其他键。</p><ul><li><p>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hset/hget/hmset/hmget/hgetall(hsetnx)</span><br><span class="line">hexists  <span class="comment">##判断键中的属性是否存在</span></span><br><span class="line">hincrby  <span class="comment">##为哈希表 key 中的域 field 的值加上增量</span></span><br><span class="line">hdel     <span class="comment">##删除</span></span><br><span class="line">hkeys/hvals  <span class="comment">##返回哈希表 key 中的所有键/值</span></span><br><span class="line">hlen     <span class="comment">##返回哈希表 key 中域的数量</span></span><br></pre></td></tr></table></figure></li><li><p>实例代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; HGET counter page_view</span><br><span class="line"><span class="string">"200"</span></span><br><span class="line"></span><br><span class="line">redis&gt; HINCRBY counter page_view -50</span><br><span class="line">(<span class="built_in">integer</span>) 150</span><br><span class="line"></span><br><span class="line">redis&gt; HGET counter page_view</span><br><span class="line"><span class="string">"150"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试对字符串值的域执行HINCRBY命令</span></span><br><span class="line"></span><br><span class="line">redis&gt; HSET myhash string hello,world       <span class="comment"># 设定一个字符串值</span></span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line"></span><br><span class="line">redis&gt; HGET myhash string</span><br><span class="line"><span class="string">"hello,world"</span></span><br><span class="line"></span><br><span class="line">redis&gt; HINCRBY myhash string 1              <span class="comment"># 命令执行失败，错误。</span></span><br><span class="line">(error) ERR <span class="built_in">hash</span> value is not an <span class="built_in">integer</span></span><br><span class="line"></span><br><span class="line">redis&gt; HGET myhash string                   <span class="comment"># 原值不变</span></span><br><span class="line"><span class="string">"hello,world"</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list是一个有序的字符串列表，列表内部实现是使用双向链表(linked list)实现的。list还可以作为队列使用，一个列表类型的键最多能容纳（<em>2的32次方-1</em>）个元素。</p><ul><li>命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lpush/rpush/lpop/rpop</span><br><span class="line">llen/lrange(-1表示最后一个元素的位置)</span><br><span class="line">lindex(查询指定角标数据)</span><br><span class="line">lset(修改)</span><br><span class="line">ltrim(截取，保留指定数据)</span><br><span class="line">rpoplpush:将元素从一个列表转到另一个列表</span><br></pre></td></tr></table></figure></li></ul><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p><strong>set集合中的元素都是不重复的，无序的</strong>，一个集合类型键可以存储至多（<em>2的32次方-1</em>）个元素 set集合类型和list列表类型的相似之处。</p><ul><li><p>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sadd/smembers/srem/sismember</span><br><span class="line">sdiff/sinter(交集)/sunion(并集)</span><br><span class="line">sdiffstore/sinterstore/sunionstore</span><br><span class="line">scard(获取集合长度)/spop(随机从集合中取出并删除一个元素)</span><br><span class="line">srandmember key [count]</span><br></pre></td></tr></table></figure></li><li><p>注 ： </p></li></ul><ol><li>如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。</li><li>如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。</li></ol><h3 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted set"></a>sorted set</h3><p><strong>有序集合，在集合类型的基础上为集合中的每个元素都关联了一个分数，这样可以很方便的获得分数最高的N个元素(topN)</strong>。</p><ul><li><p>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zadd/zscore/zrange/zrevrange/</span><br><span class="line">zrangebyscore        <span class="comment">##默认是闭区间,可使用"("使用开区间</span></span><br><span class="line">zincrby/zcard/zcount <span class="comment">##获取指定分数范围的元素个数</span></span><br><span class="line">zrem                 </span><br><span class="line"><span class="comment">##扩展：+inf(正无穷)-inf(负无穷)</span></span><br></pre></td></tr></table></figure></li><li><p>更多命令请查看：<a href="http://doc.redisfans.com/" target="_blank" rel="noopener">http://doc.redisfans.com/</a></p></li></ul><h2 id="java操作redis"><a href="#java操作redis" class="headerlink" title="java操作redis"></a>java操作redis</h2><ul><li><p>使用jedis第三方jar包操作redis , mvn依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>实例代码一 ： 通过Jedis操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TestRedis</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">new</span> Jedis( <span class="string">"192.168.3.56"</span> , <span class="number">6379</span> ) ;</span><br><span class="line">    jedis.set(<span class="string">"user:info:xxo"</span>,<span class="string">"23"</span>);</span><br><span class="line">    System.out.println(jedis.get(<span class="string">"user:info:xxo"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>实例代码二 ： redis连接池</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TestRedisPool</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1. 连接池配置</span></span><br><span class="line">    JedisPoolConfig config = <span class="keyword">new</span> JedisPoolConfig() ;</span><br><span class="line">    config.setMaxIdle(<span class="number">50</span>);         <span class="comment">//最大空闲连接</span></span><br><span class="line">    config.setMaxTotal(<span class="number">100</span>);       <span class="comment">//最大连接数</span></span><br><span class="line">    config.setMaxWaitMillis(<span class="number">2000</span>); <span class="comment">//最长连接时间</span></span><br><span class="line">    config.setTestOnBorrow(<span class="keyword">true</span>);  <span class="comment">//校验</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. 通过连接池获取Jedis</span></span><br><span class="line">    JedisPool pool = <span class="keyword">new</span> JedisPool(config, <span class="string">"192.168.3.56"</span>, <span class="number">6379</span>);</span><br><span class="line">    Jedis jedis = pool.getResource(); <span class="comment">//获取Jedis</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//3. 通过Jedis操作数据</span></span><br><span class="line">    jedis.set(<span class="string">"user:info:xxo:age"</span>, String.valueOf(<span class="number">23</span>)) ;</span><br><span class="line">    System.out.println(jedis.get(<span class="string">"user:info:xxo:age"</span>));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>实例代码三 ： 模拟一个限制非法访问连接</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userVisit</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">15</span>; i++) &#123;</span><br><span class="line">        System.out.println(checkIP(<span class="string">"192.168.3.59"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">checkIP</span><span class="params">(String ip)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1. 创建一个对象</span></span><br><span class="line">    Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"192.168.3.56"</span>, <span class="number">6379</span>) ;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. 查看ip,如果不存在</span></span><br><span class="line">    String key = jedis.get(ip);</span><br><span class="line">    <span class="keyword">if</span>( key == <span class="keyword">null</span> )&#123;</span><br><span class="line">        jedis.set( ip , <span class="string">"1"</span> );</span><br><span class="line">        jedis.expire( ip , <span class="number">5</span> ) ; <span class="comment">//有效时间</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.是否在5s之类超过限制，这里限制为10次</span></span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = Integer.valueOf( key ) ;</span><br><span class="line">        <span class="keyword">if</span>( count &gt;= <span class="number">10</span> )&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//jedis.set( ip , (++count)+"" ) ;</span></span><br><span class="line">            jedis.incr(ip) ;<span class="comment">//自动增加1，等于incrBy(ip,1);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span> ;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>expire</strong>设置一个键的生存时间，到时间后redis会自动删除它。指定时间点<strong>expireAt</strong>（expireAt [key] unix时间戳）</p></li></ul><p>应用场景：</p><blockquote><p>限时的优惠活动信息<br>网站数据缓存（对于一些需要定时更新的数据，例如：积分排行榜）<br>手机验证码（短信验证码）<br>限制网站访客访问频率（例如：1分钟最多访问10次）</p></blockquote><h2 id="附录相关redis命令"><a href="#附录相关redis命令" class="headerlink" title="附录相关redis命令"></a>附录相关redis命令</h2><ul><li><p><strong>连接操作相关的命令</strong><br>quit：关闭连接（connection）<br>auth：简单密码认证</p></li><li><p><strong>持久化</strong><br>save：将数据同步保存到磁盘<br>bgsave：将数据异步保存到磁盘<br>lastsave：返回上次成功将数据保存到磁盘的Unix时戳<br>shundown：将数据同步保存到磁盘，然后关闭服务</p></li><li><p><strong>远程服务控制</strong><br>info：提供服务器的信息和统计<br>monitor：实时转储收到的请求<br>slaveof：改变复制策略设置<br>config：在运行时配置Redis服务器</p></li><li><p><strong>对value操作的命令</strong><br>exists(key)：确认一个key是否存在<br>del(key)：删除一个key<br>type(key)：返回值的类型<br>keys(pattern)：返回满足给定pattern的所有key<br>randomkey：随机返回key空间的一个<br>keyrename(oldname, newname)：重命名key<br>dbsize：返回当前数据库中key的数目<br>expire：设定一个key的活动时间（s）<br>ttl：获得一个key的活动时间<br>select(index)：按索引查询<br>move(key, dbindex)：移动当前数据库中的key到dbindex数据库<br>flushdb：删除当前选择数据库中的所有key<br>flushall：删除所有数据库中的所有key</p></li><li><p><strong>对String操作的命令</strong><br>set(key, value)：给数据库中名称为key的string赋予值value<br>get(key)：返回数据库中名称为key的string的value<br>getset(key, value)：给名称为key的string赋予上一次的value<br>mget(key1, key2,…, key N)：返回库中多个string的value<br>setnx(key, value)：添加string，名称为key，值为value<br>setex(key, time, value)：向库中添加string，设定过期时间time<br>mset(key N, value N)：批量设置多个string的值<br>msetnx(key N, value N)：如果所有名称为key i的string都不存在<br>incr(key)：名称为key的string增1操作<br>incrby(key, integer)：名称为key的string增加integer<br>decr(key)：名称为key的string减1操作<br>decrby(key, integer)：名称为key的string减少integer<br>append(key, value)：名称为key的string的值附加value<br>substr(key, start, end)：返回名称为key的string的value的子串</p></li><li><p><strong>对List操作的命令</strong><br>rpush(key, value)：在名称为key的list尾添加一个值为value的元素<br>lpush(key, value)：在名称为key的list头添加一个值为value的 元素<br>llen(key)：返回名称为key的list的长度<br>lrange(key, start, end)：返回名称为key的list中start至end之间的元素<br>ltrim(key, start, end)：截取名称为key的list<br>lindex(key, index)：返回名称为key的list中index位置的元素<br>lset(key, index, value)：给名称为key的list中index位置的元素赋值<br>lrem(key, count, value)：删除count个key的list中值为value的元素<br>lpop(key)：返回并删除名称为key的list中的首元素<br>rpop(key)：返回并删除名称为key的list中的尾元素<br>blpop(key1, key2,… key N, timeout)：lpop命令的block版本。<br>brpop(key1, key2,… key N, timeout)：rpop的block版本。<br>rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部</p></li><li><p><strong>对Set操作的命令</strong><br>sadd(key, member)：向名称为key的set中添加元素member<br>srem(key, member) ：删除名称为key的set中的元素member<br>spop(key) ：随机返回并删除名称为key的set中一个元素<br>smove(srckey, dstkey, member) ：移到集合元素<br>scard(key) ：返回名称为key的set的基数<br>sismember(key, member) ：member是否是名称为key的set的元素<br>sinter(key1, key2,…key N) ：求交集<br>sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合<br>sunion(key1, (keys)) ：求并集<br>sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合<br>sdiff(key1, (keys)) ：求差集<br>sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合<br>smembers(key) ：返回名称为key的set的所有元素<br>srandmember(key) ：随机返回名称为key的set的一个元素</p></li><li><p><strong>对Hash操作的命令</strong><br>hset(key, field, value)：向名称为key的hash中添加元素field<br>hget(key, field)：返回名称为key的hash中field对应的value<br>hmget(key, (fields))：返回名称为key的hash中field i对应的value<br>hmset(key, (fields))：向名称为key的hash中添加元素field<br>hincrby(key, field, integer)：将名称为key的hash中field的value增加integer<br>hexists(key, field)：名称为key的hash中是否存在键为field的域<br>hdel(key, field)：删除名称为key的hash中键为field的域<br>hlen(key)：返回名称为key的hash中元素个数<br>hkeys(key)：返回名称为key的hash中所有键<br>hvals(key)：返回名称为key的hash中所有键对应的value<br>hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value</p></li><li><p>参考资料<br><a href="http://my.oschina.net/davehe/blog/129082?fromerr=6dre9pGK" title="附录来源于该网站" target="_blank" rel="noopener">http://my.oschina.net/davehe/blog/129082?fromerr=6dre9pGK</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Java </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--数据库连接池</title>
      <link href="/2016/04/26/Java-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
      <url>/2016/04/26/Java-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/</url>
      <content type="html"><![CDATA[<p>　　在我们使用数据库时，每次都需要<strong>获取数据库链接</strong>，而创建连接通常需要消耗较大的资源。对于一个很小的应用是没有什么问题，如果是一个复杂的数据库应用呢？是不是要很大的开销？<strong>如果我们去减少创建、关闭连接就会很好的降低资源消耗提升性能，于是就有了数据库连接池的出现</strong>。（<em>注：本博客主要使用mysql数据库</em>）</p><h2 id="不使用连接池"><a href="#不使用连接池" class="headerlink" title="不使用连接池"></a>不使用连接池</h2><p>需要<em>mysql-connector-java-5.0.8-bin.jar</em><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.pool;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"><span class="keyword">import</span> java.util.ResourceBundle;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 不使用连接池</span></span><br><span class="line"><span class="comment"> * JDBC DEMO</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/26.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnPool</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建连接</span></span><br><span class="line">        Connection conn = <span class="keyword">null</span>;</span><br><span class="line">        PreparedStatement statm = <span class="keyword">null</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 加载驱动</span></span><br><span class="line">            Class.forName(<span class="string">"com.mysql.jdbc.Driver"</span>);</span><br><span class="line">            conn = DriverManager.getConnection(</span><br><span class="line">                    <span class="string">"jdbc:mysql:///xiaoxiaomo?useUnicode=true&amp;characterEncoding=UTF-8"</span>,</span><br><span class="line">                    <span class="string">"root"</span>, <span class="string">"root"</span>);</span><br><span class="line">            String sql = <span class="string">"update sys_user set mobile= ? where id = ?"</span>;</span><br><span class="line">            statm = conn.prepareStatement(sql) ;</span><br><span class="line">            statm.setString(<span class="number">1</span>,<span class="string">"15826008888"</span>);</span><br><span class="line">            statm.setInt(<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line">            <span class="keyword">int</span> b = statm.executeUpdate() ;</span><br><span class="line">            <span class="keyword">if</span> (b == <span class="number">1</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">"更新成功"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">"插入失败"</span>);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 关闭连接 释放资源</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (rs != <span class="keyword">null</span>)</span><br><span class="line">                    rs.close();</span><br><span class="line">                <span class="keyword">if</span> (statm != <span class="keyword">null</span>)</span><br><span class="line">                    statm.close();</span><br><span class="line">                <span class="keyword">if</span> (conn != <span class="keyword">null</span>)</span><br><span class="line">                    conn.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><a id="more"></a><h2 id="常用数据库连接池"><a href="#常用数据库连接池" class="headerlink" title="常用数据库连接池"></a>常用数据库连接池</h2><p>数据库连接池的一些优点：</p><ol><li><strong>资源重用</strong></li><li>更快的系统响应速度</li><li>新的资源分配手段</li><li>统一的连接管理，避免数据库连接泄漏</li></ol><p>现在很多WEB服务器(<em>Weblogic, WebSphere, Tomcat</em>)都提供了DataSoruce的实现，即连接池的实现。通常我们把DataSource的实现，按其英文含义称之为数据源，数据源中都包含了数据库连接池的实现。</p><h3 id="DBCP数据源"><a href="#DBCP数据源" class="headerlink" title="DBCP数据源"></a>DBCP数据源</h3><ol><li><strong>DBCP 是 Apache 软件基金组织下的开源连接池实现</strong>，使用DBCP，需要如下两个 jar 文件（<em>commons-dbcp-1.4.jar</em>和<em>commons-pool-1.5.6.jar</em>）：</li><li><strong>Tomcat 的连接池也是采用该连接池来实现的</strong>。该数据库连接池既可以与应用服务器整合使用，也可由应用程序独立使用。</li><li>实例代码：注这里使用了配置文件，具体配置如下:<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160426233024.png" alt="DBCP"></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.pool.dbcp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbcp.BasicDataSourceFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 数据库连接池dbcp</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/26.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DbcpTest</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">//1. 数据源工厂创建数据库连接池</span></span><br><span class="line"><span class="comment">//BasicDataSource bds = new BasicDataSource();//可以不使用配置</span></span><br><span class="line">BasicDataSourceFactory factory = <span class="keyword">new</span> BasicDataSourceFactory();</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 创建配置文件对象</span></span><br><span class="line">Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line"><span class="comment">//加载配置文件流</span></span><br><span class="line">prop.load( DbcpTest.class.getResourceAsStream(<span class="string">"/dbcp.properties"</span>) );</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. 加载配置文件 生成对应数据源</span></span><br><span class="line">DataSource ds = factory.createDataSource(prop);</span><br><span class="line">Connection conn = ds.getConnection();</span><br><span class="line">Statement statm = conn.createStatement();</span><br><span class="line">ResultSet rs = statm.executeQuery(<span class="string">"select * from student"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(rs.next())&#123;</span><br><span class="line"><span class="comment">//处理rs.....</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rs.close();</span><br><span class="line">statm.close();</span><br><span class="line"><span class="comment">//不是真正的关闭连接,而是将连接返回连接池</span></span><br><span class="line">conn.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="C3P0"><a href="#C3P0" class="headerlink" title="C3P0"></a>C3P0</h3><p><strong>C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。</strong>目前使用它的开源项目有Hibernate，Spring等。C3P0数据源在项目开发中使用得比较多。</p><ol><li>c3p0与dbcp区别<br>dbcp没有自动回收空闲连接的功能<br>c3p0有自动回收空闲连接功能</li><li>需要导入jar：<em>c3p0-0.9.5.1.jar</em>和<em>mchange-commons-java-0.2.10.jar</em></li><li>在类目录下加入C3P0的配置文件：<em>c3p0-config.xml</em><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160426234822.png" alt="DBCP"></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.pool.c3p0;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"><span class="keyword">import</span> com.mchange.v2.c3p0.ComboPooledDataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * c3p0连接池用法</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/26.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">C3P0Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//ComboPooledDataSource cpds = new ComboPooledDataSource();</span></span><br><span class="line">ComboPooledDataSource cpds = <span class="keyword">new</span> ComboPooledDataSource(<span class="string">"momo"</span>);</span><br><span class="line">Connection conn = cpds.getConnection();</span><br><span class="line">Statement statm = conn.createStatement();</span><br><span class="line">ResultSet rs = statm.executeQuery(<span class="string">"select * from sys_user"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(rs.next())&#123;</span><br><span class="line"><span class="comment">//处理rs......</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rs.close();</span><br><span class="line">statm.close();</span><br><span class="line">conn.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="jdbcUtils"><a href="#jdbcUtils" class="headerlink" title="jdbcUtils"></a>jdbcUtils</h3><p><code>commons-dbutils</code> 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。</p><ul><li>org.apache.commons.dbutils.QueryRunner –核心</li><li>org.apache.commons.dbutils.ResultSetHandler –工具类</li><li><p>rg.apache.commons.dbutils.DbUtils</p></li><li><p>实例代码：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160427001332.png" alt="DBCP"></p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.pool.dbutil;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.xiaoxiaomo.pool.bean.SysUser;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.QueryRunner;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.handlers.BeanHandler;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.handlers.BeanListHandler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.mchange.v2.c3p0.ComboPooledDataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DBUtils用法</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/26.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DBUtilsTest</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//数据源</span></span><br><span class="line">ComboPooledDataSource cpds = <span class="keyword">new</span> ComboPooledDataSource(<span class="string">"momo"</span>);</span><br><span class="line"><span class="comment">//指定一个DBUtils核心类</span></span><br><span class="line">QueryRunner query = <span class="keyword">new</span> QueryRunner(cpds);</span><br><span class="line"></span><br><span class="line">SysUser account = query.query(</span><br><span class="line"><span class="string">"select * from sys_user"</span>,</span><br><span class="line"><span class="keyword">new</span> BeanHandler&lt;SysUser&gt;(SysUser.class));</span><br><span class="line">System.out.print(account.toString());</span><br><span class="line"></span><br><span class="line">cpds.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--NIO之通道(文件通道)</title>
      <link href="/2016/04/25/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93-%E6%96%87%E4%BB%B6%E9%80%9A%E9%81%93/"/>
      <url>/2016/04/25/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93-%E6%96%87%E4%BB%B6%E9%80%9A%E9%81%93/</url>
      <content type="html"><![CDATA[<p>　　上篇博文<a href="http://blog.xiaoxiaomo.com/2016/04/23/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93/">http://blog.xiaoxiaomo.com/2016/04/23/Java-NIO之通道/</a>只是泛泛地讨论通道，现在我们将具体讨论文件通道（<em>socket 通道将在下篇博客讨论</em>）。FileChannel 类可以实现常用的 read，write 以及 scatter/gather 操作，同时它也提供了很多专用于文件的新方法。这些方法中的许多都是我们所熟悉的文件操作。</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160425094103.png" alt="FileChannel 类层次结构"></p><a id="more"></a><h2 id="文件通道FileChannel"><a href="#文件通道FileChannel" class="headerlink" title="文件通道FileChannel"></a>文件通道FileChannel</h2><p>从<a href="http://blog.xiaoxiaomo.com/2016/04/23/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93/" title="Java-NIO之通道">上篇博文</a>知道，<strong>一个FileChannel对象却只能通过在一个打开的RandomAccessFile、FileInputStream或FileOutputStream对象上调用getChannel()方法来获取，开发者不能直接创建一个FileChannel</strong>。下面来看一下 <a href="http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/java/nio/channels/FileChannel.java" target="_blank" rel="noopener">FileChannel</a> 接口：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.nio.channels;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.MappedByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.spi.AbstractInterruptibleChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.*;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.attribute.FileAttribute;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.spi.*;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">FileChannel</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">AbstractInterruptibleChannel</span></span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">SeekableByteChannel</span>, <span class="title">GatheringByteChannel</span>, <span class="title">ScatteringByteChannel</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">FileChannel</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FileChannel <span class="title">open</span><span class="params">(Path path,Set&lt;? extends OpenOption&gt; options,FileAttribute&lt;?&gt;... attrs)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        FileSystemProvider provider = path.getFileSystem().provider();</span><br><span class="line">        <span class="keyword">return</span> provider.newFileChannel(path, options, attrs);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FileAttribute&lt;?&gt;[] NO_ATTRIBUTES = <span class="keyword">new</span> FileAttribute[<span class="number">0</span>];</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FileChannel <span class="title">open</span><span class="params">(Path path, OpenOption... options)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        Set&lt;OpenOption&gt; set = <span class="keyword">new</span> HashSet&lt;OpenOption&gt;(options.length);</span><br><span class="line">        Collections.addAll(set, options);</span><br><span class="line">        <span class="keyword">return</span> open(path, set, NO_ATTRIBUTES);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// -- Channel operations --</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(ByteBuffer dst)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">read</span><span class="params">(ByteBuffer[] dsts, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">read</span><span class="params">(ByteBuffer[] dsts)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> read(dsts, <span class="number">0</span>, dsts.length);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">write</span><span class="params">(ByteBuffer src)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">write</span><span class="params">(ByteBuffer[] srcs, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">write</span><span class="params">(ByteBuffer[] srcs)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> write(srcs, <span class="number">0</span>, srcs.length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// -- Other operations --</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">position</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileChannel <span class="title">position</span><span class="params">(<span class="keyword">long</span> newPosition)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">size</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileChannel <span class="title">truncate</span><span class="params">(<span class="keyword">long</span> size)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">force</span><span class="params">(<span class="keyword">boolean</span> metaData)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">transferTo</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">long</span> position, <span class="keyword">long</span> count,WritableByteChannel target)</span><span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">transferFrom</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">ReadableByteChannel src,<span class="keyword">long</span> position, <span class="keyword">long</span> count)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(ByteBuffer dst, <span class="keyword">long</span> position)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">write</span><span class="params">(ByteBuffer src, <span class="keyword">long</span> position)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// -- Memory-mapped buffers --</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MapMode</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> MapMode READ_ONLY = <span class="keyword">new</span> MapMode(<span class="string">"READ_ONLY"</span>);</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> MapMode READ_WRITE = <span class="keyword">new</span> MapMode(<span class="string">"READ_WRITE"</span>);</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> MapMode PRIVATE = <span class="keyword">new</span> MapMode(<span class="string">"PRIVATE"</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> MappedByteBuffer <span class="title">map</span><span class="params">(MapMode mode,<span class="keyword">long</span> position, <span class="keyword">long</span> size)</span><span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// -- Locks --</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileLock <span class="title">lock</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> size, <span class="keyword">boolean</span> shared)</span><span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> FileLock <span class="title">lock</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> lock(<span class="number">0L</span>, Long.MAX_VALUE, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileLock <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> size, <span class="keyword">boolean</span> shared)</span><span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> FileLock <span class="title">tryLock</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> tryLock(<span class="number">0L</span>, Long.MAX_VALUE, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ol><li><strong>文件通道总是阻塞式的，因此不能被置于非阻塞模式下。</strong></li><li><strong>FileChannel对象是线程安全的（thread-safe）</strong>，多个进程可以在同一个实例上并发调用方法而不会引起任何问题，不过并非所有的操作都是多线程的（<em>multithreaded</em>）。影响通道位置或者影响文件的操作都是单线程的(<em>single-threaded</em>)，如果有一个线程已经在执行会影响通道位置或文件大小的操作，那么其他尝试进行此类操作之一的线程必须等待，并发行为也会受到底层操作系统或文件系统的影响。</li></ol><h2 id="读-写数据"><a href="#读-写数据" class="headerlink" title="读/写数据"></a>读/写数据</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读/写数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/14.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Channel01</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 定义通道,并打开</span></span><br><span class="line">        FileChannel inChannel = <span class="keyword">new</span> RandomAccessFile(<span class="string">"abc.txt"</span>, <span class="string">"rw"</span>).getChannel();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 缓冲区</span></span><br><span class="line">        ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 读写数据</span></span><br><span class="line"><span class="comment">// 从inChannel读取的数据会读到buf中</span></span><br><span class="line">        <span class="keyword">int</span> bytesRead ;</span><br><span class="line">        <span class="keyword">while</span> ( (bytesRead = inChannel.read(buf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"=====Read "</span> + bytesRead);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//读模式下，可以读取之前写入到buffer的所有数据</span></span><br><span class="line">            buf.flip(); <span class="comment">//反转此缓冲区。将Buffer从写模式切换到读模式</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span>(buf.hasRemaining())&#123; <span class="comment">//告知在当前位置和限制之间是否有元素。</span></span><br><span class="line">                System.out.print((<span class="keyword">char</span>) buf.get());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            buf.clear(); <span class="comment">//清除此缓冲区。</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭流</span></span><br><span class="line">        inChannel.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文件空洞"><a href="#文件空洞" class="headerlink" title="文件空洞"></a>文件空洞</h2><ol><li><strong>当磁盘上一个文件的分配空间小于它的文件大小时会出现“文件空洞”</strong>。</li><li>对于内容稀疏的文件，大多数现代文件系统只为实际写入的数据分配磁盘空间（<em>更准确地说，只为那些写入数据的文件系统页分配空间</em>）。假如<strong>数据被写入到文件中非连续的位置上，这将导致文件出现在逻辑上不包含数据的区域</strong>（即“<code>空洞</code>”）<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.RandomAccessFile;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/25.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Channel04</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span> <span class="params">(String [] argv)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建一个临时文件和获取一个通道</span></span><br><span class="line">        File temp = File.createTempFile(<span class="string">"xiaoxiaomo"</span>, <span class="keyword">null</span>);</span><br><span class="line">        FileChannel channel = <span class="keyword">new</span> RandomAccessFile(temp, <span class="string">"rw"</span>).getChannel();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建一个缓冲区并存入数据</span></span><br><span class="line">        ByteBuffer byteBuffer = ByteBuffer.allocateDirect (<span class="number">100</span>);</span><br><span class="line">        putData (<span class="number">0</span>, byteBuffer, channel);<span class="comment">//position=0</span></span><br><span class="line">        putData (<span class="number">10</span>, byteBuffer, channel);<span class="comment">//position=10</span></span><br><span class="line">        putData (<span class="number">20</span>, byteBuffer, channel);<span class="comment">//position=20</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 文件中有两个洞，大小为26</span></span><br><span class="line">        System.out.println (<span class="string">"temp file '"</span> + temp.getPath( )</span><br><span class="line">                + <span class="string">"', size="</span> + channel.size( ));</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//写入数据</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">putData</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> position, ByteBuffer buffer, FileChannel channel)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        String string = <span class="string">"xiao"</span> + position;<span class="comment">//待写入字符串</span></span><br><span class="line">        buffer.clear();</span><br><span class="line">        buffer.put (string.getBytes (<span class="string">"US-ASCII"</span>));</span><br><span class="line">        buffer.flip();</span><br><span class="line"></span><br><span class="line">        channel.position(position);<span class="comment">//设置position</span></span><br><span class="line">        channel.write(buffer);<span class="comment">//写入数据</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出结果</span></span><br><span class="line"><span class="comment">//temp file 'C:\Users\Jason\AppData\Local\Temp\xiaoxiaomo*******.tmp', size=26</span></span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160425145857.png" alt="FileChannel空洞1"></p><ul><li>说明</li></ul><p><strong>所有空洞都会被“0”填充</strong>。该文件是26个字节，有些以“0”表示。FileChannel 位置（position）是从底层的文件描述符获得的，该 position 同时被作为通道引用获取来源的文件对象共享。这也就意味着一个对象对该 position 的更新可以被另一个对象看到。<strong>position()获取，position(long pos)方法设置</strong>。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.io.RandomAccessFile;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/25.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Channel03</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span> <span class="params">(String [] argv)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//创建通道</span></span><br><span class="line">        FileChannel channel = <span class="keyword">new</span> RandomAccessFile(<span class="string">"momo.txt"</span>, <span class="string">"rw"</span>).getChannel();</span><br><span class="line">        System.out.println(<span class="string">"====="</span>+channel.size());</span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> position = channel.position();</span><br><span class="line">        System.out.println(<span class="string">"当前position: "</span> + position);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//重新设定位置</span></span><br><span class="line">        channel.position(position+<span class="number">5</span>);<span class="comment">//形成文件空洞</span></span><br><span class="line">        buffer.clear();</span><br><span class="line">        buffer.put(<span class="string">"xiaoxiaomo"</span>.getBytes());</span><br><span class="line">        buffer.flip();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(buffer.hasRemaining()) &#123;<span class="comment">//写文件</span></span><br><span class="line">            channel.write(buffer);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//读取数据</span></span><br><span class="line">        System.out.println(<span class="string">"当前position: "</span> + channel.position());</span><br><span class="line">        readFile();<span class="comment">//读取数据</span></span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileChannel channel = <span class="keyword">new</span> RandomAccessFile(<span class="string">"momo.txt"</span>, <span class="string">"rw"</span>).getChannel();</span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">10</span>);</span><br><span class="line">        <span class="comment">//读文件</span></span><br><span class="line">        <span class="keyword">while</span>(channel.read(buffer) != -<span class="number">1</span> ) &#123;</span><br><span class="line">            buffer.flip();</span><br><span class="line">            <span class="keyword">while</span>(buffer.hasRemaining()) &#123;</span><br><span class="line">                System.out.print((<span class="keyword">char</span>)buffer.get());</span><br><span class="line">            &#125;</span><br><span class="line">            buffer.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//执行结果：</span></span><br><span class="line"><span class="comment">//=====0</span></span><br><span class="line"><span class="comment">//        当前position: 0</span></span><br><span class="line"><span class="comment">//        当前position: 15</span></span><br><span class="line"><span class="comment">//        xiaoxiaomo</span></span><br></pre></td></tr></table></figure></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160425153137.png" alt="FileChannel空洞2"></p><h2 id="文件锁"><a href="#文件锁" class="headerlink" title="文件锁"></a>文件锁</h2><ol><li><p><strong>文件锁针对的是文件，所以和通道无关</strong>。分为<strong>共享锁(shared)</strong>和<strong>独占锁(exclusive)</strong>。</p></li><li><p><strong>如果一个进程下的另一个线程访问一个加独占锁的文件，是可以的。因为这是底层操作系统的实现。只是针对不同的进程</strong>。所以，也有可能在某些操作系统上，独占锁只是一个建议锁，非强制性的。关于管道上的锁，有如下操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">FileChannel</span> <span class="keyword">extends</span> <span class="title">AbstractChannel</span> </span></span><br><span class="line"><span class="class">  <span class="keyword">implements</span> <span class="title">ByteChannel</span>, <span class="title">GatheringByteChannel</span>, <span class="title">ScatteringByteChannel</span> </span>&#123; </span><br><span class="line"><span class="comment">// This is a partial API listing </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> FileLock <span class="title">lock</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileLock <span class="title">lock</span> <span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> size, <span class="keyword">boolean</span> shared)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> FileLock <span class="title">tryLock</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FileLock <span class="title">tryLock</span> <span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> size, <span class="keyword">boolean</span> shared)</span> </span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>lock可以锁住一个文件的某个区域。而且这个区域可以使比文件还大。如超出文件尾的，新写入的内容也被锁住。lock可能会阻塞，等待前一个lock被释放。 </p></li><li><p>tryLock和lock一样。只是如果当时没有可用锁，就立即返回一个null，而不是阻塞。 </p></li></ol><ul><li>FileLock 类如下： </li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">FileLock</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> FileChannel <span class="title">channel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">position</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">size</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">isShared</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">overlaps</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> size)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isValid</span><span class="params">()</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一旦FileLock对象创建就生效。注意，创建以后，position，是否独占，大小就不能改变了。<br><strong>FileLock是线程安全的，可以多个线程同时访问一个锁</strong>。注意，在你不确定操作系统是否支持独占性时，使用isShared()来判断是否该锁支持共享。<br>如果你要查看一个感兴趣的区域是否与当前的锁有冲突，可以使用 overlaps，这个函数返回的是当前进程上的，即使是返回为false，也不一定可以获取到FileLock。 </p><p>最后，使用文件锁，一定要释放。使用try…catch…finally<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FileLock lock = fileChannel.lock()</span><br><span class="line"> <span class="keyword">try</span> &#123; </span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"> &#125; <span class="keyword">catch</span> (IOException) &#123; </span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"> &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">lock.release()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li>参考资料<br><a href="http://blog.csdn.net/simonchi/article/details/44488733" target="_blank" rel="noopener">http://blog.csdn.net/simonchi/article/details/44488733</a><br><a href="http://download.csdn.net/detail/tang__xuandong/9500450" title="Java NIO" target="_blank" rel="noopener">《Java NIO》-(<em>Developing High Performance Applications</em>)</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--NIO之通道</title>
      <link href="/2016/04/23/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93/"/>
      <url>/2016/04/23/Java-NIO%E4%B9%8B%E9%80%9A%E9%81%93/</url>
      <content type="html"><![CDATA[<p>　　通道与缓冲区不同，<code>通道 API 主要由接口指定</code>。<em>不同的操作系统上通道实现（Channel Implementation）会有根本性的差异</em>，所以通道 API 仅仅描述了可以做什么。因此很自然地，通道实现经常使用操作系统的本地代码。通道接口允许您以一种受控且可移植的方式来访问底层的 I/O服务。<br>　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160423165143.png" alt="Channel结构关系图"></p><a id="more"></a><p>首先，我们来更近距离地看一下基本的 Channel 接口。下面是 Channel 接口的完整源码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.nio.channels;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Channel</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isOpen</span><span class="params">( )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>从 Channel 接口引申出的其他接口都是面向字节的子接口</code>，包括 Writable ByteChannel 和ReadableByteChannel。这也正好支持了我们之前所学的：<strong>通道只能在字节缓冲区上操作</strong>。层次结构表明其他数据类型的通道也可以从 <code>Channel</code> 接口引申而来。这是一种很好的类设计，不过非字节实现是不可能的，因为操作系统都是以字节的形式实现底层 I/O 接口的。</p><h2 id="打开通道"><a href="#打开通道" class="headerlink" title="打开通道"></a>打开通道</h2><p>通道是访问 I/O 服务的导管，<strong>打开一个管道，通常就是创建一个管道</strong>。I/O 可以分为广义的两大类别：File I/O 和 Stream I/O。那么相应地也有两种类型的通道：文件（file）通道和套接字（socket）通道。通道可以以多种方式创建。</p><ol><li><strong>Socket</strong>： 通道有可以直接创建新 socket 通道的工厂方法，分别是<code>SocketChannel</code>、<code>ServerSocketChannel</code>和<code>DatagramChannel</code>。</li><li><strong>FileChannel</strong>： 对象却只能通过在一个打开的 <code>RandomAccessFile</code>、<code>FileInputStream</code> 或 <code>FileOutputStream</code>对象上调用getChannel()方法来获取，不能直接创建。</li></ol><ul><li>打开管道。例如</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Socket（套接字）</span></span><br><span class="line">SocketChannel sc = SocketChannel.open();</span><br><span class="line">ServerSocketChannel ssc = ServerSocketChannel.open();</span><br><span class="line">DatagramChannel dc = DatagramChannel.open();</span><br><span class="line"></span><br><span class="line"><span class="comment">//FileChannel</span></span><br><span class="line">FileChannel raf = <span class="keyword">new</span> RandomAccessFile(<span class="string">"file"</span>, <span class="string">"r"</span>).getChannel();</span><br><span class="line">FileChannel channel = <span class="keyword">new</span> FileInputStream(<span class="string">"abc.txt"</span>).getChannel();</span><br><span class="line">FileChannel channe = <span class="keyword">new</span> FileOutputStream(<span class="string">"abc.txt"</span>).getChannel();</span><br></pre></td></tr></table></figure><h2 id="使用通道"><a href="#使用通道" class="headerlink" title="使用通道"></a>使用通道</h2><p>打开一个管道之后就是管道的字节读写，有 <code>ReadableByteChannel</code>, <code>WritableByteChannel</code>,和<code>InterruptibleChannel</code>。ByteChannel类继承了ReadableByteChannel和WritableByteChannel的属性。然后还有很多很多的Channel了。例如：SocketChannel，FileChannel，ServerSocketChannel等等。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160423165742.png" alt="ByteChannel 接口"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReadableByteChannel</span> <span class="keyword">extends</span> <span class="title">Channel</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(ByteBuffer dst)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">WritableByteChannel</span> <span class="keyword">extends</span> <span class="title">Channel</span> </span>&#123; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">write</span><span class="params">(ByteBuffer src)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ByteChannel</span> <span class="keyword">extends</span> </span></span><br><span class="line"><span class="class"><span class="title">ReadableByteChannel</span>, <span class="title">WritableByteChannel</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>实例代码</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.Channels;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.ReadableByteChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.WritableByteChannel;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 通道</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/23.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChannelTest01</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建通道</span></span><br><span class="line">        ReadableByteChannel rbyc = Channels.newChannel(System.in);</span><br><span class="line">        WritableByteChannel wbyc = Channels.newChannel(System.out);</span><br><span class="line"></span><br><span class="line">        detailChnnel(rbyc, wbyc);</span><br><span class="line">        <span class="comment">//detailChnnel2(rbyc, wbyc);//第二种方法</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭</span></span><br><span class="line">        rbyc.close();</span><br><span class="line">        wbyc.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">detailChnnel</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            ReadableByteChannel rbyc, WritableByteChannel wbyc)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//2. 创建缓冲区</span></span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 处理数据-输入并打印到控制台</span></span><br><span class="line">        <span class="keyword">while</span> ( rbyc.read( buffer ) != -<span class="number">1</span> )&#123;<span class="comment">//读入数据到缓冲区</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">//翻转-准备读出缓冲区的数据</span></span><br><span class="line">            buffer.flip() ;</span><br><span class="line"></span><br><span class="line">            wbyc.write( buffer ) ;<span class="comment">//从缓冲区写出到控制台</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">//压缩-把已经读过的数据抛弃，使用后面的数据覆盖（移动至索引0）</span></span><br><span class="line">            buffer.compact() ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"结束程序后--------"</span>);</span><br><span class="line">        <span class="keyword">while</span> ( buffer.hasRemaining() )&#123;<span class="comment">//告知在当前位置和限制之间是否有元素。</span></span><br><span class="line">            wbyc.write( buffer ) ;<span class="comment">//</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">detailChnnel2</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            ReadableByteChannel rbyc, WritableByteChannel wbyc)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建缓冲区</span></span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">while</span> (rbyc.read(buffer) != -<span class="number">1</span>) &#123;</span><br><span class="line">            buffer.flip();</span><br><span class="line">            <span class="keyword">while</span> (buffer.hasRemaining()) &#123;</span><br><span class="line">                wbyc.write(buffer);<span class="comment">//从缓冲区写出到控制台</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//重设缓冲区以便接收更多的字节</span></span><br><span class="line">            buffer.compact();</span><br><span class="line">            <span class="comment">//buffer.clear();</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>SocketChannel和FileChannel都是实现了以上三个接口的。那么，也就是说，他们都有读写的方法，但是对于FileChannel来说，并非如此，因为有的文件可能是只读的，那么，如果调用write方法的，就会抛出NonWritableChannelException异常。 </li></ul><h2 id="Scatter-Gather"><a href="#Scatter-Gather" class="headerlink" title="Scatter/Gather"></a>Scatter/Gather</h2><p>有时候可能为了提高I/O性能，要<strong>组合多个缓冲区，或者从多个缓冲区读数据</strong>，就可以使用<code>Scatter（分散）</code>和<code>Gather（聚合）</code></p><ol><li><strong>Scatter</strong>：<strong>从一个Channel读取的信息分散到N个缓冲区中Buufer</strong>。</li><li><strong>Gather</strong>：<strong>将N个Buffer里面内容按照顺序发送到一个Channel</strong>。</li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160423175154.png" alt="Scatter/Gather"></p><ul><li>ReadableByteChannel、WritableByteChannel接口提供了通道的读写功能</li><li>ScatteringByteChannel、GatheringByteChannel接口提供了分散和聚合</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ScatteringByteChannel</span> <span class="keyword">extends</span> <span class="title">ReadableByteChannel</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">read</span> <span class="params">(ByteBuffer [] dsts)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">read</span> <span class="params">(ByteBuffer [] dsts, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> <span class="keyword">throws</span> IOException</span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">GatheringByteChannel</span> <span class="keyword">extends</span> <span class="title">WritableByteChannel</span></span>&#123; </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">write</span><span class="params">(ByteBuffer[] srcs)</span> <span class="keyword">throws</span> IOException</span>; </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">write</span><span class="params">(ByteBuffer[] srcs, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> <span class="keyword">throws</span> IOException</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>下面以FileChannel为例（<em>FileChannel implements GatheringByteChannel, ScatteringByteChannel</em>）</li><li>实例Scatter</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.RandomAccessFile;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * scatter 分散</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/23.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScatterDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Charset charset = Charset.forName(<span class="string">"GBK"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String fileName = <span class="string">"D:/test.log"</span>;</span><br><span class="line">        <span class="comment">//写入数据</span></span><br><span class="line">        writeData(fileName, <span class="string">"abcde999efghigk12345678"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**----------Scatter------------*/</span></span><br><span class="line">        <span class="comment">//read(java.nio.ByteBuffer[])</span></span><br><span class="line">        scatter(fileName);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//read(java.nio.ByteBuffer[], int, int)</span></span><br><span class="line">        scatter2(fileName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Scatter 分散</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">scatter</span><span class="params">(<span class="keyword">final</span> String fileName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//1. 获取文件通道</span></span><br><span class="line">        RandomAccessFile accessFile = <span class="keyword">new</span> RandomAccessFile(fileName, <span class="string">"r"</span>);</span><br><span class="line">        FileChannel channel = accessFile.getChannel();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//2. 创建两个缓冲区</span></span><br><span class="line">        ByteBuffer head = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        ByteBuffer body = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 缓冲区数组</span></span><br><span class="line">        ByteBuffer[] buffers = &#123;head, body&#125;;</span><br><span class="line">        <span class="comment">// channel读取的信息分散到head和body缓冲区中</span></span><br><span class="line">        <span class="comment">// head 前5个字节 |  body 剩下的</span></span><br><span class="line">        System.out.println(<span class="string">"scatter====共读到多少字节:"</span> + channel.read(buffers));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//head缓冲区中的数据:abcde</span></span><br><span class="line">        head.flip();</span><br><span class="line">        System.out.println(<span class="string">"head缓冲区中的数据:"</span> + charset.decode(head));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//body缓冲区中的数据:999efghigk12345678</span></span><br><span class="line">        body.flip();</span><br><span class="line">        System.out.println(<span class="string">"body缓冲区中的数据:"</span> + charset.decode(body));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭通道</span></span><br><span class="line">        accessFile.close();</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scatter2</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">scatter2</span><span class="params">(<span class="keyword">final</span> String fileName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 获取文件通道</span></span><br><span class="line">        RandomAccessFile accessFile = <span class="keyword">new</span> RandomAccessFile(fileName, <span class="string">"r"</span>);</span><br><span class="line">        FileChannel channel = accessFile.getChannel();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建一个四个缓冲区</span></span><br><span class="line">        ByteBuffer head = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        ByteBuffer body1 = ByteBuffer.allocate(<span class="number">3</span>);</span><br><span class="line">        ByteBuffer body2 = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        ByteBuffer body3 = ByteBuffer.allocate(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        ByteBuffer[] buffers = <span class="keyword">new</span> ByteBuffer[]&#123; head, body1, body2, body3&#125;;</span><br><span class="line">        <span class="comment">//0从那个缓冲区开始被使用，使用3个缓冲区即head,body1,body2</span></span><br><span class="line">        System.out.println(<span class="string">"scatter2====共读到多少字节:"</span> + channel.read(buffers, <span class="number">0</span>, <span class="number">3</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//head缓冲区中的数据:abcde</span></span><br><span class="line">        head.flip();</span><br><span class="line">        System.out.println(<span class="string">"head缓冲区中的数据:"</span> + charset.decode(head));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//body1缓冲区中的数据:999</span></span><br><span class="line">        body1.flip();</span><br><span class="line">        System.out.println(<span class="string">"body1缓冲区中的数据:"</span> + charset.decode(body1));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//body2缓冲区中的数据:efghi</span></span><br><span class="line">        body2.flip();</span><br><span class="line">        System.out.println(<span class="string">"body2缓冲区中的数据:"</span> + charset.decode(body2));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//body3，没有数据</span></span><br><span class="line">        body3.flip();</span><br><span class="line">        System.out.println(<span class="string">"body3缓冲区中的数据:"</span> + charset.decode(body3));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭流</span></span><br><span class="line">        accessFile.close();</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 写入数据</span></span><br><span class="line"><span class="comment">     * writeData</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeData</span><span class="params">(<span class="keyword">final</span> String fileName, String data)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        RandomAccessFile accessFile = <span class="keyword">new</span> RandomAccessFile(fileName, <span class="string">"rw"</span>);</span><br><span class="line">        accessFile.writeBytes(data);</span><br><span class="line">        accessFile.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//scatter====共读到多少字节:23</span></span><br><span class="line"><span class="comment">//head缓冲区中的数据:abcde</span></span><br><span class="line"><span class="comment">//body缓冲区中的数据:999efghigk12345678</span></span><br><span class="line"><span class="comment">//scatter2====共读到多少字节:13</span></span><br><span class="line"><span class="comment">//head缓冲区中的数据:abcde</span></span><br><span class="line"><span class="comment">//body1缓冲区中的数据:999</span></span><br><span class="line"><span class="comment">//body2缓冲区中的数据:efghi</span></span><br><span class="line"><span class="comment">//body3缓冲区中的数据:</span></span><br></pre></td></tr></table></figure><ul><li>实例Gather</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.momo.nio;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.RandomAccessFile;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Gather 聚合</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/23.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GatherDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String fileName = <span class="string">"D:/test2.log"</span>;</span><br><span class="line">        <span class="comment">/**----------Gather------------*/</span></span><br><span class="line">        <span class="comment">//FileChannel#write(java.nio.ByteBuffer[])</span></span><br><span class="line">        gather(fileName);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//FileChannel#write(java.nio.ByteBuffer[], int, int)</span></span><br><span class="line">        gather2(fileName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * gather</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gather</span><span class="params">(String fileName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 获取文件通道</span></span><br><span class="line">        RandomAccessFile accessFile = <span class="keyword">new</span> RandomAccessFile(fileName, <span class="string">"rw"</span>);</span><br><span class="line">        FileChannel channel = accessFile.getChannel();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建两个缓冲区head,body 并写入数据</span></span><br><span class="line">        ByteBuffer head = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        head.put(<span class="string">"abcde"</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        ByteBuffer body = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        body.put(<span class="string">"999efghigk12345678"</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        ByteBuffer[] allBuffers = &#123; head, body &#125;;</span><br><span class="line"></span><br><span class="line">        head.flip();</span><br><span class="line">        body.flip();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将按allBuffers顺序  写入abcde999efghigk12345678</span></span><br><span class="line">        System.out.println(<span class="string">"gather====共写入多少字节:"</span> + channel.write(allBuffers));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 关闭</span></span><br><span class="line">        accessFile.close();</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * gather2</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gather2</span><span class="params">(String fileName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 获取文件通道</span></span><br><span class="line">        RandomAccessFile accessFile = <span class="keyword">new</span> RandomAccessFile(fileName, <span class="string">"rw"</span>);</span><br><span class="line">        FileChannel channel = accessFile.getChannel();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建四个缓冲区</span></span><br><span class="line">        ByteBuffer head = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        ByteBuffer body1 = ByteBuffer.allocate(<span class="number">3</span>);</span><br><span class="line">        ByteBuffer body2 = ByteBuffer.allocate(<span class="number">5</span>);</span><br><span class="line">        ByteBuffer body3 = ByteBuffer.allocate(<span class="number">20</span>);</span><br><span class="line"></span><br><span class="line">        head.put(<span class="string">"abcde"</span>.getBytes());</span><br><span class="line">        body1.put(<span class="string">"999"</span>.getBytes());</span><br><span class="line">        body2.put(<span class="string">"efghi"</span>.getBytes());</span><br><span class="line">        body3.put(<span class="string">"gk12345678"</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        ByteBuffer[] allBuffers = <span class="keyword">new</span> ByteBuffer[]&#123;</span><br><span class="line">            head, body1, body2, body3&#125;;</span><br><span class="line"></span><br><span class="line">        head.flip();</span><br><span class="line">        body1.flip();</span><br><span class="line">        body2.flip();</span><br><span class="line">        body3.flip();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将按allBuffers数组顺序使用两个缓冲区</span></span><br><span class="line">        <span class="comment">//0从哪开始</span></span><br><span class="line">        <span class="comment">//2使用几个</span></span><br><span class="line">        <span class="comment">//当前使用head  body1</span></span><br><span class="line">        <span class="comment">//最终写入abcdefg</span></span><br><span class="line">        <span class="keyword">long</span> n = channel.write(allBuffers, <span class="number">0</span>, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//应该返回8个字节</span></span><br><span class="line">        System.out.println(<span class="string">"gather2====共写入多少字节:"</span> + n);</span><br><span class="line"></span><br><span class="line">        accessFile.close();</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//运行结果</span></span><br><span class="line"><span class="comment">//gather====共写入多少字节:23</span></span><br><span class="line"><span class="comment">//gather2====共写入多少字节:8</span></span><br></pre></td></tr></table></figure><ul><li><p>文件通道详解：<a href="http://blog.xiaoxiaomo.com/2016/04/25/Java-NIO之通道-文件通道">http://blog.xiaoxiaomo.com/2016/04/25/Java-NIO之通道-文件通道</a></p></li><li><p>参考资料<br><a href="http://blog.csdn.net/java2000_wl/article/details/7619395" target="_blank" rel="noopener">http://blog.csdn.net/java2000_wl/article/details/7619395</a><br><a href="http://download.csdn.net/detail/tang__xuandong/9500450" title="Java NIO" target="_blank" rel="noopener">《Java NIO》-(<em>Developing High Performance Applications</em>)</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--NIO之缓冲区进阶</title>
      <link href="/2016/04/22/Java-NIO%E4%B9%8B%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E9%98%B6/"/>
      <url>/2016/04/22/Java-NIO%E4%B9%8B%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E9%98%B6/</url>
      <content type="html"><![CDATA[<p>　　上一篇<a href="http://blog.xiaoxiaomo.com/2016/04/16/Java-NIO之缓冲区/" title="Java-NIO之缓冲区">http://blog.xiaoxiaomo.com/2016/04/16/Java-NIO之缓冲区/</a>讲了基本的缓冲区概念、属性以及部分操作。本片博客，主要讲解<code>缓冲区的创建、复制和字节缓冲区</code>。</p><h2 id="缓冲区的创建"><a href="#缓冲区的创建" class="headerlink" title="缓冲区的创建"></a>缓冲区的创建</h2><p>　　对于这一讨论，我们将以 CharBuffer 类为例，但是对于其它六种主要的缓冲区类也是适用的：IntBuffer，DoubleBuffer，ShortBuffer，LongBuffer，FloatBuffer，和 ByteBuffer。下面是<strong>创建一个缓冲区</strong>的关键函数，对所有的缓冲区类通用（要按照需要替换类名）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBuffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">CharSequence</span>, <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing </span></span><br><span class="line"><span class="comment">//这些都是静态方法。</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CharBuffer <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> capacity)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CharBuffer <span class="title">wrap</span> <span class="params">(<span class="keyword">char</span> [] array)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CharBuffer <span class="title">wrap</span> <span class="params">(<span class="keyword">char</span> [] array, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">hasArray</span><span class="params">( )</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">char</span> [] <span class="title">array</span><span class="params">( )</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">arrayOffset</span><span class="params">( )</span> </span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><a id="more"></a><p>新的缓冲区是由分配或包装操作创建的。</p><ol><li>分配操作：创建一个缓冲区对象并分配一个<strong>私有的空间</strong>来储存容量大小的数据元素。</li><li>包装操作创建一个缓冲区对象但是<strong>不分配任何空间来储存数据元素</strong>。它使用您所提供的数组作为存储空间来储存缓冲区中的数据元素。</li></ol><ul><li>实例一</li></ul><blockquote><p>要分配一个容量为 100 个 char 变量的 Charbuffer:<br>CharBuffer charBuffer = CharBuffer.allocate (100);<br>这段代码隐含地从堆空间中分配了一个 char 型数组作为备份存储器来储存 100 个 char变量。</p></blockquote><ul><li>实例二</li></ul><blockquote><p>如果您想提供您自己的数组用做缓冲区的备份存储器，请调用 wrap()函数：<br>char [] myArray = new char [100];<br>CharBuffer charbuffer = CharBuffer.wrap (myArray);<br>这段代码构造了一个新的缓冲区对象，但数据元素会存在于数组中。</p><p>这意味着通过调用put()函数造成的对缓冲区的改动会直接影响这个数组，而且对这个数组的任何改动也会对这个缓冲区对象可见。<br>带有 offset 和 length 作为参数的 wrap()函数版本则会构造一个按照您提供的 offset 和 length 参数值初始化位置和上界的缓冲区。如下：<br>CharBuffer charbuffer = CharBuffer.wrap (myArray, 12, 42);<br>创建了一个position值为12，limit值为54(12+42)，容量为myArray.length的缓冲区。</p></blockquote><ul><li>wrap方法使用一个现有的数组作为缓冲区备份。<code>其实缓冲区都需要这样一个真正存放数据的地方</code>，我们可以看看<code>allocate方法</code>：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (capacity &lt; <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> HeapByteBuffer(capacity, capacity);  </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">//HeapByteBuffer</span></span><br><span class="line"><span class="comment">//用父类的构造函数来初始化。</span></span><br><span class="line"><span class="comment">//第一个参数：mark，-1表示undefined，</span></span><br><span class="line"><span class="comment">//第二个参数：position</span></span><br><span class="line"><span class="comment">//第三个参数：limit</span></span><br><span class="line"><span class="comment">//第四个参数：capacity，</span></span><br><span class="line"><span class="comment">//第五个参数：数组，</span></span><br><span class="line"><span class="comment">//第六个参数：数组的偏移。 </span></span><br><span class="line">HeapByteBuffer(<span class="keyword">int</span> cap, <span class="keyword">int</span> lim) &#123;</span><br><span class="line"><span class="keyword">super</span>(-<span class="number">1</span>, <span class="number">0</span>, lim, cap, <span class="keyword">new</span> <span class="keyword">byte</span>[cap], <span class="number">0</span>);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">    hb = new byte[cap]; </span></span><br><span class="line"><span class="comment">    offset = 0; </span></span><br><span class="line"><span class="comment">    */</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>我们还应该看到一个函数，hasArray(),这说明并非所有的缓冲区都包含一个数组，那么什么样的缓冲区不包含数组呢？<code>答案是直接缓冲区。通过allocate和wrap创建的缓冲区都是间接的</code>，事实上缓冲区都必须又一个存放数据的地方。</p><ol><li>如果是直接缓冲区，我们是不能获取到数组的，所以array方法不能在直接缓冲区中调用，否则抛出<code>UnsupportedOperationException</code>异常。当然，如果是只读的缓冲区，我们也不能调用array方法或者是arrayOffset方法。 </li><li><p><code>arrayOffset</code>方法是返回作为备份数组的起始下标。这就说明，并非一个数组必须是所有元素都在缓冲区内，而是可以拆分的。但是这里还没讲到，所以，以上提到的缓冲区，如果使用arrayOffset方法，返回都是0. </p></li><li><p>为了方便，我们的CharBuffer提供了几个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBuffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">CharSequence</span>, <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CharBuffer <span class="title">wrap</span> <span class="params">(CharSequence csq)</span> </span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CharBuffer <span class="title">wrap</span> <span class="params">(CharSequence csq, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>可以这样用，CharBuffer charBuffer = CharBuffer.wrap (“Hello World”);这对于字符集码和正则表达式处理都是很方便的。 </p><h2 id="复制缓冲区"><a href="#复制缓冲区" class="headerlink" title="复制缓冲区"></a>复制缓冲区</h2><p>这里的复制，仅仅是复制缓冲区，而不是数据。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBuffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">CharSequence</span>, <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> CharBuffer <span class="title">duplicate</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> CharBuffer <span class="title">asReadOnlyBuffer</span><span class="params">( )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> CharBuffer <span class="title">slice</span><span class="params">( )</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ol><li><strong>duplicate() 函数创建了一个与原始缓冲区相似的新缓冲区。两个缓冲区共享数据元素</strong>，拥有同样的容量，<strong>但</strong>每个缓冲区拥有各自的位置，上界和标记属性。对一个缓冲区内的数据元素所做的改变会反映在另外一个缓冲区上。这一<code>副本缓冲区</code>具有与原始缓冲区同样的数据视图。如果原始的缓冲区为只读，或者为直接缓冲区，<code>新的缓冲区将继承这些属性</code>。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CharBuffer buffer = CharBuffer.allocate (<span class="number">8</span>);</span><br><span class="line">buffer.position (<span class="number">3</span>).limit (<span class="number">6</span>).mark( ).position (<span class="number">5</span>);</span><br><span class="line">CharBuffer dupeBuffer = buffer.duplicate( );</span><br><span class="line">buffer.clear( );</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422173903.png" alt="复制一个缓冲区"></p><ol start="2"><li><p><strong>asReadOnlyBuffer() 函数来生成一个只读的缓冲区视图</strong>。这与duplicate()相同，除了这个新的缓冲区不允许使用 put()，并且其 isReadOnly()函数将会返回true。对这一只读缓冲区的put()函数的调用尝试会导致抛出<code>ReadOnlyBufferException</code> 异常。</p></li><li><p><strong>slice() 创建一个从原始缓冲区的当前位置开始的新缓冲区</strong>，并且<code>其容量是原始缓冲区的剩余元素数量</code>（<em>limit-position</em>）。这个新缓冲区与原始缓冲区共享一段数据元素子序列。分割出来的缓冲区也会继承只读和直接属性 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CharBuffer buffer = CharBuffer.allocate (<span class="number">8</span>);</span><br><span class="line">buffer.position (<span class="number">3</span>).limit (<span class="number">5</span>);</span><br><span class="line">CharBuffer sliceBuffer = buffer.slice( );</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422174632.png" alt="创建分割缓冲区"></p><p>要创建一个映射到数组位置 12-20（9 个元素）的 buffer 对象，应使用下面的代码实现。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> [] myBuffer = <span class="keyword">new</span> <span class="keyword">char</span> [<span class="number">100</span>];</span><br><span class="line">CharBuffer cb = CharBuffer.wrap (myBuffer);</span><br><span class="line">cb.position(<span class="number">12</span>).limit(<span class="number">21</span>);</span><br><span class="line">CharBuffer sliced = cb.slice( );</span><br></pre></td></tr></table></figure></p><h2 id="字节缓冲区"><a href="#字节缓冲区" class="headerlink" title="字节缓冲区"></a>字节缓冲区</h2><h3 id="字节顺序"><a href="#字节顺序" class="headerlink" title="字节顺序"></a>字节顺序</h3><p>非字节类型的基本类型，除了布尔型都是由组合在一起的几个字节组成的。这些数据类型及其大小：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422175920.png" alt="基本数据类型及其大小"></p><ol><li><p>每个基本数据类型都是以连续字节序列的形式存储在内存中。例如，32 位的 int 值0x037fb4c7（十进制的 58,700,999）有两种存储方式。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422190129.png" alt="大端字节顺序"> <img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422190210.png" alt="小端字节顺序"><br><strong>多字节数值被存储在内存中的方式一般被称为 endian-ness（字节顺序）</strong>。数字数值的最高字节——big end（大端），位于低位地址那么系统就是大端字节顺序，反则小端。</p></li><li><p><strong>字节顺序的问题甚至胜过CPU硬件设计</strong>。当Internet的设计者为互联各种类型的计算机而设计网际协议（IP）时，他们意识到了在具有不同内部字节顺序的系统间传递数值数据的问题。因此，<code>IP协议规定了使用大端的网络字节顺序概念</code>。</p></li><li><p><code>在 java.nio 中，字节顺序由 ByteOrder 类封装</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.nio;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteOrder</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ByteOrder BIG_ENDIAN; <span class="comment">//大端</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ByteOrder LITTLE_ENDIAN; <span class="comment">//小端</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteOrder <span class="title">nativeOrder</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>如果您需要知道 JVM 运行的硬件平台的固有字节顺序，请调用静态类函数，nativeOrder()。它将返回两个已确定常量中的一个。</p><p>4 . 每个缓冲区类都具有一个能够通过调用 order()查询的当前字节顺序设定。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBuffer</span> <span class="keyword">extends</span> <span class="title">Buffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">implements</span> <span class="title">Comparable</span>, <span class="title">CharSequence</span></span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> ByteOrder <span class="title">order</span><span class="params">( )</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure></p><p>ByteOrder 返回两个常量之一。对于除了 ByteOrder 之外的其他缓冲区类，字节顺序是一个只读属性，并且可能根据缓冲区的建立方式而采用不同的值。</p><p>5 . ByteBuffer 类有所不同：<strong>默认字节顺序总是 ByteBuffer.BIG_ENDIAN，</strong>无论系统的固有字节顺序是什么。ByteBuffer 的字符顺序设定可以随时通过调用以 ByteOrder.BIG_ENDIAN 或ByteOrder.LITTL_ENDIAN 为参数的 order()函数来改变。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteBuffer</span> <span class="keyword">extends</span> <span class="title">Buffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">implements</span> <span class="title">Comparable</span></span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> ByteOrder <span class="title">order</span><span class="params">( )</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> ByteBuffer <span class="title">order</span> <span class="params">(ByteOrder bo)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure></p><blockquote><p>现在知道了字节顺序，那么字节缓冲区转换为其他缓冲区，也就清楚了。<br>比如，我们有一个4字节缓冲区 0x01  0x23  0x45  0x67<br>转换为一个IntBuffer，那么，根据字节顺序，如果是大端，直接就是 0x1234567<br>如果是小端顺序，那么读出来就是 0x67452301<br>注意：视图缓冲区一旦创建，字节顺序是不可改变的。视图缓冲区后面讲到</p></blockquote><h3 id="直接缓冲区"><a href="#直接缓冲区" class="headerlink" title="直接缓冲区"></a>直接缓冲区</h3><ol><li><p><code>allocate和wrap创建的都是间接缓冲区</code>。<strong>间接缓冲区</strong>，就是在操作系统和JVM之间其实有一层，我们如果对一个间接缓冲区使用，那么首先是要在操作系统层次创建一个临时缓冲区，然后copy过去，再操作，在删除临时缓冲区。这都很麻烦。通常有如下几步：</p><blockquote><p>1.创建一个临时的直接 ByteBuffer 对象。<br>2.将非直接缓冲区的内容复制到临时缓冲中<br>3.使用临时缓冲区执行低层次 I/O 操作。<br>4.临时缓冲区对象离开作用域，并最终成为被回收的无用数据。 </p></blockquote></li><li><p>直接缓冲区时 I/O 的最佳选择，但可能比创建非直接缓冲区要花费更高的成本。直接缓冲区使用的内存是通过调用本地操作系统方面的代码分配的，绕过了标准 JVM 堆栈。建立和销毁直接缓冲区会明显比具有堆栈的缓冲区更加破费，这取决于主操作系统以及 JVM 实现。直接缓冲区的内存区域不受无用存储单元收集支配，因为它们位于标准 JVM 堆栈之外。</p></li><li><p>使用直接缓冲区或非直接缓冲区的性能权衡会因JVM，操作系统，以及代码设计而产生巨大差异。</p></li><li><p>使用 allocateDirect方法就可以获得直接缓冲区。 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocateDirect</span> <span class="params">(<span class="keyword">int</span> capacity)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isDirect</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="comment">//isDirect对于直接缓冲区的非字节视图缓冲区，也可能返回true</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="视图缓冲区"><a href="#视图缓冲区" class="headerlink" title="视图缓冲区"></a>视图缓冲区</h3><p>字节缓冲区是所有缓冲类型的基础。我们在通道中，网络中文件流中四处传递字节缓冲区。但是，一旦进入应用，我们就要通过视图缓冲区来解读具体的数据了。字节缓冲区提供了很多这样的API。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteBuffer</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> CharBuffer <span class="title">asCharBuffer</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ShortBuffer <span class="title">asShortBuffer</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> IntBuffer <span class="title">asIntBuffer</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> LongBuffer <span class="title">asLongBuffer</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> FloatBuffer <span class="title">asFloatBuffer</span><span class="params">( )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> DoubleBuffer <span class="title">asDoubleBuffer</span><span class="params">( )</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>前面提到过从ByteBuffer到IntBuffer的转换。其实这种转换，是一种解释包装。<br>所以需要提供一个顺序，然后按照顺序和类型，转换成另外一种视图，而原始数据其实是不变的。<br>例如，我们可以这样；<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer byteBuffer = </span><br><span class="line">    ByteBuffer.allocate(<span class="number">7</span>).order(ByteOrder.BIG_ENDIAN);</span><br><span class="line">CharBuffer charBuffer = byteBuffer.asCharBuffer();</span><br></pre></td></tr></table></figure></p><p>注意，java中char是占两个字节的。我们的转换可以看下图：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422200211.png" alt="一个 ByteBuffer 的 CharBuffer 视图"></p><p>新的charBuffer视图其实还是使用的原来的缓冲区的数据，只是这时的元素变成了2个字节的char了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.nio.Buffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteOrder;</span><br><span class="line"><span class="keyword">import</span> java.nio.CharBuffer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBufferView</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">print</span><span class="params">(Buffer buffer)</span></span>&#123;</span><br><span class="line">System.out.println(<span class="string">"pos="</span>+buffer.position()+<span class="string">", limit="</span>+ </span><br><span class="line">buffer.limit() + <span class="string">", capacity="</span>+buffer.capacity()</span><br><span class="line">+<span class="string">":'"</span> + buffer.toString()+<span class="string">"'"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">ByteBuffer byteBuffer = ByteBuffer.allocate(<span class="number">8</span>).order(ByteOrder.BIG_ENDIAN);</span><br><span class="line">CharBuffer charBuffer = byteBuffer.asCharBuffer();</span><br><span class="line"></span><br><span class="line">byteBuffer.put(<span class="number">0</span>,(<span class="keyword">byte</span>)<span class="number">0</span>);</span><br><span class="line">byteBuffer.put(<span class="number">1</span>,(<span class="keyword">byte</span>)<span class="string">'H'</span>);</span><br><span class="line">byteBuffer.put(<span class="number">2</span>,(<span class="keyword">byte</span>)<span class="number">0</span>);</span><br><span class="line">byteBuffer.put(<span class="number">3</span>,(<span class="keyword">byte</span>)<span class="string">'e'</span>);</span><br><span class="line">byteBuffer.put(<span class="number">4</span>,(<span class="keyword">byte</span>)<span class="number">0</span>);</span><br><span class="line">byteBuffer.put(<span class="number">5</span>,(<span class="keyword">byte</span>)<span class="string">'l'</span>);</span><br><span class="line">byteBuffer.put(<span class="number">6</span>,(<span class="keyword">byte</span>)<span class="number">0</span>);</span><br><span class="line">                  byteBuffer.put(<span class="number">7</span>,(<span class="keyword">byte</span>)<span class="string">'l'</span>);</span><br><span class="line">                  byteBuffer.put(<span class="number">8</span>,(<span class="keyword">byte</span>)<span class="number">0</span>);</span><br><span class="line">                  byteBuffer.put(<span class="number">9</span>,(<span class="keyword">byte</span>)<span class="string">'o'</span>);</span><br><span class="line"></span><br><span class="line">CharBufferView.print(byteBuffer);</span><br><span class="line">CharBufferView.print(charBuffer);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li>结果：<br>pos=0, limit=10, capacity=10:’java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]’<br>pos=0, limit=5, capacity=5:’Hello’<br>可以看到，转换为视图后，limit和capacity都变了。 </li></ul><h3 id="数据元素视图"><a href="#数据元素视图" class="headerlink" title="数据元素视图"></a>数据元素视图</h3><p>上面的视图使用了一个视图类来转换。在ByteBuffer中，我们可以直接获取不同视图的元素。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteBuffer</span></span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">char</span> <span class="title">getChar</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">char</span> <span class="title">getChar</span> <span class="params">(<span class="keyword">int</span> index)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">short</span> <span class="title">getShort</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">short</span> <span class="title">getShort</span> <span class="params">(<span class="keyword">int</span> index)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">getInt</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">getInt</span> <span class="params">(<span class="keyword">int</span> index)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">getLong</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">getLong</span> <span class="params">(<span class="keyword">int</span> index)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">float</span> <span class="title">getFloat</span><span class="params">( )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">float</span> <span class="title">getFloat</span> <span class="params">(<span class="keyword">int</span> index)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">double</span> <span class="title">getDouble</span><span class="params">( )</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">double</span> <span class="title">getDouble</span> <span class="params">(<span class="keyword">int</span> index)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putChar</span> <span class="params">(<span class="keyword">char</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putChar</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">char</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putShort</span> <span class="params">(<span class="keyword">short</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putShort</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">short</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putInt</span> <span class="params">(<span class="keyword">int</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putInt</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">int</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putLong</span> <span class="params">(<span class="keyword">long</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putLong</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">long</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putFloat</span> <span class="params">(<span class="keyword">float</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putFloat</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">float</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putDouble</span> <span class="params">(<span class="keyword">double</span> value)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> ByteBuffer <span class="title">putDouble</span> <span class="params">(<span class="keyword">int</span> index, <span class="keyword">double</span> value)</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这些操作一看便知。前面也提过其实就是根据大端小端的字节顺序，和这些数据类型的长度来组织数据。这里需要注意的是:如果get或者是put时，数据不足，或者空间不够，都会发生异常。如果不是用putXX的方法，直接getXX，那么可能产生意想不到的问题。 </p><h3 id="无符号数存取"><a href="#无符号数存取" class="headerlink" title="无符号数存取"></a>无符号数存取</h3><p>对于java来说，没有无符号数处理（除了char）。为此，书中给出一个程序，用来处理无符号数缓冲区。<br>其基本原理是，使用比要存取的数据类型更大的数据类型来存放这个数，同时使用与运算强制设置符号位为0，剩余的位就可以作为数据而不是符号位了。 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Unsigned</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">short</span> <span class="title">getUnsignedByte</span> <span class="params">(ByteBuffer bb)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ((<span class="keyword">short</span>)(bb.get( ) &amp; <span class="number">0xff</span>)); </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">putUnsignedByte</span> <span class="params">(ByteBuffer bb, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">    bb.put ((<span class="keyword">byte</span>)(value &amp; <span class="number">0xff</span>));</span><br><span class="line"> &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//这里省略了其他部分。这样我们就可以看到带符号的</span></span><br></pre></td></tr></table></figure><h3 id="内存映射缓冲区"><a href="#内存映射缓冲区" class="headerlink" title="内存映射缓冲区"></a>内存映射缓冲区</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">映射缓冲区是与文件存储的数据元素关联的字节缓冲区，它通过内存映射来访问。映射缓 </span><br><span class="line">冲区通常是直接存取内存的，只能通过 FileChannel 类创建。映射缓冲区的用法和直接缓冲 </span><br><span class="line">区类似，但是 MappedByteBuffer 对象具有许多文件存取独有的特征。</span><br></pre></td></tr></table></figure><ul><li>参考资料 :<br><a href="http://download.csdn.net/detail/tang__xuandong/9500450" title="Java NIO" target="_blank" rel="noopener">《Java NIO》-(<em>Developing High Performance Applications</em>)</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Maven和nexus私服搭建</title>
      <link href="/2016/04/20/Linux-Maven%E5%92%8Cnexus%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/"/>
      <url>/2016/04/20/Linux-Maven%E5%92%8Cnexus%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>　　<code>Maven是基于项目对象模型(POM)</code>，管理项目的构建，报告和文档的软件项目管理工具。<code>Nexus是一个高效的Maven私有服务器</code>，通过<code>POM文件或者Maven的setting.xml指向私服地址</code>，这样我们便可以通过私服管理jar包；本文就介绍了如何在linux安装maven和nexus私服。</p><a id="more"></a><h2 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h2><p><strong>下载后上传：</strong></p><ol><li>本博客Maven版本使用<code>apache-maven-3.2.3-src.tar.gz</code> <strong>下载地址</strong>：<a href="https://archive.apache.org/dist/maven/maven-3/3.2.3/binaries/apache-maven-3.2.3-bin.tar.gz" title="apache-maven-3.2.3-bin.tar.gz" target="_blank" rel="noopener">https://archive.apache.org/dist/maven/maven-3/3.2.3/source/apache-maven-3.2.3-bin.tar.gz</a> </li><li>Nexus版本使用<code>nexus-2.11.4-01-bundle.tar.gz</code> <strong>下载地址</strong>：<a href="https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.11.4-01-bundle.tar.gz" title="nexus-2.11.4-01-bundle.tar.gz" target="_blank" rel="noopener">https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.11.4-01-bundle.tar.gz</a></li></ol><ul><li><strong>注意</strong>：</li><li>Maven版本的选择可以到这里<a href="https://archive.apache.org/dist/maven/maven-3" title="maven-3" target="_blank" rel="noopener">https://archive.apache.org/dist/maven/maven-3</a>，注意自己相应<strong>JDK版本</strong>的支持。</li><li>对于<code>jdk的安装</code>可参考博客<a href="http://blog.xiaoxiaomo.com/2016/03/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BJDK/" title="Linux--软件安装之JDK">http://blog.xiaoxiaomo.com/2016/03/22/Linux-软件安装之JDK/</a></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420144024.png" alt=""></p><h2 id="Maven搭建"><a href="#Maven搭建" class="headerlink" title="Maven搭建"></a>Maven搭建</h2><ul><li><strong>一、解压安装</strong></li></ul><ol><li><strong>解压</strong>： tar -zxvf apache-maven-3.2.3-bin.tar.gz </li><li><strong>移动并改名</strong>：mv apache-maven-3.2.3 /opt/maven</li><li><strong>添加环境变量</strong>：vim /etc/profile，添加下面两行<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MAVEN_HOME=/opt/maven</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>二、检查是否安装好</strong></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420205254.png" alt=""></p><ul><li><strong>三、修改配置</strong></li></ul><ol><li><p>把maven的<code>repository目录</code>指定到其他目录，即<strong>修改maven安装目录下conf中的配置文件settings.xml文件</strong> （<em>会下载很多的依赖jar到该目录，建议修改到目录到数据盘</em>）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420205738.png" alt=""></p></li><li><p>修改mirror地址为<a href="http://maven.oschina.net/" target="_blank" rel="noopener">开源中国</a>（速度快一些）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420205850.png" alt=""></p></li></ol><h2 id="Nexus私服搭建"><a href="#Nexus私服搭建" class="headerlink" title="Nexus私服搭建"></a>Nexus私服搭建</h2><ol><li>解压tar.gz包：tar -zxvf nexus-2.11.0-bundle.tar.gz<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420211546.png" alt=""></li><li><p>移动两个文件到同一目录，切换目录，到nexus-2.11.4-01<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420221647.png" alt=""></p></li><li><p>到bin目录启动，nexus<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420143045.png" alt=""></p></li><li><p>查看详细参数<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420222011.png" alt=""></p></li><li><p>尝试第一次启动，服务，通过上面的参数start。发现如下提示，提示我们最好不要使用root启动。这里我们有两种处理方式:<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420222205.png" alt=""></p></li><li><p>第一种：修改nexus配置文件<code>RUN_AS_USER=&quot;root&quot;</code>，然后启动服务即可,这种方法比较简便。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420162112.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420223146.png" alt=""></p></li><li><p>第二种：使用非root账号，这里我们使用用户momo，修改<code>RUN_AS_USER=&quot;momo&quot;</code>不然启动方式还是root。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420224348.png" alt=""></p></li><li><p>回退到目录nexus-2.11.4-01，修改所属用户组为momo。注意此时只修改了nexus-2.11.4-01目录。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420225110.png" alt=""><br>重启服务，会失败：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420225600.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420201438.png" alt=""><br>查看控制台<code>/nexus console</code>日志信息-&gt;Nexus work directory already in use</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jvm 1    | 2016-04-20 22:54:46,396+0800 WARN  [jetty-main-1] *SYSTEM org.eclipse.jetty.util.component.AbstractLifeCycle - FAILED org.eclipse.jetty.server.Server@4409a155: java.lang.IllegalStateException: **Nexus work directory already <span class="keyword">in</span> use**: /usr/<span class="built_in">local</span>/nexus/sonatype-work/nexus</span><br><span class="line">jvm 1    | java.lang.IllegalStateException: Nexus work directory already <span class="keyword">in</span> use: /usr/<span class="built_in">local</span>/nexus/sonatype-work/nexus</span><br><span class="line">jvm 1    | at com.google.common.base.Preconditions.checkState(Preconditions.java:200) ~[na:na]</span><br><span class="line">jvm 1    | at org.sonatype.nexus.webapp.WebappBootstrap.contextInitialized(WebappBootstrap.java:117) ~[na:na]</span><br><span class="line">jvm 1    | at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:782) ~[jetty-server-8.1.16.v20140903.jar:8.1.16.v20140903]</span><br></pre></td></tr></table></figure></li><li><p>所以我们需要把<code>sonatype-work</code>所属权限也分配给momo用户（<em>在这里提出这个错误主要因为我失误过</em>）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420230602.png" alt=""><br>重启后成功，2654为PID：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420230751.png" alt="Nexus安装成功"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420204230.png" alt="Nexus私服安装完成"></p></li><li><p>配置Nexus Repository</p><blockquote><ol><li>打开WEB管理界面：<a href="http://120.24.163.105:8081/nexus（*自己的私服请换掉IP*）" target="_blank" rel="noopener">http://120.24.163.105:8081/nexus（*自己的私服请换掉IP*）</a></li><li>点击右上角Log In进行登录，默认帐号：admin、密码：admin123（记得修改）</li><li>点击左侧<strong>Repositories</strong> -&gt; <strong>central仓库</strong> -&gt; <strong>Configuration</strong> -&gt; <strong>Download Remote Indexes=True</strong> -&gt; <strong>Save</strong>，<strong>表示下载远程仓库的索引</strong>。</li><li><strong>右键central仓库</strong> -&gt; <strong>Update Index</strong>，<strong>更新远程仓库索引到本地，这一步能够加速本地索引</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421084320.png" alt="Nexus配置"></li></ol></blockquote></li></ol><ul><li>说明：</li><li>1.新搭建的neuxs是空的，需手动和远程中心库进行同步，nexus默认是关闭远程索引下载，最重要的一件事情就是开启远程索引下载。 </li><li>2.列表中的三个仓库<code>Apache Snapshots</code>，<code>Codehaus Snapshots</code>和<code>Maven Central</code>，然后<strong>分别修改Download Remote Indexes为true</strong>。然后<code>Repari Index(下载远程的索引文件)</code>，<code>Update Index（更新远程仓库索引到本地）</code>。</li><li>3.新建公司的内部仓库，步骤为<strong>Repositories</strong> –&gt; <strong>Add</strong> –&gt; <strong>Hosted Repository</strong>，在页面的下半部分输入框中填入<em>Repository ID</em>和<em>Repository Name</em>即可，另外把<em>Deployment Policy设置为Allow Redeploy。</em></li></ul><h2 id="Maven和Nexus使用"><a href="#Maven和Nexus使用" class="headerlink" title="Maven和Nexus使用"></a>Maven和Nexus使用</h2><ul><li><strong>一、这里准备了一个自己创建的项目</strong></li></ul><p>通过tree查看目录结构</p><ol><li>如果没有tree命令，可以使用<code>yum install -y tree</code>安装即可。</li><li>该项目是按照Maven约定目录结构建立。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420234312.png" alt=""></li></ol><ul><li><strong>二、Maven构建项目约定</strong></li></ul><blockquote><p>src/main/java —— 存放项目的.java文件<br>src/main/resources —— 存放项目资源文件，如spring, log4j,数据库配置文件<br>src/test/java —— 存放所有测试.java文件，如JUnit测试类<br>src/test/resources —— 测试资源文件<br>target —— 项目输出位置<br>pom.xml</p></blockquote><ul><li><p><strong>二、使用命令清理mvn clean， target文件夹消失了</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn clean</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ person ---</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 0.432 s</span><br><span class="line">[INFO] Finished at: 2016-04-20T23:46:30+08:00</span><br><span class="line">[INFO] Final Memory: 5M/15M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></li><li><p><strong>三、执行编译：mvn compile，target文件夹创建了，并且Person.java被编译了</strong></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn compile</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 2.069 s</span><br><span class="line">[INFO] Finished at: 2016-04-20T23:57:05+08:00</span><br><span class="line">[INFO] Final Memory: 7M/17M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160420235913.png" alt=""></p><ul><li><strong>四、执行测试：mvn test，执行了单元测试，target中有多了几个文件夹(测试报告等)</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn test</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:<span class="built_in">test</span> (default-test) @ person ---</span><br><span class="line">[INFO] Surefire report directory: /home/up/Person/target/surefire-reports</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.xxo.maven.PersonTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.065 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 3.866 s</span><br><span class="line">[INFO] Finished at: 2016-04-21T00:01:35+08:00</span><br><span class="line">[INFO] Final Memory: 7M/18M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><ul><li><strong>五、执行打包：mvn package</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn package</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:<span class="built_in">test</span> (default-test) @ person ---</span><br><span class="line">[INFO] Surefire report directory: /home/up/Person/target/surefire-reports</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.xxo.maven.PersonTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.066 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ person ---</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 4.250 s</span><br><span class="line">[INFO] Finished at: 2016-04-21T00:03:42+08:00</span><br><span class="line">[INFO] Final Memory: 8M/20M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421000558.png" alt=""></p><ul><li><strong>六、编译：mvn install</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn install -Dmaven.test.skip=true</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ person ---</span><br><span class="line">[INFO] Not copying <span class="built_in">test</span> resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ person ---</span><br><span class="line">[INFO] Not compiling <span class="built_in">test</span> sources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:<span class="built_in">test</span> (default-test) @ person ---</span><br><span class="line">[INFO] Tests are skipped.</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ person ---</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-install-plugin:2.4:install (default-install) @ person ---</span><br><span class="line">[INFO] Installing /home/up/Person/target/person-0.0.1-SNAPSHOT.jar to /home/up/repo/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-SNAPSHOT.jar</span><br><span class="line">[INFO] Installing /home/up/Person/pom.xml to /home/up/repo/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-SNAPSHOT.pom</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 3.306 s</span><br><span class="line">[INFO] Finished at: 2016-04-21T00:15:51+08:00</span><br><span class="line">[INFO] Final Memory: 8M/19M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p><code>-Dmaven.test.skip=true</code>，可以忽略test。或者<code>mvn install -DskipTests</code>或者在配置文件中配置:<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">skip</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skip</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br></pre></td></tr></table></figure></p><ul><li><strong>七、发布到远程私服：mvn deploy</strong></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421003328.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421003427.png" alt=""></p><blockquote><p>一、添加到，下面配置到<code>项目pom</code>（<em>一般我们搭建的maven项目是通过继承的所以该文件一般放置到父级即可</em>）</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">distributionManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">snapshotRepository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>User Porject Snapshot<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://120.24.163.105:8081/nexus/content/repositories/snapshots/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">uniqueVersion</span>&gt;</span>true<span class="tag">&lt;/<span class="name">uniqueVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">snapshotRepository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>User Porject Release<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://120.24.163.105:8081/nexus/content/repositories/releases/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">distributionManagement</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>二、该账号密码配置到<code>settings.xml</code>，Deployment用户默认密码为deployment123（<em>自己记得修改账号密码，注：该<strong>server id</strong>必须与上面相同</em>）</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">server</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">username</span>&gt;</span>deployment<span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password</span>&gt;</span>deployment123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">server</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">server</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">username</span>&gt;</span>deployment<span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password</span>&gt;</span>deployment123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">server</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servers</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>三、发布到远端</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ Person]<span class="comment"># mvn deploy -Dmaven.test.skip=true</span></span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building person 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ person ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ person ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ person ---</span><br><span class="line">[INFO] Not copying <span class="built_in">test</span> resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ person ---</span><br><span class="line">[INFO] Not compiling <span class="built_in">test</span> sources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:<span class="built_in">test</span> (default-test) @ person ---</span><br><span class="line">[INFO] Tests are skipped.</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ person ---</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-install-plugin:2.4:install (default-install) @ person ---</span><br><span class="line">[INFO] Installing /home/up/Person/target/person-0.0.1-SNAPSHOT.jar to /home/up/repo/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-SNAPSHOT.jar</span><br><span class="line">[INFO] Installing /home/up/Person/pom.xml to /home/up/repo/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-SNAPSHOT.pom</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ person ---</span><br><span class="line">Downloading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/maven-metadata.xml</span><br><span class="line">Downloaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/maven-metadata.xml (769 B at 6.6 KB/sec)</span><br><span class="line">Uploading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-20160421.022446-2.jar</span><br><span class="line">Uploaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-20160421.022446-2.jar (3 KB at 20.0 KB/sec)</span><br><span class="line">Uploading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-20160421.022446-2.pom</span><br><span class="line">Uploaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/person-0.0.1-20160421.022446-2.pom (2 KB at 15.2 KB/sec)</span><br><span class="line">Downloading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/maven-metadata.xml</span><br><span class="line">Downloaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/maven-metadata.xml (279 B at 10.9 KB/sec)</span><br><span class="line">Uploading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/maven-metadata.xml</span><br><span class="line">Uploaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/0.0.1-SNAPSHOT/maven-metadata.xml (769 B at 14.4 KB/sec)</span><br><span class="line">Uploading: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/maven-metadata.xml</span><br><span class="line">Uploaded: http://120.24.163.105:8081/nexus/content/repositories/snapshots/com/xxo/maven/person/maven-metadata.xml (279 B at 7.4 KB/sec)</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 4.505 s</span><br><span class="line">[INFO] Finished at: 2016-04-21T10:24:46+08:00</span><br><span class="line">[INFO] Final Memory: 9M/23M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421102948.png" alt="Nexus已发布到远程"></p><ul><li><strong>八、手动上传项目构件到Nexus中</strong></li></ul><blockquote><p>选择Nexus某个仓库的<strong>Artifact Upload</strong>，填写相关信息即可，如下图所示（一般不建议这么做）：</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160421111319.png" alt="Nexus已发布到远程"></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-NIO之缓冲区</title>
      <link href="/2016/04/16/Java-NIO%E4%B9%8B%E7%BC%93%E5%86%B2%E5%8C%BA/"/>
      <url>/2016/04/16/Java-NIO%E4%B9%8B%E7%BC%93%E5%86%B2%E5%8C%BA/</url>
      <content type="html"><![CDATA[<p>　　<strong>通道</strong> 和 <strong>缓冲区</strong> 是 NIO 中的核心对象。<strong>数据从通道读入缓冲区，然后从缓冲区写入到通道中</strong>。<code>缓冲区本质上是一块可以写入/读取数据的内存</code>。这块内存被包装成<code>NIO Buffer</code>对象，并提供了一组方法，用来方便的访问该块内存。</p><h2 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h2><ol><li><p>缓冲区 （Buffer） 是一个对象， 它包含一些要写入或者刚读出的数据。在 NIO 库中，<strong>所有数据都是用缓冲区处理的</strong>在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。任何时候访问 NIO 中的数据，您都是将它放到缓冲区中。<em>缓冲区实质上是一个数组，它提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程</em>。</p></li><li><p>最常用的缓冲区类型是 <strong>ByteBuffer</strong>。一个 ByteBuffer 可以在其底层字节数组上进行 get/set 操作(即字节的获取和设置)。ByteBuffer 不是 NIO 中唯一的缓冲区类型。事实上，对于每一种基本 Java 类型都有一种缓冲区类型：</p></li></ol><blockquote><p>ByteBuffer<br>CharBuffer<br>ShortBuffer<br>IntBuffer<br>LongBuffer<br>FloatBuffer<br>DoubleBuffer</p></blockquote><a id="more"></a><h2 id="缓冲区组件"><a href="#缓冲区组件" class="headerlink" title="缓冲区组件"></a>缓冲区组件</h2><ol><li><p>状态变量是缓冲区的内部统计机制的关键。每一个读/写操作都会改变缓冲区的状态。通过记录和跟踪这些变化，缓冲区就可能够内部地管理自己的资源。</p></li><li><p>在从通道读取数据时，数据被放入到缓冲区。在有些情况下，可以将这个缓冲区直接写入另一个通道，但是在一般情况下，您还需要查看数据。这是使用 访问方法 <strong>get()</strong> 来完成的。同样，如果要将原始数据放入缓冲区中，就要使用访问方法 <strong>put()</strong></p></li></ol><h3 id="状态变量"><a href="#状态变量" class="headerlink" title="状态变量"></a>状态变量</h3><p>可以用三个值指定缓冲区在任意时刻的状态： <code>position</code>  <code>limit</code>  <code>capacity</code></p><ol><li><p>Position<br>缓冲区实际上就是美化了的数组， position 变量跟踪已经写了多少数据。更准确地说，它指定了下一个字节将放到数组的哪一个元素中。例如，如果您从通道中读三个字节到缓冲区中，那么缓冲区的 position 将会设置为3，指向数组中第四个元素。<br>同样，在写入通道时，您是从缓冲区中获取数据。 position 值跟踪从缓冲区中获取了多少数据。更准确地说，它指定下一个字节来自数组的哪一个元素。因此如果从缓冲区写了5个字节到通道中，那么缓冲区的 position 将被设置为5，指向数组的第六个元素。</p></li><li><p>Limit<br>limit 变量表明还有多少数据需要取出(在从缓冲区写入通道时)，或者还有多少空间可以放入数据(在从通道读入缓冲区时)。position 总是小于或者等于 limit。</p></li><li><p>Capacity<br>缓冲区的 capacity 表明可以储存在缓冲区中的最大数据容量。实际上，它指定了底层数组的大小 ― 或者至少是指定了准许我们使用的底层数组的容量。limit 决不能大于 capacity。</p></li><li><p>事例说明<br>假设这个缓冲区的 总容量 为8个字节。 Buffer 的状态如下所示：</p></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194230.png" alt="初始化为8个字节"></p><p><strong>回想一下 ，limit 决不能大于 capacity，此例中这两个值都被设置为 8。我们通过将它们指向数组的尾部之后(如果有第8个槽，则是第8个槽所在的位置)来说明这点</strong>。</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194328.png" alt="变量状态"></p><p>position 设置为0。如果我们读一些数据到缓冲区中，那么下一个读取的数据就进入 slot 0 。如果我们从缓冲区写一些数据，从缓冲区读取的下一个字节就来自 slot 0 。 position 设置如下所示：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194422.png" alt="Position=0"></p><p>由于 capacity 不会改变，所以我们在下面的讨论中可以忽略它。</p><ul><li><strong>第一次读取</strong></li></ul><p>现在我们可以开始在新创建的缓冲区上进行读/写操作。首先从输入通道中读一些数据到缓冲区中。第一次读取得到三个字节。它们被放到数组中从 position 开始的位置，这时 position 被设置为 0。读完之后，position 就增加到 3，如下所示：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194505.png" alt="Position+=3"></p><p>limit 没有改变。</p><ul><li><strong>第二次读取</strong></li></ul><p>在第二次读取时，我们从输入通道读取另外两个字节到缓冲区中。这两个字节储存在由 position 所指定的位置上， position 因而增加 2：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194549.png" alt="Position+=2"></p><ul><li>limit 没有改变。</li></ul><p><strong><code>flip</code></strong></p><p>现在我们要将数据写到输出通道中。在这之前，我们必须调用 flip() 方法。这个方法做两件非常重要的事：</p><ol><li>它将 limit 设置为当前 position。</li><li>它将 position 设置为 0。</li></ol><p>前一小节中的图显示了在 flip 之前缓冲区的情况。下面是在 flip 之后的缓冲区：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194630.png" alt="Buffer=0，limit=5"></p><p><strong>我们现在可以将数据从缓冲区写入通道了。 position 被设置为 0，这意味着我们得到的下一个字节是第一个字节。 limit 已被设置为原来的 position，这意味着它包括以前读到的所有字节，并且一个字节也不多</strong>。</p><ul><li><strong>第一次写入</strong></li></ul><p>在第一次写入时，我们从缓冲区中取四个字节并将它们写入输出通道。这使得 position 增加到 4，而 limit 不变，如下所示：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194720.png" alt="Position +=4, limit=5"></p><ul><li><strong>第二次写入</strong></li></ul><p><strong>我们只剩下一个字节可写了。 limit在我们调用 flip() 时被设置为 5，并且 position 不能超过 limit。所以最后一次写入操作从缓冲区取出一个字节并将它写入输出通道。这使得 position 增加到 5，并保持 limit 不变</strong>，如下所示：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194832.png" alt="Position=5, limit=5"></p><p><strong><code>clear</code></strong></p><p><strong>最后一步是调用缓冲区的 clear() 方法。这个方法重设缓冲区以便接收更多的字节。 Clear 做两种非常重要的事情</strong>：</p><ol><li>它将 limit 设置为与 capacity 相同。</li><li>它设置 position 为 0。</li></ol><p>下图显示了在调用 clear() 后缓冲区的状态：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416194915.png" alt="clear后状态"></p><h3 id="缓冲区API"><a href="#缓冲区API" class="headerlink" title="缓冲区API"></a>缓冲区API</h3><p>让我们来看一下可以如何使用一个缓冲区和操作缓冲区。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.nio;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Buffer</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">capacity</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">position</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">position</span><span class="params">(<span class="keyword">int</span> newPositio)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">limit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">limit</span><span class="params">(<span class="keyword">int</span> newLimit)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">mark</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">reset</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">rewind</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">remaining</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">hasRemaining</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isReadOnly</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>些函数将引用返回到它们在（this）上被引用的对象。这是一个允许级联调用的类设计方法。级联调用允许这种类型的代码：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">buffer.mark( );</span><br><span class="line">buffer.position(<span class="number">5</span>);</span><br><span class="line">buffer.reset( );</span><br><span class="line"></span><br><span class="line">##可简写 buffer.mark().position(5).reset( );</span><br></pre></td></tr></table></figure></p><h2 id="常见定义"><a href="#常见定义" class="headerlink" title="常见定义"></a>常见定义</h2><h3 id="存取"><a href="#存取" class="headerlink" title="存取"></a>存取</h3><p>　　<strong>数据保存到磁盘，先将这些数据直接放入缓冲区，然后用通道将缓冲区写入磁盘。使用 ByteBuffer 类的 get() 和 put() 方法直接访问缓冲区中的数据。</strong></p><ol><li><p><strong>get() 方法</strong><br>ByteBuffer 类中有四个 get() 方法：</p><ul><li>byte get();</li><li>ByteBuffer get( byte dst[] );</li><li>ByteBuffer get( byte dst[], int offset, int length );</li><li>byte get( int index );</li></ul></li><li><p><strong>put()方法</strong><br>ByteBuffer 类中有五个 put() 方法：</p><ul><li>ByteBuffer put( byte b );</li><li>ByteBuffer put( byte src[] );</li><li>ByteBuffer put( byte src[], int offset, int length );</li><li>ByteBuffer put( ByteBuffer src );</li><li>ByteBuffer put( int index, byte b );</li></ul></li><li><p>如果存取中的index参数超出限制，那么，是会抛出IndexOutOfBoundsException。如果是put超出，那么将抛出BufferOverflowException异常。 </p></li></ol><h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>　　填充主要使用put方法。这里的put要注意的是，如果是ByteBuffer不能这样使用buffer.put(‘H’)。因为我们put的并不是char类型，而必须是byte，所以要强制转换 buffer.put((byte)’H’); 还有，put可以使用索引下标。例如：buffer.put(0,(byte)’H’)。如果不适用下标索引，那么put到的都是放在position位置。</p><h3 id="翻转"><a href="#翻转" class="headerlink" title="翻转"></a>翻转</h3><p>　　在缓冲区填充满以后，我们需要通知使用者使用，<strong>即读取缓冲区的数据</strong>，那怎么知道我们要读取那些数据呢？</p><ol><li>limit的引入，就是解决这个问题的，<strong>通过一个flip()方法进行翻转</strong>。<strong>limit=position，position=0。</strong>这样就可以从position读取到limit。即buffer.limit(buffer.position()).position(0) 效果等于buffer.flip(); </li><li>还有一个函数和flip类似，<strong>rewind</strong>，这个函数不影响limit，只是把position重置为0，意思就是重读。如果连续两次flip，那么我们得到的就是一个position和limit都为0的缓冲区，对这样的缓冲区使用get，是会抛出BufferUnderflowException异常。</li></ol><h3 id="释放"><a href="#释放" class="headerlink" title="释放"></a>释放</h3><p>缓冲区的基本操作都有了。我们可以循环读取缓冲区的数据，但是如何知道到了上界呢？<br>函数 hasRemaining()  和 remaining()就是这样的函数。我们可以这样使用：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(buffer.hasRemaining())&#123;</span><br><span class="line">    array[i++] = buffer.get();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">or</span><br><span class="line"><span class="keyword">int</span> count = buffer.remaining();</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; count; i++)&#123;</span><br><span class="line">    array[i] = buffer.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>当然这样的效率都不会很高。 注意：缓冲区并不保证并发。<br>当我们使用完缓冲区，就可以清空了。使用 clear函数。<br>clear函数并不改变元素。只是将 limit = capacity; position=0而已。 </p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>　　有时，您可能只想从缓冲区中释放一部分数据，而不是全部，然后重新填充。为了实现这一点，未读的数据元素需要下移以使第一个元素索引为 0。</p><ol><li>compact函数。这个压缩<strong>就是把已经读过的数据抛弃，使用后面的数据覆盖（移动至索引0）</strong>，并且把limit设置为capacity。 </li><li>压缩类似于先进先出的FIFO队列。压缩完成后，注意position移动到了未处理数据之后，等待继续填充。position也就是移动的元素的个数。<br>这里比较不好理解。如果画个图，可能就容易理解了。 </li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F0a21925f-f879-3890.jpg" alt="压缩前的buffer"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F15ec3654-4143-3f43.jpg" alt="压缩后的buffer"></p><ul><li>说明：<blockquote><p>数据元素 2-5 被复制到 0-3 位置。位置 4 和 5 不受影响，<br>但现在正在或已经超出了当前位置，因此是“死的”。它们可以被之后的 put()调用重写。<br>还要注意，位置已经被设为被复制的数据元素的数目。也就是说，缓冲区现在被定位在缓&gt; 冲区中最后一个“存活”元素后插入数据的位置。<br>最后，上界属性被设置为容量的值，因此缓冲区可以被再次填满。调用 compact()的作用是丢弃已经释放的数据，保留未释放的数据，并使缓冲区对重新填充容量准备就绪</p></blockquote></li></ul><h3 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h3><p>　　标记，使缓冲区能够记住一个位置并在之后将其返回。缓冲区的标记在 mark()函数被调用之前是未定义的，调用时标记被设为当前位置的值。reset()函数将位置设为当前的标记值。如果标记值未定义，调用 reset()将导致 InvalidMarkException 异常．（一些缓冲区函数会抛弃已经设定的标记rewind()、clear()以及flip()总是抛弃标记。如果新设定的值比当前的标记小，调用limit()或 position()带有索引参数的版本会抛弃标记。）</p><p>－　eg:<br>buffer.position(2).mark().position(4);</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422162043.png" alt="设有一个标记的缓冲区"></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422162134.png" alt="一个缓冲区位置被重设为标记"></p><h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>　　这里缓冲区的比较，实际上是比较当前位置，到上界的元素是否相同。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteBuffer</span> <span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">Comparable</span></span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span> <span class="params">(Object ob)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span> <span class="params">(Object ob)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">//两个缓冲区可用下面的代码来测试是否相等：</span></span></span><br><span class="line"><span class="function"><span class="title">if</span> <span class="params">(buffer1.equals (buffer2)</span>) </span>&#123;</span><br><span class="line"><span class="comment">//......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果每个缓冲区中剩余的内容相同，那么 equals( )函数将返回 true，否则返回 false。<br>两个缓冲区被认为相等的充要条件是：</p><ol><li>两个对象类型相同。包含不同数据类型的 buffer 永远不会相等，而且 buffer绝不会等于非 buffer 对象。</li><li>两个对象都剩余同样数量的元素。Buffer 的容量不需要相同，而且缓冲区中剩余数据的索引也不必相同。但每个缓冲区中剩余元素的数目（从位置到上界）必须相<br>同。</li><li>在每个缓冲区中应被 Get()函数返回的剩余数据元素序列必须一致。</li><li>说明了两个属性不同的缓冲区也可以相等。可能看起来是完全相同的缓冲区，但测试时会发现并不相等，如下图。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422163036.png" alt="两个被认为是相等的缓冲区"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160422163121.png" alt="两个被认为不相等的缓冲区"></li></ol><p>注意除了equals还有compareTo函数。compareTo函数必须是两个相同的缓冲区，否则会抛出异常ClassCastException，而equals只是返回false。 </p><h3 id="批量移动"><a href="#批量移动" class="headerlink" title="批量移动"></a>批量移动</h3><p>对于之前的单个元素赋值，可能觉得略显繁琐。这里提供了一些批量移动操作<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CharBuffer</span></span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">Buffer</span> <span class="keyword">implements</span> <span class="title">CharSequence</span>, <span class="title">Comparable</span> </span>&#123;</span><br><span class="line"><span class="comment">// This is a partial API listing</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CharBuffer <span class="title">get</span><span class="params">(<span class="keyword">char</span> [] dst)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> CharBuffer <span class="title">get</span><span class="params">(<span class="keyword">char</span> [] dst, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> CharBuffer <span class="title">put</span><span class="params">(<span class="keyword">char</span>[] src)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> CharBuffer <span class="title">put</span><span class="params">(<span class="keyword">char</span> [] src, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> CharBuffer <span class="title">put</span><span class="params">(CharBuffer src)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> CharBuffer <span class="title">put</span><span class="params">(String src)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> CharBuffer <span class="title">put</span><span class="params">(String src, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里提供的函数get，就可以获取我们所需的缓冲区中的内容。 buffer.get(myArray)等价于buffer.get(myArray,0,myArray.length) 。<br>注意，如果数组元素太大，而我们又没有指定大小，意味着缓冲区要填充满数组，但是缓冲区太小，这样，就会抛出BufferUnderflowException异常。对于数组太大太小我们可以这样处理（对于put同理）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//数组元素太大</span></span><br><span class="line"><span class="keyword">char</span> [] bigArray = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">1000</span>];</span><br><span class="line"><span class="keyword">int</span> length = buffer.remaining();</span><br><span class="line">buffer.get(bigArray,<span class="number">0</span>,length);</span><br><span class="line"></span><br><span class="line"><span class="comment">//数组很小</span></span><br><span class="line"><span class="keyword">char</span>[] smallArray  = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">while</span>(buffer.hasRemaining())&#123;</span><br><span class="line">    <span class="keyword">int</span> length = Math.min(buffer.remaining(),smallArray.length);</span><br><span class="line">    buffer.get(smallArray,<span class="number">0</span>,length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li>参考资料<br><a href="http://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html" title="大部分都是参考该博客" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-NIO之概述</title>
      <link href="/2016/04/16/Java-NIO%E4%B9%8B%E6%A6%82%E8%BF%B0/"/>
      <url>/2016/04/16/Java-NIO%E4%B9%8B%E6%A6%82%E8%BF%B0/</url>
      <content type="html"><![CDATA[<p>　　<code>新的输入/输出 (NIO) 库</code>是在JDK1.4中引入的，弥补了原IO的不足，叫做<code>非阻塞IO</code>。本篇博客主要讲解IO与NIO的区别以及NIO的基本概念。</p><h2 id="为什么使用NIO"><a href="#为什么使用NIO" class="headerlink" title="为什么使用NIO"></a>为什么使用NIO</h2><p>　　NIO的创建目的是为了实现高速 I/O 而无需编写自定义的本机代码。NIO 将最耗时的 I/O 操作(即填充和提取缓冲区)转移回操作系统，因而可以极大地提高速度。I/O 与 NIO 最重要的区别是数据打包和传输的方式， I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。</p><p>　　面向流 的 I/O 系统一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。一个 面向块 的 I/O 系统以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。按块处理数据比按(流式的)字节处理数据要快得多。</p><a id="more"></a><h2 id="NIO概述"><a href="#NIO概述" class="headerlink" title="NIO概述"></a>NIO概述</h2><p>在 <strong>Java NIO</strong> 中Channel，Buffer 和 Selector 构成了NIO的核心的API。</p><ul><li>Channel 和 Buffer<br>基本上，所有的 IO 在 NIO 中都从一个Channel 开始。Channel 我们称之为通道， 数据可以从Channel通道中读到Buffer中，也可以从Buffer 写到Channel中。如图：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416162933.png" alt="Channel 和 Buffer"></p><p>Channel和Buffer有好几种类型。如果这些通道涵盖了UDP 和 TCP 网络IO，以及文件IO。</p><ol><li>FileChannel</li><li>DatagramChannel</li><li>SocketChannel</li><li>ServerSocketChannel</li></ol><ul><li>Selector<br>Selector允许单线程处理多个 Channel。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便。</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416163304.png" alt="Selector和Channel的关系"></p><h2 id="NIO与IO的区别"><a href="#NIO与IO的区别" class="headerlink" title="NIO与IO的区别"></a>NIO与IO的区别</h2><p>Java NIO和IO之间的主要差别：</p><ul><li>IO：  面向流   阻塞IO    无              </li><li>NIO： 面向缓冲 非阻塞IO  选择器</li></ul><ol><li><p>面向流与面向缓冲<br>IO是面向流的，NIO是面向缓冲区的。<strong>Java IO</strong> 面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。<strong>Java NIO</strong> 处理过程灵活，数据读取到缓冲区，需要时可在缓冲区中前后移动，可对缓冲区的数据进行检测等。</p></li><li><p>阻塞与非阻塞IO<br><strong>Java IO</strong> 的各种流都是阻塞的。比如，当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。<br><strong>Java NIO</strong> 非阻塞模式，比如，一个线程从某通道发送请求读取数据，它仅能得到目前可用的数据，如果目前没有数据可用时，该线程可以继续做其他的事情，直至有数据可读。 写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。</p></li><li><p>选择器（Selectors）<br><strong>Java NIO的选择器</strong>  允许一个单独的线程来监视多个输入<strong>通道</strong>，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。</p></li></ol><h2 id="设计上的不同"><a href="#设计上的不同" class="headerlink" title="设计上的不同"></a>设计上的不同</h2><h3 id="API调用"><a href="#API调用" class="headerlink" title="API调用"></a>API调用</h3><p>Java NIO 的<strong>API调用</strong>并不是仅从一个InputStream逐字节读取，而是数据必须先读入缓冲区再处理。</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ul><li>在IO中，从InputStream或 Reader逐字节读取数据。如下列文本数据：</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Name: xiaoxiaomo</span><br><span class="line">Age: <span class="number">24</span></span><br><span class="line">Email: momo@xiaoxiaomo.com</span><br><span class="line">Phone: <span class="number">1234567890</span></span><br></pre></td></tr></table></figure><p>该文本行的流可以这样处理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">InputStream input = ... ; <span class="comment">// get the InputStream from the client socket</span></span><br><span class="line"></span><br><span class="line">BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(input));</span><br><span class="line"></span><br><span class="line">String nameLine   = reader.readLine();</span><br><span class="line">String ageLine    = reader.readLine();</span><br><span class="line">String emailLine  = reader.readLine();</span><br><span class="line">String phoneLine  = reader.readLine();</span><br></pre></td></tr></table></figure><p>注意处理状态由程序执行多久决定。比如：String nameLine=reader.readLine()方法返回，表示该行已读完， readline()阻塞直到整行读完，这就是原因。你也知道此行包含名称；同样，第二个readline()调用返回的时候，你知道这行包含年龄等。即，<strong>该处理程序仅在有新数据读入时运行，并知道每步的数据是什么</strong>。一旦正在运行的线程已处理过读入的某些数据，该线程不会再回退进行数据。下图也说明了这条原则：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416153845.png" alt="IO读取数据"></p><ul><li>在NIO中的实现会有所不同，下面是一个简单的例子：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"><span class="keyword">int</span> bytesRead = inChannel.read(buffer);</span><br></pre></td></tr></table></figure><p>注意第二行，从通道读取字节到ByteBuffer。当这个方法返回时，你不知道你所需的所有数据是否在缓冲区内。你所知道的是，该缓冲区包含一些字节，这使得处理有点困难。<br>假设第一次 read(buffer)调用后，读入缓冲区的数据只有半行，例如，“Name:An”，你能处理数据吗？显然不能，需要等待，直到整行数据读入缓存，在此之前，对数据的任何处理毫无意义。</p><p>所以，你怎么知道是否该缓冲区包含足够的数据可以处理呢？好了，你不知道。发现的方法只能查看缓冲区中的数据。其结果是，在你知道所有数据都在缓冲区里之前，你必须检查几次缓冲区的数据。这不仅效率低下，而且可以使程序设计方案杂乱不堪。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"><span class="keyword">int</span> bytesRead = inChannel.read(buffer);</span><br><span class="line"><span class="keyword">while</span>(! bufferFull(bytesRead) ) &#123;</span><br><span class="line">bytesRead = inChannel.read(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bufferFull()方法必须跟踪有多少数据读入缓冲区，如果缓冲区准备好被处理，那么表示缓冲区满了。它可以被处理。如果它不满，并且在你的实际案例中有意义，你或许能处理其中的部分数据。但是许多情况下并非如此。下图展示了“缓冲区数据循环就绪”</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416154255.png" alt="NIO读取数据"></p><h3 id="线程数"><a href="#线程数" class="headerlink" title="线程数"></a>线程数</h3><p>NIO可让您只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。</p><p>如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。一个线程多个连接的设计方案如下图所示：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416154337.png" alt="一个线程多个连接"></p><p>如果你有少量的连接使用非常高的带宽，一次发送大量的数据，也许典型的IO服务器实现可能非常契合。下图说明了一个典型的IO服务器设计：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160416154405.png" alt="典型IO服务器设计"></p><ul><li>参考资料</li></ul><ol><li><a href="http://tutorials.jenkov.com/java-nio/nio-vs-io.html" title="nio" target="_blank" rel="noopener">http://tutorials.jenkov.com/java-nio/nio-vs-io.html</a></li><li><a href="http://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html" title="nio" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--网络编程InetAddr和URL</title>
      <link href="/2016/04/13/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BInetAddr%E5%92%8CURL/"/>
      <url>/2016/04/13/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BInetAddr%E5%92%8CURL/</url>
      <content type="html"><![CDATA[<p>　　Java中提供了专门的网络开发程序包<strong>java.net</strong>，提供了两种通信协议：TCP和UDP（<a href="http://blog.xiaoxiaomo.com/2016/04/12/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BTCP%E5%92%8CUDP/" title="tcp和udp">Java-网络编程TCP和UDP</a>）。这里主要讲解一下常用的网络编程类<code>InetAddr</code>和<code>URL</code>。</p><a id="more"></a><h2 id="InetAddress类"><a href="#InetAddress类" class="headerlink" title="InetAddress类"></a>InetAddress类</h2><p><code>InetAddress</code>：封装我们上篇博客中数字式的IP地址和该地址的域名。对于InetAddress，三个方法：<em>getLocalHost()</em>、<em>getByName()</em>以及<em>getAllByName()</em>可以用来创建InetAddress的实例。</p><blockquote><p>1、getLocalHost()：返回象征本地主机的InetAddress对象。<br>2、getByName()：返回一个传给它的主机名的InetAddress，无法解析引发UnknownHostException<br>3、getAllByName()：工厂方法返回代表由一个特殊名称分解的所有地址的InetAddresses类数组。不能分解时引发UnknownHostException异常。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//根据主机名来获取对应的InetAddress实例</span></span><br><span class="line">InetAddress ip = InetAddress.getByName(<span class="string">"www.baidu.com"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断是否可达</span></span><br><span class="line">System.out.println(<span class="string">"baidu是否可达："</span> + ip.isReachable(<span class="number">2000</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取该InetAddress实例的IP字符串</span></span><br><span class="line">System.out.println(ip.getHostAddress());</span><br><span class="line"></span><br><span class="line"><span class="comment">//根据原始IP地址(字节数组形式)来获取对应的InetAddress实例</span></span><br><span class="line"><span class="comment">//4个字节</span></span><br><span class="line">InetAddress local = InetAddress.getByAddress(<span class="keyword">new</span> <span class="keyword">byte</span>[]&#123;<span class="number">127</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取该InetAddress实例对应的全限定域名</span></span><br><span class="line">System.out.println(local.getCanonicalHostName());</span><br></pre></td></tr></table></figure><h2 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h2><p><code>URL</code>(<em>Uniform Resource Locator</em>)统一资源定位符，可以直接使用此类找到互联网上的<code>资源</code>。目前使用最为广泛的TCP/IP中对于URL中主机名的解析也是协议的一个标准，即所谓的<code>域名解析服务</code>。</p><h3 id="URL和URLConnection"><a href="#URL和URLConnection" class="headerlink" title="URL和URLConnection"></a>URL和URLConnection</h3><p><code>URL</code>获取资源，比如URL的<strong>InputStream</strong>对象资源的信息，以及一个到URL所引用远程对象的连接URLConnection。 URLConnection对象可以向所代表的URL发送请求和读取URL的资源，每次调用URL 的openConnection方法都打开一个新的连接。创建一个URL的连接，需要如下几个步骤：</p><blockquote><p>创建<code>URL对象</code>，并通过<strong>openConnection</strong>方法获得<code>URLConnection</code>对象；<br><strong>设置URLConnection参数和普通请求属性</strong>；<br>向远程资源<strong>发送请求</strong>；<br><strong>访问远程资源</strong>的头字段和通过输入流来读取远程资源返回的信息。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"><span class="keyword">import</span> java.net.URLConnection;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/13.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">URLDemo01</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> String URL_ = <span class="string">"http://blog.xiaoxiaomo.com"</span> ;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> String param = <span class="string">""</span> ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        myGet();</span><br><span class="line">        <span class="comment">//myPOST();</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">myGet</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 向指定URL发送GET方法的请求</span></span><br><span class="line">        URL url = <span class="keyword">new</span> URL(URL_);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 打开和URL之间的连接</span></span><br><span class="line">        URLConnection conn1 = url.openConnection();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 设置通用的请求属性</span></span><br><span class="line">        conn1.setRequestProperty(<span class="string">"accept"</span>, <span class="string">"*/*"</span>);</span><br><span class="line">        conn1.setRequestProperty(<span class="string">"connection"</span>, <span class="string">"Keep-Alive"</span>);</span><br><span class="line">        conn1.setRequestProperty(<span class="string">"user-agent"</span>,</span><br><span class="line">                <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 建立实际的连接</span></span><br><span class="line">        conn1.connect();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 直接从URL读取数据，并输出到标准输出</span></span><br><span class="line">        BufferedReader in = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(url.openStream()));</span><br><span class="line">        String line;</span><br><span class="line">        <span class="keyword">while</span> ((line = in.readLine()) != <span class="keyword">null</span>)</span><br><span class="line">            System.out.println(line);</span><br><span class="line"></span><br><span class="line">        in.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">myPOST</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 向指定URL发送POST方法的请求</span></span><br><span class="line">        URL url2 = <span class="keyword">new</span> URL(URL_);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 打开和URL之间的连接</span></span><br><span class="line">        URLConnection conn2 = url2.openConnection();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 设置通用的请求属性</span></span><br><span class="line">        conn2.setRequestProperty(<span class="string">"accept"</span>, <span class="string">"*/*"</span>);</span><br><span class="line">        conn2.setRequestProperty(<span class="string">"connection"</span>, <span class="string">"Keep-Alive"</span>);</span><br><span class="line">        conn2.setRequestProperty(<span class="string">"user-agent"</span>, </span><br><span class="line">                <span class="string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 发送POST请求必须设置如下两行</span></span><br><span class="line">        conn2.setDoOutput(<span class="keyword">true</span>);</span><br><span class="line">        conn2.setDoInput(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 获取URLConnection对象对应的输出流</span></span><br><span class="line">        PrintWriter out = <span class="keyword">new</span> PrintWriter(conn2.getOutputStream());</span><br><span class="line">        <span class="comment">//发送请求参数</span></span><br><span class="line">        <span class="comment">//out.print(param);</span></span><br><span class="line"></span><br><span class="line">        InputStream is = conn2.getInputStream();<span class="comment">//得到输入流</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 另一种得到输入流的方法:通过url直接获取</span></span><br><span class="line">        <span class="comment">// InputStream is = url.openStream();</span></span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>*<span class="number">10</span>] ;</span><br><span class="line">        <span class="keyword">int</span> len ;</span><br><span class="line">        <span class="keyword">while</span> ( ( len = is.read(bytes) ) != -<span class="number">1</span> )&#123;</span><br><span class="line">            System.out.println(<span class="keyword">new</span> String(bytes , <span class="number">0</span> ,len ));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="URLDecoder和URLEncoder"><a href="#URLDecoder和URLEncoder" class="headerlink" title="URLDecoder和URLEncoder"></a>URLDecoder和URLEncoder</h3><p><code>URLDecoder</code>：HTML格式编码的实用工具类。该类包含了将String转换为<code>application/x-www-form-urlencoded MIME</code>格式的静态方法。</p><p>String转换格式：</p><blockquote><p>1.字符”a”-“z”，”A”-“Z”，”0”-“9”，”.”，”-“，”*”，和”_” 都不会被编码;<br>2.将空格转换为加号 (+) ;<br>3.将非文本内容转换成”%xy”的形式,xy是两位16进制的数值;<br>4.在每个 name=value 对之间放置 &amp; 符号。</p></blockquote><p><code>URLEncoder</code>：该类包含了将String从<code>application/x-www-form-urlencoded MIME</code>格式解码的静态方法。</p><ul><li>事例DEMO</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.URLDecoder;</span><br><span class="line"><span class="keyword">import</span> java.net.URLEncoder;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * URLDecoder和URLEncoder</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/13.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">URLDEENcoder</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            String encodeStr = URLEncoder.encode(<span class="string">"小小默"</span>, <span class="string">"utf-8"</span>);</span><br><span class="line">            System.out.println(<span class="string">"编码:"</span> + encodeStr);</span><br><span class="line"></span><br><span class="line">            String decodeStr = URLDecoder.decode(encodeStr, <span class="string">"utf-8"</span>);</span><br><span class="line">            System.out.println(<span class="string">"解码:"</span> + decodeStr);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">编码:%E5%B0%8F%E5%B0%8F%E9%BB%98</span><br><span class="line">解码:小小默</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--网络编程TCP和UDP</title>
      <link href="/2016/04/12/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BTCP%E5%92%8CUDP/"/>
      <url>/2016/04/12/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BTCP%E5%92%8CUDP/</url>
      <content type="html"><![CDATA[<p>　　<code>计算机网络</code>，就是把分布在不同区域的计算机用通信线路连接在一起、可以方便地互相传递信息，共享资源。<code>网络编程</code>，就是<code>直接或间接地通过网络协议与其他计算机进行通讯</code>。</p><a id="more"></a><blockquote><p>网络编程中有两个重要问题：</p></blockquote><ol><li>如何<strong>准确地定位</strong>网络上一台或多台主机。</li><li>找到主机后如何<strong>可靠高效</strong>地进行数据传输。</li></ol><h2 id="基础术语"><a href="#基础术语" class="headerlink" title="基础术语"></a>基础术语</h2><ul><li>IP地址</li></ul><blockquote><p>网络中每台主机都必须有一个<code>唯一的IP地址</code>，IP地址是一个逻辑地址。<br>英特网上的IP地址具有全球唯一性。<br>32位，四个字节，常用点分十进制的格式表示。例如：113.45.153.190</p></blockquote><ul><li>协议</li></ul><blockquote><p>为进行网络中的数据交换（通信）而建立的<strong>规则、标准或约定</strong>。（=语义+语法+规则）。<br>不同层具有各自不同的协议。</p></blockquote><ul><li>端口　　<blockquote><p>在互联网上传输的数据都包含有用来<strong>识别目的地的IP地址和端口号</strong>。<br>IP地址用来标识网络上的计算机，而<strong>端口号</strong>用来指明该计算机上的<strong>应用程序</strong>。<br>端口用一个整数型标识符来表示，即端口号。<br>端口使用一个16位的数字来表示，它的<strong>范围是0~65535</strong>，<strong>1024以下的为保留端口</strong>。</p></blockquote></li></ul><ul><li>数据封装</li></ul><blockquote><p>一台计算机要发送数据到另一台计算机，数据首先必须打包，打包的过程称为<strong>封装</strong>。<br>封装就是在数据前面加上<strong>特定的协议头部</strong>。<br>在每一层传递信息的过程中都会进行一次<strong>封装</strong>，服务端收到信息后然后进行一层一层的<strong>解封装</strong>最终得到数据。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160413105038.png" alt=""></p><h2 id="ISO七层模型"><a href="#ISO七层模型" class="headerlink" title="ISO七层模型"></a>ISO七层模型</h2><p>网络体系结构解决异质性问题采用的是分层的方法——把复杂的网络互联问题划分为若干个较小的、单一的问题，在不同层上予以解决，各层之间是严格的单向依赖。</p><ul><li>OSI(<em>Open System Interconnection</em>)参考模型7层：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160413105608.png" alt=""></p><ul><li>OSI各层所使用的协议：</li></ul><blockquote><p>应用层：Telnet、FTP、HTTP、DNS、SMTP、POP3<br>传输层：TCP、UDP<br>网络层：IP、ICMP、IGMP</p></blockquote><p>详细讲解可查看博客：<a href="http://blog.csdn.net/yaopeng_2005/article/details/7064869" target="_blank" rel="noopener">http://blog.csdn.net/yaopeng_2005/article/details/7064869</a></p><h2 id="TCP-UDP"><a href="#TCP-UDP" class="headerlink" title="TCP/UDP"></a>TCP/UDP</h2><p><code>套接字Socket</code>，是连接运行在网络上的两个程序间的双向通讯的端点。<strong>网络通信其实就是Socket间的通信</strong>。即，数据在两个Socket间通过<strong>IO传输</strong>。</p><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><ul><li>UDP支持更简单的、快速的、点对点的数据报模式</li></ul><blockquote><p>将数据及源和目的封装成数据包中 <code>不需要建立连接</code>。<br>无连接，即是<strong>不可靠协议</strong>、<strong>速度快</strong>。<br>协议并不保证数据报<strong>是否能正确地到达目的地</strong>。<br>每个数据报的大小在限制在<strong>64KB内</strong>。</p></blockquote><ul><li>实例一 、简单的接收和发送数据DEMO</li></ul><ol><li><p>发送数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramPacket;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.InetAddress;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过udp协议发送数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UdpSendSimpleDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：获取socket对象</span></span><br><span class="line"><span class="comment"> * 2：对数据进行封包</span></span><br><span class="line"><span class="comment"> * 3：通过socket对象把数据包发送出去</span></span><br><span class="line"><span class="comment"> * 4：把连接关闭</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 获取socket对象</span></span><br><span class="line">DatagramSocket ds = <span class="keyword">new</span> DatagramSocket();</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 封包数据</span></span><br><span class="line">String sendMsg = <span class="string">"UDP ......你好！"</span> ;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> buf 字节流数据包</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> length 流数据包长度 eg,InetAddress.getByName("192.168.3.102")</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> address  发送地址</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> port 端口号</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">DatagramPacket p =</span><br><span class="line"><span class="keyword">new</span> DatagramPacket(sendMsg.getBytes(),sendMsg.getBytes().length,InetAddress.getLocalHost(),<span class="number">3000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. 发送数据包</span></span><br><span class="line">ds.send(p);</span><br><span class="line"></span><br><span class="line"><span class="comment">//4. 关闭连接</span></span><br><span class="line">ds.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>接送数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramPacket;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramSocket;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * UDP接收端代码</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UdpReceiveSimpleDemo</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：获取socket连接(需要指定监听的端口)</span></span><br><span class="line"><span class="comment"> * 2：通过receive方法接收数据包</span></span><br><span class="line"><span class="comment"> * 3：解包，获取数据包中的内容</span></span><br><span class="line"><span class="comment"> * 4：关闭连接</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="comment">//1:获取连接</span></span><br><span class="line">DatagramSocket ds = <span class="keyword">new</span> DatagramSocket(<span class="number">3000</span>);;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2：接收数据</span></span><br><span class="line"><span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">DatagramPacket p = <span class="keyword">new</span> DatagramPacket(buf, <span class="number">0</span>, buf.length);</span><br><span class="line">ds.receive(p);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3:获取数据</span></span><br><span class="line">System.out.println( <span class="string">"信息来源："</span>+p.getAddress().getHostAddress() );</span><br><span class="line">System.out.println( <span class="string">"收到数据："</span> + <span class="keyword">new</span> String( p.getData(),<span class="number">0</span>,p.getLength()) );</span><br><span class="line"></span><br><span class="line"><span class="comment">//4：关闭连接</span></span><br><span class="line">ds.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>运行结果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如果先运行UdpSendSimpleDemo没有任何信息</span><br><span class="line">如果先运行UdpReceiveSimpleDemo会输出：</span><br><span class="line">信息来源：<span class="number">192.168</span>.3.102</span><br><span class="line">收到数据：UDP ......你好！</span><br></pre></td></tr></table></figure></li></ol><ul><li>实例二 、相对复杂的实例</li></ul><p>发送数据后，如果不成功会继续发送4次，都不成功则表示失败。<br>接收端收到信息后，会返回消息告诉发送者已成功，发送者收到数据会进行相应的校验。</p><ol><li><p>发送数据：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InterruptedIOException;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过udp协议发送数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UdpSendDemo</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TIMEOUT = <span class="number">3000</span>;  <span class="comment">//设置接收数据的超时时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXNUM = <span class="number">5</span>;      <span class="comment">//设置重发数据的最多次数</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：获取socket对象</span></span><br><span class="line"><span class="comment"> * 2：对数据进行封包</span></span><br><span class="line"><span class="comment"> * 3：通过socket对象把数据包发送出去</span></span><br><span class="line"><span class="comment"> * 4：把连接关闭</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 获取socket对象</span></span><br><span class="line">DatagramSocket ds = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">ds = <span class="keyword">new</span> DatagramSocket(<span class="number">9000</span>); <span class="comment">//如果只是用于发送不填写端口</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (SocketException e) &#123;</span><br><span class="line">System.out.println(<span class="string">"创建一个socket对象失败！"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 封包数据</span></span><br><span class="line">String sendMsg = <span class="string">"UDP ......你好！"</span> ;</span><br><span class="line"></span><br><span class="line">DatagramPacket p = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">p = <span class="keyword">new</span> DatagramPacket(sendMsg.getBytes(),sendMsg.getBytes().length,InetAddress.getLocalHost(),<span class="number">3000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (UnknownHostException e) &#123;</span><br><span class="line">System.out.println(<span class="string">"找不到该hosts所对应的地址！"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. 发送数据包</span></span><br><span class="line"><span class="keyword">boolean</span> isReceived = <span class="keyword">false</span>; <span class="comment">//是否接收到数据的标志位</span></span><br><span class="line"><span class="keyword">int</span> tries = <span class="number">0</span>;  <span class="comment">//重发数据的次数</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">ds.setSoTimeout(TIMEOUT); <span class="comment">//设置超时时间</span></span><br><span class="line"><span class="comment">//直到接收到数据，或者重发次数达到预定值，则退出循环</span></span><br><span class="line"><span class="keyword">while</span>(!isReceived &amp;&amp; tries&lt;MAXNUM) &#123;</span><br><span class="line"></span><br><span class="line">ds.send(p); <span class="comment">//发送数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line"><span class="comment">//定义用来接收数据的DatagramPacket实例</span></span><br><span class="line">DatagramPacket dp_receive = <span class="keyword">new</span> DatagramPacket(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>], <span class="number">1024</span>);</span><br><span class="line"><span class="comment">//接收从服务端发送回来的数据</span></span><br><span class="line">ds.receive(dp_receive);</span><br><span class="line"><span class="comment">//如果接收到的数据不是来自目标地址，则抛出异常</span></span><br><span class="line"><span class="keyword">if</span>(!dp_receive.getAddress().equals( InetAddress.getLocalHost() ))&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"地址出错"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果接收到数据。则将receivedResponse标志位改为true，从而退出循环</span></span><br><span class="line">isReceived = <span class="keyword">true</span>;</span><br><span class="line">&#125;<span class="keyword">catch</span>(InterruptedIOException e)&#123;</span><br><span class="line"><span class="comment">//如果接收数据时阻塞超时，重发并减少一次重发的次数</span></span><br><span class="line">tries += <span class="number">1</span>;</span><br><span class="line">System.out.println(<span class="string">"Time out,次数："</span> + tries );</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">System.out.println(<span class="string">"发送数据失败！"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(isReceived)&#123;</span><br><span class="line"><span class="comment">//成功</span></span><br><span class="line">System.out.println(<span class="string">"发送成功！"</span>);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">//失败</span></span><br><span class="line">System.out.println(<span class="string">"重发信息"</span>+tries+<span class="string">"次后，失败！"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//4. 关闭连接</span></span><br><span class="line"><span class="keyword">if</span>( ds != <span class="keyword">null</span> )&#123;</span><br><span class="line">ds.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>接收数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramPacket;</span><br><span class="line"><span class="keyword">import</span> java.net.DatagramSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.SocketException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * UDP接收端代码</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UdpReceiveDemo</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：获取socket连接(需要指定监听的端口)</span></span><br><span class="line"><span class="comment"> * 2：通过receive方法接收数据包</span></span><br><span class="line"><span class="comment"> * 3：解包，获取数据包中的内容</span></span><br><span class="line"><span class="comment"> * 4：关闭连接</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">//1:获取连接</span></span><br><span class="line">DatagramSocket ds = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">//在3000端口监听接收到的数据</span></span><br><span class="line">ds = <span class="keyword">new</span> DatagramSocket(<span class="number">3000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (SocketException e) &#123;</span><br><span class="line"><span class="comment">//例如，该端口已被占用</span></span><br><span class="line"><span class="comment">//java.net.BindException: Address already in use: Cannot bind</span></span><br><span class="line">System.out.println(<span class="string">"创建一个socket对象失败！"</span>+e.getMessage());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//这些让它一直接收数据</span></span><br><span class="line"><span class="keyword">while</span>( ds != <span class="keyword">null</span> )&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2：接收数据</span></span><br><span class="line"><span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">DatagramPacket p = <span class="keyword">new</span> DatagramPacket(buf, <span class="number">0</span>, buf.length);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">ds.receive(p);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"><span class="comment">//例如，ds为空等</span></span><br><span class="line">System.out.println(<span class="string">"接收数据失败！"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3:获取数据</span></span><br><span class="line">System.out.println( <span class="string">"信息来源："</span>+p.getAddress().getHostAddress() );</span><br><span class="line">System.out.println( <span class="string">"收到数据："</span> + <span class="keyword">new</span> String( p.getData(),<span class="number">0</span>,p.getLength()) );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//通知9000端口的客户端数据接收成功</span></span><br><span class="line"><span class="comment">//数据发动到客户端的</span></span><br><span class="line">DatagramPacket dp_reply= <span class="keyword">new</span> DatagramPacket(p.getData() ,p.getData().length,p.getAddress(),<span class="number">9000</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">ds.send(dp_reply);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//由于dp_reply在接收了数据之后，其内部消息长度值会变为实际接收的消息的字节数，</span></span><br><span class="line"><span class="comment">//所以这里要将dp_reply的内部消息长度重新置为1024</span></span><br><span class="line">dp_reply.setLength(<span class="number">1024</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//4：关闭连接</span></span><br><span class="line"><span class="comment">//ds.close();</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ul><li>运行结果     </li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">UdpSendDemo先运行，如中途UdpReceiveDemo还未启动则运行结果：</span><br><span class="line">Time out,次数：<span class="number">1</span></span><br><span class="line">Time out,次数：<span class="number">2</span></span><br><span class="line">Time out,次数：<span class="number">3</span></span><br><span class="line">Time out,次数：<span class="number">4</span></span><br><span class="line">Time out,次数：<span class="number">5</span></span><br><span class="line">重发信息<span class="number">5</span>次后，失败！</span><br><span class="line">UdpReceiveDemo先运行,UdpSendDemo会收到发送成功！接收者</span><br><span class="line">信息来源：<span class="number">192.168</span>.3.102</span><br><span class="line">收到数据：UDP ......你好！</span><br></pre></td></tr></table></figure><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><ul><li>TCP用于网络的可靠的流式输入/输出，HTTP、FTP、Telnet等应用都需要这种可靠的通信通道。、</li></ul><blockquote><p>两个socket之间<code>必须建立连接</code>，<code>形成传输数据的通道</code><br>在连接中进行大数据量传输<br>通过三次握手完成连接 是<strong>可靠协议</strong>、<strong>效率会稍低</strong></p></blockquote><ul><li>事例一、简单的TCP实例</li></ul><ol><li><p>TCP发送端</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * TCP发送端</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TcpSendSimpleDemo</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：创建socker客户端，需要连接到接收端</span></span><br><span class="line"><span class="comment"> * 2：获取这个socket的输出流</span></span><br><span class="line"><span class="comment"> * 3：通过输出流给其他服务器发送数据</span></span><br><span class="line"><span class="comment"> * 4：关键连接</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">//1：获取socker对象</span></span><br><span class="line">Socket socket = <span class="keyword">new</span> Socket(<span class="string">"192.168.3.102"</span>,<span class="number">6000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//2:获取输出流</span></span><br><span class="line">OutputStream outputStream = socket.getOutputStream();</span><br><span class="line"></span><br><span class="line"><span class="comment">//3:通过输出流写数据</span></span><br><span class="line">outputStream.write(<span class="string">"TCP ... 你好!"</span>.getBytes());</span><br><span class="line"></span><br><span class="line"><span class="comment">//4：关闭连接</span></span><br><span class="line">socket.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>TCP接收端</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * TCP接收端</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/12.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TcpReceiveSimpleDemo</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1：创建一个socket服务端，需要监听指定端口</span></span><br><span class="line"><span class="comment"> * 2：通过这个服务端对象可以获取到给指定端口发送数据的socket客户端对象</span></span><br><span class="line"><span class="comment"> * 3：通过socket对象获取具体的读取流</span></span><br><span class="line"><span class="comment"> * 4：通过读取流获取数据</span></span><br><span class="line"><span class="comment"> * 5：关闭连接</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">//1:获取ServerSocket</span></span><br><span class="line">ServerSocket serverSocket = <span class="keyword">new</span> ServerSocket(<span class="number">6000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//2:获取客户端的socket对象</span></span><br><span class="line"><span class="comment">//是一个阻塞方法，获取socket客户端对象</span></span><br><span class="line">Socket socket = serverSocket.accept();</span><br><span class="line"></span><br><span class="line"><span class="comment">//3：获取socket的输入流</span></span><br><span class="line">InputStream in = socket.getInputStream();</span><br><span class="line"><span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//4：读取数据</span></span><br><span class="line"><span class="keyword">int</span> read = in.read(bytes);</span><br><span class="line">System.out.println(<span class="keyword">new</span> String(bytes, <span class="number">0</span>, read));</span><br><span class="line"></span><br><span class="line"><span class="comment">//5：关闭连接</span></span><br><span class="line">socket.close();</span><br><span class="line">serverSocket.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ul><li>InetAddr类讲解：<a href="http://blog.xiaoxiaomo.com/2016/04/13/Java-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8BInetAddr%E5%92%8CURL/" title="InetAddr和URL">Java-网络编程InetAddr和URL</a></li></ul><h3 id="TCP-IP模型"><a href="#TCP-IP模型" class="headerlink" title="TCP/IP模型"></a>TCP/IP模型</h3><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160413105349.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop-HDFS架构和Shell</title>
      <link href="/2016/04/11/Hadoop-HDFS%E6%9E%B6%E6%9E%84%E5%92%8CShell/"/>
      <url>/2016/04/11/Hadoop-HDFS%E6%9E%B6%E6%9E%84%E5%92%8CShell/</url>
      <content type="html"><![CDATA[<p>　　<strong>Hadoop分布式文件系统(<code>HDFS</code>)</strong>，一个<strong>高度容错性</strong>的系统，适合部署在<strong>廉价的机器上</strong>。HDFS提供了高吞吐量的数据访问，适合大规模数据集的应用。<code>HDFS采用master/slave架构</code>，<strong>HDFS集群是由一个<a href="http://blog.xiaoxiaomo.com/2016/06/25/Hadoop-HDFS之NameNode/">NameNode</a>和一定数目的<a href="http://blog.xiaoxiaomo.com/2016/06/26/Hadoop-HDFS之DataNode/">DataNodes</a>组成</strong>。</p><h2 id="HDFS架构和设计"><a href="#HDFS架构和设计" class="headerlink" title="HDFS架构和设计"></a>HDFS架构和设计</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412171211.png" alt="Hadoop HDFS架构图"></p><a id="more"></a><ol><li><p><strong>硬件错误</strong>：<br><strong>硬件错误是常态而不是异常</strong>。<code>HDFS</code>可能由成百上千的服务器所构成，每个服务器上存储着文件系统的<strong>部分数据</strong>，面对成百上千的服务器，难免会出现某些主件出现异常现象。<code>对于Hadoop来说错误检测和快速、自动的恢复是它最核心的架构目标</code>。</p></li><li><p><strong>大规模数据集</strong>：<br>在HDFS上文件大小一般都在G字节至T字节，于是HDFS被调节以<code>支持大文件存储</code>。能在一个集群里扩展到数百个节点，具有很大的数据集。</p></li><li><p><strong>流式数据访问</strong>：<br>HDFS的设计中更多的考虑到了<code>数据批处理</code>，而不是用户交互处理。比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量。</p></li><li><p><strong>一致性模型</strong>：<br><code>一次写入多次读取</code>的文件访问模型。<strong>一个文件经过创建、写入和关闭之后就不需要改变</strong>。这一假设简化了数据一致性问题，并且使高吞吐量的数据访问成为可能。</p></li><li><p><strong>移动计算</strong>：<br><strong>一个应用请求的计算，离它操作的数据越近就越高效</strong>，在数据达到海量级别的时候更是如此。因为这样就能降低网络阻塞的影响，提高系统数据的吞吐量。<code>将计算移动到数据附近</code>，比之将数据移动到应用所在显然更好。</p></li><li><p><strong>平台移植</strong>：<br>HDFS在设计的时候就考虑到<code>平台可移植性</code>。这种特性方便了HDFS作为大规模数据应用平台的推广。</p></li></ol><h2 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h2><p><code>(FS)Shell</code>命令应使用<code>bin/hadoop fs &lt;args&gt;</code>的形式。 所有的shell命令使用URI路径作为参数。eg：hadoop fs -ls hdfs://xiaoxiaomo01:9000/ </p><blockquote><ol><li>所用(FS)Shell命令都是以<code>“hadoop fs”开头（1.0）</code>，2.0修改为<code>“hdfs dfs”开头</code>。</li><li>-<em>ls 为命令选项</em>，记住和linux里面是有区别的，<code>这里每个命令前面有“-”</code>。</li><li>xiaoxiaomo01是我hadoop的<strong>主机名</strong>。</li><li>hdfs://xiaoxiaomo01:9000/可简写为“/”，&gt;<strong> hadoop fs -ls /</strong></li></ol></blockquote><ul><li><p>例如<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412184219.png" alt="hadoop fs -ls命令"></p></li><li><p><strong>(FS)Shell命令</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">-<span class="built_in">help</span> [cmd]//显示命令的帮助信息</span><br><span class="line">-ls(r) &lt;path&gt;//显示当前目录下所有文件</span><br><span class="line">-du(s) &lt;path&gt;//显示目录中所有文件大小</span><br><span class="line">-count[-q] &lt;path&gt;//显示目录中文件数量</span><br><span class="line">-mv &lt;src&gt; &lt;dst&gt;//移动多个文件到目标目录</span><br><span class="line">-cp &lt;src&gt; &lt;dst&gt;//复制多个文件到目标目录</span><br><span class="line">-rm(r)//删除文件(夹)</span><br><span class="line">-put &lt;localsrc&gt; &lt;dst&gt;//本地文件复制到hdfs</span><br><span class="line">-copyFromLocal//同put</span><br><span class="line">-moveFromLocal//从本地文件移动到hdfs</span><br><span class="line">-get [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;//复制文件到本地，可以忽略crc校验</span><br><span class="line">-getmerge &lt;src&gt; &lt;localdst&gt;//将源目录中的所有文件排序合并到一个文件中</span><br><span class="line">-cat &lt;src&gt;//在终端显示文件内容</span><br><span class="line">-text &lt;src&gt;//在终端显示文件内容</span><br><span class="line">-copyToLocal [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;//复制到本地</span><br><span class="line">-moveToLocal &lt;src&gt; &lt;localdst&gt;</span><br><span class="line">-mkdir &lt;path&gt;//创建文件夹</span><br><span class="line">-touchz &lt;path&gt;//创建一个空文件</span><br></pre></td></tr></table></figure></li></ul><p>上述的命令需要多去练习，下面据简单的举例一下上传下载，创建文件，移动复制，事例如下：</p><ol><li><p>创建文件夹<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412185551.png" alt="hadoop fs -ls和mkdir 查看和创建文件夹"><br>说明：我们首先递归查看了/test文件夹，下面只有一个文件，然后在该目录下创建了/momo目录</p></li><li><p>上传文件到指定目录（上传文件到momo目录）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412190059.png" alt="hadoop fs -put 上传本地数据到hdfs"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412190116.png" alt="hadoop fs -lsr 查看命令,递归"></p></li><li><p>下载文件<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412190555.png" alt="hadoop fs -get 获取hdfs数据到本地"></p></li><li><p>移动文件夹<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412191356.png" alt="hadoop fs -mv 移动hdfs上的数据"></p></li><li><p>复制文件<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160412191111.png" alt="hadoop fs -cp 复制hdfs上的数据"></p></li></ol><h2 id="Namenode"><a href="#Namenode" class="headerlink" title="Namenode"></a>Namenode</h2><ol><li><code>Namenode，是整个文件系统的管理节点</code>;</li><li>它维护着整个文件系统的<strong>文件目录树</strong>，文件/目录的<strong>元信息</strong>和每个文件对应的<strong>数据块列表</strong>，<strong>接收用户的操作请求</strong>;</li><li>NameNode 只有三种交互。<br>3.1. client访问NameNode获取相关DataNode信息。<br>3.2. DataNode心跳汇报当前block情况。<br>3.3. SecondaryNameNode做checkpoint交互。</li></ol><h2 id="Datanode"><a href="#Datanode" class="headerlink" title="Datanode"></a>Datanode</h2><ul><li>Datanode：提供真实文件数据的存储服务</li></ul><p><code>文件块（block）</code>：最基本的存储单位。<strong>HDFS默认Block大小是64MB(1.0版本),128(2.0版本)</strong>，如果一个文件小于一个数据块的大小，HDFS并不占用整个数据块存储空间。<br>Replication：多复本，默认是三个。</p><h2 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h2><ul><li>HA的一个解决方案。但不支持热备。配置即可</li></ul><p><code>执行过程</code>：<strong>从NameNode上下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage</strong>，在<strong>本地保存</strong>，<strong>并将其推送到NameNode</strong>，<strong>同时重置NameNode的edits</strong>.（默认在安装在NameNode节点上，但这样…不安全！）</p><ul><li>参考资料</li></ul><ol><li><a href="http://www.colabug.com/thread-1090990-1-1.html" target="_blank" rel="noopener">http://www.colabug.com/thread-1090990-1-1.html</a></li><li><a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html</a></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--1.0伪分布式安装</title>
      <link href="/2016/04/09/Hadoop-1-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2016/04/09/Hadoop-1-0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解<code>Hadoop1.0伪分布式</code>的安装配置(以<code>hadoop-1.1.2.tar.gz</code>为例)，虽然现在都在使用2.x的版本但是对于1.0的我们还是应该知道怎么去配置，当然他们只有细微的差别。如果对于环境还没准备好的，可以阅读<a href="http://blog.xiaoxiaomo.com/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/">Hadoop-安装前环境准备</a>。如需安装2.0请查看博客：<a href="http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0伪分布式安装/">http://blog.xiaoxiaomo.com/2016/05/08/Hadoop-2-0伪分布式安装/</a></p><a id="more"></a><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>首先我们需要去下载<strong><a href="http://pan.baidu.com/s/1qYcNmTQ" target="_blank" rel="noopener">hadoop-1.1.2.tar.gz</a></strong>，然后上传到Linux上，解压后配置环境变量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">命令：tar -zxvf hadoop-1.1.2.tar.gz  #解压tar.gz文件</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174157.png" alt="解压hadoop文件"></p><p><code>vi /etc/profile</code>修改环境变量并重启配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop-1.1.2 #指定目录</span><br><span class="line">export PATH=.:$JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH </span><br><span class="line"><span class="meta">#</span><span class="bash">注意PATH只在原基础上添加了:<span class="variable">$HADOOP_HOME</span>/bin</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174158.png" alt="环境变量配置"></p><p>记得重启配置：<code>source /etc/profile</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174160.png" alt="重启配置并检测是否已配置好"></p><p>上面<strong>Warning: $HADOOP_HOME is deprecated.</strong>在配置文件中添加<code>export HADOOP_HOME_WARN_SUPPRESS=0</code> 就不会再有该提示。</p><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174159.png" alt="修改配置文件"></p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>修改<code>Hadoop</code>安装目录/<code>conf</code>目录/下的配置文件</p><blockquote><p><strong>hadoop-env.sh</strong><br><strong>core-site.xml</strong><br><strong>hdfs-site.xml</strong><br><strong>mapred-site.xml</strong></p></blockquote><ul><li>A、<code>hadoop-env.sh</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/jdk1.6 #这里修改为jdk的安装目录</span><br></pre></td></tr></table></figure><ul><li>B、<code>core-site.xml</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://xiaoxiaomo01:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/usr/local/hadoop-1.1.2/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><ul><li>C、<code>hdfs-site.xml</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><ul><li>D、<code>mapred-site.xml</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapred.job.tracker&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;xiaoxiaomo01:9001&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">`</span><br></pre></td></tr></table></figure><h3 id="格式化磁盘"><a href="#格式化磁盘" class="headerlink" title="格式化磁盘"></a>格式化磁盘</h3><p> <code>hadoop namenode -format</code>    #格式化磁盘</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo01 bin]# hadoop namenode -format</span><br><span class="line">16/04/10 00:15:00 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = xiaoxiaomo01/192.168.3.221</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 1.1.2</span><br><span class="line">STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.1 -r 1440782; compiled by 'hortonfo' on Thu Jan 31 02:03:24 UTC 2013</span><br><span class="line">************************************************************/</span><br><span class="line">16/04/10 00:15:00 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">16/04/10 00:15:00 INFO util.GSet: 2% max memory = 19.33375 MB</span><br><span class="line">16/04/10 00:15:00 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">16/04/10 00:15:00 INFO util.GSet: recommended=2097152, actual=2097152</span><br><span class="line">16/04/10 00:15:00 INFO namenode.FSNamesystem: fsOwner=root</span><br><span class="line">16/04/10 00:15:00 INFO namenode.FSNamesystem: supergroup=supergroup</span><br><span class="line">16/04/10 00:15:00 INFO namenode.FSNamesystem: isPermissionEnabled=false</span><br><span class="line">16/04/10 00:15:01 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100</span><br><span class="line">16/04/10 00:15:01 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)</span><br><span class="line">16/04/10 00:15:01 INFO namenode.NameNode: Caching file names occuring more than 10 times </span><br><span class="line">16/04/10 00:15:01 INFO common.Storage: Image file of size 110 saved in 0 seconds.</span><br><span class="line">16/04/10 00:15:01 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/usr/local/hadoop-1.1.2/tmp/dfs/name/current/edits</span><br><span class="line">16/04/10 00:15:01 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/usr/local/hadoop-1.1.2/tmp/dfs/name/current/edits</span><br><span class="line">16/04/10 00:15:01 INFO common.Storage: Storage directory /usr/local/hadoop-1.1.2/tmp/dfs/name has been successfully formatted.</span><br><span class="line">16/04/10 00:15:01 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at xiaoxiaomo01/192.168.3.221</span><br><span class="line">************************************************************/</span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><p><code>start-all.sh</code> #启动服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">starting namenode, logging to /usr/local/hadoop-1.1.2/libexec/../logs/hadoop-root-namenode-xiaoxiaomo01.out</span><br><span class="line">localhost: starting datanode, logging to /usr/local/hadoop-1.1.2/libexec/../logs/hadoop-root-datanode-xiaoxiaomo01.out</span><br><span class="line">localhost: starting secondarynamenode, logging to /usr/local/hadoop-1.1.2/libexec/../logs/hadoop-root-secondarynamenode-xiaoxiaomo01.out</span><br><span class="line">starting jobtracker, logging to /usr/local/hadoop-1.1.2/libexec/../logs/hadoop-root-jobtracker-xiaoxiaomo01.out</span><br><span class="line">localhost: starting tasktracker, logging to /usr/local/hadoop-1.1.2/libexec/../logs/hadoop-root-tasktracker-xiaoxiaomo01.out</span><br></pre></td></tr></table></figure><ul><li>注意，如果没有配置ssh就会提示输入多次密码</li></ul><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>（1）、执行命令jps，查看进程，分别是：<br><strong>NameNode</strong>、<strong>SecondaryNameNode</strong>、<strong>DataNode</strong>、<strong>JobTracker</strong>、<strong>TaskTracker</strong></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174161.png" alt=""></p><p>（2）、在浏览器查看，<a href="http://xiaoxiaomo01:50070、http://xiaoxiaomo01:50030" target="_blank" rel="noopener">http://xiaoxiaomo01:50070、http://xiaoxiaomo01:50030</a><br>（如果访问的电脑没有配置hosts，192.168.3.221 xiaoxiaomo01就不能通过hostsname访问，只能通过ip，eg：<a href="http://192.168.3.221:50030/）" target="_blank" rel="noopener">http://192.168.3.221:50030/）</a></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174162.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174163.png" alt=""></p><h3 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h3><p>命令：stop-all.sh </p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoxiaomo01 bin]# ./stop-all.sh </span><br><span class="line">stopping jobtracker</span><br><span class="line">localhost: stopping tasktracker</span><br><span class="line">stopping namenode</span><br><span class="line">localhost: stopping datanode</span><br><span class="line">localhost: stopping secondarynamenode</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>启动时没有<code>NameNode</code>的可能原因:</p><blockquote><p>(1)没有格式化<br>(2)环境变量设置错误<br>(3)ip与hostname绑定失败<br>(4)配置文件写错了</p></blockquote><p>这时候我们可以到<strong>Hadoop安装目录/logs/下面查看日志文件</strong>，进行排错。</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--安装前环境准备</title>
      <link href="/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
      <url>/2016/04/09/Hadoop-%E5%AE%89%E8%A3%85%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url>
      <content type="html"><![CDATA[<p>　　<code>Hadoop的部署</code>分为了<strong>伪分布模式</strong>和<strong>集群模式</strong>，本篇博客首先会介绍在在伪分布式模式下的环境准备，等更新Hadoop集群安装后，会同时更新本篇博客的集群模式部分。</p><h1 id="伪分布式模式"><a href="#伪分布式模式" class="headerlink" title="伪分布式模式"></a>伪分布式模式</h1><h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><ul><li>需要下载软件：<blockquote><p><a href="http://pan.baidu.com/s/1gfCXvPL" target="_blank" rel="noopener">虚拟机VMware</a><br><a href="http://pan.baidu.com/s/1geGKRCJ" target="_blank" rel="noopener">centos</a><br>jdk-6u24-linux-xxx.bin（这里使用<a href="http://pan.baidu.com/s/1o8Ssj5C" target="_blank" rel="noopener">jdk-6u45-linux-x64.bin</a>）<br><a href="http://pan.baidu.com/s/1qYcNmTQ" target="_blank" rel="noopener">hadoop-1.1.2.tar.gz</a></p></blockquote></li></ul><a id="more"></a><h2 id="二、环境配置"><a href="#二、环境配置" class="headerlink" title="二、环境配置"></a>二、环境配置</h2><ul><li>需要配置环境：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; 修改ip</span><br><span class="line">&gt; 关闭防火墙</span><br><span class="line">&gt; 修改主机名</span><br><span class="line">&gt; 修改hostname</span><br><span class="line">&gt; 设置ssh</span><br><span class="line">&gt; 安装jdk</span><br></pre></td></tr></table></figure></li></ul><h3 id="设置ip地址"><a href="#设置ip地址" class="headerlink" title="设置ip地址"></a>设置ip地址</h3><ul><li>在<a href="http://blog.xiaoxiaomo.com/2016/03/15/VMware-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/">VMware-网络配置</a>中也有讲过配置网络，这里在简单的讲解一下吧：</li></ul><ol><li><p>首先修改：<code>/etc/sysconfig/network-scripts/目录下ifcfg-eth0配置文件</code>。如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409110807.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409110808.png" alt=""></p></li><li><p>然后修改：<code>ONBOOT=yes</code>、<code>BOOTPRPTP=static</code>以及添加如下网络配置：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409105925.png" alt=""></p></li><li><p>最后：<code>service network restart</code>重启网络配置<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409111407.png" alt=""></p></li></ol><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><ul><li><p>命令<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409111557.png" alt="关闭防火墙"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop #关闭防火墙</span><br><span class="line">service iptables status #查看状态</span><br></pre></td></tr></table></figure></li><li><p>注意：并且关闭防火墙的自动运行<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409112442.png" alt=""></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off #关闭自动运行</span><br><span class="line">chkconfig --list | grep iptables #验证</span><br></pre></td></tr></table></figure></li></ul><h3 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h3><ul><li>修改<code>/etc/sysconfig/network</code>的文件，这里主机名为“xiaoxiaomo01”，操作如下图所示：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409112556.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409112523.png" alt=""></li></ul><h3 id="绑定Hostname"><a href="#绑定Hostname" class="headerlink" title="绑定Hostname"></a>绑定Hostname</h3><ul><li>修改<code>/etc/hosts</code>文件，在结尾添加如下内容：<br>192.168.3.221 xiaoxiaomo01</li></ul><h3 id="设置ssh"><a href="#设置ssh" class="headerlink" title="设置ssh"></a>设置ssh</h3><ul><li>命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa  #生成rsa格式的ssh私钥和公钥</span><br><span class="line">ssh-copy-id -i xiaoxiaomo01 #把公钥复制到对方节点(这里我复制到自己的主机xiaoxiaomo01上)</span><br><span class="line">ssh xiaoxiaomo01 #验证</span><br></pre></td></tr></table></figure></li></ul><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><ul><li><p><a href="http://blog.xiaoxiaomo.com/2016/01/22/Linux-软件安装之JDK/">Linux–软件安装之JDK</a>已经详细的讲解了安装JDK的方法，这里我们主要再讲一种<code>.bin文件</code>安装的方式吧。<br>上传JDK，然后进行安装配置，<code>一般软件安装在/usr/local目录下</code>，所以先把文件复制到/usr/local目录下，命令如下：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409132817.png" alt=""></p></li><li><p>因为<a href="http://pan.baidu.com/s/1o8Ssj5C" target="_blank" rel="noopener">jdk-6u45-linux-x64.bin</a>，bin文件是一个执行文件，所以我们需要给予当前用户的执行权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod u+x jdk-6u45-linux-x64.bin</span><br><span class="line">./jdk-6u45-linux-x64.bin</span><br></pre></td></tr></table></figure></li><li><p>解压后可以修改一下jdk文件名，如我这里修改为jdk1.6：<code>mv jdk-1.6.0_24  jdk1.6</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409133730.png" alt=""><br>最后配置一下环境变量<code>vi /etc/profile</code> 增加内容如下:<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409134213.png" alt=""></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/jdk</span><br><span class="line">export PATH=.:$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>重启配置文件：<code>source /etc/profile</code><br>验证：<code>java -version</code><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409174156.png" alt="重启配置文件"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>VMware--CentOS6.5安装</title>
      <link href="/2016/04/09/VMware-CentOS6-5%E5%AE%89%E8%A3%85/"/>
      <url>/2016/04/09/VMware-CentOS6-5%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>　　本来不打算写这篇博客的，因为安装这个软件是比较<strong>简单机械</strong>的，但今天有人问了我。于是就在这里<code>简单的给出截图</code>能直观明白的表达意思就行，如有不懂得可在下方留言，下载<a href="http://pan.baidu.com/s/1geGKRCJ" target="_blank" rel="noopener">Centos6.5</a>、<a href="http://pan.baidu.com/s/1gfCXvPL" target="_blank" rel="noopener">虚拟机VMware</a> 。</p><a id="more"></a><ol><li><p>点击左上方”<strong>文件</strong>“—&gt;”<strong>新建虚拟机</strong>“<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232215.png" alt=""></p></li><li><p>选择”<strong>典型安装</strong>“—&gt;<strong>下一步</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409091802.png" alt=""></p></li><li><p>这里我们选择“稍后安装操作系统”，<em>之前试过很多次直接选择镜像安装有几次失败了( ▼-▼ )</em>。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232238.png" alt=""></p></li><li><p>然后我们选择我们Linux操作系统，这里我的系统是CentOS 64位的。选择版本后点击下一步。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232325.png" alt=""></p></li><li><p>设置虚拟机的主机名，比如我这里设置的“xiaoxiaomo”,然后选择存储位置，然后下一步。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232456.png" alt=""></p></li><li><p>设置磁盘大小，如图选择后，点击下一步，最后完成，然后基本设置就差不多了。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232637.png" alt=""></p></li><li><p>由于第3步的时候我们选择了，稍后在选择操作系统，所以现在在安装之前我们指定操作系统的镜像。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408232936.png" alt=""><br>现在就正式开始安装了，点击开启此虚拟机。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233010.png" alt=""><br>如果出现如下提示，有两个解决办法，第一个，在运行虚拟机的时候右键使用“以管理员身份运行”或者“我的电脑-右键-服务”启动服务VMware Authorization Service去开启。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409093642.png" alt=""></p></li><li><p>选择第一个，然后下一步<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233301.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233343.png" alt=""></p></li><li><p>可以测试一下<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233447.png" alt=""><br>成功，然后点击OK<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233521.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233547.png" alt=""></p></li><li><p>下面又有一个测试，点击测试，就会弹出一个错误，这里就会过不去了<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233629.png" alt=""><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233714.png" alt=""></p></li><li><p>然后点击虚拟机，设置，如下图所示，点击CD/DVD那个设备，选择设备状态“已连接”然后重新点击测试即通过。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408233903.png" alt=""></p></li><li><p>下一步，下一步就OK了，比较机械简单就不说了o(^▽^)o<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234004.png" alt=""></p></li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234045.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234118.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234157.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234249.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234353.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234435.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234507.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234849.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408234906.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160408235003.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 虚拟机 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop--简介</title>
      <link href="/2016/04/08/Hadoop-%E7%AE%80%E4%BB%8B/"/>
      <url>/2016/04/08/Hadoop-%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>　　<strong>大数据</strong>，这个词在国内 2012 年才出现 ，<strong>指的是处理TB级别以上的数据</strong>，在互联网领域中，大数据应用非常广泛。<code>Hadoop</code> 是海量数据的分布式存储和计算平台(这里“海量数据”指的是不低于 TB 级别数据)，<code>Hadoop</code>适合处理海量数据，小数据发挥不了<code>Hadoop</code>的优势。<br><a id="more"></a></p><h2 id="认识Hadoop"><a href="#认识Hadoop" class="headerlink" title="认识Hadoop"></a>认识Hadoop</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409100810.png" alt="Hadoop"><br><em>What Is Apache Hadoop?<br>The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.</em></p><ul><li><strong>解决问题</strong>：</li></ul><blockquote><p>1、海量数据的存储（<strong>HDFS</strong>）<br>2、海量数据的分析（<strong>MapReduce</strong>）<br>3、资源管理调度（<strong>YARN</strong>）（2.0 之后出现）</p></blockquote><ul><li><strong>具体能做什么</strong>？</li></ul><blockquote><p>1、擅长于在廉价机器搭建的集群上进行海量数据(结构化与非结构化)的存储与离线处理<br>2、hadoop 擅长日志分析</p></blockquote><p><strong>Hadoop的三大核心组件</strong>：</p><ol><li><code>HDFS(Hadoop Distributed File System)</code>：分布式文件系统；</li><li><code>MapReduce</code>：并行计算框架；</li><li><code>Yarn</code>：资源管理平台（2.0 版本增加）。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160625122360.png" alt="Hadoop 三大核心组件"></li></ol><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul><li>分布式易扩展</li><li>廉价易得</li><li>高吞吐量</li><li>高可靠性</li></ul><p>是一个<strong>主从结构</strong>的，有主节点和从节点。主节点只有一个：<code>namenode</code>，从节点有很多个：<code>datanodes</code></p><ol><li><p><strong>namenode</strong>:</p><blockquote><ol><li>接受用户操作请求</li><li>维护文件系统的目录结构</li><li>管理文件与block之间的关系，block与datanode之间的关系</li></ol></blockquote></li><li><p><strong>datanode</strong></p><blockquote><ol><li>负责存储文件</li><li>文件被分成block存储在磁盘上</li><li>为保证数据安全，文件会有多个副本</li></ol></blockquote></li></ol><ul><li><strong>block</strong>：就是把一个大的文件划分为多个块，每块就叫block。然后namenode就需要去管理这些块和文件之间的关系（比如文件块顺序等）。</li></ul><h2 id="MapReduce-1-0"><a href="#MapReduce-1-0" class="headerlink" title="MapReduce(1.0)"></a>MapReduce(1.0)</h2><ul><li>大容量高并发</li><li>封装分布式实现细节</li><li>大大提高分析效率</li></ul><ol><li><p><strong>主从结构</strong></p><blockquote><ol><li>主节点，只有一个：JobTracker</li><li>从节点，有很多个：TaskTrackers</li></ol></blockquote></li><li><p><strong>JobTracker</strong></p><blockquote><ol><li>接收Job，负责调度Job的每一个子任务task运行于TaskTracker上。</li><li>把计算任务分给TaskTrackers执行。</li><li>监控TaskTracker的执行情况。</li></ol></blockquote></li><li><p><strong>TaskTrackers</strong></p><blockquote><ol><li>运行在多个节点上的slaver服务。</li><li>TaskTracker主动与JobTracker通信，接收作业。</li><li>并执行JobTracker分配的每一个计算任务。</li></ol></blockquote></li></ol><h2 id="Hadoop的特点"><a href="#Hadoop的特点" class="headerlink" title="Hadoop的特点"></a>Hadoop的特点</h2><ol><li><strong>扩容能力</strong>（Scalable）:能可靠的存储和处理千兆字节（PB）数据</li><li><strong>成本低</strong>（Economical）：可以通过普通机器组成服务集群来分发以及处理数据。这些服务器群总数可达千个节点</li><li><strong>高效率</strong>：通过分发数据，hadoop可以在数据所在的节点上并行地（parallel）处理</li><li><strong>可靠性</strong>：能自动维护多个副本，并且在任务失败后能自动地重新部署（redeploy）计算任务</li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409100235.png" alt="Hadoop的特点"></p><h2 id="1-0和2-0区别"><a href="#1-0和2-0区别" class="headerlink" title="1.0和2.0区别"></a>1.0和2.0区别</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160409101416.png" alt="Hadoop 1.0和2.0"></p><ul><li><strong>Hadoop 1.0和2.0的区别</strong> 主要是2.0对1.0的MapReduce进行了拆分，拆分成了MapReduce和Yarn，当然也之前基础上做了一些改变。上面我们已经讲了MapReduce(1.0)，现在我们来讲讲2.0的<strong>MapReduce</strong>和<strong>Yarn</strong>。</li></ul><h3 id="MapReduce2-0"><a href="#MapReduce2-0" class="headerlink" title="MapReduce2.0"></a>MapReduce2.0</h3><ul><li><strong>MapReduce批处理计算模型</strong> 同样是主从结构，主节点，<strong>只有一个: MRAppMaster</strong></li></ul><ol><li><strong>MRAppMaster负责：</strong><blockquote><ol><li>接收客户提交的计算任务</li><li>把计算任务分给TaskTrackers执行，即任务调度</li><li>监控TaskTracker的执行情况 </li></ol></blockquote></li></ol><h3 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h3><ul><li><strong>资源的调度和管理平台</strong></li></ul><ol><li><p><strong>主从结构</strong></p><blockquote><ol><li>主节点，可以有2个: ResourceManager</li><li>从节点，有很多个: NodeManager</li></ol></blockquote></li><li><p><strong>ResourceManager负责</strong>：</p><blockquote><ol><li>集群资源的分配与调度</li><li>MapReduce、Storm、Spark等应用，必须实现ApplicationMaster接口，才能被RM管理</li></ol></blockquote></li><li><p><strong>NodeManager负责</strong>：</p><blockquote><ol><li>单节点资源的管理</li></ol></blockquote></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--IO操作</title>
      <link href="/2016/04/05/Scala-IO%E6%93%8D%E4%BD%9C/"/>
      <url>/2016/04/05/Scala-IO%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>　　<code>I/O</code>我想大家并不陌生了，即<strong>输入/输出(Input/Output)</strong>。本篇博客，我想看标题就清楚了，就是带着大家一起来看看scala的IO操作。</p><a id="more"></a><h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><h3 id="基本读取文件"><a href="#基本读取文件" class="headerlink" title="基本读取文件"></a>基本读取文件</h3><p>读取文件我们使用<code>scala.io.Source</code>，如下图所示，注意的是，在大部分读写操作的过程中就是引入了<code>java.io</code>包下面的方法。</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160405212159.png" alt=""></p><ul><li>读取文件，常用<code>Source.fromFile(&quot;文件路径&quot;，&quot;字符编码&quot;)</code>如下图所示：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160405213214.png" alt=""></p><p>当然我们也可以使用<code>fromIterable</code>、<code>fromChar</code>、<code>fromChars</code>、<code>fromBytes</code>、<code>fromURL</code>、<code>fromInputStream</code>等读取信息，博客中会讲解，下面先来看看Source.fromFile。</p><ul><li>主要讲解的是Source.fromFile读取文件，事例如下：</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">ackage com.xiaoxiaomo.demo.ch09</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">PrintWriter</span>, <span class="type">File</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取文件</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/5.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ReadLines</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//TEST</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="comment">//读取文件，事例一</span></span><br><span class="line">        <span class="keyword">val</span> source: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromFile(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">"D:\\test.txt"</span>),<span class="string">"UTF-8"</span>)</span><br><span class="line">        <span class="comment">//读取文件，事例二（new File可以省略，字符编码如果省略默认使用缺省值）</span></span><br><span class="line">        <span class="keyword">val</span> source2: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromFile(<span class="string">"D:\\test.txt"</span>,<span class="string">"UTF-8"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历的方式一，直接String输出</span></span><br><span class="line">        <span class="comment">//print(source.mkString)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历的方式二，使用foreach逐行输出</span></span><br><span class="line"><span class="comment">//source.getLines()</span></span><br><span class="line">        <span class="comment">//source.getLines().foreach(println)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历的方式三，使用for遍历单个字符输出</span></span><br><span class="line">        <span class="keyword">for</span> (c &lt;- source2 )&#123; <span class="comment">//逐个字符读取</span></span><br><span class="line">            println(c)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用完Source后，记得需要close</span></span><br><span class="line">        source.close()</span><br><span class="line">        source2.close()</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>第一个参数，可以是文件名或<code>java.io.File</code></li><li>第二个参数，<strong>如果没有会使用当前平台缺省的字符编码</strong></li><li><code>source.getLines读取行</code>，结果是一个迭代器可以转换成Array等</li><li>使用完Source后，记得需要<code>close</code>。</li></ol><h3 id="从URL或其他源读取"><a href="#从URL或其他源读取" class="headerlink" title="从URL或其他源读取"></a>从URL或其他源读取</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.demo.ch09</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从URL或其他源读取数据</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/5.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ReadOther</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TEST</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从URL中读取信息</span></span><br><span class="line">        <span class="comment">//注意URL中的编码</span></span><br><span class="line">        <span class="keyword">var</span> rL1: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromURL(</span><br><span class="line"><span class="string">"http://blog.xiaoxiaomo.com/2016/04/02/Scala-%E7%BB%A7%E6%89%BF/"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从String字符串中读取</span></span><br><span class="line">        <span class="keyword">val</span> string: <span class="type">Source</span> = <span class="type">Source</span>.fromString(<span class="string">"blog.xiaoxiaomo.com"</span>)</span><br><span class="line">        <span class="keyword">val</span> str = string.getLines().mkString</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从Char中读取信息</span></span><br><span class="line">        <span class="type">Source</span>.fromChar(str.charAt(<span class="number">2</span>)) ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从Byte数组中读取信息</span></span><br><span class="line">        <span class="type">Source</span>.fromBytes(<span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Byte</span>](<span class="number">100</span>)) ;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="读取词法单元和数字"><a href="#读取词法单元和数字" class="headerlink" title="读取词法单元和数字"></a>读取词法单元和数字</h3><p>在很多场景下，我们时常会遇到对读取的文件进行处理（切割，筛选等），然而我们可以<strong>读取文件后转为字符串</strong>，通过字符串的一个<code>split</code>方法进行切割。事例：现在我们项目跟目录有如下文件，然后我们使用相对路径读取，代码如下：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160406194749.png" alt=""></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">File</span></span><br><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">Source</span>, <span class="type">BufferedSource</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 根据正则读取词法单元</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/6.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ReadSqlit</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过相对路径读取资源文件</span></span><br><span class="line">        <span class="keyword">val</span> source = <span class="type">Source</span>.fromFile(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">"test.txt"</span>),<span class="string">"UTF-8"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过空格（正则表达式）切分成一个一个数据</span></span><br><span class="line">        <span class="keyword">val</span> word = source.mkString.split(<span class="string">"\\s+"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历数据</span></span><br><span class="line">        <span class="keyword">for</span>( w &lt;- word )&#123;</span><br><span class="line">            println(w)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">23</span></span><br><span class="line"><span class="number">2423</span></span><br><span class="line"><span class="number">32</span></span><br><span class="line"><span class="number">423</span></span><br><span class="line"><span class="number">423</span></span><br></pre></td></tr></table></figure><p>可以对切割后的文件进行处理，如下，转为Double<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import java.io.File</span><br><span class="line"></span><br><span class="line">import scala.io.&#123;BufferedSource, Source&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * 切割后处理</span><br><span class="line">  * Created by xiaoxiaomo on 2016/4/6.</span><br><span class="line">  */</span><br><span class="line">object ReadSqlit2 &#123;</span><br><span class="line"></span><br><span class="line">     def main(args: Array[String]) &#123;</span><br><span class="line">         val source: BufferedSource = Source.fromFile(new File(&quot;test.txt&quot;),&quot;UTF-8&quot;)</span><br><span class="line">         val word = source.mkString.split(&quot;\\s+&quot;)</span><br><span class="line"></span><br><span class="line">         //转为Double</span><br><span class="line">         for( w &lt;- word ) yield &#123;</span><br><span class="line">             val double: Double = w.toDouble</span><br><span class="line">             println(double+ &quot; &quot;)</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         //或者通过另一种方式转换</span><br><span class="line">         val map: Array[Double] = word.map(_.toDouble)</span><br><span class="line">         for( m &lt;- map ) &#123;</span><br><span class="line">             print(m+ &quot; - &quot;)</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li>运行结果</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">23.0</span> </span><br><span class="line"><span class="number">2423.0</span> </span><br><span class="line"><span class="number">32.0</span> </span><br><span class="line"><span class="number">423.0</span> </span><br><span class="line"><span class="number">423.0</span> </span><br><span class="line"><span class="number">23.0</span> - <span class="number">2423.0</span> - <span class="number">32.0</span> - <span class="number">423.0</span> - <span class="number">423.0</span> -</span><br></pre></td></tr></table></figure><h3 id="读取二进制文件"><a href="#读取二进制文件" class="headerlink" title="读取二进制文件"></a>读取二进制文件</h3><p>Scala没有提供读取二进制文件的方法，需要使用Java类库</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">File</span>, <span class="type">FileInputStream</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取二进制文件</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/6.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">InputStream</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> file: <span class="type">File</span> = <span class="keyword">new</span> <span class="type">File</span>(<span class="string">"test.txt"</span>)</span><br><span class="line">        <span class="keyword">val</span> in = <span class="keyword">new</span> <span class="type">FileInputStream</span>(file)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> c = <span class="number">0</span> ;</span><br><span class="line">        <span class="keyword">while</span>( c != <span class="number">-1</span> )&#123;</span><br><span class="line">            c = in.read()</span><br><span class="line">            print(c.toChar)</span><br><span class="line">        &#125;</span><br><span class="line">        in.close()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h2><p>Scala也没有对写入文件的内建支持，依旧可以使用Java类库来实现。如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> out = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="string">"numbers.txt"</span>)</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">100</span>) out.println(i)</span><br><span class="line">out.close()</span><br></pre></td></tr></table></figure></p><p>但是在使用这里printf方法时，传递AnyVal（比如各种数字）类型给方法时，编译器会要求将其转换成</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">AnyRef</span>：</span><br><span class="line">out.printf(<span class="string">"%6d %10.2f"</span>, quantity.asInstanceOf[<span class="type">AnyRef</span>],</span><br><span class="line">  price.asInstanceOf[<span class="type">AnyRef</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为了避免这个麻烦，可以使用String类的format方法</span></span><br><span class="line">out.printf(<span class="string">"%6d %10.2f"</span>.format(quantity, price))</span><br></pre></td></tr></table></figure><h2 id="访问目录"><a href="#访问目录" class="headerlink" title="访问目录"></a>访问目录</h2><p>目前没有“正式的”用来访问目录中所有文件，或递归遍历所有目录的类。（本章各种没有内建没有正式是闹哪样啊！也无所谓了，用Java类库就是了。）下面探讨一下替代方案。<br>遍历某目录下所有子目录的函数：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">File</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subdirs</span></span>(dir: <span class="type">File</span>): <span class="type">Iterator</span>[<span class="type">File</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> children = dir.listFiles.filter(_.isDirectory)</span><br><span class="line">  children.toIterator ++ children.toIterator.flatMap(subdirs _)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>// 调用打印出所有的子目录</p><h2 id="反-序列化"><a href="#反-序列化" class="headerlink" title="反/序列化"></a>反/序列化</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> fred = <span class="keyword">new</span> <span class="type">Person</span>(...)</span><br><span class="line"><span class="keyword">import</span> java.io._</span><br><span class="line"><span class="keyword">val</span> out = <span class="keyword">new</span> <span class="type">ObjectOutputStream</span>(<span class="keyword">new</span> <span class="type">FileOutputStream</span>(<span class="string">"/tmp/test.obj"</span>))</span><br><span class="line">out.writeObject(fred)</span><br><span class="line">out.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> in = <span class="keyword">new</span> <span class="type">ObjectInputStream</span>(<span class="keyword">new</span> <span class="type">FileInputStream</span>(<span class="string">"/tmp/test.obj"</span>))</span><br><span class="line"><span class="keyword">val</span> savedFred = in.readObject().asInstanceOf[<span class="type">Person</span>]</span><br><span class="line">in.close()</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--继承</title>
      <link href="/2016/04/02/Scala-%E7%BB%A7%E6%89%BF/"/>
      <url>/2016/04/02/Scala-%E7%BB%A7%E6%89%BF/</url>
      <content type="html"><![CDATA[<p>　　关于<code>scala继承</code>，其实很简单，基本思想和java都是相同的。主要不同在于，一些小小的细节，比如重写是需要用override,只有主构造器可以调用超类的主构造器等。</p><a id="more"></a><h2 id="重写"><a href="#重写" class="headerlink" title="重写"></a>重写</h2><p><code>继承</code>就是从已有的类中通过<code>extends关键字</code>派生出新的类，已有的类叫<code>父类</code>，新派生出的类叫<code>子类</code>。子类就拥有父类非私有的属性和行为，并能扩展新的属性和行为。<code>重写</code>（override）就是子类去重新定义父类的属性和行为。</p><ol><li><code>继承父类使用extends关键字</code></li><li><code>重写父类非私有属性和行为（非抽象方法）时必须使用override</code></li><li>调用父类的方法时使用<code>super</code>关键字,字段不需要</li><li><code>私有（private）</code>方法和属性子类无法获取和重写</li><li><code>受保护（protected）</code>方法或属性只有子类能获取和重写</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 继承</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/4.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    <span class="comment">//父类</span></span><br><span class="line">    <span class="keyword">val</span> name = <span class="string">"xiaomo"</span>;<span class="comment">//通过val重写</span></span><br><span class="line">    <span class="keyword">val</span> age = <span class="number">25</span> ; <span class="comment">//通过val重写</span></span><br><span class="line">    <span class="keyword">var</span> height = <span class="number">175.0</span> ;<span class="comment">//子类没有重写</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> six = <span class="number">0</span> ;<span class="comment">//私有字段</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">val</span> money = <span class="number">9999999</span>;<span class="comment">//protected</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//无参方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">supSex</span> </span>= six ;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//say方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">say</span></span>(info:<span class="type">String</span>)&#123;</span><br><span class="line">        println(<span class="string">"Parent say ,"</span>+ info)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubClass</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123; <span class="comment">//子类</span></span><br><span class="line">    <span class="comment">//val重写父类val参数</span></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> name = <span class="string">"xiaoxiaomo"</span></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> age  = <span class="number">24</span> ;</span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> money =  <span class="number">99999</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//val重写不带参数的def</span></span><br><span class="line">    <span class="comment">//调用父类方法使用super关键字</span></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> supSex: <span class="type">Int</span> = &#123;</span><br><span class="line">        <span class="keyword">if</span>( <span class="keyword">super</span>.supSex == <span class="number">0</span> )</span><br><span class="line">            <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//def只能重写一个def方法</span></span><br><span class="line">    <span class="comment">//访问父类字段不需要使用supper，直接访问即可</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">say</span></span>(info : <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">"SubClass say ,"</span>+ info + <span class="string">" age:"</span>+age +<span class="string">" name:"</span>+name )</span><br><span class="line">        println(<span class="string">"height:"</span>+height + <span class="string">" money:"</span>+money)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Test</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test2</span> <span class="keyword">extends</span> <span class="title">App</span></span>&#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SubClass</span>().say(<span class="string">"Hello!"</span>)</span><br><span class="line">    print(<span class="keyword">new</span> <span class="type">SubClass</span>().supSex)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SubClass say ,Hello! age:<span class="number">24</span> name:xiaoxiaomo</span><br><span class="line">height:<span class="number">175.0</span> money:<span class="number">99999</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>在每一个对象中，我们<code>隐式继承java.lang.Object</code>的一些方法。这些方法我们同样可以去重写，常见的是去重写<strong>toString()方法</strong>、<strong>equals()方法</strong>，如下图所示：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160404120452.png" alt=""></p><ul><li><code>注意</code>（重写的限制） ：</li></ul><ol><li>def只能重写另一个def</li><li>val只能重写另一个val或不带参数的def</li><li>var只能重写另一个抽象的var（下面抽象类中会讲到）</li></ol><h2 id="超类构造器"><a href="#超类构造器" class="headerlink" title="超类构造器"></a>超类构造器</h2><p>对于构造器，在前面<a href="http://blog.xiaoxiaomo.com/2016/03/28/Scala-%E7%B1%BB/">Scala–类</a>的博文中已经讲解，它和java的构造器是有一定区别的。</p><ol><li>因为子类辅助构造器必须调用子类主构造器，所以子类辅助构造器就无法调用父类的构造器</li><li>所以就必须得子类主构造器去调用超类的构造器</li><li>由于主构造器和类交织在一起，所以<code>调用父类构造器也会和类交织在一起</code></li></ol><ul><li>来看一下下面的<strong>事例</strong>，1、首先<strong>定义一个父类</strong>，父类的主构造器数(有参数age),一个辅助构造器(有参数name和age)</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.demo.ch08</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 继承-构造器</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/4.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstructorPartDemo</span>(<span class="params">val age :<span class="type">Int</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> name  = <span class="string">"xiaoxiaomo"</span></span><br><span class="line">    <span class="keyword">val</span> height = <span class="number">178</span> ;</span><br><span class="line">    println(<span class="string">"父类主构造器"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//辅助构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>( name : <span class="type">String</span>, age : <span class="type">Int</span>)&#123;</span><br><span class="line">        <span class="keyword">this</span>(age)<span class="comment">//必须在构造函数首行</span></span><br><span class="line">        println(<span class="string">"父类，辅助构造器，name:"</span>+name+<span class="string">" age:"</span>+age+<span class="string">" height:"</span>+height)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>定义<strong>三个子类</strong>，第一个继承超类的主主构造器，第二个继承超类的辅助构造器，第三个想继承父类的无参构造器，但由于超类没有无参的构造器，所以不会通过编译，下面来看一看代码：</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 第一个子类</span></span><br><span class="line"><span class="comment"> * 继承超类的主构造器</span></span><br><span class="line"><span class="comment"> * @param age 传递给父类</span></span><br><span class="line"><span class="comment"> * @param name</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstructorSub1</span>(<span class="params">age:<span class="type">Int</span>,override val name:<span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">ConstructorPartDemo</span>(<span class="params">age</span>)</span>&#123;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"子类1，主构造器"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//主构造器重已经重写了字段name，下面就不能再次重写</span></span><br><span class="line">    <span class="comment">//override val name  = "xiaoxiaomo"</span></span><br><span class="line">    <span class="comment">//辅助构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>( name : <span class="type">String</span>, age : <span class="type">Int</span>)&#123;</span><br><span class="line">        <span class="keyword">this</span>(age,name)</span><br><span class="line">        println(<span class="string">"子类1，辅助构造器，name:"</span>+name+<span class="string">" age:"</span>+age+<span class="string">" height:"</span>+height)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 第二个子类</span></span><br><span class="line"><span class="comment"> * 继承超类的辅助构造器</span></span><br><span class="line"><span class="comment"> * @param age 传递给父类</span></span><br><span class="line"><span class="comment"> * @param name 传递给父类</span></span><br><span class="line"><span class="comment"> * @param height</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstructorSub2</span>(<span class="params">age:<span class="type">Int</span>,override val name:<span class="type">String</span>,height:<span class="type">Double</span></span>) <span class="keyword">extends</span> <span class="title">ConstructorPartDemo</span>(<span class="params">name,age</span>)</span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    println(<span class="string">"子类2，主构造器"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//辅助构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>( name : <span class="type">String</span>, age : <span class="type">Int</span>)&#123;</span><br><span class="line">        <span class="keyword">this</span>( age , name , <span class="number">175</span> )</span><br><span class="line">        println(<span class="string">"子类2，辅助构造器，name:"</span>+name+<span class="string">" age:"</span>+age + <span class="string">" height:"</span>+height)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 第三个子类，无法编译</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//下面写法是不会通过编译的</span></span><br><span class="line"><span class="comment">//因为没有ConstructorPartDemo()的无参构造器</span></span><br><span class="line"><span class="comment">//class ConstructorSub3(age:Int,override val name:String) extends ConstructorPartDemo()&#123;</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//TEST</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> <span class="keyword">extends</span> <span class="title">App</span></span>&#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ConstructorSub1</span>(<span class="string">"one-snail"</span>,<span class="number">11</span>)</span><br><span class="line">    println(<span class="string">"----------------"</span>)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ConstructorSub2</span>(<span class="string">"two-snail"</span>,<span class="number">22</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>通过调用Test，运行结果：</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">父类主构造器</span><br><span class="line">子类<span class="number">1</span>，主构造器</span><br><span class="line">子类<span class="number">1</span>，辅助构造器，name:one-snail age:<span class="number">11</span> height:<span class="number">178</span></span><br><span class="line">----------------</span><br><span class="line">父类主构造器</span><br><span class="line">父类，辅助构造器，name:two-snail age:<span class="number">22</span> height:<span class="number">178</span></span><br><span class="line">子类<span class="number">2</span>，主构造器</span><br><span class="line">子类<span class="number">2</span>，辅助构造器，name:two-snail age:<span class="number">22</span> height:<span class="number">175.0</span></span><br></pre></td></tr></table></figure><h2 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h2><p><code>抽象类</code>，往往用来描述一个事物的抽象概念，不能具体指定为某一实体（<code>不能实例化</code>）。比如，我们所看到的食物苹果和梨，我们也可以统称为水果，苹果和梨就是具体的东西，水果（<strong>不能具体指某一实物</strong>）就是一个苹果和梨的抽象的概念。<br>申明抽象类使用<code>abstract</code>，在scala中，抽象类和类中的方法、字段和类型都可以是抽象。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 抽象类</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/4.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//没有初始化值，这是一个带有get方法的抽象字段</span></span><br><span class="line">    <span class="keyword">val</span> id:<span class="type">Int</span></span><br><span class="line">    <span class="comment">//没有初始化值，这是一个带有get/set方法的抽象字段</span></span><br><span class="line">    <span class="keyword">var</span> age:<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">name</span></span>:<span class="type">Unit</span> ; <span class="comment">//没有方法体</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="comment">//带参数的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sayHi</span></span>( who:<span class="type">String</span> ) ; <span class="comment">//没有方法体</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="comment">//带参数和返回值(Int)的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>( a:<span class="type">Int</span> ,b:<span class="type">Int</span> ) : <span class="type">Int</span>; <span class="comment">//没有方法体</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//这不是一个抽象方法而是一个普通方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getOther</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">        println(<span class="string">"这个方法自己有方法体"</span>)<span class="comment">//有方法体</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>实现和测试</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//实现抽象类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AbstractImp</span> <span class="keyword">extends</span> <span class="title">AbstractDemo</span></span>&#123;</span><br><span class="line">    <span class="keyword">val</span> id: <span class="type">Int</span> = <span class="number">17</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">        a + b</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">name</span> </span>= println(<span class="string">"xiaomo"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//不需要使用override</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sayHi</span></span>(who: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">"Hello everyone! My name is "</span>+who + <span class="string">" And "</span>+ age + <span class="string">" years old！"</span>)</span><br><span class="line">        getOther() ;<span class="comment">//调用自己的方法</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> age: <span class="type">Int</span> = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//这不是一个抽象方法而是一个普通方法</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getOther</span></span>(): <span class="type">Unit</span> = <span class="keyword">super</span>.getOther()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//TEST</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test3</span> <span class="keyword">extends</span> <span class="title">App</span></span>&#123;</span><br><span class="line">    <span class="keyword">val</span> abs = <span class="keyword">new</span> <span class="type">AbstractImp</span>()</span><br><span class="line">    abs.name</span><br><span class="line">    println(abs.sum(<span class="number">7</span>,<span class="number">8</span>)) <span class="comment">//调用求和方法</span></span><br><span class="line">    abs.sayHi(<span class="string">"xiaoxiaomo"</span>)<span class="comment">//sayHi方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">xiaomo</span><br><span class="line"><span class="number">15</span></span><br><span class="line">Hello everyone! My name is xiaoxiaomo And <span class="number">25</span> years old！</span><br><span class="line">这个方法自己有方法体</span><br></pre></td></tr></table></figure><ul><li>抽象字段：<code>具体类中给字段申明的时候不给字段赋值，该字段变为抽象字段</code></li><li>抽象方法：<strong>抽象方法不需要（也不允许）有abstract修饰符</strong>，<code>一个方法只要是没有实现（没有等号或没有方法体），它就是抽象的</code>，<strong>在子类中覆写或者覆写接口中的非抽象方法（方法有具体实现）要使用override关键字</strong>。</li><li>抽象类型：<code>scala中的类型成员也可以是抽象的</code>。抽象字段和抽象方法都是只有字段或者方法的定义，而没有字段或者方法的具体实现</li></ul><h2 id="Scala继承层级"><a href="#Scala继承层级" class="headerlink" title="Scala继承层级"></a>Scala继承层级</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160404161713.png" alt="">(图片来源于网络)</p><ol><li><code>Any类</code>：是整个继承层级的跟，下面有AnyVal和AnyRef</li><li><code>AnyVal</code>：包含了所用值类型以及Unit，</li><li><code>AnyRef</code>：相当于java的Object,所用的其他都是AnyRef的子类</li></ol><ul><li><strong>AnyVal</strong></li></ul><p>AnyVal并没有追加任何方法，它只是所有值类型的一个标记</p><ul><li><strong>AnyRef</strong></li></ul><p>AnyRef，追加了来之Object类的监视方法wait和notify/notifyAll，同时还提供了一个带函数参数的方法synchronized。</p><ul><li><strong>ScalaObject</strong></li></ul><p>所用的Scala类都实现ScalaObject这个标记接口，这个接口没有定义任何方法</p><ul><li><strong>Nothing/Null</strong></li></ul><ol><li>在继承的另一端是Nothing和Null类型</li><li>Null类型的唯一实例是null值，可以将null赋值给任何引用类型，但不能赋值给值类型的变量。</li><li>Nothing类型没有实例，他对于泛型结构时常用，空列表Nil的类型是List[Nothing]，它是List[T]的子类型。</li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-字节码指令</title>
      <link href="/2016/04/01/Java-%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4/"/>
      <url>/2016/04/01/Java-%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>　　<code>字节码</code>是JVM的机器语言。JVM加载类文件时，对类中的每个方法，都会得到一个<code>字节码流</code>。这些字节码流保存在JVM的方法区中。在程序运行过程中，当一个方法被调用时，它的字节码流就会被执行。</p><a id="more"></a><ul><li>基础简介</li></ul><ol><li>方法的字节码流就是JVM的指令（instruction）序列。</li><li><code>Java虚拟机的指令</code>：由<strong>一个字节长度</strong>、代表着某种特定操作含义的数字（<code>操作码Opcode</code>）以及跟随其后的0-n个代表此操作所需参数（<code>操作数Operaands</code>）而构成。即<strong>指令=操作码+操作数</strong>，虚拟机中许多指令并不包含操作数，只有一个操作码。</li><li>JVM中，所有的计算都是围绕栈。因为JVM没有存储任意数值的寄存器，<strong>所有的操作数在计算开始之前，都必须先压入栈中</strong>。</li></ol><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160402093442.png" alt=""></p><p>源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/31.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LineNumberDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String c = <span class="string">"c"</span> ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String a = <span class="string">"abc"</span> ;</span><br><span class="line">        String b = <span class="string">"ab"</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>字节码和数据类型</li></ul><p>在java虚拟机中，<code>大多数的指令都包含了操作数所对应的数据类型</code>。这一点很重要，理解了这一点很多指令都能联想记忆，例如：<em>iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload就是加载float类型的数据</em>。下面列出：</p><ol><li>i–<strong>int</strong></li><li>l–<strong>long</strong></li><li>s–<strong>short</strong></li><li>b–<strong>byte</strong></li><li>c–<strong>char</strong></li><li>f–<strong>float</strong></li><li>d–<strong>double</strong></li><li>a–<strong>reference</strong></li></ol><h2 id="加载和存储指令"><a href="#加载和存储指令" class="headerlink" title="加载和存储指令"></a>加载和存储指令</h2><p>每个操作如果需要从操作栈中读参数，则总是将这些<strong>参数出栈</strong>，如果操作有结果，总是会将结果<strong>入栈</strong>。</p><p><code>加载</code>：将数据从<strong>栈帧的局部变量表</strong>加载到<strong>操作数栈</strong>;<br><code>存储</code>：将<strong>操作数栈</strong>存储到<strong>栈帧的局部变量表</strong>;</p><ul><li>1、<code>将一个局部变量加载到操作栈</code>-<code>load</code>。例如： <strong>iload</strong>、<strong>iload_n</strong>、<strong>lload</strong>、<strong>lload_n</strong>、<strong>fload</strong>、<strong>fload_n</strong>、<strong>dload</strong>、<strong>dload_n</strong>、<strong>aload</strong>、<strong>aload_n</strong></li><li>2、<code>将一个数值从操作数栈存储到局部变量表</code>-<code>store</code>。例如： <strong>istore</strong>、<strong>istore_n</strong>、<strong>lstore</strong>、<strong>lstore_n</strong>、<strong>fstore</strong>、<strong>fstore_n</strong>、<strong>dstore</strong>、<strong>dstore_n</strong>、<strong>astore</strong>、<strong>astore_n</strong></li><li>3、<code>将一个常量加载到操作数栈</code>。例如： <strong>bipush</strong>、<strong>sipush</strong>、<strong>ldc</strong>、<strong>ldc_w</strong>、<strong>ldc2_w</strong>、<strong>aconst_null</strong>、<strong>iconst_m1</strong>、<strong>iconst_i</strong>、<strong>lconst_l</strong>、<strong>fconst_f</strong>、<strong>dconst_d</strong></li></ul><p>例如，下面事例1：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/1.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoadStoreDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">128</span> ;<span class="comment">//会自动拆箱为short</span></span><br><span class="line">        <span class="keyword">int</span> b = <span class="number">22</span> ;<span class="comment">//会自动拆箱为byte</span></span><br><span class="line">        String c =<span class="string">"momo"</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过<code>javap -c</code>编译后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">LoadStoreDemo</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> java.lang.String a;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.LoadStoreDemo();<span class="comment">//默认构造方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0 <span class="comment">//一个引用类型的局部变量加载到操作栈</span></span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V //</span></span><br><span class="line">   <span class="number">4</span>:   <span class="keyword">return</span><span class="comment">//没有返回值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(java.lang.String[]); <span class="comment">//main方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   sipush  <span class="number">128</span> <span class="comment">//将一个short类型(int自动拆箱)常量加载到操作数栈（压入栈顶）</span></span><br><span class="line">   <span class="number">3</span>:   istore_1 <span class="comment">//将数值从操作数栈存储到局部变量表，即a中(弹栈)</span></span><br><span class="line">   <span class="number">4</span>:   bipush  <span class="number">22</span> <span class="comment">//将一个byte类型(自动拆箱)常量压入栈顶</span></span><br><span class="line">   <span class="number">6</span>:   istore_2 <span class="comment">//将数值从操作数栈存储到局部变量表中，即b中</span></span><br><span class="line">   <span class="number">7</span>:   ldc     #<span class="number">2</span>; <span class="comment">//String momo //将字符串常量压入栈顶</span></span><br><span class="line">   <span class="number">9</span>:   astore_3 <span class="comment">//将数值从操作数栈存储到局部变量表c中</span></span><br><span class="line">   <span class="number">10</span>:   <span class="keyword">return</span><span class="comment">//没有返回值</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运算指令"><a href="#运算指令" class="headerlink" title="运算指令"></a>运算指令</h2><p><code>算术指令</code>，用于对两个操作数栈上的值进行某种特定运算，并把结果<strong>重新存入到操作栈顶</strong>。<br><code>运算指令分为两种</code>：<strong>整型（int,long）</strong>、<strong>浮点型（float,double）</strong>,对于没有直接支持 byte、short、char和boolean的算术指令使用int。</p><p>下面来看一下<strong>所有的算术指令</strong>：</p><ul><li><code>加法指令</code>：<strong>iadd</strong>、<strong>ladd</strong>、<strong>fadd</strong>、<strong>dadd</strong></li><li><code>减法指令</code>：<strong>isub</strong>、<strong>lsub</strong>、<strong>fsub</strong>、<strong>dsub</strong></li><li><code>乘法指令</code>：<strong>imul</strong>、<strong>lmul</strong>、<strong>fmul</strong>、<strong>dmul</strong></li><li><code>除法指令</code>：<strong>idiv</strong>、<strong>ldiv</strong>、<strong>fdiv</strong>、<strong>ddiv</strong></li><li><code>求余指令</code>：<strong>irem</strong>、<strong>lrem</strong>、<strong>frem</strong>、<strong>drem</strong></li><li><code>取反指令</code>：<strong>ineg</strong>、<strong>lneg</strong>、<strong>fneg</strong>、<strong>dneg</strong></li><li><code>位移指令</code>：<strong>ishl</strong>、<strong>ishr</strong>、<strong>iushr</strong>、<strong>lshl</strong>、<strong>lshr</strong>、<strong>lushr</strong></li><li><code>按位或指令</code>：<strong>ior</strong>、<strong>lor</strong></li><li><code>按位与指令</code>：<strong>iand</strong>、<strong>land</strong></li><li><code>按位异或指令</code>：<strong>ixor</strong>、<strong>lxor</strong></li><li><code>局部变量自增指令</code>：<strong>iinc</strong>(是少见的直接更新一个局部变量而无需在操作数栈中进行读写的指令)</li><li><code>比较指令</code>：<strong>dcmpg</strong>、<strong>dcmpl</strong>、<strong>fcmpg</strong>、<strong>fcmpl</strong>、<strong>lcmp</strong></li></ul><p>java实例代码2：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/1.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OperatorDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">127</span> ;</span><br><span class="line">        <span class="keyword">int</span> b = <span class="number">127000000</span> ;</span><br><span class="line">        <span class="keyword">int</span> d = a+b ;</span><br><span class="line">        <span class="keyword">long</span> c = a*b ;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过<code>javap -c</code>编译后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">OperatorDemo</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.OperatorDemo();<span class="comment">//默认构造方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">4</span>:   <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(java.lang.String[]); <span class="comment">//main方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   bipush  <span class="number">127</span> <span class="comment">//将一个常量加载到操作数栈</span></span><br><span class="line">   <span class="number">2</span>:   istore_1 <span class="comment">//将常量从操作数栈存储到局部变量表中，即a中</span></span><br><span class="line">   <span class="number">3</span>:   ldc     #<span class="number">2</span>; <span class="comment">//int 127000000 //int类型</span></span><br><span class="line">   <span class="number">5</span>:   istore_2 <span class="comment">//将数值从操作数栈存储到局部变量表</span></span><br><span class="line">   <span class="number">6</span>:   iload_1 <span class="comment">//将一个局部变量a加载到操作栈</span></span><br><span class="line">   <span class="number">7</span>:   iload_2 <span class="comment">//将一个局部变量b加载到操作栈</span></span><br><span class="line">   <span class="number">8</span>:   iadd <span class="comment">//把上面两个操作栈中的int数据类型相加</span></span><br><span class="line">   <span class="number">9</span>:   istore_3 <span class="comment">//把相加的结果d存到布局变量表</span></span><br><span class="line">   <span class="number">10</span>:  iload_1 <span class="comment">//重复第6步操作</span></span><br><span class="line">   <span class="number">11</span>:  iload_2 <span class="comment">//重复第7步操作</span></span><br><span class="line">   <span class="number">12</span>:  imul <span class="comment">//相乘</span></span><br><span class="line">   <span class="number">13</span>:  i2l <span class="comment">//int类型转为long类型</span></span><br><span class="line">   <span class="number">14</span>:  lstore  <span class="number">4</span> <span class="comment">//把相乘的结果c存到布局变量表</span></span><br><span class="line">   <span class="number">16</span>:  <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="类型转换指令"><a href="#类型转换指令" class="headerlink" title="类型转换指令"></a>类型转换指令</h2><p><code>类型转换指令</code>，数据类型进行相互转换，一般用于实现用户代码的<strong>显式类型转换</strong>操作，或者用来处理 Java 虚拟机字节码指令集中<code>指令非完全独立</code>的问题。</p><p>宽化类型转换</p><ul><li>int 类型到 long、float 或者 double 类型</li><li>long 类型到 float、double 类型</li><li>float 类型到 double 类型</li></ul><p>窄化类型转换</p><p>i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l 和 d2f。窄化类型转换可能会导致转换结果产生不同的正负号、不同的数量级，转换过程很可能会导致数值丢失精度。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TypeCastDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">typeCase</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">128</span> ;</span><br><span class="line">        <span class="keyword">short</span> j = (<span class="keyword">short</span>) i;</span><br><span class="line">        <span class="keyword">double</span> d = i*<span class="number">5.20</span> ;</span><br><span class="line">        <span class="keyword">int</span> z = (<span class="keyword">int</span>) d;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">TypeCastDemo</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.TypeCastDemo();</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">4</span>:   <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> typeCase();<span class="comment">//typeCase方法（下面简单的介绍一下）</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   sipush  <span class="number">128</span> <span class="comment">//将一个常量压入栈顶</span></span><br><span class="line">   <span class="number">3</span>:   istore_1 <span class="comment">//将栈顶的值弹出（弹栈）存储到局部变量表中，i中</span></span><br><span class="line">   <span class="number">4</span>:   iload_1 <span class="comment">//将局部变量中的i加载到操作栈</span></span><br><span class="line">   <span class="number">5</span>:   i2s <span class="comment">//将i的int类型转为short</span></span><br><span class="line">   <span class="number">6</span>:   istore_2 <span class="comment">//并存储到局布变量表中，j中</span></span><br><span class="line">   <span class="number">7</span>:   iload_1 <span class="comment">//加载局部变量i，到操作栈</span></span><br><span class="line">   <span class="number">8</span>:   i2d <span class="comment">//将操作栈变量i的类型转为double</span></span><br><span class="line">   <span class="number">9</span>:   ldc2_w  #<span class="number">2</span>; <span class="comment">//double 5.2d //</span></span><br><span class="line">   <span class="number">12</span>:  dmul <span class="comment">//将操作栈中的值相乘</span></span><br><span class="line">   <span class="number">13</span>:  dstore_3 <span class="comment">//将相乘的结果存储到局部变量表，d中</span></span><br><span class="line">   <span class="number">14</span>:  dload_3 <span class="comment">//加载局部变量表中的d，到操作栈</span></span><br><span class="line">   <span class="number">15</span>:  d2i <span class="comment">//将double类型的变量d转为int类型</span></span><br><span class="line">   <span class="number">16</span>:  istore  <span class="number">5</span> <span class="comment">//把结果存储到局部变量表中，z中</span></span><br><span class="line">   <span class="number">18</span>:  <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="对象创建与操作"><a href="#对象创建与操作" class="headerlink" title="对象创建与操作"></a>对象创建与操作</h2><p>虽然类实例和数组都是对象，但 Java 虚拟机对类实例和数组的创建与操作使用了不同的字节码指令：</p><p><strong>创建类实例的指令</strong>：<code>new</code><br><strong>创建数组的指令</strong>：<code>newarray</code>，<code>anewarray</code>，<code>multianewarray</code><br><strong>访问类字段（static字段，或者称为类变量）和实例字段（非static字段，或者成为实例变量）的指令</strong>：<code>getfield</code>、<code>putfield</code>、<code>getstatic</code>、<code>putstatic</code><br><strong>把一个数组元素加载到操作数栈的指令</strong>：<code>baload</code>、<code>caload</code>、<code>saload</code>、<code>iaload</code>、<code>laload</code>、<code>faload</code>、<code>daload</code>、<code>aaload</code><br><strong>将一个操作数栈的值储存到数组元素中的指令</strong>：<code>bastore</code>、<code>castore</code>、<code>sastore</code>、<code>iastore</code>、<code>fastore</code>、<code>dastore</code>、<code>aastore</code><br><strong>取数组长度的指令</strong>：<code>arraylength</code><br><strong>检查类实例类型的指令</strong>：<code>instanceof</code>、<code>checkcas</code></p><p>看看下面的实例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对象创建与操作</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Instantiation</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String NAME = <span class="string">"LIU BI"</span> ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr1 = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">5</span>] ;</span><br><span class="line">        arr1[<span class="number">0</span>] = <span class="number">86</span> ;</span><br><span class="line">        arr1[<span class="number">2</span>] = <span class="number">19</span> ;</span><br><span class="line">        String[] strs = &#123;<span class="string">"2"</span>,<span class="string">"xiao"</span>,<span class="string">"mo"</span> , NAME &#125; ;</span><br><span class="line">        String tc = <span class="keyword">new</span> String(<span class="string">"abc"</span>) ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译后<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">Instantiation</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> java.lang.String NAME;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.Instantiation();</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">4</span>:   <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(java.lang.String[]); <span class="comment">//main方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   iconst_5 <span class="comment">//将常量5压入栈顶</span></span><br><span class="line">   <span class="number">1</span>:   newarray <span class="keyword">int</span> <span class="comment">//创建一个int类型的数组</span></span><br><span class="line">   <span class="number">3</span>:   astore_1 <span class="comment">//将数组存储到局部变量表中，arr1中</span></span><br><span class="line">   <span class="number">4</span>:   aload_1 <span class="comment">//将局部变量arr1加载到操作栈</span></span><br><span class="line">   <span class="number">5</span>:   iconst_0 <span class="comment">//将常量0加载到操作数栈，</span></span><br><span class="line">   <span class="number">6</span>:   bipush  <span class="number">86</span> <span class="comment">//将一个byte类型常量86加载到操作数栈</span></span><br><span class="line">   <span class="number">8</span>:   iastore <span class="comment">//将一个操作数栈的值86储存到数组元素中,arr[0]中</span></span><br><span class="line">   <span class="number">9</span>:   aload_1 <span class="comment">//将局部变量arr1加载到操作栈</span></span><br><span class="line">   <span class="number">10</span>:  iconst_2 <span class="comment">//将常量2加载到操作数栈</span></span><br><span class="line">   <span class="number">11</span>:  bipush  <span class="number">19</span> <span class="comment">//将一个byte类型常量19加载到操作数栈</span></span><br><span class="line">   <span class="number">13</span>:  iastore <span class="comment">//将一个操作数栈的值19储存到数组元素中,arr[2]中</span></span><br><span class="line">   <span class="number">14</span>:  iconst_4 <span class="comment">// 将常量4压入栈顶</span></span><br><span class="line">   <span class="number">15</span>:  anewarray       #<span class="number">2</span>; <span class="comment">//class java/lang/String //创建一个String类型的数组</span></span><br><span class="line">   <span class="number">18</span>:  dup <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">19</span>:  iconst_0 <span class="comment">//将常量0加载到操作数栈，</span></span><br><span class="line">   <span class="number">20</span>:  ldc     #<span class="number">3</span>; <span class="comment">//String 2 //字符串常量加载到操作数栈,2</span></span><br><span class="line">   <span class="number">22</span>:  aastore <span class="comment">//将引用类型的操作数栈的值储存到数组元素中，strs[0]中</span></span><br><span class="line">   <span class="number">23</span>:  dup <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">24</span>:  iconst_1 <span class="comment">//将常量1加载到操作数栈，</span></span><br><span class="line">   <span class="number">25</span>:  ldc     #<span class="number">4</span>; <span class="comment">//String xiao //字符串常量xiao加载到操作数栈</span></span><br><span class="line">   <span class="number">27</span>:  aastore <span class="comment">//将引用类型的操作数栈的值储存到数组元素中，strs[1]中</span></span><br><span class="line">   <span class="number">28</span>:  dup <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">29</span>:  iconst_2 <span class="comment">//将常量2加载到操作数栈，</span></span><br><span class="line">   <span class="number">30</span>:  ldc     #<span class="number">5</span>; <span class="comment">//String mo //字符串常量加载到操作数栈</span></span><br><span class="line">   <span class="number">32</span>:  aastore <span class="comment">//将引用类型的操作数栈的值储存到数组元素中，strs[2]中</span></span><br><span class="line">   <span class="number">33</span>:  dup  <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">34</span>:  iconst_3 <span class="comment">//将常量3加载到操作数栈，</span></span><br><span class="line">   <span class="number">35</span>:  getstatic       #<span class="number">6</span>; <span class="comment">//Field NAME:Ljava/lang/String; //获取静态变量</span></span><br><span class="line">   <span class="number">38</span>:  aastore <span class="comment">//将引用类型的操作数栈的值储存到变量中</span></span><br><span class="line">   <span class="number">39</span>:  astore_2 <span class="comment">//将引用类型的操作数栈的值储存到变量中</span></span><br><span class="line">   <span class="number">40</span>:  <span class="keyword">new</span>     #<span class="number">2</span>; <span class="comment">//class java/lang/String //实例化一个对象</span></span><br><span class="line">   <span class="number">43</span>:  dup <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">44</span>:  ldc     #<span class="number">7</span>; <span class="comment">//String abc //将字符串常量abc加载到操作数栈</span></span><br><span class="line">   <span class="number">46</span>:  invokespecial   #<span class="number">8</span>; <span class="comment">//Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V //调用实例方法new String</span></span><br><span class="line">   <span class="number">49</span>:  astore_3 <span class="comment">//将引用类型的操作数栈的值储存到变量中，tc中</span></span><br><span class="line">   <span class="number">50</span>:  <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> &#123;&#125;; <span class="comment">//静态区域</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   ldc     #<span class="number">9</span>; <span class="comment">//String LIU BI //字符串常量‘LIU BI’加载到操作数栈</span></span><br><span class="line">   <span class="number">2</span>:   putstatic       #<span class="number">6</span>; <span class="comment">//Field NAME:Ljava/lang/String;//实例静态字段</span></span><br><span class="line">   <span class="number">5</span>:   <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="操作数栈管理指令"><a href="#操作数栈管理指令" class="headerlink" title="操作数栈管理指令"></a>操作数栈管理指令</h2><p>虚拟机提供了一些用于直接操作操作数栈的指令，包括：pop、pop2、dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2 和 swap。如上事例，直接操作数栈</p><h2 id="控制转移指令"><a href="#控制转移指令" class="headerlink" title="控制转移指令"></a>控制转移指令</h2><p><code>控制转移指令</code>，可以让JVM有条件或无条件地<strong>从指定指令</strong>转移到指令的下一条指令<strong>继续执行程序</strong>。控制转移指令包括有：</p><p><code>条件分支</code>：<strong>ifeq</strong>、<strong>iflt</strong>、<strong>ifle</strong>、<strong>ifne</strong>、<strong>ifgt</strong>、<strong>ifge</strong>、<strong>ifnull</strong>、<strong>ifnonnull</strong>、<strong>if_icmpeq</strong>、<strong>if_icmpne</strong>、<strong>if_icmplt</strong>, <strong>if_icmpgt</strong>、<strong>if_icmple</strong>、<strong>if_icmpge</strong>、<strong>if_acmpeq</strong> 和 <strong>if_acmpne</strong><br><code>复合条件分支</code>：<strong>tableswitch</strong>、<strong>lookupswitch</strong><br><code>无条件分支</code>：<strong>goto</strong>、<strong>goto_w</strong>、<strong>jsr</strong>、<strong>jsr_w</strong>、<strong>ret</strong></p><ul><li>事例代码</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 流程控制语句</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ControlStatement</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> a , <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> max = a ;</span><br><span class="line">        <span class="keyword">if</span>( b &gt; a )&#123;</span><br><span class="line">            max = b ;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">formatPrint</span><span class="params">( <span class="keyword">int</span>[] arr )</span></span>&#123;</span><br><span class="line">        System.out.print(<span class="string">"["</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; arr.length ; i++ )&#123;</span><br><span class="line">            System.out.print(arr[i]);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>( i &lt; arr.length -<span class="number">1</span> )&#123;</span><br><span class="line">                System.out.print(<span class="string">","</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.print(<span class="string">"]"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>反编译后字节码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">ControlStatement</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.ControlStatement();</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">4</span>:   <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> max(<span class="keyword">int</span>, <span class="keyword">int</span>); <span class="comment">//max方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   iload_1 <span class="comment">//将一个局部变量加载到操作数栈，a</span></span><br><span class="line">   <span class="number">1</span>:   istore_3 <span class="comment">//将上面操作数栈存储到局部变量表中，max</span></span><br><span class="line">   <span class="number">2</span>:   iload_2 <span class="comment">//将变量压入操作数栈中，b</span></span><br><span class="line">   <span class="number">3</span>:   iload_1 <span class="comment">//将变量压入操作数栈中，a</span></span><br><span class="line">   <span class="number">4</span>:   if_icmple <span class="number">9</span> <span class="comment">//比较栈顶的两个值的大小,如果为false回调到第9条字节码处执行</span></span><br><span class="line">   <span class="number">7</span>:   iload_2 <span class="comment">//如果判断为true,会加载栈顶的值，b</span></span><br><span class="line">   <span class="number">8</span>:   istore_3 <span class="comment">//将b值存储到局部变量max中</span></span><br><span class="line">   <span class="number">9</span>:   iload_3 <span class="comment">//如果判断为false，则会加载局部变量数值，max</span></span><br><span class="line">   <span class="number">10</span>:  ireturn <span class="comment">//返回一个int类型数据</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">formatPrint</span><span class="params">(<span class="keyword">int</span>[])</span></span>;<span class="comment">//一个静态方法</span></span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   getstatic  #<span class="number">2</span>; <span class="comment">//Field java/lang/System.out:Ljava/io/PrintStream;//获取输出流</span></span><br><span class="line">   <span class="number">3</span>:   ldc     #<span class="number">3</span>; <span class="comment">//String [ //将字符串常量‘[’压入栈顶(和加载到操作数栈一个意思)</span></span><br><span class="line">   <span class="number">5</span>:   invokevirtual #<span class="number">4</span>; <span class="comment">//Method java/io/PrintStream.print:(Ljava/lang/String;)V //io输出流</span></span><br><span class="line">   <span class="number">8</span>:   iconst_0 <span class="comment">//将常量0加载到操作数栈</span></span><br><span class="line">   <span class="number">9</span>:   istore_1 <span class="comment">//将栈顶的值出栈存储到局部变量表中，i=0</span></span><br><span class="line">   <span class="number">10</span>:  iload_1 <span class="comment">//加载局部变量i到操作栈，此时i已有值</span></span><br><span class="line">   <span class="number">11</span>:  aload_0 <span class="comment">//加载引用类型的变量到操作栈中，arr</span></span><br><span class="line">   <span class="number">12</span>:  arraylength <span class="comment">//获取数组长度，arr.length</span></span><br><span class="line">   <span class="number">13</span>:  if_icmpge <span class="number">47</span> <span class="comment">//判断局部变量i是否大于等于数组长度，如果true，跳到47条指令</span></span><br><span class="line">   <span class="number">16</span>:  getstatic #<span class="number">2</span>; <span class="comment">//Field java/lang/System.out:Ljava/io/PrintStream;//获取输出流</span></span><br><span class="line">   <span class="number">19</span>:  aload_0 <span class="comment">//加载引用类型的变量到操作栈中,arr；同第11条指令</span></span><br><span class="line">   <span class="number">20</span>:  iload_1 <span class="comment">//加载int类型的变量到操作栈中,即i</span></span><br><span class="line">   <span class="number">21</span>:  iaload <span class="comment">//把arr的数组元素加载到操作数栈中</span></span><br><span class="line">   <span class="number">22</span>:  invokevirtual   #<span class="number">5</span>; <span class="comment">//Method java/io/PrintStream.print:(I)V //调用输出打印</span></span><br><span class="line">   <span class="number">25</span>:  iload_1 <span class="comment">//加载局部变量i到操作栈</span></span><br><span class="line">   <span class="number">26</span>:  aload_0 <span class="comment">//加载引用类型的变量到操作栈中,arr；同第11条指令</span></span><br><span class="line">   <span class="number">27</span>:  arraylength <span class="comment">////获取数组长度，arr.length；同第12条指令</span></span><br><span class="line">   <span class="number">28</span>:  iconst_1 <span class="comment">//将常量1加载到操作数栈，</span></span><br><span class="line">   <span class="number">29</span>:  isub <span class="comment">//在操作数栈中使用数组长度减去变量1</span></span><br><span class="line">   <span class="number">30</span>:  if_icmpge <span class="number">41</span> <span class="comment">//如果变量i大于等于数组长度，跳转到第41条指令</span></span><br><span class="line">   <span class="number">33</span>:  getstatic #<span class="number">2</span>; <span class="comment">//Field java/lang/System.out:Ljava/io/PrintStream;//获取输出流</span></span><br><span class="line">   <span class="number">36</span>:  ldc     #<span class="number">6</span>; <span class="comment">//String , //将字符串常量‘,’压入栈顶</span></span><br><span class="line">   <span class="number">38</span>:  invokevirtual   #<span class="number">4</span>; <span class="comment">//Method java/io/PrintStream.print:(Ljava/lang/String;)V调用输出打印</span></span><br><span class="line">   <span class="number">41</span>:  iinc    <span class="number">1</span>, <span class="number">1</span> <span class="comment">//变量i自增1（局部变量表中的第1个位置的值（即i）加1）</span></span><br><span class="line">   <span class="number">44</span>:  <span class="keyword">goto</span>    <span class="number">10</span> <span class="comment">//回调到第10条指令，继续执行</span></span><br><span class="line">   <span class="number">47</span>:  getstatic       #<span class="number">2</span>; <span class="comment">//Field java/lang/System.out:Ljava/io/PrintStream;//获取输出流</span></span><br><span class="line">   <span class="number">50</span>:  ldc     #<span class="number">7</span>; <span class="comment">//String ] //将字符串常量‘]’压入栈顶</span></span><br><span class="line">   <span class="number">52</span>:  invokevirtual   #<span class="number">4</span>; <span class="comment">//Method java/io/PrintStream.print:(Ljava/lang/String;)V调用输出打印</span></span><br><span class="line">   <span class="number">55</span>:  <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法调用和返回指令"><a href="#方法调用和返回指令" class="headerlink" title="方法调用和返回指令"></a>方法调用和返回指令</h2><ul><li>四条指令用于方法调用</li></ul><p><code>invokevirtual</code>：指令<strong>用于调用对象的实例方法</strong>，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。<br><code>invokeinterface</code>：指令<strong>用于调用接口方法</strong>，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。<br><code>invokespecial</code>：指令<strong>用于调用一些需要特殊处理的实例方法</strong>，<strong>包括实例初始化方法、私有方法和父类方法</strong>。<br><code>invokestatic</code>：指令<strong>用于调用类方法（static方法）</strong>。</p><ul><li>方法返回指令</li></ul><p><code>ireturn</code>：（当返回值是 boolean、byte、char、short 和 int 类型时使用）<br><code>lreturn</code>：返回long类型<br><code>freturn</code>：返回floalt类型<br><code>dreturn</code>：返回double类型<br><code>areturn</code>：返回对象<br><code>return</code> ：指令表示为<strong>void的方法</strong>、<strong>实例初始化方法</strong>、<strong>类和接口的类初始化方法</strong>使用。</p><h2 id="抛出异常"><a href="#抛出异常" class="headerlink" title="抛出异常"></a>抛出异常</h2><p>在程序中显式抛出异常的操作会由 <code>athrow</code> 指令实现，除了这种情况，还有别的异常会在其它 Java 虚拟机指令检测到异常状况时由虚拟机自动抛出。</p><h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><p>JVM可以支持<code>方法级的同步</code>和<code>方法内部一段指令序列的同步</code>，这两种同步结构都是使用管程（<code>Monitor</code>）来支持的。</p><ul><li>方法级的同步：是隐式，即无需通过字节码指令来控制的，它<strong>实现在方法调用和返回操作之中</strong>。</li></ul><p>虚拟机可以从方法常量池中的方法表结构（method_info Structure）中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有管程，然后再执行方法，最后再方法完成（无论是正常完成还是非正常完成）时释放管程。在方法执行期间，执行线程持有了管程，其他任何线程都无法再获得同一个管程。如果一个同步方法执行期间抛出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的管程将在异常抛到同步方法之外时自动释放。</p><ul><li>同步一段指令集序列：通常是由Java语言中的<strong>synchronized块</strong>来表示的。</li></ul><p>JVM的指令集中有monitorenter和monitorexit两条指令来支持synchronized关键字的语义，正确实现 synchronized 关键字需要编译器与 Java 虚拟机两者协作支持。</p><p><code>结构化锁定（Structured Locking）</code>：是指在方法调用期间每一个管程退出都与前面的管程进入相匹配的情形。因为无法保证所有提交给 Java 虚拟机执行的代码都满足结构化锁定，所以 Java 虚拟机允许（但不强制要求）通过以下两条规则来保证结构化锁定成立。假设 T 代表一条线程，M 代表一个管程的话：</p><p>T在方法执行时持有管程 M 的次数必须与 T 在方法完成（包括正常和非正常完成）时释放管程 M 的次数相等。<br>找方法调用过程中，任何时刻都不会出现线程 T 释放管程 M 的次数比 T 持有管程 M 次数多的情况。<br>请注意，在同步方法调用时自动持有和释放管程的过程也被认为是在方法调用期间发生。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/4/2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SynDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Integer num=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> Lock lock=<span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="keyword">private</span> AtomicInteger number=<span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> SynDemo().syn() ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">syn</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//启动10个线程</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(<span class="keyword">new</span> TestSyn()).start() ;</span><br><span class="line">            <span class="comment">//new Thread(new LockTest()).start() ;</span></span><br><span class="line">            <span class="comment">//new Thread(new LockFreeTest()).start() ;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">TestSyn</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (num) &#123;  <span class="comment">// 间接的被转化为单线程了，相当于串行执行代码</span></span><br><span class="line">                <span class="keyword">if</span>(  num &lt; <span class="number">5</span> )&#123;</span><br><span class="line">                    System.out.println(String.format(</span><br><span class="line">                            <span class="string">"name:%s,   num:%s"</span>,Thread.currentThread().getName(),num));</span><br><span class="line">                    num ++ ;</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用lock方式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">LockTest</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            lock.lock();</span><br><span class="line">            <span class="keyword">if</span> (num &lt; <span class="number">5</span>) &#123;</span><br><span class="line">                System.out.println(String.format(<span class="string">"thread:%s   num:%s Do some thing"</span>, Thread.currentThread().getName(), num));</span><br><span class="line">                num++;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用原子类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">LockFreeTest</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (number.get() &lt; <span class="number">5</span>) &#123;</span><br><span class="line">                System.out.println(String.format(<span class="string">"thread:%s   num:%s Do some thing"</span>, Thread.currentThread().getName(),</span><br><span class="line">                        number.getAndIncrement()));</span><br><span class="line">                <span class="comment">//num++;</span></span><br><span class="line">                <span class="comment">// System.out.println(num);</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译后，如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">SynDemo</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span></span><br><span class="line">java.lang.Integer num;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.SynDemo();</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">3</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">4</span>:   aload_0</span><br><span class="line">   <span class="number">5</span>:   iconst_0</span><br><span class="line">   <span class="number">6</span>:   invokestatic    #<span class="number">4</span>; <span class="comment">//Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span></span><br><span class="line">   <span class="number">9</span>:   putfield        #<span class="number">5</span>; <span class="comment">//Field num:Ljava/lang/Integer;</span></span><br><span class="line">   <span class="number">12</span>:  aload_0</span><br><span class="line">   <span class="number">13</span>:  <span class="keyword">new</span>     #<span class="number">6</span>; <span class="comment">//class java/util/concurrent/locks/ReentrantLock</span></span><br><span class="line">   <span class="number">16</span>:  dup</span><br><span class="line">   <span class="number">17</span>:  invokespecial   #<span class="number">7</span>; <span class="comment">//Method java/util/concurrent/locks/ReentrantLock."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">20</span>:  putfield        #<span class="number">2</span>; <span class="comment">//Field lock:Ljava/util/concurrent/locks/Lock;</span></span><br><span class="line">   <span class="number">23</span>:  aload_0</span><br><span class="line">   <span class="number">24</span>:  <span class="keyword">new</span>     #<span class="number">8</span>; <span class="comment">//class java/util/concurrent/atomic/AtomicInteger</span></span><br><span class="line">   <span class="number">27</span>:  dup</span><br><span class="line">   <span class="number">28</span>:  iconst_0</span><br><span class="line">   <span class="number">29</span>:  invokespecial   #<span class="number">9</span>; <span class="comment">//Method java/util/concurrent/atomic/AtomicInteger."&lt;init&gt;":(I)V</span></span><br><span class="line">   <span class="number">32</span>:  putfield        #<span class="number">1</span>; <span class="comment">//Field number:Ljava/util/concurrent/atomic/AtomicInteger;</span></span><br><span class="line">   <span class="number">35</span>:  <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(java.lang.String[]);</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   <span class="keyword">new</span>     #<span class="number">10</span>; <span class="comment">//class com/xxo/demo/util/SynDemo</span></span><br><span class="line">   <span class="number">3</span>:   dup</span><br><span class="line">   <span class="number">4</span>:   invokespecial   #<span class="number">11</span>; <span class="comment">//Method "&lt;init&gt;":()V</span></span><br><span class="line">   <span class="number">7</span>:   invokespecial   #<span class="number">12</span>; <span class="comment">//Method syn:()V</span></span><br><span class="line">   <span class="number">10</span>:  <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> java.util.concurrent.locks.Lock access$<span class="number">000</span>(com.xxo.demo.util.SynDemo);</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   getfield        #<span class="number">2</span>; <span class="comment">//Field lock:Ljava/util/concurrent/locks/Lock;</span></span><br><span class="line">   <span class="number">4</span>:   areturn</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> java.util.concurrent.atomic.AtomicInteger access$<span class="number">100</span>(com.xxo.demo.util.SynDemo);</span><br><span class="line">  Code:</span><br><span class="line">   <span class="number">0</span>:   aload_0</span><br><span class="line">   <span class="number">1</span>:   getfield        #<span class="number">1</span>; <span class="comment">//Field number:Ljava/util/concurrent/atomic/AtomicInteger;</span></span><br><span class="line">   <span class="number">4</span>:   areturn</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-工具javap讲解</title>
      <link href="/2016/03/31/Java-%E5%B7%A5%E5%85%B7javap%E8%AE%B2%E8%A7%A3/"/>
      <url>/2016/03/31/Java-%E5%B7%A5%E5%85%B7javap%E8%AE%B2%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　<code>javap</code>，是Java class文件分解器，反编译class文件，也可以查看java编译器生成的字节码。主要用于分解class文件。学习这个工具之前可以先去简单了解一下<a href="http://blog.xiaoxiaomo.com/2016/03/31/Java-%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/">class类文件结构</a>。</p><a id="more"></a><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><p>命令格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javap [option] class文件（没有后缀名）</span><br></pre></td></tr></table></figure><p>如果[option]为空，javap将输出传递给它的类的public域及方法，并输出到标准输出设备上（默认I/O为控制台）。如下代码，先javac编译源码,然后javap反编译class文件，注意不需要添加“.class”后缀。源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/31.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavapDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> num = <span class="number">10</span> ;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String name = <span class="string">"momo"</span> ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String a = name ;</span><br><span class="line">        String b = <span class="string">"abc"</span> ;</span><br><span class="line">        String c = a+b ;</span><br><span class="line">        System.out.println(c);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331144401.png" alt=""></p><ul><li>下面来看一下javap的一些选项（常用的）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">javap -<span class="built_in">help</span> <span class="comment">#输出 javap 的帮助信息。</span></span><br><span class="line">javap　　-l   <span class="comment">#输出行及局部变量表。</span></span><br><span class="line">javap -public <span class="comment">#只显示public类及成员。</span></span><br><span class="line">javap -protected <span class="comment">#只显示protected和public类及成员。</span></span><br><span class="line">javap -package <span class="comment">#只显示包、protected和public类及成员。这是缺省设置。</span></span><br><span class="line">javap -private <span class="comment">#显示所有类和成员。</span></span><br><span class="line">javap -s 输出内部类型签名。</span><br><span class="line">javap -c <span class="comment">#输出类中各方法的未解析的代码，即构成Java字节码的指令。</span></span><br><span class="line">javap -verbose <span class="comment">#输出堆栈大小、各方法的locals及args数,以及class文件的编译版本</span></span><br></pre></td></tr></table></figure><h2 id="javap-l-命令"><a href="#javap-l-命令" class="headerlink" title="javap -l 命令"></a>javap -l 命令</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331162656.png" alt=""></p><p><strong>public com.xxo.demo.util.JavapDemo();</strong> 表示的默认的无参构造函数，</p><h2 id="javap-pub-pro-pac-pri"><a href="#javap-pub-pro-pac-pri" class="headerlink" title="javap -pub|pro|pac|pri"></a>javap -pub|pro|pac|pri</h2><ul><li>来简单看一下<code>javap -public</code></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331150306.png" alt=""></p><p>就会显示出类中所用的public的类，构造方法，全局变量，局部变量就不会在此显示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class com.xxo.demo.util.JavapDemo extends java.lang.Object&#123;//类信息</span><br><span class="line">    public static java.lang.String name;//public全部变量</span><br><span class="line">    public com.xxo.demo.util.JavapDemo();//默认的构造方法</span><br><span class="line">    public static void main(java.lang.String[]);//main方法</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面来修改一下源代码，</p><ol><li>私有化一下默认构造方法，然后重写一下带参构造方法</li><li>定义一个protected的全局变量</li><li>private的HashMap类型的变量</li><li>修改后javac编译源码</li></ol><p>源码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * javap Demo</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/31.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavapDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> num = <span class="number">10</span> ;<span class="comment">//私有全局变量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String name = <span class="string">"momo"</span> ;<span class="comment">//共有全局变量</span></span><br><span class="line">    <span class="keyword">protected</span> Double height = <span class="number">175.0</span> ;<span class="comment">//protected</span></span><br><span class="line">    <span class="keyword">private</span> HashMap map ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">JavapDemo</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JavapDemo</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.num = num;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String a = name ;</span><br><span class="line">        String b = <span class="string">"abc"</span> ;</span><br><span class="line">        String c = a+b ;</span><br><span class="line">        System.out.println(c);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用<code>javap -protected</code>查看，显示protected和public类及成员：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331161232.png" alt=""></p><ul><li>使用<code>javap -package</code>查看，会显示包、protected和public类及成员：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331162124.png" alt=""></p><ul><li>使用<code>javap -private</code>查看，会显示所用成员：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331162204.png" alt=""></p><h2 id="javap-c-命令"><a href="#javap-c-命令" class="headerlink" title="javap -c 命令"></a>javap -c 命令</h2><p>javap -c #输出类中各方法的未解析的代码，即构成Java字节码的指令。我们这里还是使用上例中的源码，输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  javap -c JavapDemo</span><br></pre></td></tr></table></figure><ul><li>编译后结果：</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Compiled from <span class="string">"JavapDemo.java"</span>                                                             </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">xxo</span>.<span class="title">demo</span>.<span class="title">util</span>.<span class="title">JavapDemo</span> <span class="title">extends</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span>&#123;</span>                         </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> java.lang.String name; <span class="comment">//静态的全局变量name</span></span><br><span class="line">                                                                                           </span><br><span class="line"><span class="keyword">protected</span> java.lang.Double height;<span class="comment">//Double类型的变量height</span></span><br><span class="line">                                                                                           </span><br><span class="line"><span class="keyword">public</span> com.xxo.demo.util.JavapDemo(<span class="keyword">int</span>);<span class="comment">//带参构造函数</span></span><br><span class="line">  Code:                                                                                    </span><br><span class="line">   <span class="number">0</span>:   aload_0 <span class="comment">//将引用类型的局部变量加载到操作栈，即this</span></span><br><span class="line">   <span class="number">1</span>:   invokespecial   #<span class="number">1</span>; <span class="comment">//Method java/lang/Object."&lt;init&gt;":()V //实例化对象this  </span></span><br><span class="line">   <span class="number">4</span>:   aload_0 <span class="comment">//将引用类型的局部变量加载到操作栈，即this      </span></span><br><span class="line">   <span class="number">5</span>:   bipush  <span class="number">10</span> <span class="comment">//将一个常量加载到操作数栈，10</span></span><br><span class="line">   <span class="number">7</span>:   putfield        #<span class="number">2</span>; <span class="comment">//Field num:I //设置类中字段this.num的值为10</span></span><br><span class="line">   <span class="number">10</span>:  aload_0    <span class="comment">//加载局部变量表中的数据到操作栈中，即this  </span></span><br><span class="line">   <span class="number">11</span>:  ldc2_w  #<span class="number">3</span>; <span class="comment">//double 175.0d  //将double类型的常量175.0d加载到操作数栈</span></span><br><span class="line">   <span class="number">14</span>:  invokestatic    #<span class="number">5</span>; <span class="comment">//Method java/lang/Double.valueOf:(D)Ljava/lang/Double;//调Double的valueOf方法</span></span><br><span class="line">   <span class="number">17</span>:  putfield        #<span class="number">6</span>; <span class="comment">//Field height:Ljava/lang/Double;//设置类中字段this.height的值</span></span><br><span class="line">   <span class="number">20</span>:  aload_0 <span class="comment">//加载局部变量表中的数据到操作栈中，即this</span></span><br><span class="line">   <span class="number">21</span>:  iload_1 <span class="comment">// 将int类型的局部变量加载到操作栈,即方法传递的num</span></span><br><span class="line">   <span class="number">22</span>:  putfield        #<span class="number">2</span>; <span class="comment">//Field num:I //设置类中字段this.num的值为num</span></span><br><span class="line">   <span class="number">25</span>:  <span class="keyword">return</span>  <span class="comment">//没有返回值</span></span><br><span class="line">                                                                                           </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(java.lang.String[]); <span class="comment">//main方法         </span></span><br><span class="line">  Code:                                                                                    </span><br><span class="line">   <span class="number">0</span>:   getstatic       #<span class="number">7</span>; <span class="comment">//Field name:Ljava/lang/String; //获取静态变量name，并压入栈顶</span></span><br><span class="line">   <span class="number">3</span>:   astore_1    <span class="comment">//将变量从操作数栈存储到局部变量中，（弹栈），即存入a中</span></span><br><span class="line">   <span class="number">4</span>:   ldc     #<span class="number">8</span>; <span class="comment">//String abc //字符串常量加载到操作数栈,abc</span></span><br><span class="line">   <span class="number">6</span>:   astore_2    <span class="comment">//将abc存储到局部变量表中，b中</span></span><br><span class="line">   <span class="number">7</span>:   <span class="keyword">new</span>     #<span class="number">9</span>; <span class="comment">//class java/lang/StringBuilder  //创建一个StringBuilder对象                                      </span></span><br><span class="line">   <span class="number">10</span>:  dup        <span class="comment">//直接操作操作数栈</span></span><br><span class="line">   <span class="number">11</span>:  invokespecial   #<span class="number">10</span>; <span class="comment">//Method java/lang/StringBuilder."&lt;init&gt;":()V //</span></span><br><span class="line">   <span class="number">14</span>:  aload_1 <span class="comment">//加载局部变量表中的数据到操作栈中,即a的数据（第四条指令把a已加载到局部变量表中）</span></span><br><span class="line">   <span class="number">15</span>:  invokevirtual   #<span class="number">11</span>; <span class="comment">//Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line"><span class="comment">//调用Builder的append方法</span></span><br><span class="line">   <span class="number">18</span>:  aload_2 <span class="comment">//加载局部变量表中的数据到操作栈中,即b的数据</span></span><br><span class="line">   <span class="number">19</span>:  invokevirtual   #<span class="number">11</span>; <span class="comment">//Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line"><span class="comment">//调用Builder的append方法                                                                   </span></span><br><span class="line">   <span class="number">22</span>:  invokevirtual   #<span class="number">12</span>; <span class="comment">//Method java/lang/StringBuilder.toString:()Ljava/lang/String;//调用Builder的toString方法</span></span><br><span class="line">                                                                                           </span><br><span class="line">   <span class="number">25</span>:  astore_3 <span class="comment">//将a+b的结果存储到局部变量表中，即c中</span></span><br><span class="line">   <span class="number">26</span>:  getstatic       #<span class="number">13</span>; <span class="comment">//Field java/lang/System.out:Ljava/io/PrintStream;//获取输出流</span></span><br><span class="line">   <span class="number">29</span>:  aload_3 <span class="comment">//加载局部变量表中的数据到操作栈中（第25条指令把c加载到了局部变量表）</span></span><br><span class="line">   <span class="number">30</span>:  invokevirtual   #<span class="number">14</span>; <span class="comment">//Method java/io/PrintStream.println:(Ljava/lang/String;)V //并输出打印</span></span><br><span class="line">   <span class="number">33</span>:  <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line">                                  </span><br><span class="line"><span class="keyword">static</span> &#123;&#125;;                                                                                 </span><br><span class="line">  Code:                                                                                    </span><br><span class="line">   <span class="number">0</span>:   ldc     #<span class="number">15</span>; <span class="comment">//String momo   //字符串常量加载到操作数栈,"momo"</span></span><br><span class="line">   <span class="number">2</span>:   putstatic       #<span class="number">7</span>; <span class="comment">//Field name:Ljava/lang/String; //设置类中字段name的值为momo</span></span><br><span class="line">   <span class="number">5</span>:   <span class="keyword">return</span> <span class="comment">//没有返回值</span></span><br><span class="line">                   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="javap-verbose"><a href="#javap-verbose" class="headerlink" title="javap -verbose"></a>javap -verbose</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Compiled from <span class="string">"JavapDemo.java"</span></span><br><span class="line">public class com.xxo.demo.util.JavapDemo extends java.lang.Object</span><br><span class="line">  SourceFile: <span class="string">"JavapDemo.java"</span></span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 50</span><br><span class="line">  Constant pool:</span><br><span class="line">const <span class="comment">#1 = Method       #17.#36;        //  java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">const <span class="comment">#2 = Field        #16.#37;        //  com/xxo/demo/util/JavapDemo.num:I</span></span><br><span class="line">const <span class="comment">#3 = double       175.0d;</span></span><br><span class="line">const <span class="comment">#5 = Method       #38.#39;        //  java/lang/Double.valueOf:(D)Ljava/lang/Double; const #6 = Field        #16.#40;        //  com/xxo/demo/util/JavapDemo.height:Ljava/lang/Double;</span></span><br><span class="line">const <span class="comment">#7 = Field        #16.#41;        //  com/xxo/demo/util/JavapDemo.name:Ljava/lang/String;</span></span><br><span class="line">const <span class="comment">#8 = String       #42;    //  abc</span></span><br><span class="line">const <span class="comment">#9 = class        #43;    //  java/lang/StringBuilder</span></span><br><span class="line">const <span class="comment">#10 = Method      #9.#36; //  java/lang/StringBuilder."&lt;init&gt;":()V</span></span><br><span class="line">const <span class="comment">#11 = Method      #9.#44; //  java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line">const <span class="comment">#12 = Method      #9.#45; //  java/lang/StringBuilder.toString:()Ljava/lang/String;</span></span><br><span class="line">const <span class="comment">#13 = Field       #46.#47;        //  java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">const <span class="comment">#14 = Method      #48.#49;        //  java/io/PrintStream.println:(Ljava/lang/String;)V</span></span><br><span class="line">const <span class="comment">#15 = String      #50;    //  momo</span></span><br><span class="line">const <span class="comment">#16 = class       #51;    //  com/xxo/demo/util/JavapDemo</span></span><br><span class="line">const <span class="comment">#17 = class       #52;    //  java/lang/Object</span></span><br><span class="line">const <span class="comment">#18 = Asciz       num;</span></span><br><span class="line">const <span class="comment">#19 = Asciz       I;</span></span><br><span class="line">const <span class="comment">#20 = Asciz       name;</span></span><br><span class="line">const <span class="comment">#21 = Asciz       Ljava/lang/String;;</span></span><br><span class="line">const <span class="comment">#22 = Asciz       height;</span></span><br><span class="line">const <span class="comment">#23 = Asciz       Ljava/lang/Double;;</span></span><br><span class="line">const <span class="comment">#24 = Asciz       map;</span></span><br><span class="line">const <span class="comment">#25 = Asciz       Ljava/util/HashMap;;</span></span><br><span class="line">const <span class="comment">#26 = Asciz       &lt;init&gt;;</span></span><br><span class="line">const <span class="comment">#27 = Asciz       ()V;</span></span><br><span class="line">const <span class="comment">#28 = Asciz       Code;</span></span><br><span class="line">const <span class="comment">#29 = Asciz       LineNumberTable;</span></span><br><span class="line">const <span class="comment">#30 = Asciz       (I)V;</span></span><br><span class="line">const <span class="comment">#31 = Asciz       main;</span></span><br><span class="line">const <span class="comment">#32 = Asciz       ([Ljava/lang/String;)V;</span></span><br><span class="line">const <span class="comment">#33 = Asciz       &lt;clinit&gt;;</span></span><br><span class="line">const <span class="comment">#34 = Asciz       SourceFile;</span></span><br><span class="line">const <span class="comment">#35 = Asciz       JavapDemo.java;</span></span><br><span class="line">const <span class="comment">#36 = NameAndType #26:#27;//  "&lt;init&gt;":()V</span></span><br><span class="line">const <span class="comment">#37 = NameAndType #18:#19;//  num:I</span></span><br><span class="line">const <span class="comment">#38 = class       #53;    //  java/lang/Double</span></span><br><span class="line">const <span class="comment">#39 = NameAndType #54:#55;//  valueOf:(D)Ljava/lang/Double;</span></span><br><span class="line">const <span class="comment">#40 = NameAndType #22:#23;//  height:Ljava/lang/Double;</span></span><br><span class="line">const <span class="comment">#41 = NameAndType #20:#21;//  name:Ljava/lang/String;</span></span><br><span class="line">const <span class="comment">#42 = Asciz       abc;</span></span><br><span class="line">const <span class="comment">#43 = Asciz       java/lang/StringBuilder;</span></span><br><span class="line">const <span class="comment">#44 = NameAndType #56:#57;//  append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line">const <span class="comment">#45 = NameAndType #58:#59;//  toString:()Ljava/lang/String;</span></span><br><span class="line">const <span class="comment">#46 = class       #60;    //  java/lang/System</span></span><br><span class="line">const <span class="comment">#47 = NameAndType #61:#62;//  out:Ljava/io/PrintStream;</span></span><br><span class="line">const <span class="comment">#48 = class       #63;    //  java/io/PrintStream</span></span><br><span class="line">const <span class="comment">#49 = NameAndType #64:#65;//  println:(Ljava/lang/String;)V</span></span><br><span class="line">const <span class="comment">#50 = Asciz       momo;</span></span><br><span class="line">const <span class="comment">#51 = Asciz       com/xxo/demo/util/JavapDemo;</span></span><br><span class="line">const <span class="comment">#52 = Asciz       java/lang/Object;</span></span><br><span class="line">const <span class="comment">#53 = Asciz       java/lang/Double;</span></span><br><span class="line">const <span class="comment">#54 = Asciz       valueOf;</span></span><br><span class="line">const <span class="comment">#55 = Asciz       (D)Ljava/lang/Double;;</span></span><br><span class="line">const <span class="comment">#56 = Asciz       append;</span></span><br><span class="line">const <span class="comment">#57 = Asciz       (Ljava/lang/String;)Ljava/lang/StringBuilder;;</span></span><br><span class="line">const <span class="comment">#58 = Asciz       toString;</span></span><br><span class="line">const <span class="comment">#59 = Asciz       ()Ljava/lang/String;;</span></span><br><span class="line">const <span class="comment">#60 = Asciz       java/lang/System;</span></span><br><span class="line">const <span class="comment">#61 = Asciz       out;</span></span><br><span class="line">const <span class="comment">#62 = Asciz       Ljava/io/PrintStream;;</span></span><br><span class="line">const <span class="comment">#63 = Asciz       java/io/PrintStream;</span></span><br><span class="line">const <span class="comment">#64 = Asciz       println;</span></span><br><span class="line">const <span class="comment">#65 = Asciz       (Ljava/lang/String;)V;</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">public static java.lang.String name;</span><br><span class="line"></span><br><span class="line">protected java.lang.Double height;</span><br><span class="line"></span><br><span class="line">public com/xxo.demo.util.JavapDemo(int);</span><br><span class="line">  Code:</span><br><span class="line">   Stack=3, Locals=2, Args_size=2</span><br><span class="line">   0:   aload_0</span><br><span class="line">   1:   invokespecial   <span class="comment">#1; //Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   4:   aload_0</span><br><span class="line">   5:   bipush  10</span><br><span class="line">   7:   putfield        <span class="comment">#2; //Field num:I</span></span><br><span class="line">   10:  aload_0</span><br><span class="line">   11:  ldc2_w  <span class="comment">#3; //double 175.0d</span></span><br><span class="line">   14:  invokestatic    <span class="comment">#5; //Method java/lang/Double.valueOf:(D)Ljava/lang/Double;</span></span><br><span class="line">   17:  putfield        <span class="comment">#6; //Field height:Ljava/lang/Double;</span></span><br><span class="line">   20:  aload_0</span><br><span class="line">   21:  iload_1</span><br><span class="line">   22:  putfield        <span class="comment">#2; //Field num:I</span></span><br><span class="line">   25:  <span class="built_in">return</span></span><br><span class="line">  LineNumberTable:</span><br><span class="line">   line 16: 0</span><br><span class="line">   line 10: 4</span><br><span class="line">   line 12: 10</span><br><span class="line">   line 17: 20</span><br><span class="line">   line 18: 25</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public static void main(java.lang.String[]);</span><br><span class="line">  Code:</span><br><span class="line">   Stack=2, Locals=4, Args_size=1</span><br><span class="line">   0:   getstatic       <span class="comment">#7; //Field name:Ljava/lang/String;</span></span><br><span class="line">   3:   astore_1</span><br><span class="line">   4:   ldc     <span class="comment">#8; //String abc</span></span><br><span class="line">   6:   astore_2</span><br><span class="line">   7:   new     <span class="comment">#9; //class java/lang/StringBuilder</span></span><br><span class="line">   10:  dup</span><br><span class="line">   11:  invokespecial   <span class="comment">#10; //Method java/lang/StringBuilder."&lt;init&gt;":()V</span></span><br><span class="line">   14:  aload_1</span><br><span class="line">   15:  invokevirtual   <span class="comment">#11; //Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line">   18:  aload_2</span><br><span class="line">   19:  invokevirtual   <span class="comment">#11; //Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;</span></span><br><span class="line">   22:  invokevirtual   <span class="comment">#12; //Method java/lang/StringBuilder.toString:()Ljava/lang/String;</span></span><br><span class="line"></span><br><span class="line">   25:  astore_3</span><br><span class="line">   26:  getstatic       <span class="comment">#13; //Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">   29:  aload_3</span><br><span class="line">   30:  invokevirtual   <span class="comment">#14; //Method java/io/PrintStream.println:(Ljava/lang/String;)V</span></span><br><span class="line">   33:  <span class="built_in">return</span></span><br><span class="line">  LineNumberTable:</span><br><span class="line">   line 21: 0</span><br><span class="line">   line 22: 4</span><br><span class="line">   line 23: 7</span><br><span class="line">   line 24: 26</span><br><span class="line">   line 25: 33</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">static &#123;&#125;;</span><br><span class="line">  Code:</span><br><span class="line">   Stack=1, Locals=0, Args_size=0 //</span><br><span class="line">   0:   ldc     <span class="comment">#15; //String momo</span></span><br><span class="line">   2:   putstatic       <span class="comment">#7; //Field name:Ljava/lang/String;</span></span><br><span class="line">   5:   <span class="built_in">return</span></span><br><span class="line">  LineNumberTable:</span><br><span class="line">   line 11: 0</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本篇博客就不一一讲解字节码指令的具体含义了，在后面的一篇博客”<a href="http://blog.xiaoxiaomo.com/2016/04/01/Java-%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4/">java-字节码</a>“，会详细的讲解字节码指令的具体含义。</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-类文件结构</title>
      <link href="/2016/03/31/Java-%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/"/>
      <url>/2016/03/31/Java-%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/</url>
      <content type="html"><![CDATA[<p>　　电脑只认识’0’和’1’，我们的程序经过编译器编译成0和1组成的<code>二进制文件</code>的时候才能由计算机执行。虽然10多年过去了，电脑还是只能识别0和1，但现在可以把编译结果转为<code>字节码</code>，是<strong>存储格式</strong>发展的一小步，却是<strong>编译语言</strong>发展的一大步。</p><a id="more"></a><h2 id="class文件结构"><a href="#class文件结构" class="headerlink" title="class文件结构"></a>class文件结构</h2><p>Java语言”<code>一次编译，到处运行</code>“，原理就是：<em>源码文件并没有直接编译成机器指令，而是编译成Java虚拟机可以识别和运行的<code>字节码.class文件</code></em>。<code>字节码文件</code>，是一种平台无关的中间编译结果，由java虚拟机读取，解析和执行。</p><p><code>Class文件是一组以8位字节为基础单位的二进制流</code>，各数据项严格按顺序排列其中，中间没有添加任何分隔符。当遇到占用8位字节以上空间的数据项时，按照高位在前的方式<code>分割成若干个8位字节进行存储</code>。根据<em>《JAVA虚拟机规范》</em>的规定，<em>class文件格式采用一种类似C语言结构体的伪结构来存储</em>，这种伪结构中只有<strong>两种数据类型</strong>：<code>无符号</code>数和<code>表</code>。</p><ul><li>无符号数</li></ul><p>属于基本类型的数据，以<code>u1</code>, <code>u2</code>, <code>u4</code>, <code>u8</code>来分别代表<code>1个字节，2个字节，4个字节和8个字节</code>的无符号数，<strong>无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码的字符串值</strong>。</p><ul><li>表</li></ul><p><strong>由多个无符号数或其他表作为数据项构成的复合数据类型</strong>，所以表都习惯性地以“<code>_info</code>“结尾。表用于描述有层次关系的复合结构数据，<strong>整个Class文件就是一张表</strong>。表由下图所示的数据项构成：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331193340.png" alt="class文件结构">（图片来源于网络）</p><p><code>magic</code>：前1-4字节被称为<code>魔数</code>，<strong>魔数值来唯一确定文件类型</strong>，java的Class文件魔数是：0xCAFEBABE。<br><code>minor_version</code>和<code>major_version</code>：5-6个字节代表次版本号，7-8个字节代表主版本号。<br><code>constant_pool_count</code>：常量池的数目<br><code>constant_pool</code>：<code>常量池</code>，Class类文件中出现的第一个表类型数据，分为两种：</p><ol><li>字面量：包括文本字符串、final类型常量值。</li><li>符号引用：包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。</li></ol><p><code>access_flags</code>：类或接口层面的<code>访问控制</code>信息，通常存储的信息包括：Class类文件是类、接口、枚举或是注解；是否定义为public类型；是否定义为abstract类型；类是否被定义为final等等。<br><code>this_class</code>：<strong>类索引</strong>用于确定类的全限定名<br><code>super_class</code>：<strong>父类索引</strong>用于确定父类的全限定名<br><code>interfaces</code>：<strong>接口索引用</strong>于确定接口的全限定名<br><code>interfaces_count</code>：存储接口数量（可以实现多个接口）<br><code>field_info</code>：描述接口或者类中声明的<code>变量</code>，<br><code>field</code>：包括了<strong>类级变量(静态变量)</strong>和<strong>实例级变量(成员变量)</strong>，但<em>不包括方法内部的局部变量</em><br><code>fields_count</code>：类和实例变量总数<br><code>method_info</code>：描述类或者接口中声明的<code>方法</code><br><code>methods_count</code>：文件中方法总数<br><code>method</code>：方法存储了方法的<strong>访问标识</strong>、<em>是否静态、是否final、是否同步synchronized、是否本地方法native、是否抽象方法abstract、方法返回值类型、方法名称、方法参数列表</em>等信息。<br><code>attribute_info</code>：<code>属性表</code>是Class文件格式中最具扩展性的一种数据项目，用于存放：<strong>field_info字段表</strong>、<strong>method_info方法表</strong>以及<strong>Class文件的专有信息</strong>，属性表不要求各个属性有严格顺序，只要求不与已有的属性名字重复即可。</p><p><code>属性表</code>中存放的常用信息如下:</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331200538.png" alt="属性表"></p><h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p><code>属性表</code>如上图所示，对于每个属性，它的名称需要从常量池中引用一个<code>CONSTANT_Utf8_info</code>类型的常量表来表示，而属性值的结构则是完全自定义的，只要说明属性值所占用的位数长度即可。</p><blockquote><p>Code属性</p></blockquote><p><code>方法体中的字节码指令存储在Code属性中</code>，code属性是Class文件最重要的一个属性。<br><code>max_stack</code>：代表<code>操作栈深度的最大值</code>，<strong>在方法执行的任何时刻，操作数栈都不会超过这个深度</strong>，虚拟机运行的时候需要根据这个值来分配栈帧中的操作栈深度。<br><code>max_locals</code>：代表局部变量表所需的存储空间，单位为slot，对于byte,char,float,int,short,boolean,reference和returnAddress每个局部变量占用一个slot,而double和long需要两个slot.</p><ul><li>并不是方法中用到了多少个局部变量，就把这些局部变量所占的Slot之和作为max_locals的值，原因是局部变量表中的slot可以重用，当代码执行超过一个局部变量的作用域时，这个局部变量所占用的slot就可以被其他局部变量所使用。这个值编译器会自动计算得出。</li></ul><p><code>code_length</code>和<code>code</code>：用来<strong>存储java源程序编译后生成的字节码指令</strong>，<strong>code_length代表字节码长度</strong>，<strong>code用于存储字节码指令的一系列字节流</strong>。<em>字节码的每个指令就是一个字节</em>。这样可以推出，一个字节最多可以代表256条指令，目前已经使用了约200条。</p><ul><li>而code_length有4个字节，所以一个方法做多允许有65535条字节码指令，如果超过这个限制，javac就会拒绝编译，一般JSP可能会这个原因导致失败。<br>在任何实例方法中，都可以通过this关键字访问到此方法所属的对象，<strong>它的底层实现就是通过javac编译器在编译的时候把this关键字的访问转变为对一个普通方法参数的访问</strong>。<br>因此，<strong>任何实例方法的参数Args_size最少是1，而且locals最少也是1.而静态方法就可以为0</strong>了。</li></ul><p><strong>异常表</strong>：实际是Java代码的一部分，从<strong>start_pc</strong>行到<strong>end_pc</strong>行出现了类型为<strong>catch_type</strong>的异常，就转到第<strong>handler_pc</strong>行处理。这四个参数就组成了异常表。<br>对于finally的实现，实际上就是对catch字段和前面对于任意情况都运行的异常表记录</p><blockquote><p>Exceptions属性</p></blockquote><p>表示方法<strong>可能抛出number_of_exceptions种受查异常</strong>，每种受查异常使用一个exception_index_table项表示</p><blockquote><p>LineNumberTable属性</p></blockquote><p>用于描述<code>java源代码行号与字节码行号直接的对应关系</code>。可以用<code>-g:none</code>或<code>-g:lines</code>选项来取消或要求生成这项信息，<strong>如果取消主要影响就是当抛出异常时，不会显示出错的行号，调试时无法设置断点</strong>。我们可以使用“javap -l class文件”来查看：<br>eg ： </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxo.demo.util;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/31.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LineNumberDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String c = <span class="string">"c"</span> ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String a = <span class="string">"abc"</span> ;</span><br><span class="line">        String b = <span class="string">"ab"</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160331222603.png" alt="属性表"></p><blockquote><p>LocalVariableTable属性</p></blockquote><p>用于描述<code>栈帧中局部变量表中的变量与源码中定义的变量之间的关系</code>。也可以选择开关，关闭后果就是报错时看不到变量名称。</p><blockquote><p>SourceFile属性</p></blockquote><p>用于<code>记录生成这个Class文件的源码文件名称</code>。可选,sourcefile_index数据项是指向常量池中CONSTANT_Utf8_info型常量的索引，常量值是源文件的文件名</p><blockquote><p>ConstantValue属性</p></blockquote><p>通知虚拟机自动为静态变量赋值，<strong>只有被static关键字修饰的变量才可以使用这项属性</strong>。</p><ul><li>eg：int x=123；和static int x=123;的区别在于，</li><li><strong>非静态变量</strong>（实例变量）的赋值是在<code>实例构造器&lt;init&gt;</code>方法中进行的；</li><li>而<strong>静态变量</strong>，则有两种方式可以选择：</li></ul><ol><li>在类构造器<clinit>方法中进行，</clinit></li><li>使用ConstantValue属性来赋值。</li></ol><p>目前Sun Java编译器的选择是：如果<em>同时使用final和static来修饰一个变量，并且这个变量的数据类型是基本类型或者String的话，就生成ConstantValue属性来进行初始化</em>。如果<em>这个变量没有用final修饰，或者非以上类型，则选择在<clinit>中进行初始化</clinit></em>。</p><blockquote><p>InnerClasses属性</p></blockquote><p><code>用于记录内部类与宿主类之间的关系</code>，如果一个类中定义了内部类，那编译器将会为它以及他所包含的内部类生成InnerClasses属性。</p><blockquote><p>Deprecated和synthetic属性</p></blockquote><p><code>都属于标志类布尔属性</code>，只存在有和没有的区别，没有属性值的概念。</p><ul><li>deprecated：属性用于表示某个类，字段或者方法，已经被程序作者定为<strong>不再推荐使用</strong>，可以在代码中使用@deprecated注释进行设置。</li><li>synthetic：<strong>表示字段或方法不是java源码产生，而是编译器自行添加的</strong>。</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--包</title>
      <link href="/2016/03/30/Scala-%E5%8C%85/"/>
      <url>/2016/03/30/Scala-%E5%8C%85/</url>
      <content type="html"><![CDATA[<p>　　<code>包</code>，<strong>主要作用就是用来管理类</strong>。给类划分一个自己的空间，这样即使相同的文件只要在不同的包名下也是可以。</p><a id="more"></a><h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><p>包下面可以嵌套包，下面写一个，PackageTest类和ObjectTest对象，让后把它放到com.xiaoxiaomo.demo.ch07.test下，那我们来看一下scala包结构和java的一些不同写法，如下<code>实例1</code>代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 包</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/30.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.demo.ch07&#123;</span><br><span class="line">    <span class="keyword">package</span> test&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//类在：com.xiaoxiaomo.demo.ch07.test下</span></span><br><span class="line">        <span class="class"><span class="keyword">class</span> <span class="title">PackageTest</span> </span>&#123;</span><br><span class="line">            <span class="comment">//对象</span></span><br><span class="line">            <span class="class"><span class="keyword">object</span> <span class="title">ObjectTest</span></span>&#123;</span><br><span class="line">                <span class="comment">//方法</span></span><br><span class="line">                <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>( num : <span class="type">Int</span> ) &#123;</span><br><span class="line">                    println(<span class="string">"num:"</span>+num)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">object</span> <span class="title">ObjectTest</span></span>&#123;</span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">ObjTestMethod</span></span>&#123;</span><br><span class="line">                println(<span class="string">"Hello!"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">package</span> test2&#123;</span><br><span class="line">            <span class="class"><span class="keyword">object</span> <span class="title">ObjTestMethod2</span></span>&#123;</span><br><span class="line">                <span class="comment">//可以直接调用上级方法</span></span><br><span class="line">                <span class="type">ObjectTest</span>.<span class="type">ObjTestMethod</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><code>包结构可以嵌套</code>，如上例中定义了两级嵌套结构，等价于：<code>com.xiaoxiaomo.demo.ch07.test</code>；</p></blockquote><h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><blockquote><p><code>作用域同样支持嵌套，命名空间下级包可以直接访问上层作用域的对象或类</code>，例如上例中的包test2可以访问它的上级包的类或对象而无须引入。</p></blockquote><ul><li>作用域引发的一个问题</li></ul><p>下面看看一个《快学Sacla》中的事例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 找不到scala.collection</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/30.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> com &#123;</span><br><span class="line">    <span class="keyword">package</span> horstmann &#123;</span><br><span class="line">        <span class="keyword">package</span> impatient &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//即使引入包名</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line">            <span class="class"><span class="keyword">class</span> <span class="title">Manager</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 因为scala包总是被引入，所以下面的collection包实际是指scala.collection</span></span><br><span class="line">                <span class="keyword">val</span> subordinates = <span class="keyword">new</span> collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">String</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//如果再有一个包这样定义，上面“mutable”任然会报错</span></span><br><span class="line"><span class="comment">//new collection.mutable.ArrayBuffer[String]</span></span><br><span class="line"><span class="keyword">package</span> com &#123;</span><br><span class="line">    <span class="keyword">package</span> horstmann &#123;</span><br><span class="line">        <span class="keyword">package</span> collection &#123;</span><br><span class="line">        <span class="comment">//....</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Java中包名是绝对的，总是从包层级的最顶端开始，所以就不会出现上例中的问题。在Scala中包名是<code>相对</code>的，相对的包名可能会带来问题。所以解决办法就是使用绝对包名，以<code>_root_</code>开始。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> subordinates = <span class="keyword">new</span> _root_.scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">String</span>]</span><br></pre></td></tr></table></figure><h3 id="串联式包语句"><a href="#串联式包语句" class="headerlink" title="串联式包语句"></a>串联式包语句</h3><p>上面的问题，主要来源于，包名相对的问题，如果我们<code>使用串联的包名</code>也是同样可以避免的。<br>如下代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.horstmann.horstmann &#123;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Manager</span> </span>&#123;</span><br><span class="line">        <span class="keyword">val</span> subordinates = <span class="keyword">new</span> collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">String</span>]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件顶部标记"><a href="#文件顶部标记" class="headerlink" title="文件顶部标记"></a>文件顶部标记</h3><p>如果文件中的所有代码都属于同一个包，在文件顶部标记包是更好的做法。这样看着代码模块化一点，并且不需要包含在括号之中，如下代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.demo</span><br><span class="line"><span class="keyword">package</span> ch07</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">demo</span></span>&#123;</span><br><span class="line">    <span class="comment">//info</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 上面的等同于</span></span><br><span class="line"><span class="keyword">package</span> com.xiaoxiaomo.demo &#123;</span><br><span class="line">    <span class="keyword">package</span> ch07 &#123;</span><br><span class="line">        <span class="class"><span class="keyword">class</span> <span class="title">demo</span></span>&#123;</span><br><span class="line">            <span class="comment">//info</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p><code>引入</code>，import即引入包名的命名空间。如下代码，去调用<code>实例1</code>中的代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.xiaoxiaomo.demo.ch07.test.&#123;<span class="type">PackageTest</span>, <span class="type">ObjectTest</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">PackageCom</span></span>&#123;</span><br><span class="line">    <span class="comment">//test</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    </span><br><span class="line">            <span class="comment">//调用com.xiaoxiaomo.demo.ch07.test下</span></span><br><span class="line">    </span><br><span class="line">            <span class="comment">//1、ObjectTest的ObjTestMethod方法</span></span><br><span class="line">            <span class="type">ObjectTet</span>.<span class="type">ObjTestMethod</span> ;</span><br><span class="line">            <span class="comment">//2、PackageTest类的ObjectTest对象的test方法</span></span><br><span class="line">            <span class="keyword">new</span> <span class="type">PackageTest</span>().<span class="type">ObjectTest</span>.test(<span class="number">888</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><code>import语句可以出现在任何地方</code>，而不是只能在文件顶部;<br>多个成员可以使用“<code>{A,B}</code>”;<br>引入包内所用成员使用“<code>_</code>”，在Java中使用*，eg：java.util._<br>scala引入还可以进行<code>重命名</code>，使用<code>=&gt;</code>。eg：import java.util.{HashMap=&gt;JavaHashMap}<br>还可以进行<code>隐藏</code>，eg：import java.util.{HashMap=&gt;_,_}，此时HashMap被隐藏。这种可以用于如果发现引入包中存在相同引入，可以隐藏不使用的。</p></blockquote><h3 id="隐式引入"><a href="#隐式引入" class="headerlink" title="隐式引入"></a>隐式引入</h3><p><code>隐式引入</code>，就是指Scala总会引入<code>java.lang._</code>、<code>scala._</code>和<code>Predef._</code></p><blockquote><p>1、java.lang总会被引入;<br>2、然后引入scala包，scala包将会覆盖java.lang中的内容;<br>3、最后引入Predef包。</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--对象</title>
      <link href="/2016/03/29/Scala-%E5%AF%B9%E8%B1%A1/"/>
      <url>/2016/03/29/Scala-%E5%AF%B9%E8%B1%A1/</url>
      <content type="html"><![CDATA[<p>　　<code>Scala对象</code>，在scala中没有静态方法或静态字段，我们可以用<code>object</code>，这个语法结构来达到目的。对象，定义了某个类的单个实例。</p><a id="more"></a><h2 id="单例对象"><a href="#单例对象" class="headerlink" title="单例对象"></a>单例对象</h2><p>使用object中的常量或方法，通过<code>object</code>名直接调用，<code>对象构造器在对象第一次被使用时调用</code>（<strong>如果某对象一直未被使用，那么其构造器也不会被调用</strong>）。object的构造器<code>不接受参数传递</code>。</p><ul><li>一个简单的例子</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 单例对象</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/29.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Compute</span> </span>&#123;</span><br><span class="line">    <span class="comment">//在对象中定义变量</span></span><br><span class="line"><span class="comment">//即静态的常量可以直接使用Compute.sums调用</span></span><br><span class="line">    <span class="keyword">var</span> sums = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>( a : <span class="type">Int</span> , b :<span class="type">Int</span> ) : <span class="type">Int</span> =  &#123;</span><br><span class="line">        sums = a + b <span class="comment">//不需要添加return</span></span><br><span class="line">        sums</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">isSame</span></span>&#123;</span><br><span class="line">    <span class="comment">//test</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span> </span>(args: <span class="type">Array</span>[<span class="type">String</span>])&#123;</span><br><span class="line">        println( <span class="type">Compute</span>.sum(<span class="number">8</span>,<span class="number">9</span>) )<span class="comment">//静态方法</span></span><br><span class="line">        println( <span class="type">Compute</span>.sums )<span class="comment">//静态常量</span></span><br><span class="line">        <span class="comment">//判断是否是相同对象</span></span><br><span class="line">        println(<span class="type">Compute</span> == <span class="type">Compute</span>)<span class="comment">//true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">17</span><br><span class="line">17</span><br><span class="line">true</span><br></pre></td></tr></table></figure><blockquote><p>可以看出object定义的方法和变量，就类是于java中的静态方法和变量。<br>获取属性：<code>object对象名.属性</code>，eg:Compute.sums ;<br>获取方法：<code>object对象名.方法名(参数列表)</code>，eg：Compute.sum(8,9) ;</p></blockquote><h2 id="伴生对象"><a href="#伴生对象" class="headerlink" title="伴生对象"></a>伴生对象</h2><p>在上面我们可以创建静态方法和静态字段，但如果我们要想使用静态类呢？或在静态类中定义静态常量怎么办？解决办法就是定义一个和类相同名称的object对象,这个对象叫做“<code>伴生对象</code>”。我们可以把方法和字段定义到伴生对象当中，已达到类似的静态类和静态常量</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 伴生对象</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/29.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Account</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用伴生对象，即使是私有的</span></span><br><span class="line"><span class="comment">//必须使用:伴生对象.方法</span></span><br><span class="line">    <span class="keyword">var</span> id = <span class="type">Account</span>.newUniqueNuber()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> balance = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deposit</span></span>(amount:<span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">        balance += amount</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个不是伴生对象，newUniqueNumber为private</span></span><br><span class="line">    <span class="comment">//然后这里调用就会失败，</span></span><br><span class="line">    <span class="comment">//Accounts.newUniqueNuberPri() ;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//伴生对象</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Account</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> lastNumber = <span class="number">0</span> ;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在该Account作用范围之外无法调用</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">newUniqueNuberPri</span></span>() = &#123;</span><br><span class="line">        lastNumber  += <span class="number">1</span></span><br><span class="line">        lastNumber</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newUniqueNuber</span></span>() = &#123;</span><br><span class="line">        lastNumber  += <span class="number">1</span></span><br><span class="line">        lastNumber</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><code>伴生对象与类同名</code>，且必须放置在同一源文件中。<br>类可以访问伴生对象私有特性，但是必须通过 <code>伴生对象.属性名</code>或<code>伴生对象.方法</code>调用。<br><code>类和它的伴生对象可以互相访问私有特性</code>。</p></blockquote><h2 id="继承或扩展多个特质"><a href="#继承或扩展多个特质" class="headerlink" title="继承或扩展多个特质"></a>继承或扩展多个特质</h2><p>对象可以扩展一个类，并<code>继承</code>，就是面向对象的特征之一，即：如果子类继承了父类，子类就拥有了父类所有共有的特性。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 继承</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/29.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">var name:<span class="type">String</span> = "momo", var age:<span class="type">Int</span></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> height = <span class="number">178</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> sex = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>():<span class="type">Unit</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">info2</span></span>()&#123;</span><br><span class="line">        println(<span class="string">"name:"</span>+name+<span class="string">", sex:"</span>+sex)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">man</span> <span class="keyword">extends</span> <span class="title">Person</span>(<span class="params">"xiaoxiaomo", 23</span>)</span>&#123;</span><br><span class="line">    <span class="comment">//实现方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>()&#123;</span><br><span class="line">        println(<span class="string">"my name:"</span>+name+<span class="string">", age:"</span>+age +<span class="string">","</span>+height)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">woman</span> <span class="keyword">extends</span> <span class="title">Person</span>(<span class="params">"",22</span>)</span>&#123;</span><br><span class="line">    <span class="comment">//实现方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>()&#123;</span><br><span class="line">        println(<span class="string">"my name:"</span>+name+<span class="string">",age:"</span>+age <span class="comment">/*, + sex*/</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">test</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        man.info()</span><br><span class="line">man.info2()</span><br><span class="line">        woman.info()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my name:xiaoxiaomo, age:<span class="number">23</span>,<span class="number">178</span></span><br><span class="line">name:xiaoxiaomo, sex:<span class="number">0</span></span><br><span class="line">my name:,age:<span class="number">22</span></span><br></pre></td></tr></table></figure><blockquote><p><code>子类继承父类，</code>就拥有了父类所有非私有特性，eg：上例中height，name…,info2()<br>必须实现“<code>抽象</code>”（def 方法名([参数列表]):Unit）方法，普通方法可以不实现，eg必须实现info(),可以不重写info2()</p></blockquote><h2 id="apply方法"><a href="#apply方法" class="headerlink" title="apply方法"></a>apply方法</h2><p>其实我们平常都在使用apply方法，当遇到如下表达式的时候，apply方法便会被调用：</p><blockquote><p>object(参数1, 参数2,….,参数N)</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * apply方法</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/29.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AccountApply</span> (<span class="params"> val id : <span class="type">Int</span> , initialBalance : <span class="type">Double</span> </span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> balance  = initialBalance ;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//伴生对象</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AccountApply</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//apply方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>( initialBalance : <span class="type">Double</span> ) =</span><br><span class="line">        <span class="keyword">new</span> <span class="type">AccountApply</span>(<span class="type">Compute</span>.sum(<span class="number">8</span>,<span class="number">9</span>) ,initialBalance) ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> acct = <span class="type">AccountApply</span>(<span class="number">1000.0</span>) ;</span><br><span class="line">        println(acct)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="main方法"><a href="#main方法" class="headerlink" title="main方法"></a>main方法</h2><p><code>main方法定义</code>在object中，形式如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>])&#123;</span><br><span class="line">println(<span class="string">"Hello World!"</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有一种方式：通过<code>继承App</code>,然后将程序代码放object体内就可</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> <span class="keyword">extends</span> <span class="title">App</span></span>&#123;</span><br><span class="line">println(<span class="string">"Hello World!"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><p>Scala并没有定义枚举类型，但是可以通过定义<code>扩展Enumeration</code>的对象，并用Value方法初始化枚举类中的所有可选值，提供枚举。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 枚举</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/29.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Week</span> <span class="keyword">extends</span> <span class="title">Enumeration</span></span>&#123;</span><br><span class="line">    <span class="comment">//第一种初始化</span></span><br><span class="line">    <span class="keyword">var</span> <span class="type">Monday</span>,<span class="type">Tuesday</span>,<span class="type">Wednesday</span>,<span class="type">Thursday</span>,<span class="type">Friday</span>,<span class="type">Saturday</span>,<span class="type">Sunday</span> = <span class="type">Value</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//第二种初始化</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">M</span> = <span class="type">Value</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">T</span> = <span class="type">Value</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">W</span> = <span class="type">Value</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//第三种初始化</span></span><br><span class="line">    <span class="comment">//调用Value方法设置值id或者name</span></span><br><span class="line">    <span class="comment">//id为Int，name为String</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">M2</span> = <span class="type">Value</span>(<span class="number">30</span>,<span class="string">"M2"</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">M3</span> = <span class="type">Value</span>(<span class="number">40</span>)<span class="comment">//可以只设置id或name</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">M4</span> = <span class="type">Value</span>(<span class="string">"M4name"</span>)<span class="comment">//Id默认为11,在之前+1</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">testEnume</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> <span class="type">Mon</span> = <span class="type">Week</span>.<span class="type">Monday</span> </span><br><span class="line">        <span class="keyword">val</span> <span class="type">M4Id</span> = <span class="type">Week</span>.withName(<span class="string">"M4name"</span>) <span class="comment">//获取Id</span></span><br><span class="line">        <span class="keyword">val</span> m4 = <span class="type">Week</span>(<span class="number">41</span>) <span class="comment">//获取值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历</span></span><br><span class="line">        <span class="keyword">for</span> ( w &lt;- <span class="type">Week</span>.values )&#123;</span><br><span class="line">            printf(<span class="string">"id:%s , value:%s"</span>,w.id,w)</span><br><span class="line">            println (<span class="string">""</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        println(<span class="string">"Mon:"</span>+<span class="type">Mon</span>)</span><br><span class="line">        println(<span class="string">"M4Id:"</span>+<span class="type">M4Id</span>)</span><br><span class="line">        println(<span class="string">"m4:"</span>+m4)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">id:<span class="number">0</span> , value:<span class="type">Monday</span></span><br><span class="line">id:<span class="number">1</span> , value:<span class="type">Tuesday</span></span><br><span class="line">id:<span class="number">2</span> , value:<span class="type">Wednesday</span></span><br><span class="line">id:<span class="number">3</span> , value:<span class="type">Thursday</span></span><br><span class="line">id:<span class="number">4</span> , value:<span class="type">Friday</span></span><br><span class="line">id:<span class="number">5</span> , value:<span class="type">Saturday</span></span><br><span class="line">id:<span class="number">6</span> , value:<span class="type">Sunday</span></span><br><span class="line">id:<span class="number">7</span> , value:<span class="type">M</span></span><br><span class="line">id:<span class="number">8</span> , value:<span class="type">T</span></span><br><span class="line">id:<span class="number">9</span> , value:<span class="type">W</span></span><br><span class="line">id:<span class="number">30</span> , value:<span class="type">M2</span></span><br><span class="line">id:<span class="number">40</span> , value:<span class="type">M3</span></span><br><span class="line">id:<span class="number">41</span> , value:<span class="type">M4name</span></span><br><span class="line"><span class="type">Mon</span>:<span class="type">Monday</span></span><br><span class="line"><span class="type">M4Id</span>:<span class="type">M4name</span></span><br><span class="line">m4:<span class="type">M4name</span></span><br></pre></td></tr></table></figure><blockquote><p>对于<code>枚举的初始化</code>，有上例中的三种方法；<br>第三种初始化可以指定id或者name，<code>id为Int类型，name为String类型</code>；<br>可以通过<code>id获取值</code>(<em>eg:Week(41</em>)默认调用了apply方法)，也可以通过<code>值来获取id</code>(<em>withName方法</em>)。</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--类</title>
      <link href="/2016/03/28/Scala-%E7%B1%BB/"/>
      <url>/2016/03/28/Scala-%E7%B1%BB/</url>
      <content type="html"><![CDATA[<p>　　<code>scala类</code>，是比较精简。主构造器和类交织在一起，而且，scala类上面声明的全局变量，自带了get/set方法，还可以转化为java的bean。总体来说比较简单，精简，易懂。</p><a id="more"></a><h2 id="一个简单的类"><a href="#一个简单的类" class="headerlink" title="一个简单的类"></a>一个简单的类</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/28.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleClazz</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> num = <span class="number">0</span> ;<span class="comment">//必须初始化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//默认是一个public方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">increase</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">        num += <span class="number">1</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//一个简单的取值方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIncrease</span> </span>= num ;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试一下</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestSimpleClazz</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> simple = <span class="keyword">new</span> <span class="type">SimpleClazz</span>()</span><br><span class="line">        simple.increase() <span class="comment">//建议有“()”</span></span><br><span class="line">        println( simple.getIncrease ) <span class="comment">//可以省略“()”</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure><blockquote><p>scala文件可以包含多个类，<strong>类中的成员变量必须初始化</strong>。<br>调用scala类中需要<code>new 类[()]</code>，“()”可以省略。<br>调用该方法是如果是一个简单的取值方法可以省略“()”，否则建议添加“()”。注：只是建议的一种风格而已。</p></blockquote><h2 id="get-set"><a href="#get-set" class="headerlink" title="get/set"></a>get/set</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.beans.<span class="type">BeanProperty</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/28.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetSetClazz</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//必须初始化</span></span><br><span class="line">    <span class="comment">//默认共有字段，自带共有get/set方法</span></span><br><span class="line">    <span class="keyword">var</span> name = <span class="string">"twosnail"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//共有字段，由于声明为val不能修改所以只带get方法</span></span><br><span class="line">    <span class="keyword">val</span> age = <span class="number">23</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//私有字段，只有自己能访问的get/set方法</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> sex = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//私有字段，只有自己能访问的get方法</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> work = <span class="string">"hadoop工程师"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//@BeanProperty生成JavaBeans规范get/set</span></span><br><span class="line">    <span class="meta">@BeanProperty</span> <span class="keyword">var</span> height = <span class="number">175.00</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setSex</span></span>( sex : <span class="type">Int</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">        <span class="keyword">if</span>( sex != <span class="number">0</span> &amp;&amp; sex != <span class="number">1</span> )&#123;</span><br><span class="line">            println(<span class="string">"性别设置异常！"</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">this</span>.sex = sex</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getSex</span> </span>= sex <span class="comment">//自定义的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getWork</span> </span>= work  <span class="comment">//自定义方法提供给外部访问</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试一下</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestGetSetClazz</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> clazz = <span class="keyword">new</span> <span class="type">GetSetClazz</span>()</span><br><span class="line">        <span class="comment">//var name 可以get/set</span></span><br><span class="line">        clazz.name = <span class="string">"xiaoxiaomo"</span></span><br><span class="line">        println(clazz.name)</span><br><span class="line">        <span class="comment">//val age 只有get</span></span><br><span class="line">        println(clazz.age)</span><br><span class="line">        <span class="comment">//java规范或者普通的</span></span><br><span class="line">        clazz.setHeight(<span class="number">180.00</span>)<span class="comment">//等于 clazz.height = 180.00</span></span><br><span class="line">        println(clazz.getHeight)<span class="comment">//等于 println(clazz.height)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//调用自定义方法</span></span><br><span class="line">        clazz.setSex(<span class="number">0</span>)</span><br><span class="line">        println(clazz.getSex)</span><br><span class="line">        println(clazz.getWork)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>执行结果</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xiaoxiaomo</span><br><span class="line">23</span><br><span class="line">180.0</span><br><span class="line">0</span><br><span class="line">hadoop工程师</span><br></pre></td></tr></table></figure><p>对于<code>get/set</code>的用法很简单，只需要记住几点就行了：</p><blockquote><p><code>成员变量需要需要初始化</code><br><code>默认共有的字段外部可以访问和修改</code>（<code>val类型的不可以修改</code>）<br><code>私有的成员变量外部不可以访问</code>，在类的作用范围内可使用<br>访问当权对象的字段可以使用this<br>变量声明前加<code>@BeanProperty</code>生成<code>JavaBeans规范get/set</code>，即getXXX,setXXX。</p></blockquote><h2 id="构造器"><a href="#构造器" class="headerlink" title="构造器"></a>构造器</h2><h3 id="主构造器"><a href="#主构造器" class="headerlink" title="主构造器"></a>主构造器</h3><p>在scala中，<strong>每一个类都用主构造器</strong>，并和类的定义交织在一起。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 主构造器</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/28.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StructureClazz</span>(<span class="params"> val name:<span class="type">String</span> , private var age :<span class="type">Int</span> = 0</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"这是一个主构造器！ name："</span>+ name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addAge</span> </span>= age += <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getAge</span></span>() = age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestStructure</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> test = <span class="keyword">new</span> <span class="type">StructureClazz</span>(<span class="string">"xiaoxiaomo"</span>)</span><br><span class="line">        println(test.getAge())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这是一个主构造器！ name：xiaoxiaomo</span><br><span class="line">0</span><br></pre></td></tr></table></figure><p>记住重要的一点，就是：<code>默认的构造器(主构造器)和类交织在一起</code>。</p><blockquote><p>主构造器的<code>参数直接跟在类名后面</code>；<br>主构造器如果没有参数，就是一个<code>无参的主构造器</code>，仅仅是简单的执行以下类里面的语句；<br>参数可以添加默认值，修饰符，<code>如果没有默认值时在构造这个函数时必须传值初始化</code>；<br>构造一个构造器时，<code>会默认执行类中语句</code>（我们可以去加载一些配置文件等）。</p></blockquote><h3 id="辅助构造器"><a href="#辅助构造器" class="headerlink" title="辅助构造器"></a>辅助构造器</h3><p>scala类中，除了主构造器之外还有很多辅助构造器，赋值构造器使用<code>this</code>命名<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 辅助构造器</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/28.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AssistClazz</span>(<span class="params"> val name:<span class="type">String</span> , private var age :<span class="type">Int</span> = 0</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> sex = <span class="number">0</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> height = <span class="number">175.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//第一个辅助构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(sex:<span class="type">Int</span>)&#123;</span><br><span class="line">        <span class="keyword">this</span>(<span class="string">"xiaoxiaomo"</span>)<span class="comment">//调用的主构造器</span></span><br><span class="line">        <span class="keyword">this</span>.sex = sex</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//第二个辅助构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(sex:<span class="type">Int</span>,height:<span class="type">Double</span>)&#123;</span><br><span class="line">        <span class="keyword">this</span>(sex)<span class="comment">//调用的上面一个辅助构造器</span></span><br><span class="line">        <span class="keyword">this</span>.height = height</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试一下</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestAssistClazz</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">AssistClazz</span>(<span class="string">"twosnail"</span>)<span class="comment">//调用的主构造器</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">AssistClazz</span>(<span class="string">"twosnail"</span>,<span class="number">23</span>)<span class="comment">//调用主构造器</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">AssistClazz</span>(<span class="number">1</span>)<span class="comment">//调用第一个辅助构造器</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">AssistClazz</span>(<span class="number">1</span>,<span class="number">178.0</span>)<span class="comment">//调用第二个辅助构造器</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>辅助构造器的名称为this；<br>每一个辅助构造器都必须以一个对先前已定义的其他辅助构造器或主构造器的调用开始（必须在第一行）；<br>通常我们可以在主构造器中使用默认参数来避免过多的使用辅助构造器；</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java--内部类</title>
      <link href="/2016/03/27/Java-%E5%86%85%E9%83%A8%E7%B1%BB/"/>
      <url>/2016/03/27/Java-%E5%86%85%E9%83%A8%E7%B1%BB/</url>
      <content type="html"><![CDATA[<p>　　一提到写Java的博客，就有点犯困，原因是：<code>大牛太多</code>！自己写好一篇博客感觉压力挺大的，因为随便一搜就是一大堆优秀的博客，笔记Java这个生态系统发展这么多年已经很完善了。我在这里只是做一些总结和完善吧，写之前我也阅读过很多相关博客，不得不承认他们的优秀。</p><a id="more"></a><p><code>内部类</code>，就是在一个类里面再定义一个类。分为四大类：<code>成员内部类</code>、<code>匿局部内部类</code>、<code>匿名内部类</code>和<code>静态内部类</code>。</p><h2 id="成员内部类"><a href="#成员内部类" class="headerlink" title="成员内部类"></a>成员内部类</h2><ul><li><p><code>成员内部</code>：<code>定义一个类位于另一个类的内部</code>，内部类能无限制的访问<code>外围类公有/私有</code>成员变量和方法。如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo01</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  </span>&#123;</span><br><span class="line">        Outer o = <span class="keyword">new</span> Outer();</span><br><span class="line">        o.method();</span><br><span class="line"><span class="comment">//如果，Inter为public则调用show方法时，使用如下代码</span></span><br><span class="line"><span class="comment">//Outer.Inter i = new Outer().new Inter();</span></span><br><span class="line">        <span class="comment">//i.show();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123; <span class="comment">//外部</span></span><br><span class="line">    <span class="keyword">private</span> String name = <span class="string">"momo"</span> ; <span class="comment">//Outer.this.name</span></span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">10</span>;<span class="comment">//Outer.this.num</span></span><br><span class="line">    <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Inter</span> </span>&#123; <span class="comment">//编译源码会发现=&gt;内部类,持有一个外围类的引用</span></span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">20</span>;<span class="comment">//this.num</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> num = <span class="number">30</span>;<span class="comment">//num</span></span><br><span class="line"><span class="comment">//外围类的private，name成员变量</span></span><br><span class="line">            System.out.println(<span class="string">"name:"</span>+Outer.<span class="keyword">this</span>.name+<span class="string">" Outer.this.num:"</span>+</span><br><span class="line">                    Outer.<span class="keyword">this</span>.num+<span class="string">" this.num:"</span>+<span class="keyword">this</span>.num +<span class="string">" num:"</span>+num );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Inter i = <span class="keyword">new</span> Inter(); <span class="comment">//提供一个访问入口</span></span><br><span class="line">        i.show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>运行结果：name:momo Outer.this.num:10 this.num:20 num:30</p></li></ul><h2 id="局部内部类"><a href="#局部内部类" class="headerlink" title="局部内部类"></a>局部内部类</h2><ul><li><p><code>局部内部类</code>：<code>嵌套在方法和作用于内的</code>。主要是应用于想创建一个类来辅助我们的解决解决比较复杂的问题，又不希望这个类是公共可用的，所以就产生了局部内部类。局部内部类和成员内部作用域不同，它<code>只能在该方法和属性中被使用，出了该方法和属性就会失效</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo02</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        Outer02 o = <span class="keyword">new</span> Outer02();</span><br><span class="line">        o.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer02</span> </span>&#123;<span class="comment">//外部</span></span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">10</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">20</span>; <span class="comment">//在这里定义的num内部类访问不到</span></span><br><span class="line">        <span class="class"><span class="keyword">class</span> <span class="title">Inter02</span> </span>&#123;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">int</span> num = <span class="number">30</span> ;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"Outer02.this.num:"</span>+Outer02.<span class="keyword">this</span>.num +</span><br><span class="line">                        <span class="string">" this.num:"</span>+<span class="keyword">this</span>.num+<span class="string">" num:"</span>+num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Inter02 in = <span class="keyword">new</span> Inter02();</span><br><span class="line">        in.show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>运行结果：Outer02.this.num:10 this.num:<code>30</code> num:30</p></li></ul><blockquote><p>成员内部类中不能存在任何public、protected、private以及static的变量和方法；</p></blockquote><h2 id="匿名内部类"><a href="#匿名内部类" class="headerlink" title="匿名内部类"></a>匿名内部类</h2><p><code>匿名内部类</code>：<code>必须要继承一个父类或者实现一个接口</code>，只是用一次，通常用来简化代码。没有class关键字，因为匿名内部类是直接使用new来生成一个对象的引用。当然这个引用是隐式的，没有构造方法。</p><ul><li><p>匿名内部类的结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> 父类构造器（参数列表）| 实现结构（）&#123;</span><br><span class="line"><span class="comment">//重写父类的方法或实现接口的方法</span></span><br><span class="line"><span class="comment">//目的：在这个地方想对某个类有特殊实现。</span></span><br><span class="line"><span class="comment">//对于java任何类或接口，都可以声明一个匿名内部类继承或实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo03</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Outer03 o = <span class="keyword">new</span> Outer03();</span><br><span class="line">        o.method(<span class="string">"xiaoxiaomo"</span>,<span class="number">23</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//抽象类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbsDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer03</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(<span class="keyword">final</span> String name,<span class="keyword">int</span> num)</span></span>&#123;</span><br><span class="line"><span class="comment">//new AbsDemo()&#123;//匿名内部类,第一种调用方式</span></span><br><span class="line"><span class="comment">//public void show()&#123;</span></span><br><span class="line"><span class="comment">//System.out.println(name);</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"><span class="comment">//&#125;.show();</span></span><br><span class="line"></span><br><span class="line">        AbsDemo a = <span class="keyword">new</span> AbsDemo()&#123;<span class="comment">//第二种</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>&#123;</span><br><span class="line">                System.out.println(name <span class="comment">/*+num*/</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;  <span class="comment">//分号不能省</span></span><br><span class="line">        a.show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><blockquote><ul><li>匿名内部类是没有访问修饰符的。</li><li><code>new 匿名内部类()</code>;这个类首先是要存在的。如果我们将那个AbsDemo抽象类注释掉，会编译出错。</li><li>注意method()方法的形参，第一个形参是用final修饰的，而第二个却没有（使用就会编译出错）。所以当方法的形参需要被匿名内部类使用，那么这个形参就必须为final。</li></ul></blockquote><h2 id="静态内部类。"><a href="#静态内部类。" class="headerlink" title="静态内部类。"></a>静态内部类。</h2><p><code>静态内部类</code>：使用static修饰的内部类称之为静态内部类。静态内部类与非静态内部类之间存在一个最大的区别，就是<code>非静态内部类在编译完成之后会持有一个外围类的引用，但是静态内部类却没有</code>。没有这个引用就意味着：</p><ol><li>它的创建是不需要依赖于外围类的。</li><li>它不能使用任何外围类的非static成员变量和方法。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo04</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Outer04.Inner i = <span class="keyword">new</span> Outer04.Inner();</span><br><span class="line">        i.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer04</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name = <span class="string">"xiaoxiaomo"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> num = <span class="number">8</span> ; <span class="comment">//静态</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Inner</span></span>&#123;</span><br><span class="line">        <span class="comment">//String s = name ; //不能使用非静态变量</span></span><br><span class="line">        String str  = <span class="string">"这里可以"</span> ;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span></span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"num:"</span>+num+<span class="string">" str:"</span>+str);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="内部类的作用"><a href="#内部类的作用" class="headerlink" title="内部类的作用"></a>内部类的作用</h2><ul><li><p>作用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">方便将存在一定逻辑关系的类关联到一起，并可以实现隐藏。比如一般的类不能进行私有化操作。</span><br><span class="line">内部类是的多继承的解决方案更加完善。比如我们可以在第一个类里面定义多个内部类分别继承不同的类。</span><br><span class="line">能无条件的访问外围类所有元素</span><br><span class="line">很方便的编写多线程和事件驱动程序。</span><br></pre></td></tr></table></figure></li><li><p>参考资料：</p></li><li><a href="http://www.cnblogs.com/chenssy/p/3388487.html" target="_blank" rel="noopener">http://www.cnblogs.com/chenssy/p/3388487.html</a></li><li><a href="http://blog.csdn.net/chenssy/article/details/13170015" target="_blank" rel="noopener">http://blog.csdn.net/chenssy/article/details/13170015</a></li><li><a href="http://www.cnblogs.com/nerxious/archive/2013/01/25/2876489.html" target="_blank" rel="noopener">http://www.cnblogs.com/nerxious/archive/2013/01/25/2876489.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--映射和元祖</title>
      <link href="/2016/03/26/Scala-%E6%98%A0%E5%B0%84%E5%92%8C%E5%85%83%E7%A5%96/"/>
      <url>/2016/03/26/Scala-%E6%98%A0%E5%B0%84%E5%92%8C%E5%85%83%E7%A5%96/</url>
      <content type="html"><![CDATA[<p>　　<code>映射</code>,就是键值对偶的集合，元祖就是n个对象的聚集，所以对偶就是n=2的元祖。简单来说就相当于java中的Map。</p><a id="more"></a><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><blockquote><p><code>两种定义方式</code><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> map = <span class="type">Map</span>(<span class="string">"a"</span> -&gt; <span class="number">1</span> , <span class="string">"b"</span> -&gt; <span class="number">2</span> ,<span class="string">"c"</span> -&gt; <span class="number">3</span>)         ##第一种定义方式</span><br><span class="line">map: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(a -&gt; <span class="number">1</span>, b -&gt; <span class="number">2</span>, c -&gt; <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; map(<span class="string">"d"</span>) = <span class="number">4</span>                                         ##赋值</span><br><span class="line">&lt;console&gt;:<span class="number">12</span>: error: value update is not a member of scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>]</span><br><span class="line">       map(<span class="string">"d"</span>) = <span class="number">4</span></span><br><span class="line">       ^</span><br><span class="line">scala&gt; <span class="keyword">val</span> map2 = <span class="type">Map</span>((<span class="string">"a"</span>,<span class="number">1</span>),(<span class="string">"b"</span>,<span class="number">2</span>),(<span class="string">"c"</span>,<span class="number">3</span>))              ##第二种定义方式</span><br><span class="line">map2: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(a -&gt; <span class="number">1</span>, b -&gt; <span class="number">2</span>, c -&gt; <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p></blockquote><ol><li>定义对偶：使用 “<code>-&gt;</code>“ 。</li><li>直接使用Map是使用<code>immutable下面的Map</code>,此时这个map是<code>一个不可变的</code>。</li><li>如果要定义一个<code>可变的Map</code>需要<code>scala.collection.mutable.Map</code>，下面定义一个可变的map:<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> canchage = scala.collection.mutable.<span class="type">Map</span>(<span class="string">"a"</span> -&gt; <span class="number">1</span> , <span class="string">"b"</span> -&gt; <span class="number">2</span> ,<span class="string">"c"</span> -&gt; <span class="number">3</span>)</span><br><span class="line">canchage: scala.collection.mutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(b -&gt; <span class="number">2</span>, a -&gt; <span class="number">1</span>, c -&gt; <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; canchage(<span class="string">"d"</span>) = <span class="number">4</span>  <span class="comment">//能正常的修改值</span></span><br><span class="line"></span><br><span class="line">scala&gt; canchage(<span class="string">"d"</span>)   <span class="comment">//获取值</span></span><br><span class="line">res10: <span class="type">Int</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="获取值"><a href="#获取值" class="headerlink" title="获取值"></a>获取值</h2><h3 id="获取单个值"><a href="#获取单个值" class="headerlink" title="获取单个值"></a>获取单个值</h3><p>从上面的事例可以看出，获取值可以直接使用：<code>变量名(&quot;key&quot;)</code>。</p><ul><li>但如果没有该key怎么办？<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; map(<span class="string">"d"</span>)</span><br><span class="line">java.util.<span class="type">NoSuchElementException</span>: key not found: d</span><br><span class="line">  at scala.collection.<span class="type">MapLike</span>$<span class="class"><span class="keyword">class</span>.<span class="title">default</span>(<span class="params"><span class="type">MapLike</span>.scala:228</span>)</span></span><br><span class="line"><span class="class">  <span class="title">at</span> <span class="title">scala</span>.<span class="title">collection</span>.<span class="title">AbstractMap</span>.<span class="title">default</span>(<span class="params"><span class="type">Map</span>.scala:59</span>)</span></span><br><span class="line"><span class="class">  <span class="title">at</span> <span class="title">scala</span>.<span class="title">collection</span>.<span class="title">MapLike$class</span>.<span class="title">apply</span>(<span class="params"><span class="type">MapLike</span>.scala:141</span>)</span></span><br><span class="line"><span class="class">  <span class="title">at</span> <span class="title">scala</span>.<span class="title">collection</span>.<span class="title">AbstractMap</span>.<span class="title">apply</span>(<span class="params"><span class="type">Map</span>.scala:59</span>)</span></span><br><span class="line"><span class="class">  ... 33 <span class="title">elided</span></span></span><br></pre></td></tr></table></figure></li></ul><ol><li>当不存在key时，直接会抛出异常，可以使用<code>contains</code>进行判断;</li><li>或者直接使用，<code>getOrElse(&quot;key&quot;,如不存在的值)</code>;<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; map.contains(<span class="string">"d"</span>)</span><br><span class="line">res14: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">scala&gt; map.getOrElse(<span class="string">"d"</span>,<span class="number">66</span>)</span><br><span class="line">res15: <span class="type">Int</span> = <span class="number">66</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="迭代映射"><a href="#迭代映射" class="headerlink" title="迭代映射"></a>迭代映射</h3><p>有<a href="http://blog.xiaoxiaomo.com/2016/03/25/Scala-%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%E5%92%8C%E5%87%BD%E6%95%B0/">for基础</a>后，再来看迭代就很简单了，直接看事例吧：</p><ul><li>示例：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span>((k,v) &lt;- map) print(k+<span class="string">"-&gt;"</span>+v + <span class="string">", "</span>)     ##迭代键、值</span><br><span class="line">a-&gt;<span class="number">1</span>, b-&gt;<span class="number">2</span>, c-&gt;<span class="number">3</span>,</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">for</span>(k &lt;- map.keySet) print(k+ <span class="string">", "</span>)          ##迭代键</span><br><span class="line">a, b, c,</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">for</span>(v &lt;- map.values) print(v+ <span class="string">", "</span>)          ##迭代值</span><br><span class="line"><span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,</span><br></pre></td></tr></table></figure></li></ul><blockquote><ol><li>基本语法就是：<code>for((k ,v) &lt;- 映射 ) 处理k/v</code></li><li>如果只想获取值就迭代<code>values</code>,只想获取键迭代<code>keySet</code></li></ol></blockquote><h2 id="更新值"><a href="#更新值" class="headerlink" title="更新值"></a>更新值</h2><ul><li><code>下面更新操作都是在可变的映射下完成</code>，现在canchage中有key-&gt;a、b、c、d<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; canchage(<span class="string">"d"</span>) = <span class="number">7</span>                            ##直接修改</span><br><span class="line">scala&gt; canchage(<span class="string">"e"</span>) = <span class="number">5</span>                            ##不存在该值即添加该元祖</span><br><span class="line">scala&gt; canchage                                     ##查看一下map中的数据</span><br><span class="line">res23: scala.collection.mutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>]=<span class="type">Map</span>(e-&gt;<span class="number">5</span>,b-&gt;<span class="number">2</span>,d-&gt;<span class="number">7</span>,a-&gt;<span class="number">1</span>,c-&gt;<span class="number">3</span>)</span><br><span class="line">scala&gt; canchage += (<span class="string">"e"</span>-&gt; <span class="number">1</span> ,<span class="string">"f"</span>-&gt;<span class="number">6</span>)                ##这样同样可以修改和增加</span><br><span class="line">res24: canchage.<span class="keyword">type</span> = <span class="type">Map</span>(e -&gt; <span class="number">1</span>, b -&gt; <span class="number">2</span>, d -&gt; <span class="number">7</span>, a -&gt; <span class="number">1</span>, c -&gt; <span class="number">3</span>, f -&gt; <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; canchage -= (<span class="string">"e"</span>,<span class="string">"a"</span>)                        ##删除多个</span><br><span class="line">res25: canchage.<span class="keyword">type</span> = <span class="type">Map</span>(b -&gt; <span class="number">2</span>, d -&gt; <span class="number">7</span>, c -&gt; <span class="number">3</span>, f -&gt; <span class="number">6</span>)</span><br><span class="line">scala&gt; canchage -= <span class="string">"b"</span>                              ##删除单个</span><br><span class="line">res26: canchage.<span class="keyword">type</span> = <span class="type">Map</span>(d -&gt; <span class="number">7</span>, c -&gt; <span class="number">3</span>, f -&gt; <span class="number">6</span>)</span><br></pre></td></tr></table></figure></li></ul><ol><li><p>从上面的事例可以看出map的顺序在不断地改变，如果要创建一个不可变的Map使用：<code>scala.collection.mutable.LinkedHashMap</code></p></li><li><p>对于不可变的映射，可以重新再定义一个变量，后面添加需要修改和添加的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">scala&gt; map</span><br><span class="line">res43: scala.collection.immutable.Map[String,Int] = Map(a -&gt; 1, b -&gt; 2, c -&gt; 3)</span><br><span class="line"></span><br><span class="line">scala&gt; val mapch = map + (&quot;a&quot;-&gt;10 , &quot;d&quot;-&gt;14)        ##mapch同样不可改变</span><br><span class="line">mapch: scala.collection.immutable.Map[String,Int] = Map(a -&gt; 10, b -&gt; 2, c -&gt; 3, d -&gt; 14)</span><br></pre></td></tr></table></figure></li></ol><h2 id="与java互转"><a href="#与java互转" class="headerlink" title="与java互转"></a>与java互转</h2><blockquote><p>示例代码，java 转为scala<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.JavaConverters;</span><br><span class="line"><span class="keyword">import</span> scala.collection.immutable.Map$;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * java 代码</span></span><br><span class="line"><span class="comment"> * javamap 转为scala map</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/26.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaMap</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取一个java Map</span></span><br><span class="line">        Map&lt;String, Integer&gt; map = getJavaMap();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//java map 转换为可变的scala map</span></span><br><span class="line">        scala.collection.mutable.Map&lt;String, Integer&gt; mutableMap = JavaConverters.mapAsScalaMapConverter(map).asScala();</span><br><span class="line">        System.out.println(mutableMap.keySet());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//java map 转换为不可变的scala map</span></span><br><span class="line">        Object obj = Map$.MODULE$.&lt;String,Integer&gt;newBuilder().$plus$plus$eq(mutableMap.toSeq());</span><br><span class="line">        Object result = ((scala.collection.mutable.Builder) obj).result();</span><br><span class="line"></span><br><span class="line">        scala.collection.immutable.Map&lt;String,String&gt; immutableMap = (scala.collection.immutable.Map)result;</span><br><span class="line">        System.out.println(immutableMap.keySet());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String,Integer&gt; <span class="title">getJavaMap</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Map&lt;String,Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String,Integer&gt;() ;</span><br><span class="line">        map.put(<span class="string">"a"</span>,<span class="number">1</span>);</span><br><span class="line">        map.put(<span class="string">"b"</span>, <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">return</span> map ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="元祖"><a href="#元祖" class="headerlink" title="元祖"></a>元祖</h2><p><code>元祖</code>，就是不同类型值的聚集。<code>元祖的值是通过将单个的值包含在圆括号中构成的</code>。下面来看看元祖的一些使用（赋值、获取值）。</p><ul><li><p>实例代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">scala&gt; (<span class="string">"blog"</span>,<span class="string">"."</span>,<span class="string">"xiaoxiaomo"</span>,<span class="number">19</span>)</span><br><span class="line">res31: (<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">Int</span>) = (blog,.,xiaoxiaomo,<span class="number">19</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; res31._1                     ##可以看出元祖的下标是从<span class="number">1</span>开始，获取值使用“._”</span><br><span class="line">res32: <span class="type">String</span> = blog</span><br><span class="line"></span><br><span class="line">scala&gt; res31 _3                    ##第二种获取元祖方法“ _”，注意中间有一个空格</span><br><span class="line">warning: there was one feature warning; re-run <span class="keyword">with</span> -feature <span class="keyword">for</span> details</span><br><span class="line">res33: <span class="type">String</span> = xiaoxiaomo</span><br></pre></td></tr></table></figure></li><li><p>还有另一种获取元祖的方式，叫做<code>模式匹配</code>。这种方式可使一个方法变相的返回<code>多个返回值</code>，示例如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> (a,b,c,_) = res31        ##hexo不想匹配的值使用“_”</span><br><span class="line">a: <span class="type">String</span> = blog</span><br><span class="line">b: <span class="type">String</span> = .</span><br><span class="line">c: <span class="type">String</span> = xiaoxiaomo  </span><br><span class="line"></span><br><span class="line">scala&gt; a</span><br><span class="line">res34: <span class="type">String</span> = blog</span><br><span class="line"></span><br><span class="line">scala&gt; c</span><br><span class="line">res35: <span class="type">String</span> = xiaoxiaomo</span><br></pre></td></tr></table></figure></li></ul><h2 id="拉链操作"><a href="#拉链操作" class="headerlink" title="拉链操作"></a>拉链操作</h2><p><code>元祖</code>可以把很多值关联起来，以便统一处理。<code>对于这种链式处理，我们还可以使用zip</code>,还<strong>可以让两个数组组合成一个对偶数组</strong>，然后对偶数组可以<code>toMap</code>转为映射。</p><ul><li><p>示例代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> k = <span class="type">Array</span>(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>)       ##数组<span class="number">1</span></span><br><span class="line">k: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(a, b, c)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> v1 = <span class="type">Array</span>(<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>)            ##数组<span class="number">2</span></span><br><span class="line">v1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; k.zip(v1)                        ##两个数组组合成一个对偶数组</span><br><span class="line">res37: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((a,<span class="number">7</span>), (b,<span class="number">8</span>), (c,<span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; res37.toMap                      ##对偶数组转为映射</span><br><span class="line">res38: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(a -&gt; <span class="number">7</span>, b -&gt; <span class="number">8</span>, c -&gt; <span class="number">9</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>注</code> ：如果两个数组的长度不一致，会以长度短的为准，长的数据会丢失。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> v = <span class="type">Array</span>(<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>)</span><br><span class="line">v: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; k.zip(v)</span><br><span class="line">res39: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((a,<span class="number">7</span>), (b,<span class="number">8</span>), (c,<span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; v.zip(k)</span><br><span class="line">res41: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">7</span>,a), (<span class="number">8</span>,b), (<span class="number">9</span>,c))</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--数组</title>
      <link href="/2016/03/26/Scala-%E6%95%B0%E7%BB%84/"/>
      <url>/2016/03/26/Scala-%E6%95%B0%E7%BB%84/</url>
      <content type="html"><![CDATA[<p>　　<code>数组</code>，<strong>存储相同类型元素的连续集合</strong>。在JVM中，scala以java数组的方式实现，Array[Int],Array[String]等分别对应着java的基本类型数组int[]、String[]。</p><a id="more"></a><h2 id="数组语法"><a href="#数组语法" class="headerlink" title="数组语法"></a>数组语法</h2><ul><li><p><code>语法</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span>|<span class="keyword">var</span> 变量名：<span class="type">Array</span>[变量类型] = <span class="keyword">new</span> <span class="type">Array</span>[变量类型](长度)　　#数组的定义</span><br><span class="line"><span class="keyword">val</span>|<span class="keyword">var</span> 变量名 = <span class="keyword">new</span> <span class="type">Array</span>[变量类型](长度)　　#简化形式（常用）</span><br><span class="line"><span class="keyword">val</span>|<span class="keyword">var</span> 变量名 = <span class="type">Array</span>(初始化值)　　#直接初始化值，自动会进行类型推断</span><br></pre></td></tr></table></figure></li><li><p><strong>示例一</strong>：定义了一个长度为5的String数组，然后可以看见该数组被默认初始化为5个null值在数组中</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> array: <span class="type">Array</span>[<span class="type">String</span>] = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">5</span>)</span><br><span class="line">array: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>)</span><br><span class="line"></span><br><span class="line">###然后定义五个<span class="type">Int</span>类型的数组，默认初始化为<span class="number">0</span>。</span><br><span class="line">scala&gt; <span class="keyword">var</span> array1 = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">5</span>)</span><br><span class="line">array1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>示例二</strong>：定义数组并初始化值，如果没有指定数组类型，会自动进行类型推断</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> array2 = <span class="type">Array</span>(<span class="number">8989</span>,<span class="string">"xiaoxiaomo"</span>)</span><br><span class="line">array2: <span class="type">Array</span>[<span class="type">Any</span>] = <span class="type">Array</span>(<span class="number">8989</span>, xiaoxiaomo)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> array3 = <span class="type">Array</span>(<span class="number">8989</span>,<span class="number">77.5</span>)</span><br><span class="line">array3: <span class="type">Array</span>[<span class="type">Double</span>] = <span class="type">Array</span>(<span class="number">8989.0</span>, <span class="number">77.5</span>)</span><br></pre></td></tr></table></figure></li><li><p>从上面的例子中可以看到：</p><blockquote><ol><li>当我们定义数组时，如果没有初始化值它会根据数据的长度<code>自动初始化</code>，设置默认参数；</li><li>数组可以自己进行类型推断，当类型不一致时，会为<code>Any类型</code>；</li><li><code>提供了初始值就不需要new</code>;</li><li><code>定长数组必须指定数组长度</code>；</li></ol></blockquote></li></ul><blockquote><p>还需要注意的是，如果数组声明为val那么该<strong>数组的值</strong>是可以改变的；只是该<strong>变量</strong>不能重新被赋值，即<strong>变量指定的数组对象地址不能改变，数组对象的值可以变</strong>。</p></blockquote><ul><li><p><code>变长数组</code></p></li><li><p>变长数组，使用<code>ArrayBuffer</code>也叫<code>数组缓冲</code>。就是定义一个可以改变的数组，在定义时<strong>可以不指定数组长度</strong>，如下示例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ab = <span class="keyword">new</span> scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line">ab: scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = <span class="type">ArrayBuffer</span>()</span><br><span class="line"></span><br><span class="line">scala&gt; ab += <span class="number">12</span>;    ##虽然是<span class="keyword">val</span>定义的变量，但是我们还是可以修改值。</span><br><span class="line">res0: ab.<span class="keyword">type</span> = <span class="type">ArrayBuffer</span>(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; ab += (<span class="number">34</span>,<span class="number">45</span>)</span><br><span class="line">res1: ab.<span class="keyword">type</span> = <span class="type">ArrayBuffer</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; res0 ++=ab</span><br><span class="line">res2: res0.<span class="keyword">type</span> = <span class="type">ArrayBuffer</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>, <span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; ab.toArray</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>, <span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; res0.toArray</span><br><span class="line">res4: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>, <span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; res1.toArray</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>, <span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; res2.toArray</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>, <span class="number">12</span>, <span class="number">34</span>, <span class="number">45</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>注意</code></p></li></ul><ol><li><p>定义变长数组时，“<strong>()</strong>”可以省略。记住<code>省略“()”后就不能省略new,省略new就不能省略“()”</code>在下图事例中，第一种定义就无效；</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> abc = scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>]  ##`括号和<span class="keyword">new</span>至少要有一样`</span><br><span class="line">&lt;console&gt;:<span class="number">7</span>: error: missing arguments <span class="keyword">for</span> method apply in <span class="class"><span class="keyword">class</span> <span class="title">GenericCompanion</span></span>;</span><br><span class="line">follow <span class="keyword">this</span> method <span class="keyword">with</span> `_' <span class="keyword">if</span> you want to treat it as a partially applied function</span><br><span class="line">       <span class="keyword">val</span> abc = scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">                                                     ^</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> abc = scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line">abc: scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = <span class="type">ArrayBuffer</span>()</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> abc = <span class="keyword">new</span> scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">abc: scala.collection.mutable.<span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = <span class="type">ArrayBuffer</span>()</span><br></pre></td></tr></table></figure></li><li><p>给数组赋值时，可以使用“<code>+=单个参数|(多个)</code>”，“<code>++=数组</code>”在尾部追加数据；</p></li><li>赋值完成后，<code>可以使用toArray方法转为数组，当然也可使用toArrayBuffer转回去</code>；</li><li>数组常用方法，<code>remove</code>(…),<code>insert</code>(…),<code>trimEnd</code>;</li></ol><h2 id="数值遍历"><a href="#数值遍历" class="headerlink" title="数值遍历"></a>数值遍历</h2><ul><li>　　之前我们已经讲过for循环，使用上面定义的<strong>ab</strong>数组做一下遍历<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span>( i &lt;- <span class="number">0</span> until ab.length )&#123;</span><br><span class="line">     | print( <span class="string">" "</span> + ab(i) )</span><br><span class="line">     | &#125;</span><br><span class="line"> <span class="number">12</span> <span class="number">34</span> <span class="number">45</span> <span class="number">12</span> <span class="number">34</span> <span class="number">45</span></span><br><span class="line">scala&gt; <span class="keyword">for</span>( i &lt;- <span class="number">0</span> until ab.length <span class="keyword">if</span> ab(i) % <span class="number">4</span> ==<span class="number">0</span> )</span><br><span class="line">     | <span class="keyword">yield</span> ab(i)<span class="number">-6</span></span><br><span class="line">res9: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">6</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure></li></ul><p><code>注意</code>：</p><ol><li>数组的小标从0开始，所以最大小标为length-1，不然会越界，通常使用<code>unitl</code>；</li><li>获取数组元素的时候使用“<code>()</code>”,和java不同；</li><li><strong>使用yield可以创建一个新的集合，原始集合并不受影响</strong>，注意<strong>yield在“{}”的后面</strong>，“{}”也可省略；</li><li>当然同样可使用“<strong>带刀侍卫</strong>”(●’◡’●)，侍卫也能获取元素；</li></ol><h2 id="常用算法"><a href="#常用算法" class="headerlink" title="常用算法"></a>常用算法</h2><blockquote><p>具体内容可阅读<code>scaladoc</code>文档，这里简单的举例<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="type">Array</span>(<span class="number">8</span>,<span class="number">92</span>,<span class="number">32</span>,<span class="number">53</span>).sum</span><br><span class="line">res11: <span class="type">Int</span> = <span class="number">185</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">Array</span>(<span class="number">8</span>,<span class="number">92</span>,<span class="number">32</span>,<span class="number">53</span>).max</span><br><span class="line">res12: <span class="type">Int</span> = <span class="number">92</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">Array</span>(<span class="number">8</span>,<span class="number">92</span>,<span class="number">32</span>,<span class="number">53</span>).sorted</span><br><span class="line">res13: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">8</span>, <span class="number">32</span>, <span class="number">53</span>, <span class="number">92</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">Array</span>(<span class="number">8</span>,<span class="number">92</span>,<span class="number">32</span>,<span class="number">53</span>).sortWith(_ &gt; _)</span><br><span class="line">res14: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">92</span>, <span class="number">53</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">Array</span>(<span class="number">8</span>,<span class="number">92</span>,<span class="number">32</span>,<span class="number">53</span>).count(_ &gt; <span class="number">0</span> )</span><br><span class="line">res15: <span class="type">Int</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure></p></blockquote><h2 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h2><blockquote><p>多位数组和java的数组类似，里面也是使用了数组。二维数组使用关键只<code>ofDim</code>方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> dim = <span class="type">Array</span>.ofDim[<span class="type">Int</span>](<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">dim: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="type">Array</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; dim(<span class="number">0</span>)(<span class="number">1</span>) = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; dim(<span class="number">1</span>)(<span class="number">2</span>) = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">scala&gt; dim</span><br><span class="line">res18: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>), <span class="type">Array</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="与java互转"><a href="#与java互转" class="headerlink" title="与java互转"></a>与java互转</h2><p>与java互转操作，在后面应该会常用。在scala中<code>Scala.collection.JavaConversions</code>里的有隐式转换方法。</p><blockquote><p>下面来写一个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 一个简单的java代码demo</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/26.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaArraList</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getListStr</span><span class="params">()</span></span>&#123; <span class="comment">//会返回一个List&lt;String&gt;类型的集合</span></span><br><span class="line">        List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;() ;</span><br><span class="line">        list.add(<span class="string">"Hello"</span>);</span><br><span class="line">        list.add(<span class="string">"word"</span>);</span><br><span class="line">        <span class="keyword">return</span> list ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setListStr</span><span class="params">(List&lt;String&gt; arrList)</span></span>&#123;<span class="comment">//需要传递一个List集合</span></span><br><span class="line">        <span class="keyword">for</span> ( String str : arrList )</span><br><span class="line">            System.out.print(<span class="string">" "</span> + str);</span><br><span class="line">        System.out.println();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>scala操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xiaoxiaomo on 2016/3/25.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> sca = <span class="type">ArrayBuffer</span>(<span class="string">"Hl"</span>, <span class="string">"ooo"</span>, <span class="string">"woddd"</span>) ;</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      println(<span class="string">"scala转java"</span>)</span><br><span class="line">      <span class="keyword">new</span> <span class="type">JavaArraList</span>().setListStr(<span class="type">JavaConversions</span>.bufferAsJavaList(sca));</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      println(<span class="string">"java转scala"</span>)</span><br><span class="line">      <span class="keyword">val</span> j2s =<span class="type">JavaConversions</span>.asScalaBuffer(<span class="keyword">new</span> <span class="type">JavaArraList</span>().getListStr()) ;</span><br><span class="line">      <span class="keyword">for</span>( i &lt;- <span class="number">0</span> until j2s.length )  print( <span class="string">" "</span> + j2s(i) )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><ul><li>运行结果<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala转java</span><br><span class="line"> Hl ooo woddd</span><br><span class="line">java转scala</span><br><span class="line"> Hello word</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--控制结构和函数</title>
      <link href="/2016/03/25/Scala-%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%E5%92%8C%E5%87%BD%E6%95%B0/"/>
      <url>/2016/03/25/Scala-%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%E5%92%8C%E5%87%BD%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>　　本篇博客，将介绍scala的：</p><ol><li><code>条件表达式</code></li><li><code>循环</code></li><li><code>函数</code></li></ol><ul><li>主要是对这些<strong>表达式</strong>和<strong>语句结构</strong>的熟悉，需要多练习。在scala中表达式（3+4）和语句（if语句）是不同的概念，<code>表达式有值，语句执行动作</code>。</li><li><strong><code>记住</code></strong>，scala几乎所有构造出来的语法结构都有值。</li></ul><a id="more"></a><h2 id="条件表达式"><a href="#条件表达式" class="headerlink" title="条件表达式"></a>条件表达式</h2><ul><li><code>if/else</code>的表达式语法和java类似，只是需要注意的是：</li></ul><ol><li>if/else有返回值</li><li>scala代码结尾不需要“;”，除非一行要写多条语句，这个和<code>Python</code>类似。下例打印出了if的<strong>返回值</strong>1，这个小例子就充分说明了if语句是有返回值的。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> isTrue=<span class="literal">true</span></span><br><span class="line">isTrue: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">if</span>(isTrue) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>  ##返回值</span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> f = <span class="keyword">if</span>(isTrue) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>  ##返回值</span><br><span class="line">f: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></li></ol><ul><li><code>if/else表达式的类型推断</code>，取两个类型的公共父类型，如下String和Int，则表达式的值是Any<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> f = <span class="keyword">if</span>(isTrue) <span class="string">"this reture true"</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">f: <span class="type">Any</span> = <span class="keyword">this</span> reture <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="块语句"><a href="#块语句" class="headerlink" title="块语句"></a>块语句</h2><ul><li>在scala中“<code>{}</code>”包含的一系列表达式，叫做块语句，<code>块中最后一个表达式的值就是块的值</code>，即块的返回值。下面，定义一个块语句，执行后返回了变量ss的值，ss的值就是块语句中最后一个表达式的值。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ss = &#123; <span class="keyword">val</span> s1=<span class="number">78</span>; <span class="keyword">val</span> s2=s1*<span class="number">0.8</span>; s1+s2 &#125;</span><br><span class="line">ss: <span class="type">Double</span> = <span class="number">140.4</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h2><ul><li><p><code>while循环</code>，和java的while和do循环相同，这里就不过多讲解了，实例如下图所示。我们定义了一个var变量，然后通过while循环打印出结果，注意scala不支持<strong>n++</strong>,<strong>n- -</strong>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; :paste</span><br><span class="line"><span class="comment">// Entering paste mode (ctrl-D to finish)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> n =<span class="number">3</span></span><br><span class="line"><span class="keyword">while</span>( n &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">    n-=<span class="number">1</span></span><br><span class="line">    println(n)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Exiting paste mode, now interpreting.</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line">n: <span class="type">Int</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p>注：<strong>在”Repl”中写多行代码的时候</strong>，每写一行敲一下“回车键”然后它会自动去识别程序是否结束，直到你真正的写完代码，有时候不是很方便；<br>还有一种粘贴的方法，输入<code>:paste</code>然后就可以随意的写代码了，写完后<code>Ctrl+D</code>退出并运行代码，如上图所示。</p></li></ul><h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h2><h3 id="for基础"><a href="#for基础" class="headerlink" title="for基础"></a>for基础</h3><ul><li><p><code>语句结构</code>：</p><blockquote><p>for( i &lt;- 表达式 )  #让变量i遍历&lt;-右边的表达式的所有值，i具体执行取决于表达式<br>　　循环体</p></blockquote></li><li><p>示例1，for循环中的to：<code>to</code>：包含上线区间。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> n = <span class="number">10</span>; <span class="keyword">for</span>(i &lt;- <span class="number">1</span> to n) println(i)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">10</span></span><br><span class="line">n: <span class="type">Int</span> = <span class="number">10</span></span><br></pre></td></tr></table></figure></li><li><p>示例2，for循环中的<code>until</code>，<code>until</code>：返回一个并不包含上线的区间。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> n = <span class="number">10</span>; <span class="keyword">for</span>(i &lt;- <span class="number">1</span> until n) println(i)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line">n: <span class="type">Int</span> = <span class="number">10</span></span><br></pre></td></tr></table></figure></li><li><p>示例3，不使用to和until</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span>(s &lt;- <span class="string">"blog.xiaoxiaomo.com"</span>) print(s+<span class="string">" "</span>)</span><br><span class="line">b l o g . x i a o x i a o m o . c o m</span><br></pre></td></tr></table></figure></li></ul><h3 id="for跳出语句"><a href="#for跳出语句" class="headerlink" title="for跳出语句"></a>for跳出语句</h3><ul><li><p>scala中没有<strong>break</strong>和<strong>continue</strong>来退出循环，我们可以这样<strong>操作</strong>：</p><blockquote><ol><li>使用Boolean的变量控制。</li><li>使用嵌套函数，可以从函数当中return。</li><li>使用Breaks对象的break方法。</li></ol></blockquote></li><li><p>eg：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">breakable&#123;</span><br><span class="line">    <span class="keyword">for</span> (...) &#123;</span><br><span class="line">        <span class="keyword">if</span>（...) <span class="keyword">break</span> ;<span class="comment">//#退出breakable块</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="for进阶"><a href="#for进阶" class="headerlink" title="for进阶"></a>for进阶</h3><ol><li>在for循环“（）”中可以使用<strong>多个生成器</strong>， 用“;”隔开；</li><li>并且每一个生成器都可以带一个<strong><code>守卫</code></strong>（<code>if开头的Boolean表达式</code>）；</li><li><strong>for推导式</strong>，如下示例：</li></ol><ul><li><p>示例1，多个生成器，即多层循环</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; :paste</span><br><span class="line"><span class="comment">// Entering paste mode (ctrl-D to finish)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">9</span>; j &lt;- <span class="number">1</span> to <span class="number">9</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(j == <span class="number">9</span>) &#123;</span><br><span class="line">        println(i * j)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        print(i * j + <span class="string">" "</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Exiting paste mode, now interpreting.</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span></span><br><span class="line"><span class="number">2</span> <span class="number">4</span> <span class="number">6</span> <span class="number">8</span> <span class="number">10</span> <span class="number">12</span> <span class="number">14</span> <span class="number">16</span> <span class="number">18</span></span><br><span class="line"><span class="number">3</span> <span class="number">6</span> <span class="number">9</span> <span class="number">12</span> <span class="number">15</span> <span class="number">18</span> <span class="number">21</span> <span class="number">24</span> <span class="number">27</span></span><br><span class="line"><span class="number">4</span> <span class="number">8</span> <span class="number">12</span> <span class="number">16</span> <span class="number">20</span> <span class="number">24</span> <span class="number">28</span> <span class="number">32</span> <span class="number">36</span></span><br><span class="line"><span class="number">5</span> <span class="number">10</span> <span class="number">15</span> <span class="number">20</span> <span class="number">25</span> <span class="number">30</span> <span class="number">35</span> <span class="number">40</span> <span class="number">45</span></span><br><span class="line"><span class="number">6</span> <span class="number">12</span> <span class="number">18</span> <span class="number">24</span> <span class="number">30</span> <span class="number">36</span> <span class="number">42</span> <span class="number">48</span> <span class="number">54</span></span><br><span class="line"><span class="number">7</span> <span class="number">14</span> <span class="number">21</span> <span class="number">28</span> <span class="number">35</span> <span class="number">42</span> <span class="number">49</span> <span class="number">56</span> <span class="number">63</span></span><br><span class="line"><span class="number">8</span> <span class="number">16</span> <span class="number">24</span> <span class="number">32</span> <span class="number">40</span> <span class="number">48</span> <span class="number">56</span> <span class="number">64</span> <span class="number">72</span></span><br><span class="line"><span class="number">9</span> <span class="number">18</span> <span class="number">27</span> <span class="number">36</span> <span class="number">45</span> <span class="number">54</span> <span class="number">63</span> <span class="number">72</span> <span class="number">81</span></span><br></pre></td></tr></table></figure></li><li><p>示例2，for循环守卫</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">20</span> <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>) println(i)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="number">18</span></span><br><span class="line"><span class="number">20</span></span><br></pre></td></tr></table></figure></li><li><p><strong>for推导式</strong>：如果for循环的循环体以yield开始，该循环就会构造出一个集合，每次迭代就生成一个集合的值。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span>( i &lt;- <span class="number">2</span> to <span class="number">8</span> ) <span class="keyword">yield</span> i%<span class="number">2</span></span><br><span class="line">res7: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><ul><li>语法如图：</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325202143.png" alt="图来源于：《Scala编程》"></p><ol><li>函数必须指定<code>参数的类型</code>。</li><li>函数只要不是递归的就不需要指定<code>返回值类型</code>（因为无法推断出递归函数的类型）。</li><li>在函数中，不需要使用return。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>( x:<span class="type">Int</span>, y:<span class="type">Int</span> ) : <span class="type">Int</span> =&#123;</span><br><span class="line">     | <span class="keyword">if</span>(x&gt;y) x</span><br><span class="line">     | <span class="keyword">else</span> y</span><br><span class="line">     | &#125;</span><br><span class="line">max: (x: <span class="type">Int</span>, y: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; max(<span class="number">78</span>,<span class="number">88</span>)</span><br><span class="line">res8: <span class="type">Int</span> = <span class="number">88</span></span><br><span class="line"></span><br><span class="line">scala&gt; max(<span class="number">18</span>,<span class="number">99</span>)</span><br><span class="line">res10: <span class="type">Int</span> = <span class="number">99</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><p>在函数中，我们可以使用<code>默认参数</code>。函数调用时：</p><blockquote><p>1、如果没用给出所有参数，函数会使用默认参数（后面不够的参数使用默认值）。<br>2、也可以指定参数名，参数名不需要按顺序排列。<br>3、如果混合使用（未名参数和带名参数），只要未名参数排在前面即可。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">defStr</span></span>( left:<span class="type">String</span> = <span class="string">"["</span> , str:<span class="type">String</span> , right:<span class="type">String</span> = <span class="string">"]"</span> ) = &#123;</span><br><span class="line">     | print( left + str + right )</span><br><span class="line">     | &#125;</span><br><span class="line">defStr: (left: <span class="type">String</span>, str: <span class="type">String</span>, right: <span class="type">String</span>)<span class="type">Unit</span></span><br><span class="line"></span><br><span class="line">scala&gt; defStr(<span class="string">"["</span>,<span class="string">"Hi"</span>)</span><br><span class="line">[<span class="type">Hi</span>]</span><br><span class="line">scala&gt; defStr(left=<span class="string">"&lt;"</span>,right=<span class="string">"&gt;"</span>,str=<span class="string">"xiaoxiaomo"</span>)</span><br><span class="line">&lt;xiaoxiaomo&gt;</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>4、<strong>变长参数</strong>，可以接受多个参数</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(args:<span class="type">Int</span>*) = &#123;</span><br><span class="line">    <span class="keyword">var</span> result = <span class="number">0</span> ;</span><br><span class="line">    <span class="keyword">for</span>(arg &lt;- args) result+=arg</span><br><span class="line">    result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用函数，sum(3,4,6,23,3),函数得到的是一个Seq类型的参数，注意调用函数是传入的参数不能是一个区间，eg：<br>sum(2 to 9)是不可以的，应该为sum(2 to 9:_*);</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><ul><li><p>在scala中，如果函数没有返回值，那么该返回值类型我们可以用<code>Unit</code>来表示，这种<code>没有返回值的函数我们称之为过程</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">pr</span></span>(s:<span class="type">String</span>)&#123;</span><br><span class="line">     | print(s)</span><br><span class="line">     | &#125;</span><br><span class="line">pr: (s: <span class="type">String</span>)<span class="type">Unit</span></span><br><span class="line"></span><br><span class="line">scala&gt; pr(<span class="string">"小小默"</span>)</span><br><span class="line">小小默</span><br></pre></td></tr></table></figure></li><li><p>上面<strong>省略了Unit</strong>,由于没有返回值也可以<strong>省略“=”号</strong>，下面语句相同：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">pr</span></span>(s:<span class="type">String</span>) : <span class="type">Unit</span> = &#123;</span><br><span class="line">     | print(s)</span><br><span class="line">     | &#125;</span><br><span class="line">pr: (s: <span class="type">String</span>)<span class="type">Unit</span></span><br><span class="line"></span><br><span class="line">scala&gt; pr(<span class="string">"小小默"</span>)</span><br><span class="line">小小默</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Scala--基础入门</title>
      <link href="/2016/03/25/Scala-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"/>
      <url>/2016/03/25/Scala-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>　　这是<code>Scala</code>系列的第一篇博客，<code>后面会持续更新Scala系列以及Spark</code>等，希望和大家一起学习和探讨。</p><ul><li>本篇博客主要讲解：</li></ul><ol><li>Scala的<strong>简介和安装</strong></li><li>Scala的<strong>变量定义</strong></li><li>Scala的<strong>变量类型</strong></li><li>Scala的<strong>脚本</strong></li><li>以及扩展在<strong>Intellij IDEA</strong>上安装Scala插件。</li></ol><a id="more"></a><h1 id="简介-安装"><a href="#简介-安装" class="headerlink" title="简介/安装"></a>简介/安装</h1><p>Scala，是一门运行在JVM上的<code>函数式面向对象语言</code>，可以很好的兼容java。函数式面向对象语言，也就是说既有像java面向对象语言的特性又有类似于Python函数式语言的特性。下面让我们一起来看看Scala的环境搭建：</p><ol><li><p>安装配置</p><blockquote><p>1、首先安装一下JDK(略)<br>2、安装scala，官方下载：<a href="http://www.scala-lang.org/download/2.11.0.html" target="_blank" rel="noopener">http://www.scala-lang.org/download/2.11.0.html</a>；<br>3、配置好环境变量（略）</p></blockquote></li><li><p>配置好后，打开cmd命令窗口，输入<code>scala</code>就进入了友好的scala的”<code>Repl</code>“界面，：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\Administrator&gt;scala</span><br><span class="line">Welcome to Scala version 2.11.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_80).</span><br><span class="line">Type in expressions to have them evaluated.</span><br><span class="line">Type :help for more information.</span><br></pre></td></tr></table></figure></li><li><p>在“<code>Repl</code>”界面我们就可以进行一些简单的计算和操作。<code>每一次都会返回一个结果</code>，如下图所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; 7+12                             #数字相加返回int</span><br><span class="line">res0: Int = 19</span><br><span class="line"></span><br><span class="line">scala&gt; res0*3.5                         #自动识别结果为Double</span><br><span class="line">res1: Double = 66.5</span><br><span class="line"></span><br><span class="line">scala&gt; res1+&quot; Hello Word &quot;              #自动识别结果为String</span><br><span class="line">res2: String = &quot;66.5 Hello Word &quot;</span><br></pre></td></tr></table></figure></li></ol><ul><li>进行简单计算，7+12:<code>res0:Int=19</code>（该信息体现了参数的定义，只是省略了val）。然后我们就可以通过参数名res0使用该值，例如：res0*0.35，如上图所示。<blockquote><p>res0 ( res1， res2， … )　　    #为返回值名称<br>Int ( Double， String， … )　　 #为返回值类型</p></blockquote></li></ul><h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><ul><li><p>变量定义：<code>val|var 参数名：参数类型=参数值</code></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> msg3:<span class="type">String</span> = <span class="string">"Hello"</span>        #定义一个变量</span><br><span class="line">msg3: <span class="type">String</span> = <span class="type">Hello</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> msg4 = <span class="string">"Word"</span></span><br><span class="line">msg4: <span class="type">String</span> = <span class="type">Word</span></span><br><span class="line"></span><br><span class="line">scala&gt; msg4 = <span class="string">"Word!"</span>                   #<span class="keyword">val</span>的变量不能被改变</span><br><span class="line">&lt;console&gt;:<span class="number">8</span>: error: reassignment to <span class="keyword">val</span></span><br><span class="line">       msg4 = <span class="string">"Word!"</span></span><br><span class="line">            ^</span><br><span class="line"></span><br><span class="line">scala&gt; println(msg3+msg4)</span><br><span class="line"><span class="type">HelloWord</span></span><br><span class="line"></span><br><span class="line">scala&gt; println(msg3+ <span class="string">" "</span> +msg4)</span><br><span class="line"><span class="type">Hello</span> <span class="type">Word</span></span><br></pre></td></tr></table></figure></li><li><p><strong>Scala有两种声明变量的方式</strong>：<code>var</code>和<code>val</code></p></li></ul><ol><li><code>val，类是于Java中的final变量</code>，一旦初始化就不能修改，例如上图中msg4。</li><li><code>var，声明的变量就可以多次被赋值</code>,scala建议声明为val。</li><li><p>在声明变量时也可以不指定类型，scala自己会进行<code>类型推断</code>，判断出“Word”为String类型（java.lang.String）。</p></li><li><p><strong><code>懒值</code></strong> ，当val被声明为lazy时。它的初始化将被推迟，直到我们首次使用它，eg：</p><blockquote><p>lazy val words = scala.io.Source.fromFile(“/use/word”).mkString</p></blockquote></li></ol><h1 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h1><ol><li><p><code>变量类型</code>：<strong>scala中有7种数值类型</strong>：<code>Byte</code>、<code>Char</code>、<code>Short</code>、<code>Int</code>、<code>Long</code>、<code>Float</code>、<code>Double</code>和<code>Boolean</code>，这类用法和java的基本类型类似。只是<code>scala这些类型是类</code>，它不区分引用类型和基本类型;</p></li><li><p><code>扩展类</code>：对于字符串它使用的<code>java.lang.String</code>，但scala也有自己的扩展<code>StringOps</code>类；其他类型的一些扩展比如，RichInt、RichDouble、RichChar，还有java.math.BigIng、java.math.BigDecimal等;</p></li><li><p><code>基本类型和包装类型之间的转换</code>：这个scala编译器会自动完成，eg：创建一个Int[]数组，最后在虚拟机中得到的是int[];</p></li><li><p><code>数值类型之间的转换</code>：在scala中，数值类型之间的转换不是强制类型转换而是使用<code>方法</code>，eg：<code>toInt</code>、<code>toDouble</code>、<code>toChar等</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a:Int = 55</span><br><span class="line">a: Int = 55</span><br><span class="line"></span><br><span class="line">scala&gt; a.toChar</span><br><span class="line">res3: Char = 7</span><br><span class="line"></span><br><span class="line">scala&gt; a.toString</span><br><span class="line">res4: String = 55</span><br></pre></td></tr></table></figure></li></ol><h1 id="scala脚本"><a href="#scala脚本" class="headerlink" title="scala脚本"></a>scala脚本</h1><ul><li><p>脚本，就是一些简短的命令组合放在一个文件中，运行脚本就是按顺序执行文件中的语句。比如我们把这两行代码写到script.scala文件中：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325210208.png" alt=""></p></li><li><p>然后运行：<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325210612.png" alt=""></p></li></ul><p>args(n) , 就可以接受到后面的参数（这个和java很像，java中main方法args[]同样能接收到）（注意：数组java是”[]”而scala中是”()”）。</p><h1 id="扩展-Intellij使用"><a href="#扩展-Intellij使用" class="headerlink" title="扩展-Intellij使用"></a>扩展-Intellij使用</h1><p>这里顺便讲一下使用<code>Intellij IDEA</code>开发scala：</p><blockquote><p><a href="http://www.jetbrains.com/idea/" target="_blank" rel="noopener">下载</a>安装Intellij IDEA<br>安装Intellij的scala插件</p></blockquote><p>菜单File—&gt;Settings</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325212935.png" alt=""></p><p>输入scala，然后点击右边的<code>install plugin</code></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325213129.png" alt=""></p><p>安装好插件后重启就可以新建项目了，File—&gt;New—&gt;Project,选择scala:</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325214254.png" alt=""></p><p>输入项目名，选择项目地址和JDK和scala的SDK,Finish</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325214355.png" alt=""></p><p>右键创建一个<code>scala class</code>，我们这里选择为Object</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325215114.png" alt=""></p><p>写一个简单的例子，测试一下，okay!</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160325214646.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--RPM软件包管理</title>
      <link href="/2016/03/21/Linux-RPM%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/"/>
      <url>/2016/03/21/Linux-RPM%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>　　<code>RPM(RedHat Package Manager)红帽包管理</code>，之前是有红帽公司研发和管理的。由于它的优秀逐渐被其他公司所接受，于是就开始在各个版本的Linux系统中流行起来。</p><a id="more"></a><h3 id="RPM的简介"><a href="#RPM的简介" class="headerlink" title="RPM的简介"></a>RPM的简介</h3><p>　　RPM,可以来对软件进行查询、验证、安装、升级及卸载等。比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apache-1.7.5-17.i386.rpm</span><br><span class="line">1.7.5-17　　<span class="comment">#软件的版本号，主版本和此版本.</span></span><br><span class="line">i386　　<span class="comment">#表示用于Intel x86平台.</span></span><br><span class="line">后缀名为<span class="string">".rpm"</span>　　<span class="comment">#表示rpm包。</span></span><br></pre></td></tr></table></figure><h3 id="PRM的安装"><a href="#PRM的安装" class="headerlink" title="PRM的安装"></a>PRM的安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rpm [option] rpm软件包</span><br><span class="line">-i <span class="comment">#表示安装</span></span><br><span class="line">-v <span class="comment">#显示安装过程</span></span><br><span class="line">-h <span class="comment">#显示进度条，一般使用"-ivh"组合一起使用,eg：rpm -ivh apache-1.7.5-17.i386.rpm</span></span><br><span class="line">--force <span class="comment">#强制安装</span></span><br><span class="line">--nodeps <span class="comment">#忽略依赖包直接安装</span></span><br><span class="line">* <span class="comment">#可以使用通配符批量安装，eg：rpm -ivh http-* --force。</span></span><br><span class="line">-U <span class="comment">#升级软件包</span></span><br></pre></td></tr></table></figure><ul><li>注意</li></ul><blockquote><ol><li>当软件包已经安装，解决办法：一是先卸载后重新安装；二是使用–force选项强制安装。 </li><li>当软件包出现依赖关系 –force也不行，可以使用–nodeps忽略。</li><li>安装软件的时候，最常见的就是提示依赖关系，就必须先把最底层的依赖安装好。</li></ol></blockquote><h3 id="RPM的查询"><a href="#RPM的查询" class="headerlink" title="RPM的查询"></a>RPM的查询</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa  <span class="comment">#查询系统中已安装的软件包,eg：rpm -qa apache-1.7.5-17.i386.rpm</span></span><br><span class="line">rpm -qi  <span class="comment">#查询软件的相关信息</span></span><br><span class="line">rpm -l  <span class="comment">#查询软件的安装位置，使用-l选项</span></span><br><span class="line">rpm -f  <span class="comment">#查询文件归属, -qf该文件属于哪个软件包。 如果顺坏可重新安装。</span></span><br><span class="line">rpm -V  <span class="comment">#对系统中已经安装的软件包进行验证。</span></span><br></pre></td></tr></table></figure><h3 id="RPM的卸载"><a href="#RPM的卸载" class="headerlink" title="RPM的卸载"></a>RPM的卸载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -e 软件名 <span class="comment">#软件名不可以有rpm后缀,依赖关系-nodeps忽略</span></span><br><span class="line">eg：rpm -e --nodeps java-1.5.2-gcj-1.5.2.0-29.1.el8.x86_64 <span class="comment">#卸载jdk</span></span><br></pre></td></tr></table></figure><h3 id="RPM源码包"><a href="#RPM源码包" class="headerlink" title="RPM源码包"></a>RPM源码包</h3><p>对于一些软件包是以.src.rpm为扩展名的，这类软件包就是包含了源代码的rpm包，在安装<br>的时候需要进行编译，步骤如下：</p><blockquote><ol><li>rpm -i apache-1.7.5-17.i386.src.rpm</li><li>cd /usr/src/redhat/SPECS/     /切换到该目录</li><li>rpmbuild -bb apache-1.7.5-17.i386.specs或者rpmbuild -bp apache-1.7.5-17.i386.specs</li></ol></blockquote><ul><li>注意：</li></ul><p>如果上面步骤一，在/usr/src/redhat/RPMS/noarch/目录下生成一个新的rpm包，可rpm -ivh xx.rpm 进行安装搞定；<br>如果上面步骤二，在/usr/src/redhat/BUILD/software/目录下生成此软件包的源码包，可能通过脚本安装或编译源代码安装，具体不做说明。</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--awk命令详解</title>
      <link href="/2016/03/19/Linux-awk%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
      <url>/2016/03/19/Linux-awk%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>　　<code>awk是一个强大的文本分析工具</code>，<em>awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母</em>。相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。</p><a id="more"></a><h2 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h2><p>　　awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。</p><h3 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h3><blockquote><p>awk [options] program file</p><ol><li>options ：选项</li><li>program ：程序</li><li>file：文件（需要处理的数据文件）</li></ol></blockquote><ul><li><code>awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。</code></li></ul><h3 id="调用awk"><a href="#调用awk" class="headerlink" title="调用awk"></a>调用awk</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1. 命令行方式</span><br><span class="line">awk [-F  field-separator]  <span class="string">'&#123;commands&#125;'</span>  file</span><br><span class="line">===&gt;  [-F域分隔符]是可选的，commands 是真正awk命令，file 是待处理的文件。</span><br><span class="line">===&gt;  在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。</span><br><span class="line">===&gt;  通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。</span><br><span class="line"></span><br><span class="line">2. shell脚本方式</span><br><span class="line">将所有的awk命令插入一个文件，使程序可执行，然后awk命令解释器作为脚本的首行，通过键入脚本名称来调用。</span><br><span class="line">相当于shell脚本首行的：<span class="comment">#!/bin/bash</span></span><br><span class="line">可以换成：<span class="comment">#!/bin/awk</span></span><br><span class="line"></span><br><span class="line">3. 将所有的awk命令插入一个单独文件，然后调用：</span><br><span class="line">awk -f awk-script-file file</span><br><span class="line">其中，-f选项加载awk-script-file中的awk脚本</span><br></pre></td></tr></table></figure><h2 id="awk处理文本"><a href="#awk处理文本" class="headerlink" title="awk处理文本"></a>awk处理文本</h2><p>awk的基本特性之一就是它处理文本文件中数据的能力。它会自动给每行中的每个数据元素分配一个变量。</p><blockquote><p><strong>$0</strong>： 代表整个文本行<br><strong>$1</strong>： 代表文本行中的第1个数据字段（第一个域）<br><strong>$2</strong>： 代表文本行中的第2个数据字段<br><strong>$n</strong>： 代表文本行中的第n个数据字段</p></blockquote><ul><li>注意：每个数据字段在文本行中都是通过字段分隔符来划分的。awk中的<code>默认字段分隔符是任意的空白字符</code>(例如空格或制表符)</li><li><strong>如果想要读取使用其他字段分隔符的文件</strong>，<code>可以使用-F 选项指定：awk -F: &#39;{print $1}&#39; /etc/passwd</code></li><li>实例一，默认字段分隔符<br>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419194421.png" alt=""></li></ul><p>下面我们来取head_7.log的第一个域和第七个域，如图：awk ‘{print $1,$7 }’ head_7.log</p><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419194513.png" alt=""></p><ul><li>实例二，使用自己的分隔符<br>来看一看默认的/etc/passwd文件<br>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419194919.png" alt=""></li></ul><p>取出第一和第七域</p><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419195222.png" alt=""></p><h2 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h2><p>awk编程语言允许你将多条命令组成一个脚本程序。<code>把多条命令保存到一个文件中，这个文件我们就称为awk的脚本文件</code>。</p><blockquote><p>格式：只要将每条命令放到一个新的行就好了，不需要用分号。<br>awk -F: -f script /etc/passwd<br>这里的script是一个文件，需要使用-f参数指定</p></blockquote><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419202620.png" alt=""></p><h2 id="BEGIN-END"><a href="#BEGIN-END" class="headerlink" title="BEGIN|END"></a>BEGIN|END</h2><blockquote><p>BEGIN： 有时可能需要在处理数据前运行脚本，比如为报告创建开头部分。<br>END： 跟BEGIN关键字类似，END关键字允许你指定一个程序脚本，awk会在读完数据后执行它。</p></blockquote><h2 id="awk内置变量"><a href="#awk内置变量" class="headerlink" title="awk内置变量"></a>awk内置变量</h2><blockquote><p><strong>FS</strong>： Field Seperator, 输入时的字段分隔符<br><strong>RS</strong>： Record Seperator, 输入行分隔符<br><strong>OFS</strong>: Output Field Seperator, 输出时的字段分隔符;<br><strong>ORS</strong>: Outpput Row Seperator, 输出时的行分隔符；<br><strong>NF</strong>： Numbers of Field，字段数量<br><strong>NR</strong>： Numbers of Record, 行号；所有文件的一并计数；<br><strong>FNR</strong>：行号；各文件分别计数；</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419203241.png" alt=""></p><h2 id="awk进阶"><a href="#awk进阶" class="headerlink" title="awk进阶"></a>awk进阶</h2><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><blockquote><p>()   {}   ##不支持<br>. * ^ $ ? + [] | \&lt; > ()  ##可以直接使用</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'/^root/&#123;print $1,$7&#125;'</span> /etc/passwd</span><br><span class="line">root /bin/bash</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'!/^root/&#123;print $1,$NF&#125;'</span> /etc/passwd|head -5  </span><br><span class="line">bin /sbin/nologin</span><br><span class="line">daemon /sbin/nologin</span><br><span class="line">adm /sbin/nologin</span><br><span class="line">lp /sbin/nologin</span><br><span class="line">sync /bin/sync</span><br></pre></td></tr></table></figure><h3 id="关系运算符"><a href="#关系运算符" class="headerlink" title="关系运算符"></a>关系运算符</h3><blockquote><p>/&gt; &lt; == != &gt;= &lt;=<br>~（匹配） !~（不匹配）</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'$3 == 0 &#123;print $1&#125;'</span> /etc/passwd</span><br><span class="line">root</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'$3 != 0&#123; print $1&#125;'</span> /etc/passwd | head -2</span><br><span class="line">bin</span><br><span class="line">daemon</span><br></pre></td></tr></table></figure><h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><blockquote><p>&amp;&amp; || ! ##与 或 非</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'$3 &gt; 0 &amp;&amp; $3 &lt; 10 &#123;print $1, $3&#125;'</span> /etc/passwd |head -2</span><br><span class="line">bin 1</span><br><span class="line">daemon 2</span><br></pre></td></tr></table></figure><h3 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h3><blockquote><p><strong>+-*/%</strong>（取模(余数)） ^（幂运算）</p></blockquote><h2 id="awk流控制-循环"><a href="#awk流控制-循环" class="headerlink" title="awk流控制|循环"></a>awk流控制|循环</h2><h3 id="简单的条件判断"><a href="#简单的条件判断" class="headerlink" title="简单的条件判断"></a>简单的条件判断</h3><blockquote><p>语法：(表达式 ? 值1 : 值2) 如果表达式成立，输出值1；否则输出值2</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@momo ~]<span class="comment"># cat num</span></span><br><span class="line">2 8 9</span><br><span class="line">8 4 6</span><br><span class="line">3 5 7</span><br><span class="line"></span><br><span class="line">[root@momo ~]<span class="comment"># awk '&#123;print ( $1 &gt; $2 ? $1 : $2)&#125;' num</span></span><br><span class="line">8</span><br><span class="line">8</span><br><span class="line">5</span><br></pre></td></tr></table></figure><h3 id="if判断"><a href="#if判断" class="headerlink" title="if判断"></a>if判断</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">语法：</span><br><span class="line">  &#123; <span class="keyword">if</span> ( 表达式 )</span><br><span class="line">      &#123;</span><br><span class="line">           //......</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">多支判断：</span><br><span class="line">&#123; <span class="keyword">if</span> (表达式)</span><br><span class="line">&#123;</span><br><span class="line">//......</span><br><span class="line">&#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (表达式)</span><br><span class="line">&#123;</span><br><span class="line">//......</span><br><span class="line">&#125;</span><br><span class="line">  //......</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123; </span><br><span class="line">//......</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果表达式成立，那么执行动作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@momo ~]<span class="comment"># awk '&#123;if ($2&gt;=80 &amp;&amp; $2 &lt;=100) &#123;print $1,"great"&#125; else &#123;print $1, "good"&#125;&#125;' cj</span></span><br><span class="line">tx great</span><br><span class="line">tx1 great</span><br><span class="line">tx2 good</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ cat ifTest.txt</span><br><span class="line">zangs 95 86 86 78</span><br><span class="line">lishi 89 88 85 34</span><br><span class="line">wangwu 73 89 85 77 </span><br><span class="line">zhaoliu 80 71 65 66</span><br><span class="line">qitian 75 85 69 99</span><br><span class="line">wangba 78 82 89 88</span><br><span class="line"></span><br><span class="line"><span class="comment">##判断的标准：</span></span><br><span class="line">90-100 A</span><br><span class="line">80-89  B</span><br><span class="line">70-79  C</span><br><span class="line">60-69  D</span><br><span class="line">0-59   E</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ awk <span class="string">'&#123; if ($2 &gt;= 90 &amp;&amp; $2 &lt;= 100) &#123;print $1,"A"&#125; else if ($2 &gt;= 80 &amp;&amp; $2 &lt; 90) &#123;print $1,"B"&#125; else if ($2 &gt;= 70 &amp;&amp; $2 &lt; 80) &#123;print $1,"C"&#125; else if ($2 &gt;= 60 &amp;&amp; $2 &lt; 70) &#123;print $1,"D"&#125; else &#123;print $1,"E"&#125; &#125;'</span> ifTest.txt</span><br><span class="line">zangs A</span><br><span class="line">lishi B</span><br><span class="line">wangwu C</span><br><span class="line">zhaoliu B</span><br><span class="line">qitian C</span><br><span class="line">wangba C</span><br></pre></td></tr></table></figure><h3 id="循环while"><a href="#循环while" class="headerlink" title="循环while"></a>循环while</h3><blockquote><p>语法： ‘var=初值; while (表达式){ //… }’</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ awk -F: <span class="string">'&#123;i=1; while (i&lt;=NF)&#123;print $i;i++&#125;&#125;'</span> /etc/passwd |head -8</span><br><span class="line">root</span><br><span class="line">x</span><br><span class="line">0</span><br><span class="line">0</span><br><span class="line">root</span><br><span class="line">/root</span><br><span class="line">/bin/bash</span><br><span class="line">bin</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ awk <span class="string">'BEGIN &#123;FS=":"&#125;&#123;i=NF;while(i&gt;=2)&#123;printf $i ":";i--&#125;print $1&#125;'</span> /etc/passwd | head -n 7</span><br><span class="line">/bin/bash:/root:root:0:0:x:root</span><br><span class="line">/sbin/nologin:/bin:bin:1:1:x:bin</span><br><span class="line">/sbin/nologin:/sbin:daemon:2:2:x:daemon</span><br><span class="line">/sbin/nologin:/var/adm:adm:4:3:x:adm</span><br><span class="line">/sbin/nologin:/var/spool/lpd:lp:7:4:x:lp</span><br><span class="line">/bin/sync:/sbin:sync:0:5:x:sync</span><br><span class="line">/sbin/shutdown:/sbin:shutdown:0:6:x:shutdown</span><br></pre></td></tr></table></figure><h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><blockquote><p>语法： { for(表达式) {  //……}  }<br>表达式：分为3部分：<br>(1)初始化表达式 i=1<br>(2)测试表达式   i&lt;10<br>(3)更新测试表达式 i++</p></blockquote><ul><li>语句：<br>next 处理输入行的下一个输入行<br>exit 退出<br>continue 结束本次循环<br>break 跳出循环</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ awk <span class="string">'BEGIN &#123;FS=":"&#125;&#123;for(i=NF;i&gt;=2;i--)&#123;printf $i ";"&#125;;print $1&#125;'</span> /etc/passwd |head -n 5</span><br><span class="line">/bin/bash;/root;root;0;0;x;root</span><br><span class="line">/sbin/nologin;/bin;bin;1;1;x;bin</span><br><span class="line">/sbin/nologin;/sbin;daemon;2;2;x;daemon</span><br><span class="line">/sbin/nologin;/var/adm;adm;4;3;x;adm</span><br><span class="line">/sbin/nologin;/var/spool/lpd;lp;7;4;x;lp</span><br></pre></td></tr></table></figure><ul><li>参考资料<br><a href="http://www.centoscn.com/shell/2013/0802/884.html" target="_blank" rel="noopener">http://www.centoscn.com/shell/2013/0802/884.html</a><br><a href="http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html" target="_blank" rel="noopener">http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--grep和正则表达式</title>
      <link href="/2016/03/17/Linux-grep%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/2016/03/17/Linux-grep%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>　　<code>grep</code>（Global search REgular expression and Print out the line）英文有点长，<code>全局搜索正则表达式并打印出匹配的行</code>。从字面意思就知道一个很强大的文本匹配工具，可以通过正则来匹配，并且把匹配的行打印出来。</p><a id="more"></a><h2 id="grep"><a href="#grep" class="headerlink" title="grep"></a><strong>grep</strong></h2><p>语法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep [-acinv] [--color=auto] [-A n] [-B n] <span class="string">'匹配字符串'</span> 匹配文件</span><br></pre></td></tr></table></figure></p><p>常用参数说明</p><blockquote><p><strong>-c</strong> ：#统计匹配次数<br><strong>-i</strong> ：#忽略大小写<br><strong>-n</strong> ：#显示行号<br><strong>-v</strong> ：#反选<br><strong>–color</strong> :#高亮匹配字段，可自定义<br><strong>-A</strong> ：#显示匹配行之后n行的信息，After,必须指定n<br><strong>-B</strong> ：#显示匹配行之前n行的信息，Before,必须指定n<br>注意：匹配的字段最好用’’单引号，避免和shell元字符冲突。</p></blockquote><p>eg.</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317154131.png" alt=""></p><p>在当前目录下（以“.class”结尾的文件），匹配‘Thread’字符串，并显示出行号，高亮以及匹配字符后两行。</p><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a><strong>正则表达式</strong></h2><h3 id="常用正则表达式"><a href="#常用正则表达式" class="headerlink" title="常用正则表达式"></a><strong>常用正则表达式</strong></h3><blockquote><p><strong>.</strong> 匹配任意一个字符 #eg：grep ‘a.r’text，会匹配arr,不会匹配ar。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317163701.png" alt=""></p><blockquote><p><strong>*</strong> 前面字符出现0-n次。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317163525.png" alt=""></p><blockquote><p><strong>[]</strong> 匹配括号中的任意一个 </p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317165905.png" alt=""></p><ul><li>[0-9]会匹配0-9</li><li>[a-z]会匹配a-z</li><li>[A-Z]会匹配A-Z</li><li>[0-9A-Z]会匹配0-9和A-Z</li><li>[[:space:]]会匹配空格</li><li>[[:punct:]]会匹配标点符号</li></ul><blockquote><p><strong>{n,m}</strong> 匹配前面字符重复n,m,次</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317170706.png" alt=""></p><blockquote><p><strong>[^]</strong> 匹配非字符串，#eg：grep ‘[^java]’ text,匹配非java字符串。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317170841.png" alt=""></p><blockquote><p><strong>^</strong> 匹配以什么开头的行<br><strong>\$</strong> 匹配以什么结尾的行 #eg：grep -n ‘sleep\$’ text。<br><strong>\&lt;</strong> 匹配以什么开头的单词<br><strong>></strong> 匹配以什么结尾的单词</p></blockquote><h3 id="扩展正则表达式"><a href="#扩展正则表达式" class="headerlink" title="扩展正则表达式"></a><strong>扩展正则表达式</strong></h3><p>可以通过-E参数使用grep的扩展正则表达式，等于egrep.</p><blockquote><p><strong>?</strong> 匹配前面字符，0，1次。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317165437.png" alt=""></p><blockquote><p><strong>+</strong> 匹配前面字符，1-n次。eg：grep -E ‘a+r’ text。会匹配ar,aar等。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317164242.png" alt=""></p><blockquote><p><strong>|</strong> 匹配多个字符串</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317171543.png" alt=""></p><blockquote><p><strong>()</strong> 匹配括号中的字符串</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317172007.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Shell函数及进阶</title>
      <link href="/2016/03/13/Linux-Shell%E5%87%BD%E6%95%B0%E5%8F%8A%E8%BF%9B%E9%98%B6/"/>
      <url>/2016/03/13/Linux-Shell%E5%87%BD%E6%95%B0%E5%8F%8A%E8%BF%9B%E9%98%B6/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解<code>Shell函数</code>，及其<code>Shell编程相关的一些命令</code>。如对Shell基本用户不够清楚可查看博客<a href="http://blog.xiaoxiaomo.com/2016/03/05/Linux-Shell%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/" title="Linux--Shell编程入门">Shell编程入门</a>、<a href="http://blog.xiaoxiaomo.com/2016/03/06/Linux-Shell%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%8F%8A%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97/" title="Linux-Shell条件判断及算术运算/">Shell条件判断及算术运算</a>、<a href="http://blog.xiaoxiaomo.com/2016/03/12/Linux-Shell%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/" title="Linux--Shell循环结构">Shell循环结构</a>。</p><a id="more"></a><h2 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h2><ol><li>有利于代码的重用性</li><li>函数传递参数</li><li>函数的返回值，只能是数字</li></ol><blockquote><p><strong>function</strong> 函数名(){<br>　　//…<br>}</p></blockquote><p>引用自定义函数文件时，使用source  func.sh</p><ul><li>eg : 事例一 一个简单的方法调用</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#simple function</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">sayHi</span></span>()&#123;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>,say Hi!"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sayHi</span><br></pre></td></tr></table></figure><p>运行结果：</p><blockquote><p>./func.sh,say Hi!</p></blockquote><ul><li>eg : 事例二，写一个脚本后在另一个脚本中调用</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ cat function.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">main</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">" <span class="variable">$0</span>  main function start..... <span class="variable">$1</span> "</span></span><br><span class="line">&#125;</span><br><span class="line">main</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ cat functionTest.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> function.sh</span><br><span class="line"></span><br><span class="line">main <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ ./functionTest.sh Shell_Function</span><br><span class="line"> ./functionTest.sh  main <span class="keyword">function</span> start.....  </span><br><span class="line"> ./functionTest.sh  main <span class="keyword">function</span> start..... Shell_Function</span><br></pre></td></tr></table></figure><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><ul><li>linux中的命令可以分为两种：help/man</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">内建命令:<span class="built_in">command</span> is a shell <span class="built_in">builtin</span></span><br><span class="line">外部命令:显示具体的路径</span><br></pre></td></tr></table></figure><ul><li>如何区分命令属于哪一种</li></ul><blockquote><p>type command<br>内建命令使用：help command<br>外部命令使用：man command</p></blockquote><ul><li>eg ： 实例</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ <span class="built_in">type</span> <span class="built_in">cd</span>  <span class="comment">#内部命令</span></span><br><span class="line"><span class="built_in">cd</span> is a shell <span class="built_in">builtin</span></span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ <span class="built_in">type</span> date  <span class="comment">#外部命令</span></span><br><span class="line">date is /bin/date</span><br></pre></td></tr></table></figure><h2 id="date"><a href="#date" class="headerlink" title="date"></a>date</h2><ul><li>显示当前时间</li></ul><blockquote><p>格式化输出 +%Y-%m-%d<br>格式%s表示自1970-01-01 00:00:00以来的秒数<br>指定时间输出  –date=’2009-01-01 11:11:11’<br>指定时间输出  –date=’3 days ago’</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ date</span><br><span class="line">2016年 04月 19日 星期二 17:55:18 CST</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ date +%Y-%m-%d</span><br><span class="line">2016-04-19</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ date +%s</span><br><span class="line">1461059756</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ date +%Y-%m-%d --date=<span class="string">'2016-04-19 11:11:11'</span></span><br><span class="line">2016-04-17</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ date +%Y-%m-%d --date=<span class="string">'3 days ago'</span></span><br><span class="line">2016-04-16</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ date +%Y-%m-%d --date=<span class="string">'-3 days ago'</span></span><br><span class="line">2016-04-22</span><br></pre></td></tr></table></figure><h2 id="read"><a href="#read" class="headerlink" title="read"></a>read</h2><p>read命令接收标准输入（键盘）的输入，或者其他文件描述符的输入。得到输入后，read命令将数据放入一个标准变量中。<br>格式</p><blockquote><p>read VAR_NAME</p></blockquote><p>read如果后面不指定变量，那么read命令会将接收到的数据放置在环境变量REPLY中<br>read -p “Enter your name:” VAR_NAME<br>read -t 5 -p “enter your name:” VAR_NAME<br>read -s -p “Enter your password: “ pass</p><h2 id="declare"><a href="#declare" class="headerlink" title="declare"></a>declare</h2><p>用来限定变量的属性</p><blockquote><p>-r 只读<br>-i 整数：某些算术计算允许在被声明为整数的变量中完成，而不需要特别使用expr或let来完成。<br>-a 数组</p></blockquote><h2 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">获取长度：$&#123;#VAR_NAME&#125;</span><br><span class="line">字符串截取</span><br><span class="line">$&#123;variable:offset:length&#125;或者$&#123;variable:offset&#125;</span><br><span class="line">取尾部的指定个数的字符</span><br><span class="line"> $&#123;variable: -length&#125;：注意冒号后面有空格</span><br><span class="line">大小写转换</span><br><span class="line">小--&gt;大：$&#123;variable^^&#125;</span><br><span class="line">大--&gt;小：$&#123;variable,,&#125;</span><br></pre></td></tr></table></figure><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><blockquote><p>定义：<strong>declare -a</strong>：表示定义普通数组<br>特点：</p><ol><li>支持稀疏格式</li><li>仅支持一维数组</li></ol></blockquote><ul><li>数组赋值方式</li></ul><ol><li>一次对一个元素赋值a[0]=$RANDOM</li><li>一次对多个元素赋值a=(a b c d)</li><li>按索引进行赋值a=([0]=a [3]=b [1]=c)</li><li>使用read命令read -a ARRAY_NAME</li></ol><ul><li>查看元素</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$&#123;a&#125;：#查看数组的第一个元素</span><br><span class="line">$&#123;a[index]&#125;：#查看数组指定角标的元素</span><br><span class="line">$&#123;a[*]&#125;或者$&#123;a[@]&#125;：#查看数组的所有元素</span><br></pre></td></tr></table></figure><ul><li>获取数组的长度</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$&#123;#a[*]&#125; | $&#123;#a[@]&#125; ：#元素长度</span><br><span class="line">$&#123;#a[0]&#125; ：#获取数组内元素的长度</span><br><span class="line"></span><br><span class="line">注意：$&#123;#a[0]&#125;表示获取数组中的第一个元素的长度，等于$&#123;#a&#125;</span><br></pre></td></tr></table></figure><ul><li>从数组中获取某一片段之内的元素</li></ul><blockquote><p>格式： ${a[@]:offset:length}<br>offset：偏移的元素个数<br>length：取出的元素的个数</p></blockquote><p>${a[@]:offset:length}：取出偏移量后的指定个数的元素<br>${a[@]:offset}：取出数组中偏移量后的所有元素</p><ul><li>数组删除元素：</li></ul><p>unset a[index]</p><ul><li>eg ： 事例</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160419092105.png" alt=""></p><h2 id="后台模式运行脚本"><a href="#后台模式运行脚本" class="headerlink" title="后台模式运行脚本"></a>后台模式运行脚本</h2><p>在脚本后面加一个&amp;<br>test.sh &amp;<br>这样的话虽然可以在后台运行，但是当用户注销(logout)或者网络断开时,终端会收到Linux HUP信号(hangup)信号从而关闭其所有子进程<br>nohup命令<br>不挂断的运行命令，忽略所有挂断(hangup)信号<br>使用nohup test.sh &amp;<br>nohup会忽略进程的hangup挂断信号，所以关闭当前会话窗口不会停止这个进程的执行。<br>nohup会在当前执行的目录生成一个nohup.out日志文件</p><h2 id="标准输入-输出"><a href="#标准输入-输出" class="headerlink" title="标准输入/输出"></a>标准输入/输出</h2><blockquote><p>标准输入、输出、错误可以使用文件描述符0、1、2引用</p></blockquote><ul><li>使用重定向可以把信息重定向到其他位置</li></ul><ol><li>ls &gt;file 或者 ls 1&gt;file（ls &gt;&gt;file）</li><li>lk 2&gt;file(lk是一个错误命令)</li><li>ls &gt;file 2&gt;&amp;1</li><li>ls &gt; /dev/null(把输出信息重定向到无底洞)</li></ol><p>例子：command &gt;/dev/null 2&gt;&amp;1</p><h2 id="crontab定时器"><a href="#crontab定时器" class="headerlink" title="crontab定时器"></a>crontab定时器</h2><ul><li><strong>linux下的定时任务</strong></li></ul><blockquote><p>编辑使用crontab  -e ，一共6列，分别是:分 时 日 月 周 命令<br>查看使用crontab -l<br>删除任务crontab -r</p></blockquote><ul><li><strong>查看crontab执行日志</strong></li></ul><blockquote><p>tail -f /var/log/cron<br>tail -f /var/spool/mail/root(查看crontab最近的执行情况)</p></blockquote><ul><li><strong>查看cron服务状态</strong></li></ul><blockquote><p>service crond status</p></blockquote><ul><li><strong>启动cron服务</strong></li></ul><blockquote><p>service crond start</p></blockquote><ul><li>注意：必须打开rsyslog服务cron文件中才会有执行日志(service rsyslog status)</li><li>附件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">编辑crontab，实现秒级执行任务</span><br><span class="line">crontab -e</span><br><span class="line">* * * * * /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line">* * * * * sleep 10; /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line">* * * * * sleep 20; /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line">* * * * * sleep 30; /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line">* * * * * sleep 40; /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line">* * * * * sleep 50; /bin/date &gt;&gt;/tmp/date.txt</span><br><span class="line"></span><br><span class="line">另外一种秒执行任务思路</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">while</span> : ;<span class="keyword">do</span></span><br><span class="line">/root/scripts.sh 2&gt;/dev/null &amp;</span><br><span class="line">sleep 3</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">基本格式 : </span><br><span class="line">*　　*　　*　　*　　*　　command </span><br><span class="line">分　时　日　月　周　命令 </span><br><span class="line">第1列表示分钟1～59 每分钟用*或者 */1表示 </span><br><span class="line">第2列表示小时1～23（0表示0点） </span><br><span class="line">第3列表示日期1～31 </span><br><span class="line">第4列表示月份1～12 </span><br><span class="line">第5列标识号星期0～6（0表示星期天） </span><br><span class="line">第6列要运行的命令 </span><br><span class="line">crontab文件的一些例子： </span><br><span class="line">30 21 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每晚的21:30重启apache。 </span><br><span class="line">45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每月1、10、22日的4 : 45重启apache。 </span><br><span class="line">10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每周六、周日的1 : 10重启apache。 </span><br><span class="line">0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。 </span><br><span class="line">0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每星期六的11 : 00 pm重启apache。 </span><br><span class="line">* */1 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">每一小时重启apache </span><br><span class="line">* 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">晚上11点到早上7点之间，每隔一小时重启apache </span><br><span class="line">0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">每月的4号与每周一到周三的11点重启apache </span><br><span class="line">0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">一月一号的4点重启apache </span><br><span class="line">名称 : crontab </span><br><span class="line">使用权限 : 所有使用者 </span><br><span class="line">使用方式 : </span><br><span class="line">crontab file [-u user]-用指定的文件替代目前的crontab。 </span><br><span class="line">crontab-[-u user]-用标准输入替代目前的crontab. </span><br><span class="line">crontab-1[user]-列出用户目前的crontab. </span><br><span class="line">crontab-e[user]-编辑用户目前的crontab. </span><br><span class="line">crontab-d[user]-删除用户目前的crontab. </span><br><span class="line">crontab-c dir- 指定crontab的目录。 </span><br><span class="line">crontab文件的格式：M H D m d cmd. </span><br><span class="line">M: 分钟（0-59）。 </span><br><span class="line">H：小时（0-23）。 </span><br><span class="line">D：天（1-31）。 </span><br><span class="line">m: 月（1-12）。 </span><br><span class="line">d: 一星期内的天（0~6，0为星期天）。 </span><br><span class="line">cmd要运行的程序，程序被送入sh执行，这个shell只有USER,HOME,SHELL这三个环境变量 </span><br><span class="line">说明 : </span><br><span class="line">crontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。-u user 是指设定指定 </span><br><span class="line">user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设 </span><br><span class="line">定自己的时程表。 </span><br><span class="line">参数 : </span><br><span class="line">crontab -e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数 </span><br><span class="line">来指定使用那个文字编辑器(比如说 setenv VISUAL joe) </span><br><span class="line">crontab -r : 删除目前的时程表 </span><br><span class="line">crontab -l : 列出目前的时程表 </span><br><span class="line">crontab file [-u user]-用指定的文件替代目前的crontab。 </span><br><span class="line">时程表的格式如下 : </span><br><span class="line">f1 f2 f3 f4 f5 program </span><br><span class="line">其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执 </span><br><span class="line">行的程序。 </span><br><span class="line">当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 </span><br><span class="line">当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 </span><br><span class="line">当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推</span><br><span class="line">当 f1 为 a, b, c,... 时表示第 a, b, c,... 分钟要执行，f2 为 a, b, c,... 时表示第 a, b, c...个小时要执行，其馀类推 </span><br><span class="line">使用者也可以将所有的设定先存放在档案 file 中，用 crontab file 的方式来设定时程表。 </span><br><span class="line">例子 : </span><br><span class="line">#每天早上7点执行一次 /bin/ls : </span><br><span class="line">0 7 * * * /bin/ls </span><br><span class="line">在 12 月内, 每天的早上 6 点到 12 点中，每隔3个小时执行一次 /usr/bin/backup : </span><br><span class="line">0 6-12/3 * 12 * /usr/bin/backup </span><br><span class="line">周一到周五每天下午 5:00 寄一封信给 alex@domain.name : </span><br><span class="line">0 17 * * 1-5 mail -s &quot;hi&quot; alex@domain.name &lt; /tmp/maildata </span><br><span class="line">每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分....执行 echo &quot;haha&quot; </span><br><span class="line">20 0-23/2 * * * echo &quot;haha&quot; </span><br><span class="line">注意 : </span><br><span class="line">当程序在你所指定的时间执行后，系统会寄一封信给你，显示该程序执行的内容，若是你不希望收到这样的信，请在每一行空一格之 </span><br><span class="line">后加上 &gt; /dev/null 2&gt;&amp;1 即可 </span><br><span class="line">例子2 : </span><br><span class="line">#每天早上6点10分 </span><br><span class="line">10 6 * * * date </span><br><span class="line">#每两个小时 </span><br><span class="line">0 */2 * * * date </span><br><span class="line">#晚上11点到早上8点之间每两个小时，早上8点 </span><br><span class="line">0 23-7/2，8 * * * date </span><br><span class="line">#每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 </span><br><span class="line">0 11 4 * mon-wed date </span><br><span class="line">#1月份日早上4点 </span><br><span class="line">0 4 1 jan * date </span><br><span class="line">范例 </span><br><span class="line">$crontab -l 列出用户目前的crontab.</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Shell循环结构</title>
      <link href="/2016/03/12/Linux-Shell%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/"/>
      <url>/2016/03/12/Linux-Shell%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/</url>
      <content type="html"><![CDATA[<p>　　上篇博客讲了<a href="http://blog.xiaoxiaomo.com/2016/03/06/Linux-Shell%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%8F%8A%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97/" title="Linux-Shell条件判断及算术运算/">http://blog.xiaoxiaomo.com/2016/03/06/Linux-Shell条件判断及算术运算/</a>，本篇博客主要讲解，<code>for循环结构体和while循环结构</code>，语法结果和Java都很类似，容易学习，只需记住一些小小的差别即可。</p><a id="more"></a><h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h2><p>通过使用一个变量去遍历给定列表中的每个元素，在每次变量赋值时执行一次循环体，直至赋值完成所有元素退出循环</p><ul><li>语法:<blockquote><p>for ((初始值;限制值;执行步长))<br>do<br>　　//….<br>done</p></blockquote></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#####格式1</span></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;10;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  //...</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####格式2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> 0 1 2 3 4 5 6 7 8 9</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">  //...</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#####格式3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;0..9&#125;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  //...</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">注意：<span class="keyword">for</span> i <span class="keyword">in</span> &#123;0..9&#125; 等于<span class="keyword">for</span> i <span class="keyword">in</span> &#123;0..9..2&#125;</span><br></pre></td></tr></table></figure><ol><li>初始值 : 某个变量在循环中的起始值，直接以类似i=1的方式设置好。</li><li>限制值 : 当变量值在这个限制值的范围内，就继续进行循环。例如:i&lt;=10</li><li>执行步长 : 每做一次循环时变量的变化量。例如：i++</li></ol><ul><li>eg ： 事例</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">s=0</span><br><span class="line"><span class="keyword">for</span> (( i=1; i&lt;=10; i++ ))  <span class="comment">#必须使用双括号</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    ((s=<span class="variable">$s</span>+i))             <span class="comment">#必须使用(())，在双括号中可以进行算数运算。</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"sum:"</span> <span class="variable">$s</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h2><p>适用于循环次数未知，或不便用for直接生成较大的列表时</p><ul><li>第一种格式：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> [ condition ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    程序段</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这种方式中，当condition条件成立时，就进行循环，直到condition的条件不成立才停止。</span></span><br></pre></td></tr></table></figure><ul><li><p>第二种格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">until [ condition ]</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">     程序段</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这种方式和while相反，它就是说“当condition条件成立时，就终止循环，否则就持续执行循环的程序段”。</span></span><br></pre></td></tr></table></figure></li><li><p>eg : </p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#while循环</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> [ <span class="string">"<span class="variable">$1</span>"</span> == <span class="string">"xiao"</span> ] || [ <span class="string">"<span class="variable">$1</span>"</span> == <span class="string">"xiaomo"</span> ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">" xiaoxiaomo:"</span>+  <span class="variable">$1</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="循环控制命令"><a href="#循环控制命令" class="headerlink" title="循环控制命令"></a>循环控制命令</h2><ul><li>break</li></ul><p>break命令是在处理过程中跳出循环的一种简单方法，可以使用break命令退出任何类型的循环，包括while循环和for循环</p><ul><li>continue<br>continue命令是一种提前停止循环内命令，而不完全终止循环的方法，这就需要在循环内设置shell不执行命令的条件</li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Shell条件判断及算术运算</title>
      <link href="/2016/03/06/Linux-Shell%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%8F%8A%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97/"/>
      <url>/2016/03/06/Linux-Shell%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%8F%8A%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97/</url>
      <content type="html"><![CDATA[<p>　　上篇博客<a href="http://blog.xiaoxiaomo.com/2016/03/05/Linux-Shell%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/" title="Shell编程入门">http://blog.xiaoxiaomo.com/2016/03/05/Linux-Shell编程入门/</a>，讲解了变量及使用。本篇博客主要讲解<code>Shell条件判断和算术运算</code>基本思路和Java差不多，变动的就是一些<strong>语法格式</strong>。</p><a id="more"></a><h2 id="bash条件测试"><a href="#bash条件测试" class="headerlink" title="bash条件测试"></a>bash条件测试</h2><p>shell有一个内部命令test经常用于对判断语句进行测试一种或几种状态的条件是否成立。0表示成功，1-255表示匹配失败。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#####格式： </span></span><br><span class="line">  1、<span class="built_in">test</span> EXPR </span><br><span class="line">  2、[ EXPR ]：注意中括号和表达式之间的空格</span><br><span class="line">  3、[[ EXPR ]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#####整型测试：</span></span><br><span class="line">-gt：大于：例如[ <span class="variable">$A</span> -gt <span class="variable">$B</span> ]或者<span class="built_in">test</span>，测试<span class="variable">$A</span>是否大于<span class="variable">$B</span></span><br><span class="line">-lt：小于</span><br><span class="line">-ge：大于等于</span><br><span class="line">-le：小于等于</span><br><span class="line">-eq：等于</span><br><span class="line">-ne：不等于</span><br><span class="line"></span><br><span class="line"><span class="comment">#####字符串测试：</span></span><br><span class="line">=：等于，例如判断变量是否为空 [ <span class="string">"<span class="variable">$str</span>"</span> =  <span class="string">""</span> ] 或者[ -z <span class="variable">$str</span> ]</span><br><span class="line">!=：不等于</span><br><span class="line"></span><br><span class="line"><span class="comment">#####逻辑关系</span></span><br><span class="line">逻辑与： &amp;&amp;</span><br><span class="line">逻辑或： ||</span><br></pre></td></tr></table></figure><ul><li>实例代码</li></ul><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418220102.png" alt=""></p><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418222740.png" alt=""></p><h2 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h2><p>算术运算符指的是可以在程序中实现加、减、乘、除等数学运算的运算符。Shell中常用的数学运算符如下所示。</p><blockquote><p><strong>+</strong>：对两个变量做加法。<br><strong>-</strong>：对两个变量做减法。<br><strong>*</strong>：对两个变量做乘法。<br><strong>/</strong>：对两个变量做除法。<br><strong>**</strong>：对两个变量做幂运算。<br><strong>%</strong>：取模运算，第一个变量除以第二个变量求余数。<br><strong>+=</strong>：加等于，在自身基础上加第二个变量。<br><strong>-=</strong>：减等于，在第一个变量的基础上减去第二个变量。<br><strong>*=</strong>：乘等于，在第一个变量的基础上乘以第二个变量。<br><strong>/=</strong>：除等于，在第一个变量的基础上除以第二个变量。<br><strong>%=</strong>：取模赋值，第一个变量对第二个变量取模运算，再赋值给第一个变量。</p></blockquote><ul><li>eg ：</li></ul><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418224922.png" alt=""></p><ul><li>输出结果<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 ~]$ ./operation.sh </span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">36</span></span><br><span class="line"><span class="number">300</span></span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="if分支"><a href="#if分支" class="headerlink" title="if分支"></a>if分支</h2><ul><li>if分支语法：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">##### 单分支</span></span><br><span class="line">  <span class="keyword">if</span> 测试条件;<span class="keyword">then</span></span><br><span class="line"> 选择分支</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##### 双分支</span></span><br><span class="line">  <span class="keyword">if</span> 测试条件</span><br><span class="line">  <span class="keyword">then</span></span><br><span class="line">    选择分支1</span><br><span class="line">  <span class="keyword">else</span> </span><br><span class="line">    选择分支2</span><br><span class="line">  <span class="keyword">fi</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">##### 多分支</span></span><br><span class="line">  <span class="keyword">if</span> 条件1; <span class="keyword">then</span></span><br><span class="line">分支1</span><br><span class="line">  <span class="keyword">elif</span> 条件2; <span class="keyword">then</span></span><br><span class="line">分支2</span><br><span class="line">  <span class="keyword">elif</span> 条件3; <span class="keyword">then</span></span><br><span class="line">分支3</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">else</span> </span><br><span class="line">    分支n</span><br><span class="line">  <span class="keyword">fi</span></span><br></pre></td></tr></table></figure><ul><li>eg ：</li></ul><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418231003.png" alt=""></p><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418230914.png" alt=""></p><h2 id="case分支"><a href="#case分支" class="headerlink" title="case分支"></a>case分支</h2><p>有多个测试条件时，case语句会使得语法结构更清晰，更容易看出分块管理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">格式： </span><br><span class="line"><span class="keyword">case</span> 变量引用 <span class="keyword">in</span></span><br><span class="line">PATTERN1)</span><br><span class="line">分支1</span><br><span class="line">;;</span><br><span class="line">PATTERN2)</span><br><span class="line">分支2</span><br><span class="line">;;</span><br><span class="line">...</span><br><span class="line">*)</span><br><span class="line">分支n</span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><ul><li>注</li></ul><p>PATTERN :类同于文件名通配机制，但支持使用|表示或者<br>a|b：a或者b<br>*：匹配任意长度的任意字符<br>?：匹配任意单个字符<br>[a-z]：指定范围内的任意单个字符</p><ul><li>eg ： </li></ul><p>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418232550.png" alt=""></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@momo1 shell]<span class="comment"># ./caseShell.sh stop</span></span><br><span class="line">The server stop......</span><br><span class="line">[root@momo1 shell]<span class="comment"># ./caseShell.sh start</span></span><br><span class="line">The server starting......</span><br><span class="line">[root@momo1 shell]<span class="comment"># ./caseShell.sh status</span></span><br><span class="line">The server off</span><br></pre></td></tr></table></figure><h2 id="算术运算"><a href="#算术运算" class="headerlink" title="算术运算"></a>算术运算</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">let</span> varName=算术表达式</span><br><span class="line"></span><br><span class="line">varName=$[算术表达式]</span><br><span class="line"></span><br><span class="line">varName=$((算术表达式))</span><br><span class="line"></span><br><span class="line">varName=`expr <span class="variable">$num1</span> + <span class="variable">$num2</span>`</span><br><span class="line">使用这种格式要注意两个数字和+号中间要有空格。</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Shell编程入门</title>
      <link href="/2016/03/05/Linux-Shell%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/"/>
      <url>/2016/03/05/Linux-Shell%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>　　<code>Shell</code>是用户与Linux操作系统沟通的桥梁。Linux的Shell种类众多，这里我们学习的是<strong>bash</strong>，也就是<em>Bourne Again Shell</em>。因为他易用和免费，并且是大部分Linux默认的Shell。</p><a id="more"></a><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ol><li><p>shell脚本文件格式</p><blockquote><p>文件名后缀通常是.sh<br>#!/bin/bash (同样还可以使用#!/bin/sh)<br>#这里是注释</p></blockquote></li><li><p>脚本执行的常用方式，比如mo.sh</p><blockquote><p>1、mo.sh（需有执行权限并且环境变量PATH中有(.)）<br>2、./mo.sh（只要保证这个脚本具有执行权限即可）<br>3、/home/momo1/mo.sh（只要保证这个脚本具有执行权限即可）<br>4、bash mo.sh（直接可以执行，甚至这个脚本文件中的第一行都可以不引入/bin/bash）<br>5、bash -x /home/momo1/mo.sh #bash的单步执行<br>6、bash -n /home/momo1/mo.sh #bash语法检查</p></blockquote></li></ol><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>变量不需要声明，初始化不需要指定类型。分为，<strong>本地变量</strong>、<strong>环境变量</strong>、<strong>局部变量</strong>、<strong>位置变量</strong>、<strong>特殊变量</strong>。<code>变量赋值时“=”等号左右边不能有空格。</code></p><ul><li>变量命名</li></ul><ol><li>只能使用数字，字母和下划线，且不能以数字开头</li><li>变量名区分大小写</li><li>建议命令要通俗易懂</li></ol><p>显示变量值： 使用echo命令，加上$变量名，也可以使用${变量名}<br>例如：echo $JAVA_HOME<br>或者echo ${JAVA_HOME}</p><h3 id="本地变量"><a href="#本地变量" class="headerlink" title="本地变量"></a>本地变量</h3><p>只对当前shell进程有效的，对当前进程的子进程和其它shell进程无效，相当于java中的私有变量(private)。</p><blockquote><p>1、定义：VAR_NAME=VALUE<br>2、变量引用：${VAR_NAME}|$VAR_NAME<br>3、取消变量：unset VAR_NAME</p></blockquote><p>事例如下，定义一个变量，然后将它输出到控制台<br>    <img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418195305.png" alt=""></p><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>自定义的环境变量对当前shell进程及其子shell进程有效，对其它的shell进程无效。配置到配置文件<code>/etc/profile</code>中对所有shell进程都有效。</p><blockquote><p>定义：export VAR_NAME=VALUE</p></blockquote><pre><code>![](https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418200252.png)</code></pre><ul><li>配置文件中环境变量（修改后记得source /ect/profile重启）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 ~]$ vim /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> /etc/profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ......</span></span><br><span class="line">export PATH=.:$PATH</span><br></pre></td></tr></table></figure><h3 id="局部变量"><a href="#局部变量" class="headerlink" title="局部变量"></a>局部变量</h3><p>在函数中调用，函数执行结束，变量就会消失。对shell脚本中某代码片段有效。</p><blockquote><p>定义：local VAR_NAME=VALUE</p></blockquote><h3 id="位置变量"><a href="#位置变量" class="headerlink" title="位置变量"></a>位置变量</h3><p>用于接收 传递过来的参数。相当于java中main函数中的args参数。</p><blockquote><p>定义：$0,$1,$2,…..${n}</p></blockquote><ul><li>事例：定义shell脚本，内容如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo $0 #（脚本自己本身）</span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br></pre></td></tr></table></figure><p>执行命令，并传入参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[momo1@momo1 shell]$ ./site.sh xiaoxiaomo</span><br><span class="line">./site.sh</span><br><span class="line">xiaoxiaomo</span><br><span class="line"></span><br><span class="line">[momo1@momo1 shell]$ ./site.sh xiaoxiaomo blog</span><br><span class="line">./site.sh</span><br><span class="line">xiaoxiaomo</span><br><span class="line">blog</span><br><span class="line">[momo1@momo1 shell]$ ./site.sh xiaoxiaomo blog com</span><br><span class="line">./site.sh</span><br><span class="line">xiaoxiaomo</span><br><span class="line">blog</span><br></pre></td></tr></table></figure><h3 id="特殊变量"><a href="#特殊变量" class="headerlink" title="特殊变量"></a>特殊变量</h3><blockquote><p>1、<strong>$?</strong>：接收上一条命令的返回状态码（状态码在0-255之间）<br>2、<strong>$#</strong>：参数个数<br>3、<strong>$*</strong>：或者$@：所有的参数<br>4、<strong>$$</strong>：获取当前shell的进程号（PID）(可以实现脚本自杀)(或者使用exit命令直接退出也可以使用exit [num])</p></blockquote><pre><code>![](https://img.xiaoxiaomo.com/blog%2Fimg%2F20160418222049.png)</code></pre><h2 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h2><p>Shell中，符号分为：单引号、双引号、反引号</p><p><strong>‘’单引号</strong>：不解析变量，echo ‘$xiaoxiaomo’<br><strong>“”双引号</strong>：会解析变量，echo “$xiaoxiaomo”<br><strong>``反引号</strong>：是执行并引用一个命令的执行结果，类似于$(…)，echo `$xiaoxiaomo`</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--磁盘管理及挂载</title>
      <link href="/2016/02/29/Linux-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E5%8F%8A%E6%8C%82%E8%BD%BD/"/>
      <url>/2016/02/29/Linux-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E5%8F%8A%E6%8C%82%E8%BD%BD/</url>
      <content type="html"><![CDATA[<p>　　<strong>硬盘</strong>：一个IO设备。设备名称： <code>IDE硬盘为hdx（x为从a—d硬盘最多四个）</code>，SCSI，SATA，USB硬盘为sdx（x为a—z））。<code>硬盘主分区最多为4个（sdb1-sdb4），逻辑分区从sdb5开始</code>。本篇博客主要讲解查看和管理磁盘的基本命令，最主要内容还是磁盘分区和挂载。</p><h2 id="查看磁盘信息"><a href="#查看磁盘信息" class="headerlink" title="查看磁盘信息"></a>查看磁盘信息</h2><h3 id="df命令"><a href="#df命令" class="headerlink" title="df命令"></a>df命令</h3><ul><li>查看已挂载磁盘的总容量、使用容量、剩余容量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df -i <span class="comment">#使用inodes 显示结果</span></span><br><span class="line">df -h <span class="comment">#用合适的单位显示,G,M等</span></span><br><span class="line">df -k <span class="comment">#显示单位K</span></span><br><span class="line">df –m <span class="comment">#显示单位M</span></span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155228.png" alt=""></p><a id="more"></a><p>说明：</p><blockquote><p>Filesystem #表示扇区,划分磁盘时所分的区<br>Used #已使用<br>Available #剩余<br>Use% #已经使用的百分比<br>Mounted on #扇区挂载点</p></blockquote><h3 id="du命令"><a href="#du命令" class="headerlink" title="du命令"></a>du命令</h3><p>查看某个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">du [-abckmsh] [文件或者目录名]</span><br><span class="line">du -a <span class="comment">#全部文件与目录大小都列出来,如果不加参数列出目录（包含子目录）。</span></span><br><span class="line">du -h <span class="comment">#用合适的单位显示, 还有单位-b -k –m。</span></span><br><span class="line">du -s <span class="comment">#只显示总和。</span></span><br><span class="line">du -c <span class="comment">#最后显示总和。</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155228.png" alt=""></p><h2 id="磁盘挂载"><a href="#磁盘挂载" class="headerlink" title="磁盘挂载"></a>磁盘挂载</h2><h3 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h3><p>硬盘分区及挂载操作步骤：</p><blockquote><ol><li><strong><code>fdisk -l</code></strong>#查看未挂载的硬盘（名称为/dev/xvdb）<br>Disk /dev/xvdb doesn’t contain a valid partition table</li><li><strong><code>fdisk /dev/xvdb</code></strong>  # 创建分区</li><li>输入n<br>Command (m for help):n</li><li>输入p<br>Command action<br>e extended<br>p primary partition (1-4)<br>p</li><li>输入1<br>Partition number (1-4): 1</li><li>回车<br>First cylinder (1-2610, default 1):<br>Using default value 1</li><li>回车<br>Last cylinder, +cylinders or +size{K,M,G} (1-2610, default 2610):<br>Using default value 2610</li><li>输入w<br>Command (m for help): w<br>The partition table has been altered!</li><li><strong><code>mkfs.ext3 /dev/xvdb1</code></strong> #格式化分区</li><li><strong><code>mkdir /data</code></strong> #建立挂载目录</li><li><strong><code>mount /dev/xvdb1 /data</code></strong>   #挂载分区</li><li><strong><code>vi /etc/fstab</code></strong>  #设置开机自动挂载<br>在vi中输入i进入INERT模式，将光标移至文件结尾处并回车，将下面的内容复制/粘贴，然后按Esc键，输入:x保存并退出<br>/dev/xvdb               /data                   ext3    defaults        0 0</li><li><strong><code>reboot</code></strong> #重启服务器</li><li><strong><code>df</code></strong> #查看硬盘分区<br>/dev/xvdb             20635700    176196  19411268   1% /data</li></ol></blockquote><h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><ul><li><p>第一步：查看磁盘分区，发现/dev/xvdb并没有挂载信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># fdisk -l</span></span><br><span class="line"></span><br><span class="line">Disk /dev/xvda: 21.5 GB, 21474836480 bytes</span><br><span class="line">255 heads, 63 sectors/track, 2610 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0x00078f9c</span><br><span class="line"></span><br><span class="line">    Device Boot      Start         End      Blocks   Id  System  <span class="comment">#挂载信息</span></span><br><span class="line">/dev/xvda1   *           1        2611    20970496   83  Linux</span><br><span class="line"></span><br><span class="line">Disk /dev/xvdb: 32.2 GB, 32212254720 bytes</span><br><span class="line">255 heads, 63 sectors/track, 3916 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0x00000000    <span class="comment">##没有挂载信息,iden=0x00000000</span></span><br></pre></td></tr></table></figure></li><li><p>第二步：创建磁盘分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># fdisk /dev/xvdb</span></span><br><span class="line">Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel</span><br><span class="line">Building a new DOS disklabel with disk identifier 0xc27ae924.</span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, until you decide to write them.</span><br><span class="line">After that, of course, the previous content won<span class="string">'t be recoverable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">WARNING: DOS-compatible mode is deprecated. It'</span>s strongly recommended to</span><br><span class="line">         switch off the mode (<span class="built_in">command</span> <span class="string">'c'</span>) and change display units to</span><br><span class="line">         sectors (<span class="built_in">command</span> <span class="string">'u'</span>).</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n   <span class="comment">##输入n</span></span><br><span class="line">Command action</span><br><span class="line">   e   extended</span><br><span class="line">   p   primary partition (1-4)</span><br><span class="line">p</span><br><span class="line">Partition number (1-4): 1   <span class="comment">##输入1</span></span><br><span class="line">First cylinder (1-3916, default 1):   <span class="comment">##回车键</span></span><br><span class="line">Using default value 1</span><br><span class="line">Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-3916, default 3916): <span class="comment">##回车</span></span><br><span class="line">Using default value 3916</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w    <span class="comment">##输入w</span></span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># fdisk -l  ##再次查看磁盘信息</span></span><br><span class="line"></span><br><span class="line">Disk /dev/xvda: 21.5 GB, 21474836480 bytes</span><br><span class="line">255 heads, 63 sectors/track, 2610 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0x00078f9c</span><br><span class="line"></span><br><span class="line">    Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/xvda1   *           1        2611    20970496   83  Linux</span><br><span class="line"></span><br><span class="line">Disk /dev/xvdb: 32.2 GB, 32212254720 bytes</span><br><span class="line">255 heads, 63 sectors/track, 3916 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0xc27ae924   <span class="comment">##已经不是0x00000000，并下面有磁盘信息</span></span><br><span class="line"></span><br><span class="line">    Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/xvdb1               1        3916    31455238+  83  Linux</span><br></pre></td></tr></table></figure></li><li><p>第三步：格式化分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># mkfs.ext3 /dev/xvdb1</span></span><br><span class="line">mke2fs 1.41.12 (17-May-2010)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS <span class="built_in">type</span>: Linux</span><br><span class="line">Block size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Fragment size=4096 (<span class="built_in">log</span>=2)</span><br><span class="line">Stride=0 blocks, Stripe width=0 blocks</span><br><span class="line">1966080 inodes, 7863809 blocks</span><br><span class="line">393190 blocks (5.00%) reserved <span class="keyword">for</span> the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=4294967296</span><br><span class="line">240 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">4096000</span><br><span class="line"></span><br><span class="line">Writing inode tables: <span class="keyword">done</span>                            </span><br><span class="line">Creating journal (32768 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">This filesystem will be automatically checked every 29 mounts or</span><br><span class="line">180 days, whichever comes first.  Use tune2fs -c or -i to override.</span><br></pre></td></tr></table></figure></li><li><p>第四步：创建挂载目录并挂载分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># mkdir /data ##博主创建挂载目录为/data</span></span><br><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># mount /dev/xvdb1 /data ##挂载分区到/data目录</span></span><br></pre></td></tr></table></figure></li><li><p>第五步：设置开机自动挂载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># vi /etc/fstab</span></span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160430095852.png" alt="开机自动挂载"></p><ul><li>第六步：重启系统，并查看信息<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># reboot</span></span><br><span class="line">[root@iZ94r8hgrjcZ /]<span class="comment"># fdisk -l</span></span><br><span class="line"></span><br><span class="line">Disk /dev/xvda: 21.5 GB, 21474836480 bytes</span><br><span class="line">255 heads, 63 sectors/track, 2610 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0x00078f9c</span><br><span class="line"></span><br><span class="line">    Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/xvda1   *           1        2611    20970496   83  Linux</span><br><span class="line"></span><br><span class="line">Disk /dev/xvdb: 32.2 GB, 32212254720 bytes</span><br><span class="line">255 heads, 63 sectors/track, 3916 cylinders</span><br><span class="line">Units = cylinders of 16065 * 512 = 8225280 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk identifier: 0xc27ae924</span><br><span class="line"></span><br><span class="line">    Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/xvdb1               1        3916    31455238+  83  Linux</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--常用VI/VIM命令</title>
      <link href="/2016/02/28/Linux-%E5%B8%B8%E7%94%A8VI-VIM%E5%91%BD%E4%BB%A4/"/>
      <url>/2016/02/28/Linux-%E5%B8%B8%E7%94%A8VI-VIM%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>　　VI编辑器是Unix和Linux系统下标准的编辑器，VIM就是VI的升级版，多了高亮，等特性。VI和VIM是比较常用的文本编辑工具，是必须要使用的，需要记住常用的命令。下面内容主要使用VIM来表示：</p><a id="more"></a><h3 id="三种模式"><a href="#三种模式" class="headerlink" title="三种模式"></a>三种模式</h3><blockquote><p>三种模式： 1，命令模式   2，输入模式   3，末行模式</p></blockquote><ul><li>命令模式 ：就是使用”vim打开文本”后进入的模式。该模式下不可直接输入，可以进行光标移动删除等操作。</li><li>输入模式 ：就是在命令模式通过”Insert”进入的模式。该模式下可进行键盘输入等操作。</li><li>末行模式 ：在底端进行命令输入的模式，该模式下可进行文件保存，退出，查找，替换等操作。</li></ul><h3 id="光标的移动"><a href="#光标的移动" class="headerlink" title="光标的移动"></a>光标的移动</h3><ul><li>屏幕移动：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[ctrl]+f：(向下PgDn)、[ctrl]+b：(向上PgUp)</span><br><span class="line">H：  <span class="comment">#移动到当前屏幕第一个字符</span></span><br><span class="line">M：  <span class="comment">#移动到当前屏幕中间第一个字符</span></span><br><span class="line">L：  <span class="comment">#移动到当前屏幕最后一个字符</span></span><br></pre></td></tr></table></figure><ul><li>行的移动：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[n]G： <span class="comment">#移动到第n行，不写n移动到最后一行。 eg：移动到第一行，相当于1G。</span></span><br><span class="line">n[Enter]：<span class="comment">#光标向下移动多少行。</span></span><br></pre></td></tr></table></figure><ul><li>字符移动：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">↑上、↓下、左←、右→：<span class="comment">#（前面加数字n,表示移动多少字符，例如：20→向右移动20个字符=n&lt;apace&gt;）。</span></span><br><span class="line">0或^或功能键[Home]：<span class="comment">#当前行开始字符。</span></span><br><span class="line">$或功能键[End]：<span class="comment">#当前行结尾字符。</span></span><br></pre></td></tr></table></figure><h3 id="查找和替换"><a href="#查找和替换" class="headerlink" title="查找和替换"></a>查找和替换</h3><ul><li>查找：   </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/：  <span class="comment">#（向下查找）</span></span><br><span class="line">？： <span class="comment">#（向上查找）。==&gt;（n继续向下，N继续向上）</span></span><br></pre></td></tr></table></figure><ul><li>替换：   </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r：  <span class="comment">#替换单个字符，[exit]推出。</span></span><br><span class="line">R：  <span class="comment">#连续替换单个字符。</span></span><br><span class="line">:n1,n2s/word1/word2/g[c]：<span class="comment">#在第n1行和n2（n2-&gt;$可以用来表示最后一行）行之间查找word1并替换为word2。 (c,提示用户确认confirm)。</span></span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">删除字符：[n]x，  <span class="comment">#表示向后删除n个字符（用X向前删除）。（x=[Del]，X=[Backspace]）</span></span><br><span class="line">删除某行：[n]dd， <span class="comment">#删除光标所在行的n行。（例如，dd删除当前行）</span></span><br></pre></td></tr></table></figure><h3 id="复制-粘贴"><a href="#复制-粘贴" class="headerlink" title="复制/粘贴"></a>复制/粘贴</h3><h4 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">复制字符：</span><br><span class="line">y0：    <span class="comment">#复制光标所在字符到行首所有数据。</span></span><br><span class="line">y$：    <span class="comment">#复制光标所在字符到行末所有数据。</span></span><br><span class="line">复制某行：</span><br><span class="line">[n]yy： <span class="comment">#向下复制n行，（yy复制当前行）。</span></span><br></pre></td></tr></table></figure><h4 id="粘贴"><a href="#粘贴" class="headerlink" title="粘贴"></a>粘贴</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p：   <span class="comment">#粘贴数据到下一行。</span></span><br><span class="line">P：   <span class="comment">#粘贴数据到上一行。</span></span><br></pre></td></tr></table></figure><h3 id="撤销-重复"><a href="#撤销-重复" class="headerlink" title="撤销/重复"></a>撤销/重复</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">撤销：u：   <span class="comment">#撤销前一个操作。[n]u撤销最近几次。</span></span><br><span class="line">重做：[Ctrl]+r： <span class="comment">#撤销最后一次撤销操作。（常和u组合使用）</span></span><br><span class="line">重复：.    <span class="comment">#:重复前一个操作。</span></span><br></pre></td></tr></table></figure><h3 id="选择（可视化模式）"><a href="#选择（可视化模式）" class="headerlink" title="选择（可视化模式）"></a>选择（可视化模式）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">字符选择：v   </span><br><span class="line">行选择 ： V   </span><br><span class="line">块选择 ：[Ctrl]+v  <span class="comment">#（长方形方式）</span></span><br></pre></td></tr></table></figure><h3 id="命令模式，扩展几个命令"><a href="#命令模式，扩展几个命令" class="headerlink" title="命令模式，扩展几个命令"></a>命令模式，扩展几个命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ZZ：   <span class="comment">#文件已改动保存后离开，未改动不保存离开。</span></span><br><span class="line">:w [fileName]：  <span class="comment">#将编辑的文件另存为。(:n1 n2 w [fileName],n1到n2行的数据另存为新文件)。</span></span><br><span class="line">:<span class="built_in">set</span> nu：   <span class="comment">#设置行号（:set nonu取消设置）。</span></span><br></pre></td></tr></table></figure><blockquote><p>例子：选某字符后删除/复制 :v d/y</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--MySQL源码安装及配置</title>
      <link href="/2016/02/25/Linux-Mysql%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/"/>
      <url>/2016/02/25/Linux-Mysql%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　上篇博客<a href="http://blog.xiaoxiaomo.com/2016/02/22/Linux-软件安装之Mysql/">http://blog.xiaoxiaomo.com/2016/02/22/Linux-软件安装之Mysql/</a>，使用了一种相对比较简单的安装方式。本片博客，在讲解另外一种安装方式。</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>下载地址Cmake：<a href="https://cmake.org/download/" target="_blank" rel="noopener">http://www.cmake.org/cmake/resources/software.html</a></li><li>下载地址Mysql：<a href="http://www.mysql.com" target="_blank" rel="noopener">http://www.mysql.com</a></li><li>博主下载了版本分别为：<a href="http://download.csdn.net/detail/tang__xuandong/9502755" target="_blank" rel="noopener">mysql-5.5.40 linux.tar.gz</a>和<a href="http://download.csdn.net/detail/tang__xuandong/9502759" target="_blank" rel="noopener">cmake-3.0.2.tar.gz</a>（<em>这里提供了下载</em>）</li></ul><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li>1.先安装cmake<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ up]<span class="comment"># tar -zxvf cmake-3.0.2.tar.gz </span></span><br><span class="line">[root@iZ94r8hgrjcZ up]<span class="comment"># mv cmake-3.0.2 /opt/   </span></span><br><span class="line">[root@iZ94r8hgrjcZ up]<span class="comment"># cd /opt/cmake-3.0.2/</span></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># ./configure ##如报错，请看下面解决办法</span></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># make</span></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># make install</span></span><br></pre></td></tr></table></figure></li></ul><p>问题一：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># ./configure </span></span><br><span class="line">---------------------------------------------</span><br><span class="line">CMake 3.0.2, Copyright 2000-2014 Kitware, Inc.</span><br><span class="line">---------------------------------------------</span><br><span class="line">Error when bootstrapping CMake:</span><br><span class="line">Cannot find appropriate C compiler on this system.</span><br><span class="line">Please specify one using environment variable CC.</span><br><span class="line">See cmake_bootstrap.log <span class="keyword">for</span> compilers attempted.</span><br><span class="line"></span><br><span class="line">---------------------------------------------</span><br><span class="line">Log of errors: /opt/cmake-3.0.2/Bootstrap.cmk/cmake_bootstrap.log</span><br><span class="line">---------------------------------------------</span><br></pre></td></tr></table></figure></p><p>解决办法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">1. <span class="comment">##安装gcc环境</span></span><br><span class="line">yum -y install gcc </span><br><span class="line"></span><br><span class="line">2. 然后运行：[root@iZ94r8hgrjcZ</span><br><span class="line">3. </span><br><span class="line">4.  cmake-3.0.2]<span class="comment"># ./bootstrap #报错如下</span></span><br><span class="line">---------------------------------------------</span><br><span class="line">CMake 3.0.2, Copyright 2000-2014 Kitware, Inc.</span><br><span class="line">C compiler on this system is: cc </span><br><span class="line">---------------------------------------------</span><br><span class="line">Error when bootstrapping CMake:</span><br><span class="line">Cannot find appropriate C++ compiler on this system.</span><br><span class="line">Please specify one using environment variable CXX.</span><br><span class="line">See cmake_bootstrap.log <span class="keyword">for</span> compilers attempted.</span><br><span class="line">---------------------------------------------</span><br><span class="line">Log of errors: /opt/cmake-3.0.2/Bootstrap.cmk/cmake_bootstrap.log</span><br><span class="line">---------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment">##缺少c++的环境</span></span><br><span class="line">yum -y install gcc-c++  </span><br><span class="line"></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># ./bootstrap </span></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># gmake  </span></span><br><span class="line">[root@iZ94r8hgrjcZ cmake-3.0.2]<span class="comment"># gmake install</span></span><br></pre></td></tr></table></figure><ul><li><p>2.创建mysql的安装目录及数据库存放目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ opt]<span class="comment"># mkdir -p /opt/mysql //安装mysql </span></span><br><span class="line">[root@iZ94r8hgrjcZ opt]<span class="comment"># mkdir -p /opt/mysql/data //存放数据库</span></span><br></pre></td></tr></table></figure></li><li><p>3.创建mysql用户及用户组</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ opt]<span class="comment"># groupadd mysql</span></span><br><span class="line">[root@iZ94r8hgrjcZ opt]<span class="comment"># useradd -r -g mysql mysql</span></span><br></pre></td></tr></table></figure></li><li><p>4.安装mysql</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ up]<span class="comment"># tar -zxvf mysql-5.5.40\ linux.tar.gz </span></span><br><span class="line">[root@iZ94r8hgrjcZ up]<span class="comment"># cd mysql-5.5.40</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql-5.5.40]<span class="comment"># cmake . -DCMAKE_INSTALL_PREFIX=/opt/mysql -DMYSQL_DATADIR=/opt/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DEXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 //注意：上面是一条命令</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql-5.5.40]<span class="comment"># make  </span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql-5.5.40]<span class="comment"># make install</span></span><br></pre></td></tr></table></figure></li><li><p>5.问题解决（博主报了如下错误）</p></li></ul><p>错误一： 在cmake时，出现如下错误：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- Could NOT find Curses (missing:  CURSES_LIBRARY CURSES_INCLUDE_PATH) </span><br><span class="line">CMake Error at cmake/readline.cmake:83 (MESSAGE):</span><br><span class="line">  Curses library not found.  Please install appropriate package,</span><br><span class="line"></span><br><span class="line">      remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, on Redhat andevel.</span><br><span class="line">Call Stack (most recent call first):</span><br><span class="line">  cmake/readline.cmake:127 (FIND_CURSES)</span><br><span class="line">  cmake/readline.cmake:217 (MYSQL_USE_BUNDLED_LIBEDIT)</span><br><span class="line">  CMakeLists.txt:369 (MYSQL_CHECK_READLINE)</span><br></pre></td></tr></table></figure></p><p>解决办法：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ncurses-devel</span><br><span class="line">yum -y install bison</span><br><span class="line">make &amp;&amp; make install <span class="comment">#编译完成</span></span><br></pre></td></tr></table></figure></p><p>错误二： 在make时，出现了如下错误：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make: *** No targets specified and no makefile found.  Stop.</span><br></pre></td></tr></table></figure></p><p>解决办法：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1、wget http://ftp.gnu.org/pub/gnu/ncurses/ncurses-5.6.tar.gz</span><br><span class="line">2、tar zxvf ncurses-5.6.tar.gz</span><br><span class="line">3、<span class="built_in">cd</span> ncurses-5.6</span><br><span class="line">4、 ./configure -prefix=/opt -with-shared -without-debug</span><br><span class="line">    ./configure --with-shared --without-debug --with-ticlib</span><br><span class="line">5、make &amp;&amp; make install</span><br></pre></td></tr></table></figure></p><p>注意：如果执行<code>cmake . -DCMAKE_INSTALL_PREFIX=/opt/mysql -DMYSQL_DATADIR=/opt/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DEXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1</code>还是报错:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, </span><br><span class="line">on Redhat and derivates it is ncurses-devel.  </span><br><span class="line">Call Stack (most recent call first):  </span><br><span class="line">  cmake/readline.cmake:127 (FIND_CURSES)  </span><br><span class="line">  cmake/readline.cmake:217 (MYSQL_USE_BUNDLED_LIBEDIT)  </span><br><span class="line">  CMakeLists.txt:257 (MYSQL_CHECK_READLINE)</span><br></pre></td></tr></table></figure></p><p>记得清除旧的对象文件和缓存<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make clean</span></span><br><span class="line"><span class="comment"># rm -f CMakeCache.txt</span></span><br></pre></td></tr></table></figure></p><ul><li>6.参数说明：<blockquote><p>-DCMAKE_INSTALL_PREFIX=/opt/mysql //安装目录<br>-DINSTALL_DATADIR=/opt/mysql/data //数据库存放目录<br>-DDEFAULT_CHARSET=utf8 //使用utf8字符<br>-DDEFAULT_COLLATION=utf8_general_ci //校验字符<br>-DEXTRA_CHARSETS=all //安装所有扩展字符集<br>-DENABLED_LOCAL_INFILE=1  //允许从本地导入数据</p></blockquote></li></ul><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul><li>一、设置目录权限</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql-5.5.40]<span class="comment"># cd /opt/mysql/</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># ll</span></span><br><span class="line">total 200</span><br><span class="line">drwxr-xr-x  2 root root   4096 Apr 25 19:24 bin</span><br><span class="line">-rw-r--r--  1 root root  17987 Sep  8  2014 COPYING</span><br><span class="line">drwxr-xr-x  3 root root   4096 Apr 25 19:24 data</span><br><span class="line">drwxr-xr-x  2 root root   4096 Apr 25 19:24 docs</span><br><span class="line">drwxr-xr-x  3 root root   4096 Apr 25 19:24 include</span><br><span class="line">-rw-r--r--  1 root root 132608 Sep  8  2014 INSTALL-BINARY</span><br><span class="line">drwxr-xr-x  3 root root   4096 Apr 25 19:24 lib</span><br><span class="line">drwxr-xr-x  4 root root   4096 Apr 25 19:24 man</span><br><span class="line">drwxr-xr-x 10 root root   4096 Apr 25 19:24 mysql-test</span><br><span class="line">-rw-r--r--  1 root root   2496 Sep  8  2014 README</span><br><span class="line">drwxr-xr-x  2 root root   4096 Apr 25 19:24 scripts</span><br><span class="line">drwxr-xr-x 27 root root   4096 Apr 25 19:24 share</span><br><span class="line">drwxr-xr-x  4 root root   4096 Apr 25 19:24 sql-bench</span><br><span class="line">drwxr-xr-x  2 root root   4096 Apr 25 19:24 support-files、</span><br><span class="line"></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># chown -R root:mysql .</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># chown -R mysql:mysql data</span></span><br></pre></td></tr></table></figure><ul><li>二、将mysql的启动服务添加到系统服务中</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># cp support-files/my-medium.cnf /etc/my.cnf //my-medium.cnf不仅限于这一个文件</span></span><br><span class="line"></span><br><span class="line">//查看可以使用的文件</span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># cd support-files/</span></span><br><span class="line">[root@iZ94r8hgrjcZ support-files]<span class="comment"># ll</span></span><br><span class="line"><span class="comment">#下面列出的×.cnf结尾的都可以，但是每一个都有不同的用处</span></span><br><span class="line">total 152</span><br><span class="line">-rwxr-xr-x 1 root mysql  1153 May 29 11:14 binary-configure</span><br><span class="line">-rwxr-xr-x 1 root mysql  4528 May 29 11:14 config.huge.ini</span><br><span class="line">-rwxr-xr-x 1 root mysql  2382 May 29 11:14 config.medium.ini</span><br><span class="line">-rwxr-xr-x 1 root mysql  1626 May 29 11:14 config.small.ini</span><br><span class="line">-rw-r--r-- 1 root mysql   773 Jul  2  2012 magic</span><br><span class="line">-rw-r--r-- 1 root mysql  4691 May 29 11:14 my-huge.cnf</span><br><span class="line">-rw-r--r-- 1 root mysql 19759 May 29 11:14 my-innodb-heavy-4G.cnf</span><br><span class="line">-rw-r--r-- 1 root mysql  4665 May 29 11:14 my-large.cnf</span><br><span class="line">-rw-r--r-- 1 root mysql  4676 May 29 11:14 my-medium.cnf</span><br><span class="line">-rw-r--r-- 1 root mysql  2840 May 29 11:14 my-small.cnf</span><br><span class="line">-rwxr-xr-x 1 root mysql  1061 May 29 11:14 mysqld_multi.server</span><br><span class="line">-rwxr-xr-x 1 root mysql   839 May 29 11:14 mysql-log-rotate</span><br><span class="line">-rwxr-xr-x 1 root mysql 10650 May 29 11:14 mysql.server</span><br><span class="line">-rwxr-xr-x 1 root mysql  1326 May 29 11:14 ndb-config-2-node.ini</span><br></pre></td></tr></table></figure><ul><li>三、创建系统数据库的表</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># cd /opt/mysql</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># scripts/mysql_install_db --user=mysql</span></span><br></pre></td></tr></table></figure><ul><li><p>四、设置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># vi /etc/profile</span></span><br><span class="line"><span class="comment"># Path manipulation</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$EUID</span>"</span> = <span class="string">"0"</span> ]; <span class="keyword">then</span></span><br><span class="line">        pathmunge /sbin</span><br><span class="line">        pathmunge /usr/sbin</span><br><span class="line">        pathmunge /usr/<span class="built_in">local</span>/sbin</span><br><span class="line">        pathmunge /opt/mysql/bin/<span class="comment">##添加行</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># source /etc/profile</span></span><br></pre></td></tr></table></figure></li><li><p>五、将mysql添加到系统服务中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># cp support-files/mysql.server /etc/init.d/mysqld　//将mysql的启动服务添加到系统服务中</span></span><br></pre></td></tr></table></figure></li><li><p>六、启动mysql的方法(mysql已经被添加到系统服务中)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># service mysql start  //启动mysql服务</span></span><br><span class="line">***********************************************</span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># service mysql stop　　//停止mysql服务</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># service mysql restart     //重启mysql服务</span></span><br></pre></td></tr></table></figure></li><li><p>七、修改MySQL的root用户的密码以及打开远程连接</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment">#  mysql -u root -p</span></span><br><span class="line">Enter password:</span><br><span class="line">//这里MySQL的root用户还没有配置密码，直接点回车键即可。</span><br><span class="line"></span><br><span class="line">mysql&gt; use mysql; //使用mysql这个库</span><br><span class="line">Database changed</span><br><span class="line"></span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@<span class="string">"%"</span> IDENTIFIED BY <span class="string">"root"</span>;  //添加远程连接</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; update user <span class="built_in">set</span> Password = password(<span class="string">'xiaoxiaomo.com'</span>) <span class="built_in">where</span> User=<span class="string">'root'</span>; //设置密码为xiaoxiaomo.com</span><br><span class="line">Query OK, 5 rows affected (0.01 sec)</span><br><span class="line">Rows matched: 5  Changed: 5  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select Host,User,Password  from user <span class="built_in">where</span> User=<span class="string">'root'</span>;</span><br><span class="line">+--------------+------+-------------------------------------------+</span><br><span class="line">| Host         | User | Password                                  |</span><br><span class="line">+--------------+------+-------------------------------------------+</span><br><span class="line">| localhost    | root | *758A8EEE3D96A07C409995FD1E7C66493AC52206 |</span><br><span class="line">| iz94r8hgrjcz | root | *758A8EEE3D96A07C409995FD1E7C66493AC52206 |</span><br><span class="line">| 127.0.0.1    | root | *758A8EEE3D96A07C409995FD1E7C66493AC52206 |</span><br><span class="line">| ::1          | root | *758A8EEE3D96A07C409995FD1E7C66493AC52206 |</span><br><span class="line">| %            | root | *758A8EEE3D96A07C409995FD1E7C66493AC52206 |</span><br><span class="line">+--------------+------+-------------------------------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="built_in">exit</span></span><br><span class="line">Bye</span><br><span class="line"></span><br><span class="line">[root@ iZ94r8hgrjcZ mysql]<span class="comment"># mysql -u root -p</span></span><br><span class="line"></span><br><span class="line">若还不能进行远程连接，则查看防火墙是否开启</span><br></pre></td></tr></table></figure><ul><li><p>八、设置开机启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># chkconfig --level 345 mysql on //设置开机启动(取消开机启动：把 on 改为 off)</span></span><br></pre></td></tr></table></figure></li><li><p>九、修改mysql的最大连接数</p></li></ul><p>mysql默认安装的最大连接数是100。100一般是不够用的。要增大连接数，要怎样增加呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]# vi /etc/my.cnf  </span><br><span class="line"></span><br><span class="line"># The MySQL server</span><br><span class="line">[mysqld]</span><br><span class="line">port = 3306</span><br><span class="line">socket = /tmp/mysql.sock</span><br><span class="line">skip-external-locking</span><br><span class="line">key_buffer_size = 16M</span><br><span class="line">max_allowed_packet = 4M</span><br><span class="line">table_open_cache = 64</span><br><span class="line">sort_buffer_size = 512K</span><br><span class="line">net_buffer_length = 8K</span><br><span class="line">read_buffer_size = 256K</span><br><span class="line">read_rnd_buffer_size = 512K</span><br><span class="line">myisam_sort_buffer_size = 8M</span><br><span class="line">#一定要加在[mysqld]这段里面,根据你的需求自行更改数据</span><br><span class="line">max_connections=1000         # 最大连接数</span><br><span class="line">max_user_connections=500     # 每个用户最大连接数</span><br><span class="line">wait_timeout=200             # 多少秒后关闭空闲（IDLE）</span><br></pre></td></tr></table></figure><p>检测：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># service mysql restart  //重启mysql服务</span></span><br><span class="line">[root@iZ94r8hgrjcZ mysql]<span class="comment"># cd /opt/mysql/bin</span></span><br><span class="line">[root@iZ94r8hgrjcZ bin]<span class="comment"># mysqladmin -u root -p variables //检测</span></span><br><span class="line">输入root数据库账号的密码后可看到 (屏幕上的数据有点多，慢慢找)</span><br><span class="line"></span><br><span class="line">|max_connections             | 1000</span><br><span class="line">|max_user_connections        | 500</span><br><span class="line">|wait_timeout                | 200</span><br><span class="line"><span class="comment">#改动已经生效。</span></span><br></pre></td></tr></table></figure><ul><li>十、查看修改mysql编码方式</li></ul><p>MySQL的默认编码是Latin1，不支持中文，要支持中文需要把数据库的默认编码修改为gbk或者utf8（java的一般都是用utf-8，乱码问题蛋疼啊，我就用utf-8演示）。</p><ol><li><p>需要以root用户身份登陆才可以查看数据库编码方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">'character%'</span>;</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">| Variable_name            | Value                            |</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">| character_set_client     | utf8                             |</span><br><span class="line">| character_set_connection | utf8                             |</span><br><span class="line">| character_set_database   | latin1                           |</span><br><span class="line">| character_set_filesystem | binary                           |</span><br><span class="line">| character_set_results    | utf8                             |</span><br><span class="line">| character_set_server     | latin1                           |</span><br><span class="line">| character_set_system     | utf8                             |</span><br><span class="line">| character_sets_dir       | /opt/mysql/share/charsets/ |</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure></li><li><p>停止mysql服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ etc]<span class="comment"># service mysql stop</span></span><br><span class="line">Shutting down MySQL.                                       [  OK  ]</span><br></pre></td></tr></table></figure></li><li><p>编辑my.cnf</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ etc]<span class="comment"># vi /etc/my.cnf</span></span><br><span class="line"><span class="comment"># The following options will be passed to all MySQL clients</span></span><br><span class="line">[client]</span><br><span class="line"><span class="comment">#password       = your_password</span></span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /tmp/mysql.sock</span><br><span class="line">default-character-set=utf8  <span class="comment">##为添加内容1</span></span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">port            = 3306</span><br><span class="line">max_connections=1000       <span class="comment"># 最大连接数</span></span><br><span class="line">max_user_connections=500   <span class="comment"># 每个用户最大连接数</span></span><br><span class="line">wait_timeout=200           <span class="comment"># 多少秒后关闭空闲（IDLE）</span></span><br><span class="line">character-set-server =utf8 <span class="comment">##为添加内容2</span></span><br></pre></td></tr></table></figure><ol start="4"><li>检查<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ etc]<span class="comment"># service mysql start</span></span><br><span class="line">Starting MySQL..                                           [  OK  ]</span><br><span class="line">[root@iZ94r8hgrjcZ etc]<span class="comment"># mysql -u root -p</span></span><br><span class="line">Enter password:</span><br><span class="line">mysql&gt; show variables like <span class="string">'character%'</span>;</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">| Variable_name            | Value                            |</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">| character_set_client     | utf8                             |</span><br><span class="line">| character_set_connection | utf8                             |</span><br><span class="line">| character_set_database   | utf8                             |</span><br><span class="line">| character_set_filesystem | binary                           |</span><br><span class="line">| character_set_results    | utf8                             |</span><br><span class="line">| character_set_server     | utf8                             |</span><br><span class="line">| character_set_system     | utf8                             |</span><br><span class="line">| character_sets_dir       | /opt/mysql/share/charsets/ |</span><br><span class="line">+--------------------------+----------------------------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure></li></ol><ul><li>参考资料<br><a href="http://www.cnblogs.com/zz0412/archive/2013/05/21/mysql.html" target="_blank" rel="noopener">http://www.cnblogs.com/zz0412/archive/2013/05/21/mysql.html</a><br><a href="http://hezuyou.blog.163.com/blog/static/78497415201311734452972/" target="_blank" rel="noopener">http://hezuyou.blog.163.com/blog/static/78497415201311734452972/</a><br><a href="http://wytoy.iteye.com/blog/1161906" target="_blank" rel="noopener">http://wytoy.iteye.com/blog/1161906</a></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--软件安装之Redis</title>
      <link href="/2016/02/23/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BRedis/"/>
      <url>/2016/02/23/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BRedis/</url>
      <content type="html"><![CDATA[<p>　　<code>Redis</code>是一个开源（BSD许可）的，<code>内存中的数据结构存储系统</code>，它<code>可以用作数据库、缓存和消息中间件</code>。 它支持多种类型的数据结构，事务等。</p><h2 id="下载-安装"><a href="#下载-安装" class="headerlink" title="下载/安装"></a>下载/安装</h2><ul><li>1、官网下载：</li></ul><blockquote><p><a href="http://redis.io/download" target="_blank" rel="noopener">http://redis.io/download</a>  #第一种：官方下载后上传<br><em>wget <a href="http://download.redis.io/releases/redis-3.0.6.tar.gz" target="_blank" rel="noopener">http://download.redis.io/releases/redis-3.0.6.tar.gz</a></em> #第二种：命令字节下载：（软件本身不大，看网速）</p></blockquote><ul><li>2、解压编译源码安装</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf redis-3.0.6.tar.gz -C /usr/<span class="built_in">local</span>/src　　　<span class="comment">#解压缩到指定目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/redis-3.0.1/　　　<span class="comment">#到解压的目录去编译源码</span></span><br><span class="line">make PREFIX=/usr/<span class="built_in">local</span>/redis install　　　<span class="comment">#安装到指定目录</span></span><br></pre></td></tr></table></figure><p><code>注</code>：如果make失败，一般是你们系统中还未安装gcc,那么可以通过yum安装：<code>yum install gcc</code></p><p>出现下面信息表示编译安装成功！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Hint: It<span class="string">'s a good idea to run '</span>make <span class="built_in">test</span><span class="string">' ;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    INSTALL install</span></span><br><span class="line"><span class="string">    INSTALL install</span></span><br><span class="line"><span class="string">    INSTALL install</span></span><br><span class="line"><span class="string">    INSTALL install</span></span><br><span class="line"><span class="string">    INSTALL install</span></span><br><span class="line"><span class="string">make[1]: Leaving directory `/usr/local/src/redis-3.0.6/src'</span></span><br></pre></td></tr></table></figure></p><a id="more"></a><h2 id="将redis做成服务"><a href="#将redis做成服务" class="headerlink" title="将redis做成服务"></a>将redis做成服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####将redis_init_script复制到/etc/rc.d/init.d/同时改名为redis</span></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/redis-3.0.1/utils/redis_init_script /etc/rc.d/init.d/redis</span><br><span class="line">vim /etc/rc.d/init.d/redis</span><br><span class="line"></span><br><span class="line"><span class="comment">####修改下面4行</span></span><br><span class="line">&gt; <span class="comment">#chkconfig: 2345 80 90   ##注意：这个在上面蓝色字体第二行</span></span><br><span class="line">&gt; EXEC=/usr/<span class="built_in">local</span>/redis/bin/redis-server　　<span class="comment">##第七行</span></span><br><span class="line">&gt; CLIEXEC=/usr/<span class="built_in">local</span>/redis/bin/redis-cli　　<span class="comment">##第八行</span></span><br><span class="line">&gt; <span class="variable">$EXEC</span> <span class="variable">$CONF</span> &amp;　　　　<span class="comment">##第二十行</span></span><br></pre></td></tr></table></figure><p><code>注</code>：后面的那个“&amp;”，即是将服务转到后面运行的意思</p><p>修改后，文件如下</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F0f8d10bb-a736-49b6-9c3e-1201ca161082.png" alt=""></p><h2 id="配置redis"><a href="#配置redis" class="headerlink" title="配置redis"></a>配置redis</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###配置文件拷贝到/etc/redis/$&#123;REDISPORT&#125;.conf </span></span><br><span class="line">mkdir /etc/redis   </span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/redis-3.0.6/redis.conf /etc/redis/6379.conf</span><br><span class="line"><span class="comment">###这样，redis服务脚本指定的CONF就存在了。</span></span><br><span class="line"><span class="comment">###默认情况下，Redis未启用认证，可以通过开启6379.conf的requirepass 指定一个验证密码。</span></span><br></pre></td></tr></table></figure><blockquote><p>注册redis服务：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig --add redis</span><br></pre></td></tr></table></figure><blockquote><p>然后将Redis的命令所在目录添加到系统参数PATH中</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile　　　　＃编辑环境变量</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$PATH</span>:/usr/local/redis/bin"</span>　＃添加环境变量（记得指定到自己的目录）</span><br><span class="line"><span class="built_in">source</span>  /etc/profile　　　<span class="comment">#重启配置</span></span><br></pre></td></tr></table></figure><p>redis安装就完成了！</p><h2 id="简单操作"><a href="#简单操作" class="headerlink" title="简单操作"></a>简单操作</h2><h3 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h3><ul><li>通过我们注册的服务启动redis<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ94r8hgrjcZ home]<span class="comment"># service redis start</span></span><br><span class="line">Starting Redis server...</span><br><span class="line">[root@iZ94r8hgrjcZ home]<span class="comment">#                 _._                                                  </span></span><br><span class="line">           _.-``__ <span class="string">''</span>-._                                             </span><br><span class="line">      _.-``    `.  `_.  <span class="string">''</span>-._           Redis 3.0.6 (00000000/0) 64 bit</span><br><span class="line">  .-`` .-```.  ```\/    _.,_ <span class="string">''</span>-._                                   </span><br><span class="line"> (    <span class="string">'      ,       .-`  | `,    )     Running in standalone mode</span></span><br><span class="line"><span class="string"> |`-._`-...-` __...-.``-._|'</span>` _.-<span class="string">'|     Port: 6379</span></span><br><span class="line"><span class="string"> |    `-._   `._    /     _.-'</span>    |     PID: 4028</span><br><span class="line">  `-._    `-._  `-./  _.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |           http://redis.io        </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line"> |`-._`-._    `-.__.-<span class="string">'    _.-'</span>_.-<span class="string">'|                                  </span></span><br><span class="line"><span class="string"> |    `-._`-._        _.-'</span>_.-<span class="string">'    |                                  </span></span><br><span class="line"><span class="string">  `-._    `-._`-.__.-'</span>_.-<span class="string">'    _.-'</span>                                   </span><br><span class="line">      `-._    `-.__.-<span class="string">'    _.-'</span>                                       </span><br><span class="line">          `-._        _.-<span class="string">'                                           </span></span><br><span class="line"><span class="string">              `-.__.-'</span>                                               </span><br><span class="line"></span><br><span class="line">4028:M 30 Apr 11:06:22.282 <span class="comment"># WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.</span></span><br><span class="line">4028:M 30 Apr 11:06:22.282 <span class="comment"># Server started, Redis version 3.0.6</span></span><br><span class="line">4028:M 30 Apr 11:06:22.283 <span class="comment"># WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.</span></span><br><span class="line">4028:M 30 Apr 11:06:22.283 <span class="comment"># WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span></span><br><span class="line">4028:M 30 Apr 11:06:22.283 * The server is now ready to accept connections on port 6379</span><br><span class="line">^C</span><br><span class="line">[root@iZ94r8hgrjcZ home]<span class="comment"># ps -ef|grep redis ##任然在后台运行</span></span><br><span class="line">root      4028     1  0 11:06 pts/0    00:00:00 /usr/<span class="built_in">local</span>/redis/bin/redis-server *:6379              </span><br><span class="line">root      4034  1079  0 11:06 pts/0    00:00:00 grep redis</span><br></pre></td></tr></table></figure></li></ul><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##redis客户端</span></span><br><span class="line">redis-cli [-h 127.0.0.1] [-p 6379] </span><br><span class="line"><span class="comment">##关闭</span></span><br><span class="line">redis-cli shutdown</span><br></pre></td></tr></table></figure><ul><li>实例代码：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># redis-cli    ##连接到服务端</span></span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> blog blog.xiaoxiaomo.com  <span class="comment">##设置值</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get blog         <span class="comment">##获取值</span></span><br><span class="line"><span class="string">"blog.xiaoxiaomo.com"</span></span><br><span class="line">127.0.0.1:6379&gt; shutdown         <span class="comment">##关闭redis</span></span><br><span class="line">4227:M 27 Apr 04:29:56.025 <span class="comment"># User requested shutdown...</span></span><br><span class="line">4227:M 27 Apr 04:29:56.025 * Saving the final RDB snapshot before exiting.</span><br><span class="line">4227:M 27 Apr 04:29:56.039 * DB saved on disk</span><br><span class="line">4227:M 27 Apr 04:29:56.039 <span class="comment"># Redis is now ready to exit, bye bye...</span></span><br><span class="line">not connected&gt; get blog</span><br><span class="line">Could not connect to Redis at 127.0.0.1:6379: Connection refused</span><br><span class="line">not connected&gt; </span><br><span class="line">[1]+  Done                    redis-server</span><br><span class="line">[root@localhost ~]<span class="comment"># ps -ef|grep redis        ##已关闭</span></span><br><span class="line">root       4248   2765  0 04:30 pts/2    00:00:00 grep redis</span><br><span class="line"></span><br><span class="line"><span class="comment">##注：dump.rdb文件保存到了跟目录</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="附：另一种快速安装"><a href="#附：另一种快速安装" class="headerlink" title="附：另一种快速安装"></a>附：另一种快速安装</h2><ul><li><p>1、 <strong>解压redis然后cd到目录并安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tar -zxvf redis-3.0.6.tar.gz -C /usr/local/src/</span></span><br><span class="line"><span class="comment">#cd /usr/local/src/redis-3.0.6/</span></span><br><span class="line"><span class="comment">#make &amp;&amp; install</span></span><br></pre></td></tr></table></figure></li><li><p>2、 <strong>修改配置文件redis.conf</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##改为下面的参数，可以后台运行</span></span><br><span class="line">daemonize yes</span><br></pre></td></tr></table></figure></li><li><p>3、 <strong>让redis在后台运行</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加上`&amp;` 使redis以后台程序方式运行</span></span><br><span class="line">./redis-server &amp;</span><br></pre></td></tr></table></figure></li><li><p>4、<strong>通过加载配置的方式</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis.conf路径 <span class="comment">##eg: redis-server ../redis.conf</span></span><br><span class="line"><span class="comment">##我们可以把配置文件cp到/etc/下面方便操作</span></span><br></pre></td></tr></table></figure></li><li><p><strong>注意</strong>这两种启动方式：<br>在那个目录启动，dump.rdb持久化文件就会在哪儿生成rdb文件，所以最好是在同一个目录下启动redis，<strong>以免数据丢失</strong>！</p></li><li><p><strong>redis持久化查看博客</strong>：<a href="http://blog.xiaoxiaomo.com/2016/04/28/Redis-持久化方案及备份/">http://blog.xiaoxiaomo.com/2016/04/28/Redis-持久化方案及备份/</a></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--软件安装之MySQL</title>
      <link href="/2016/02/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BMysql/"/>
      <url>/2016/02/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BMysql/</url>
      <content type="html"><![CDATA[<p>　　Mysql的安装，第一次自己去折腾的时候倒挺麻烦的，下载哪一个版本的mysql都不确定。之后在DBA的帮助下，很顺畅的就完成了，在这里呢总结一下安装流程：</p><a id="more"></a><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>可以去官网下载mysql数据库，我这里下载的是：mysql-5.7.9-1.el6.x86_64.rpm-bundle.tar，<a href="http://yun.baidu.com/share/link?shareid=1740266037&amp;uk=2971593620" target="_blank" rel="noopener">点击</a>这里可下载。</p><ul><li>检测系统中是否存在mysql，存在就卸载<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">命令：rpm -qa | grep mysql</span><br><span class="line">通过rpm安装mysql</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F3d24438d-fb81-407c-8b7a-fc2beeabe541.png" alt="检测系统中是否存在mysql"></p><h2 id="卸载Mysql"><a href="#卸载Mysql" class="headerlink" title="卸载Mysql"></a>卸载Mysql</h2><ul><li><p>卸载Mysql</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">【命令】：rpm -e mysql // 普通删除模式（如有依赖无法卸载）</span><br><span class="line">【命令】：rpm -e --nodeps mysql // 强力删除模式（可以忽略依赖）</span><br><span class="line">【命令】：yum -y remove mysql    // yum卸载可以卸载依赖包</span><br></pre></td></tr></table></figure></li><li><p>如下信息，就需要–nodeps忽略依赖<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F6143abdf-ad73-4820-98f2-94e838002ef5.png" alt="卸载MySQL"></p></li></ul><h2 id="安装Mysql"><a href="#安装Mysql" class="headerlink" title="安装Mysql"></a>安装Mysql</h2><ol><li><p>准备阶段<br>1.1. 上传我们下载好的mysql tar文件。<br>2.2. 然后使用命令：tar -xvf ；发现mysql包含了很多的rpm文件。<br>3.3. 我们需要使用<code>rpm命令</code>从上面的rpm文件一个一个的安装。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F3513692b-9334-48f9-af70-48954f0ffd44.png" alt="准备"></p></li><li><p>安装第一个mysql-community-common-5.7.9-1.el6.x86_64.rpm，第一个顺利完成。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fa9d79ab9-3113-446a-baec-22357343b1a6.png" alt="安装mysql-community-common-5.7.9-1.el6.x86_64.rpm"></p></li><li><p>安装第二个mysql-community-server，发现需要依赖包mysql-community-client<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F93e5c0ff-bb41-4434-9924-c5895355deea.png" alt="安装mysql-community-server"></p></li><li><p>于是我们安装mysql-community-client，发现需要依赖包lib，<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fe2db2b30-08e2-4984-885d-79b5242fff45.png" alt="安装mysql-community-client"></p></li><li><p>然后安装lib成功，安装client也成功了,目前到这里还是比较顺利。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F18932347-c250-49d0-8130-2825f1728e2b.png" alt="安装lib成功，安装client也成功"></p></li><li><p>然后再次尝试安装server,发现还需要很多的依赖包。晕菜了，这么多，这个可以按照上面的方法逐步安装,是可以得，博客中就不讲解了，换成使用yum命令。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fede8b13f-5c40-448c-a7f9-c118a6f65d29.png" alt="好多......"></p></li><li><p>使用yum命令安装一下server，最下图表示安装完成！<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F3275131b-9925-4135-8a6b-afc2669f9537.png" alt="使用yum命令安装一下server"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160322231708.jpg" alt="安装完成"></p></li></ol><h2 id="初始化mysql"><a href="#初始化mysql" class="headerlink" title="初始化mysql"></a>初始化mysql</h2><ol><li><p>mysql_install_db<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Ff5507559-ea43-444b-b00a-653951f98d08.png" alt="执行mysql_install_db"><br>mysql_install_db is deprecated. Please consider switching to mysqld –initialize，mysql_install_db已弃用，使用新命令。</p></li><li><p><code>mysqld --initialize</code>命令不现实任何信息，表示是个好的结果，去<code>var/log/mysqld.log</code>查看一下日志，这里面记录了mysql的初始密码<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F5776c6c1-3088-4228-9009-c85a555b0415.png" alt="查看日志"></p></li><li><p>尝试启动一下mysql<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F7bc033d1-cd37-49fa-8ba4-ec483e813db6.png" alt="启动一下mysql"></p></li><li><p>启动失败，这时候需要去<code>/var/lib</code>修改一下mysql的所属权限<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F2243b2ad-c8e7-4bdf-9b34-70c32cf2549b.png" alt="修改MySQL的所属权限"></p></li><li><p>重新启动mysql数据库，然后设置密码，就可以登陆了。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F5ce9ebab-82bb-4a6f-aa4b-8a1224e4e6a4.png" alt="重新启动mysql数据库"></p></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--系统进程管理</title>
      <link href="/2016/02/18/Linux-%E7%B3%BB%E7%BB%9F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
      <url>/2016/02/18/Linux-%E7%B3%BB%E7%BB%9F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>　　在早期的计算机中不包含操作系统，从头到位一台计算机只运行了一个程序，并且这个程序能访问计算机中的所有资源，只做一件事情。操作系统的出现使得计算机能运行多个程序，并且不同的程序都在单独的进程中运行，进程又可以启动多个线程。</p><a id="more"></a><h3 id="系统进程"><a href="#系统进程" class="headerlink" title="系统进程"></a>系统进程</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><blockquote><ol><li><code>计算机</code>，主要是由<code>内核（Kernel）</code>和运行在内核之上的众多<code>进程（Process）</code>来实现的。（内核也是一个程序）</li><li><code>内核</code>，主要负责管理系统的进程，内存，设备驱动和网络等</li><li><code>程序</code>是静态概念，本身作为一种软件资源长期保存；而进程是程序的执行过程，是动态概念，有一定的生命周期，动态产生和消亡的。</li><li><code>进程</code>是指一个在内存中运行的应用程序，一个进程可以启动多个线程。对于计算机来而言，主要工作都在CUP和内存中完成。</li><li><code>线程</code>是指进程中的一个执行流程，线程总是属于某个进程，进程中的多个线程<strong>共享进程的内存空间</strong>。</li><li><code>注意</code>：程序，由指令+数据组成。</li></ol></blockquote><h4 id="程序的运行"><a href="#程序的运行" class="headerlink" title="程序的运行"></a>程序的运行</h4><ul><li>一个命令的运行</li></ul><p><em><code>内存是由内存环的，内核运行在0环（内核空间），用户进程运行在3环（用户空间），当执行一些敏感信息的时候都是由内核完成</code></em>。比如运行一个mkdir命令，发起这个命令就启动mkdir这个进程，当按下“Enter”键的时候，程序就会被装载到内存，在内存中会划分一个区域（保存这该进程的数据和指令），这就表示启动一个进程了。当运行起来的时候，就需要创建一个目录，发现需要去操作硬盘，mkdir这个进程通过系统调用会向内核发送操作硬盘的申请。内核接收到申请后,就转入内核模式，mkdir就从cpu中退出了（归队）,退出时会保存进程信息（保存在内核中，内核会追踪每一个进程信息，内核里面有一个<code>（task structure）数据结构</code>；会维护每一个进程信息<strong>ID,NAME,PID,PPID</strong>等）内核持有CPU，接受到命令读取内存信息并修改，完成后同步到硬盘，该命令执行完成。</p><ul><li>多个进程的运行</li></ul><p><em><code>CPU要么由进程所持有，要么由内核所持有，进程的执行信息保存在内存当中，描述信息在内核当中</code></em>。<em>当多个程序同时运行的时候（以为同时），<strong>多个进程和内核就会轮流的去持有CPU资源</strong>。<strong>进程所有数据就会加载到内存当中</strong>（在内存修改的数据可以同步到硬盘IO设备）</em>，CPU就会管理着内存当中的进程（<code>户口本</code>，该那个进程运行，运行的时间，下一个是谁运行）。CPU只有一个的情况下，当一个进程所持有CPU的时间到了，但没有执行完，内核就会持有CPU保存进程的描述信息（<code>寄存器</code>，记录执行到哪儿）这个过程叫做<code>保存现场</code>，进程归队。CPU会调度下一个进程，执行完成后之前的进程如果被唤醒，内核信息里面就会给出之前执行到哪儿的信息，让该进程继续执行，这个过程就叫<code>恢复现场</code>。 当执行完成之后，该进程就退出了，内存空间就释放了，内核也会销毁这个进程信息。</p><h3 id="相关管理工具"><a href="#相关管理工具" class="headerlink" title="相关管理工具"></a>相关管理工具</h3><h4 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h4><ul><li>基本命令</li></ul><pre><code class="bash">ps        <span class="comment">#查看静态的进程统计信息（processes statistic），当前控制台下该属于该用户的进程</span>          <span class="comment">#ps -ef #可以显示出所有用户的进程System V风格,ps aux是BSD风格</span>top       <span class="comment">#查看进程动态信息</span>htop      <span class="comment">#查看进程动态信息，top的升级版</span>pgrep     <span class="comment">#查询进程信息</span>pstree    <span class="comment">#查看进程</span></code></pre><ul><li>ps</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160319112646.jpg" alt=""></p><p>说明：</p><blockquote><p><strong>UID</strong>：     #用户Id<br><strong>PID</strong> ：    #进程号<br><strong>PPLD</strong>：    #父进程的进程号<br><strong>STIME</strong>：   #创建进程时间<br><strong>TTY</strong>：     #进程启动的终端<br><strong>STAT</strong>：    #进程当前状态（<code>S休眠状态，D不可中断的休眠状态，R运行状态，Z僵死状态，T停止</code>）<br><strong>NI</strong> ：     #进程优先级<br><strong>TIME</strong>：    #进程运行时间<br><strong>COMMAND/CMD</strong>：#进程的命令<br><strong>%CPU</strong>：    #占用CPU时间和总时间的百分比<br><strong>%MEM</strong>：    #占用内存与系统内存总量的百分比</p></blockquote><ul><li>pstree</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160319115428.jpg" alt=""></p><p>除init进程以外，其他进程都有父进程，init是伴随着系统的启动。</p><h4 id="管理进程"><a href="#管理进程" class="headerlink" title="管理进程"></a>管理进程</h4><ul><li>启动进程</li></ul><blockquote><ol><li>前台启动：使用<code>service 程序 start</code>，eg：service network start。</li><li>后台程序：使用<code>service 程序 start $</code>，eg：service network start $。</li><li>前台启动，放入后台：正在运行的程序，按Ctrl+Z组合键。</li><li>后台进程，调回前台：使用”job -l”选项显示进程的PID，后通过fg或fg PID 命令讲后台进程调入前台执行。</li></ol></blockquote><ul><li>杀掉进程</li></ul><blockquote><ol><li><strong>kill -1 PID </strong> #终端断线</li><li><strong>kill -2 PID</strong>  #中断正在执行的程序,等于Ctrl + c</li><li><strong>kill -3 PID</strong>  #退出（同 Ctrl + \）</li><li><strong>kill -9 PID</strong>  #强制、尽快终止进程</li><li><strong>kill -15 PID</strong> #终止进程</li><li><strong>kill -18 PID</strong> #继续（与STOP相反， fg/bg命令）</li><li><strong>kill -19 PID</strong> #暂停（同 Ctrl + Z）</li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--操作系统及常用命令</title>
      <link href="/2016/02/16/Linux-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2016/02/16/Linux-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>　　主要介绍操作系统上一些<code>常见命令</code>，比如创建文件目录mkdir，查看目录下文件ls，系统环境变量，系统时间，帮助文档等。</p><a id="more"></a><h2 id="目录-文件简介"><a href="#目录-文件简介" class="headerlink" title="目录/文件简介"></a>目录/文件简介</h2><p>路径：从指定起始点到目的地的所经过的位置。<br>命令规则：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">长度不能操作255个字符；</span><br><span class="line">不能使用“/”当文件名；</span><br><span class="line">严格区分大小写</span><br></pre></td></tr></table></figure></p><h2 id="目录-文件查看"><a href="#目录-文件查看" class="headerlink" title="目录/文件查看"></a>目录/文件查看</h2><blockquote><p>查看目录文件 <code>ls</code>：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ls -l <span class="comment">#长格式，可以简化为，ll；</span></span><br><span class="line">ls -h <span class="comment">#做单位换算，human can readable；</span></span><br><span class="line">ls -a <span class="comment">#以点开头的文件（包括隐藏文件、.表示当前目录、..表示上级目录）；</span></span><br><span class="line">ls -A <span class="comment">#显示全部文件（不包括.和..）；</span></span><br><span class="line">ls -d <span class="comment">#显示自身属性；</span></span><br><span class="line">ls -i <span class="comment">#index node，inode(显示文件唯一序号)；</span></span><br><span class="line">ls -r <span class="comment">#逆序显示；</span></span><br><span class="line">ls -R <span class="comment">#递归显示（recursive）；</span></span><br></pre></td></tr></table></figure><ul><li>eg：<code>ls -l</code></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Ff19aa739-0de8-499b-b978-bedd1bb1a849.png" alt=""></p><ol><li><p><strong>第一位,表示<code>文件类型</code></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- -：普通文件（f），如上图第二个文件；</span><br><span class="line">- d：目录文件，如上图第一为文件目录；</span><br><span class="line">- b：块设备文件（block）</span><br><span class="line">- c：字节设备文件（character）</span><br><span class="line">- l ：符号链接文件（sysbolic link ）</span><br><span class="line">- p：管道命令（pipe）</span><br><span class="line">- s：套接字文件（socket）</span><br></pre></td></tr></table></figure></li><li><p><strong>文件权限</strong>：紧接着后面9位，每三位一组，每一组（rwx）r：可读，w：可写：x:可执行</p></li><li><strong>文件硬链接次数</strong></li><li><strong>文件的属主</strong>（owner）</li><li><strong>文件的所属组</strong>（group）</li><li><strong>文件的大小</strong>（size）,单位字节</li><li><strong>时间戳</strong>（timestamp）:最近一次被修改的时间（文件内容）</li></ol><p>其他基本命令：</p><blockquote><p>pwd　　#显示目录路径<br>cd　　#切换目录，当前目录<br>tree　　#查看目录树<br>stat　　#查看状态</p></blockquote><h2 id="目录-文件操作"><a href="#目录-文件操作" class="headerlink" title="目录/文件操作"></a>目录/文件操作</h2><blockquote><p><code>mkdir</code>：创建空目录</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-p： <span class="comment">#递归创建，eg：mkdir -p test/test01/test02</span></span><br><span class="line">-m： <span class="comment">#创建文件夹时，指定权限。eg：mkdir -m 777 test03</span></span><br><span class="line">-v： <span class="comment">#创建文件夹时，展示详细信息。eg：mkdir -v test04</span></span><br><span class="line">&#123;&#125;： <span class="comment">#多级创建,eg：#mkdir -pv test05/a&#123;x/m,y&#125;</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160327114247.png" alt=""></p><blockquote><p><code>rmdir</code>：删除空目录</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-p： <span class="comment">#删除多级非空目录</span></span><br></pre></td></tr></table></figure><blockquote><p><code>touch</code>：创建文件</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-a： <span class="comment">#修改访问你时间（默认修改为当前时间）atime=access time</span></span><br><span class="line">-m： <span class="comment">#只更改变动时间，mtime=modify time</span></span><br><span class="line">-t： <span class="comment">#修改某个时间</span></span><br></pre></td></tr></table></figure><blockquote><p><code>rm</code>：删除文件/目录</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-i： <span class="comment">#--interactive，进行交互式删除</span></span><br><span class="line">-f： <span class="comment">#--force，忽略不存在的文件，不给出提示</span></span><br><span class="line">-r： <span class="comment">#--recursive递归删除多级目录，eg:rm -rf /tmp #删除tem目录及其子目录全部文件</span></span><br><span class="line">-v： <span class="comment">#--verbose ，详细显示进行的步骤</span></span><br></pre></td></tr></table></figure><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><blockquote><p>命令的内存空间，env<br>变量赋值<br>eg：NAME=Tom(在内存中着一段空间，起名叫NAME,空间放的数据叫Tom),申请变量的过程，就是申请内存使用的过程。<br>path：以冒号隔开的一对路径。<br>hash：查看缓存</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Facf4c7a3-9a2c-4ddf-aff9-5e78ee439f50.png" alt=""></p><p><code>缓存，catch is king.保存的是hash列表。在key,value中的查找速度是O(1).O(1):表示查找时间，不会随着，数据的增加而递增。</code></p><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data：</span><br></pre></td></tr></table></figure><blockquote><p>硬件主板的震荡器，rtc<br>硬件时钟：clock<br>系统时钟：date</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hwclock   <span class="comment">#（写入时间）</span></span><br></pre></td></tr></table></figure><blockquote><p>-w：读取系统时间到硬件中<br>-s ：读取硬件时间到系统中</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cal：日历</span><br></pre></td></tr></table></figure><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><p>在线文档<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">info COMMAND(主要讲历史等)</span><br><span class="line">文档：/usr/share/doc</span><br></pre></td></tr></table></figure></p><blockquote><p>内部命令：help COMMAND<br>外部命令：COMMAND –help<br>命令手册：manual<br>man COMMAND<br>whatis COMMAND<br>分章节<br>    1、用户命令（/bin , /usr/bin , /usr/local）<br>    2、系统调用<br>    3、库用户<br>    4、特殊文件（设备文件）<br>    5、文件格式（配置文件的语法）<br>    6、游戏<br>    7、杂项（Miscellaneous）<br>    8、管理命令（/sbin,  /usr/sbin  , /usr/local/sbin），管理员，会修改硬件相关的信息</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">man 命令:</span><br></pre></td></tr></table></figure><blockquote><p>[]   ：可选<br>&lt;&gt;：必须有<br>…  ：可以出现多次<br>|   ：多选一<br>{}  ：分组<br>NAME：命令名称及功能简要说明<br>SYNAPOSIS：用户说明，包括可用的选项<br>DESCREPTION：命令功能的详细说明， 可能包括没一个选项的意义<br>OPTIONS：选项<br>FILES：此命令的相关配置<br>BUGS：<br>Examples：使用示例<br>SEE ALSO：另外参考</p></blockquote>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--跟文件系统</title>
      <link href="/2016/02/16/Linux-%E8%B7%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2016/02/16/Linux-%E8%B7%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
      <content type="html"><![CDATA[<p>　　根文件系统<code>rootfs</code>(<em>Root File System</em>)，Linux是一种树形结构组织文件<code>FHS</code>（<em>FileSystem Hierarchy Standard</em>）。<code>“/”是所有文件的跟</code>，本篇主要介绍一下linux“/”目录下面文件夹的一些作用和用途。</p><a id="more"></a><h2 id="目录简介图"><a href="#目录简介图" class="headerlink" title="目录简介图"></a>目录简介图</h2><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Frootfs.jpg" alt="rootfs，基本树结构截图">（<em>图片来源于网络</em>）</p><h2 id="详细讲解"><a href="#详细讲解" class="headerlink" title="详细讲解"></a>详细讲解</h2><ul><li><strong><code>/boot</code></strong>：存放<code>引导系统启动的相关文件</code>，如内核，initrd，以及grub(bootloader)。</li><li><p><strong><code>/dev</code></strong>：<code>设备文件</code>,起一个连接作用，可以看作访问这些外部设备的端口；把你对设备的操作映射到具体的驱动程序代码中去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">设备文件分为两种：块设备文件(b，随机访问，数据块)和字符设备文件(c，线性访问，按字符为单位)</span><br><span class="line">常见文件目录如下：</span><br><span class="line">/dev/hd[a-t]：IDE设备</span><br><span class="line">/dev/sd[a-z]：SCSI设备</span><br><span class="line">/dev/md[0-31]：软raid设备</span><br><span class="line">/dev/loop[0-7]：本地回环设备</span><br><span class="line">/dev/ram[0-15]：内存</span><br><span class="line">/dev/null：无限数据接收设备,相当于`黑洞`</span><br><span class="line">/dev/tty[0-63]：虚拟终端</span><br><span class="line">/dev/ttyS[0-3]：串口</span><br><span class="line">/dev/console：控制台</span><br><span class="line">/dev/fb[0-31]：framebuffer</span><br></pre></td></tr></table></figure></li><li><p><strong><code>/etc</code></strong>： 主要存放了<code>系统配置文件</code>，<code>网络配置文件</code>等等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/etc/profile：系统环境变量</span><br><span class="line">/etc/passwd：用户数据库，包括用户名、用户目录、加密的口令和用户的其他信息</span><br><span class="line">/etc/group：组的数据库，类似/etc/passwd</span><br><span class="line">/etc/inittab：init配置文件</span><br><span class="line">/etc/login.defs：login 命令的配置文件</span><br><span class="line">/etc/rc|rc.d|rc*.d：指定运行模式及相关初始化工作，各个启动级别的执行程序连接目录</span><br><span class="line">/etc/magic：file的配置文件.包含不同文件格式的说明，文件开头几行指定了文件格式也叫魔术</span><br><span class="line">/etc/motd：Message Of TheDay，录后成功登自动输出.内容由系统管理员确定</span><br><span class="line">/etc/shadow：安装了影子口令软件的影子口令文件.比如将/etc/passwd文件中的加密口令移动到/etc/shadow中</span><br><span class="line">/etc/securetty：确认安全终端，即哪个终端允许root登录</span><br></pre></td></tr></table></figure></li><li><p><strong><code>/home</code></strong>：<code>普通用户</code>的相关文件</p></li><li><strong><code>/root</code></strong>：<code>系统管理员</code>（root user）的目录。它是一个特殊的用户，用所最高权限，一般情况加不要使用，以免误操作。</li><li><p><strong><code>/lib</code></strong>：<code>库文件</code>一般在/lib、/usr/lib；主要存放系统的链接库文件，没有该目录则系统无法正常运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">有一个特点所有的库以lib开头；</span><br><span class="line">一般库文件分为两种：静态库（以“.a”开头）和动态库|共享库（.dll , .so(shared object))；</span><br><span class="line">GCC在链接时优先使用共享库，只有当共享库不存在时才考虑使用静态库；</span><br><span class="line">/lib：目录中存储着程序运行时使用的共享库,共享库使程序可以重用代码；</span><br><span class="line">/lib/modules：内核模块，运行的时候需</span><br></pre></td></tr></table></figure></li><li><p><strong><code>/media</code></strong>：挂载点目录，移动设备（u盘，光盘）</p></li><li><strong><code>/mnt</code></strong>：默认挂在公区或软驱的，额外的临时文件系统，（第二块硬盘）</li><li><strong><code>/misc</code></strong>： 杂项</li><li><strong><code>/opt</code></strong>：可选目录，早期安装第三方程序的安装目录。安装到/opt目录下的程序，它所有的数据、库文件等等都是放在同个目录下面，如果要删除软件比较方便。</li><li><p><strong><code>/proc</code></strong>：伪文件系统，内核映射文件。（以后的相关优化等）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">操作系统运行时，进程信息及内核信息（比如cpu、硬盘分区、内存信息等）存放在这里。</span><br><span class="line">/proc目录伪装的文件系统proc的挂载目录，proc并不是真正的文件系统，它的定义可以参见 /etc/fstab</span><br></pre></td></tr></table></figure></li><li><p><strong><code>/sys</code></strong>：伪文件系统，跟硬件设备相关的属性映射（例如修改磁盘调度队列IO）</p></li><li><strong><code>/tmp</code></strong>：临时文件系统，有些linux系统会定期自动对这个目录清理,还有一个目录/var/tmp</li><li><p><strong><code>/var</code></strong>：存放系统运行时经常变动的文件，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/var目录中有些内容是在/usr中的，但为了保持/usr目录的相对稳定就把常变得放在/var；</span><br><span class="line">/var/lib：存放系统正常运行时要改变的文件。</span><br><span class="line">/var/local：存放 /usr/local 中安装的程序的可变数据</span><br><span class="line">/var/lock：锁定文件</span><br><span class="line">/var/log：各种程序的日志 (log) 文件</span><br><span class="line">/var/tmp：比 /tmp 允许更大的或需要存在较长时间的临时文件</span><br></pre></td></tr></table></figure></li><li><p><strong><code>/bin</code></strong>：可执行文件，用户命令即系统所需要的那些命令位于此目录，eg:ls、cp、mkdir</p></li><li><strong><code>/sbin</code></strong>：超级用户专用的命令；</li><li><strong><code>/usr</code></strong>：用户共享的只读文件(<em>user shared read-only</em>)，那些不适合放在/bin或/etc目录下的额外的工具都放在这里。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin：目录用于存放程序;</span><br><span class="line">/usr/share：用于存放一些共享的数据；</span><br><span class="line">/usr/share/fonts字体目录；</span><br><span class="line">/usr/share/doc和/usr/share/man帮助文件；</span><br><span class="line">/usr/local：这里主要存放手动安装的软件,目录结构和/usr类似；</span><br><span class="line">/usr/lib：存放那些不能直接运行的,但却是许多程序运行所必需的一些函数库文件</span><br><span class="line">注意：/bin、/sbin、/lib存着系统启动时依赖的文件，而/usr下面的bin、sbin、lib下面存放着系统启动后功能所需要的文件</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--基本配置修改</title>
      <link href="/2016/02/14/Linux-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9/"/>
      <url>/2016/02/14/Linux-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9/</url>
      <content type="html"><![CDATA[<p>　　本博客介绍一些我们常用linux配置文件的修改，主要包括网络地址，主机名，hosts文件，端口，防火墙等基本操作。</p><a id="more"></a><h3 id="修改网卡"><a href="#修改网卡" class="headerlink" title="修改网卡"></a>修改网卡</h3><p>　　网络接口（网卡）的脚本文件<code>ifcfg-eth0</code>是默认的第一个网络接口，在<code>/ect/sysconfig/network-script/</code>目录下。如果有多个会以<code>ifcfg-ethn</code>命名n为（0，1，2，3，4……）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim /ect/sysconfig/network-script/ifcfg-eth0</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160324093923.png" alt=""><br>参数说明：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DEVICE　　<span class="comment">#网卡名,在`/etc/udev/rules.d/70-persistent-net.rules`有中有记录。</span></span><br><span class="line">HWADDR　　<span class="comment">#MAC地址,和网卡相对应。</span></span><br><span class="line">USERCTL　　<span class="comment">#[yes|no]（非root用户是否可以控制该设备）</span></span><br><span class="line">BOOTPROTO　　<span class="comment">#IP的配置方法[none|static|bootp|dhcp]（|静态分配IP|BOOTP协议|DHCP协议）</span></span><br><span class="line">ONBOOT　　<span class="comment">#系统启动的时候网络接口是否有效（yes/no）   </span></span><br><span class="line">TYPE　　<span class="comment">#网络类型（通常是Ethemet）   </span></span><br><span class="line">NETMASK　　<span class="comment">#网络掩码   </span></span><br><span class="line">IPADDR　　<span class="comment">#IP地址   </span></span><br><span class="line">IPV6INIT　　<span class="comment">#IPV6是否有效[yes/no]   </span></span><br><span class="line">GATEWAY　　<span class="comment">#默认网关IP地址</span></span><br><span class="line">BROADCAST　　<span class="comment">#广播地址</span></span><br><span class="line">NETWORK　　<span class="comment">#网络地址</span></span><br></pre></td></tr></table></figure></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160324095902.png" alt=""></p><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/sysconfig/network   <span class="comment">#修改这个文件，系统生效</span></span><br></pre></td></tr></table></figure><ul><li>还有一种方法修改：hostname命令。（临时修改，机器重新启动之后就会恢复原来的值）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hostname　　　　//查看机器名</span><br><span class="line">$ hostname -i  //查看本机器名对应的ip地址</span><br><span class="line">$ hostname 新名称　　//修改主机名(临时有效)</span><br></pre></td></tr></table></figure><h3 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/hosts　　<span class="comment">#修改ip和域名/主机名映射</span></span><br></pre></td></tr></table></figure><p>例如：</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160324100025.png" alt=""></p><h3 id="修改默认端口"><a href="#修改默认端口" class="headerlink" title="修改默认端口"></a>修改默认端口</h3><ol><li><p>修改配置文件：/etc/ssh/sshd_config ，找到#port 22 ，如图<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F75e6c306-ec03-4767-b39d-42139b2cf43e.png" alt=""></p></li><li><p>先将Port 22 前面的 # 号去掉，并另起一行。如定义SSH端口号为21117，则输入（建议在万位的端口）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Ffe475739-4f9b-461d-b08c-bc2c0c209444.png" alt=""></p></li><li><p>修改完毕后，重启SSH服务，并退出当前连接的SSH端口<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fdca4f2c3-1d50-4162-ab37-90d482b725fc.png" alt=""></p></li><li><p>退出后，重新连接一下，链接成功后可以删除22那行记录。</p></li></ol><h3 id="禁用root本地或远程登陆"><a href="#禁用root本地或远程登陆" class="headerlink" title="禁用root本地或远程登陆"></a>禁用root本地或远程登陆</h3><ol><li>禁止root本地登录</li></ol><blockquote><p>修改/etc/pam.d/login文件增加下面一行<br>auth required pam_succeed_if.so user != root quiet</p></blockquote><ol start="2"><li>禁止root远程ssh登录</li></ol><blockquote><p>修改/etc/ssh/sshd_config文件，将PermitRootLogin yes 改为no</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F5e15de04-7cca-4ae3-b555-5325718f7063.png" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fd66c86e2-53c1-424b-b884-5f2fc64be994.png" alt=""></p><ol start="3"><li>重新启动sshd服务。</li></ol><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ service iptables XX</span><br><span class="line">$ service iptables status</span><br><span class="line">$ service iptables stop</span><br></pre></td></tr></table></figure><ul><li>防火墙是否开机自启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ chkconfig iptables --list</span><br><span class="line">$ vi /etc/inittab</span><br><span class="line">$ chkconfig iptables off</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--Yum源码安装配置</title>
      <link href="/2016/02/11/Linux-Yum%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
      <url>/2016/02/11/Linux-Yum%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　　<code>YUM(Yellow dog Updater, Modified)</code>是一个基于RPM包管理，比RPM软件包管理更加的自能。能够从<code>指定的服务器自动下载</code>RPM包并且安装，并且可以<code>自动处理依赖性关系</code>，一次安装所有依赖的软件包。</p><a id="more"></a><h3 id="配置和安装"><a href="#配置和安装" class="headerlink" title="配置和安装"></a>配置和安装</h3><p>由于yum需要从指定的服务器中自动下载，所以他就需要有可靠的软件仓库（<code>repository</code>），有点类似于Maven的中央仓库的概念。下面来安装一下<code>yum源</code>：</p><h4 id="准备yum源"><a href="#准备yum源" class="headerlink" title="准备yum源"></a>准备yum源</h4><p>我们选择<code>国内的163yum源</code>：<a href="http://mirrors.163.com/.help/centos.html" title="国内163yum源" target="_blank" rel="noopener">http://mirrors.163.com/.help/centos.html</a></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F636e527d-27f7-4737-890b-11886dd40e26.png" alt=""></p><h4 id="备份本地yum"><a href="#备份本地yum" class="headerlink" title="备份本地yum"></a>备份本地yum</h4><blockquote><p>把之前的repo文件备份，我这里重命名添加”.bak”后缀,然后上传下载的163源。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F97714618-2baf-4ba1-a155-53268ddd8f0d.png" alt=""></p><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><blockquote><p>清楚之前版本，并且添加本地缓存<br>1、yum clean all<br>2、yum makecache #注意：如下错误需要去添加域名解析到hosts文件，重新运行yum makecache</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fccce88c7-fa4d-4732-9420-69ed1f19ca86.png" alt=""></p><blockquote><p>重新运行，OK</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F21ef4f10-cd44-4862-8aaf-7e2a8c5b9d3c.png" alt=""></p><blockquote><p>【附,常用域名解析】：<br>123.58.173.185 mirrors.163.com<br>202.76.233.2 mirror.centos.org</p></blockquote><h3 id="yum命令"><a href="#yum命令" class="headerlink" title="yum命令"></a>yum命令</h3><h4 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum [-y] [install|remove|update] name <span class="comment">#-y可选表示自动运行yes,不然需要手动Y/N。</span></span><br><span class="line">yum -y install name <span class="comment">#安装软件,具体事例可查看后面博客安装mysql</span></span><br><span class="line">yum -y remove name <span class="comment">#删除,eg:yum -y remove java-1.4.2-gcj-1.4.2.0-40jpp.115</span></span><br><span class="line">yum -y update name <span class="comment">#升级软件</span></span><br></pre></td></tr></table></figure><h4 id="查询命令"><a href="#查询命令" class="headerlink" title="查询命令"></a>查询命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum search name <span class="comment">#关键字搜索软件</span></span><br><span class="line">yum info name <span class="comment">#显示软件信息</span></span><br><span class="line">yum list all <span class="comment">#列出全部的的软件(这个显示有点多)。</span></span><br><span class="line">yum list installed <span class="comment">#列出安装的的软件　</span></span><br><span class="line">yum list recent <span class="comment">#列出最近的的软件　</span></span><br><span class="line">yum list updates <span class="comment">#列出更新的软件　</span></span><br><span class="line">yum whatprovides name <span class="comment">#查询某个rpm软件包含该目标文件</span></span><br></pre></td></tr></table></figure><ul><li>例子</li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160321174056.jpg" alt=""></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160321174057.jpg" alt=""></p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--压缩及归档</title>
      <link href="/2016/01/28/Linux-%E5%8E%8B%E7%BC%A9%E5%8F%8A%E5%BD%92%E6%A1%A3/"/>
      <url>/2016/01/28/Linux-%E5%8E%8B%E7%BC%A9%E5%8F%8A%E5%BD%92%E6%A1%A3/</url>
      <content type="html"><![CDATA[<p>　　对于压缩和解压缩，在<em>Micrsoft windows</em>下的zip格式，我想大家都很熟悉，可以很好的用来管理我们的文件及文件夹。在Linux中压缩工具和命令也是是我们必须掌握的，常用于解压我们下载的文件，下面来看看常见的压缩格式和命令。</p><a id="more"></a><h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a><strong>压缩</strong></h2><h3 id="常见压缩格式"><a href="#常见压缩格式" class="headerlink" title="常见压缩格式"></a><strong>常见压缩格式</strong></h3><p><code>bz2</code>，<code>gz</code>，<code>zip</code>，<code>Z</code>，<code>xz</code></p><ul><li><code>bz2</code>：<code>bzip2</code>工具，采用Burrows-Wheeler块排序文本压缩算法和霍夫曼编码。</li><li><code>gz</code> ：<code>gzip</code>工具，GNU压缩工具，用Lempel-Ziv编码。</li><li><code>zip</code>：<code>zip</code>工具，Windows上PKZIP工具的Unix实现。</li><li><code>Z</code>  ：<code>compress</code>工具，原始的Unix文件压缩工具，现在已不常用。</li></ul><h3 id="压缩工具"><a href="#压缩工具" class="headerlink" title="压缩工具"></a><strong>压缩工具</strong></h3><ul><li>bzip2工具</li></ul><p>该工具逐渐普及，是相对来说是较新的压缩包，在压缩大型二进制文件比较流行。该软件包有以下压缩工具。</p><blockquote><p><strong>bzip2</strong> ：用来压缩文件。压缩文件自动替换之前文件，并添加后缀名。</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317195305.png" alt="stat"></p><blockquote><p><strong>bzcat</strong> ：用来查看压缩文件，可以直接查看到内容。<br><strong>bunzip2</strong> ：用来解压缩后的.bz2文件。<br><strong>bzip2recover</strong>：用来尝试恢复已损文件。</p></blockquote><ul><li>gzip工具</li></ul><p>是目前Linux最流行的文件压缩工具，是用来代替compress工具.z的，该软件包有以下压缩工具。使用方法类似上面bzip2。</p><blockquote><p><strong>gzip</strong>：用来压缩文件。<br><strong>gzcat</strong>：用来查看压缩文件的内容。<br><strong>gunzip</strong>：用来压缩文件。</p></blockquote><ul><li>zip工具</li></ul><p>该工具和MS-DOS、Windwos的PKZIP是兼容的。该压缩文件可以压缩文件和目录。</p><blockquote><p><strong>zip</strong> ：创建一个压缩文件。包含指定的文件和目录。<br><strong>zipcloak</strong>：一个加密的压缩文件。<br><strong>zipnore</strong>：从压缩文件中提取批准。<br><strong>zipsplit</strong>：将一个现有的zip压缩文件分割成更小的固定大小的文件。<br><strong>unzip</strong>：解压缩</p></blockquote><h2 id="归档"><a href="#归档" class="headerlink" title="归档"></a><strong>归档</strong></h2><p>虽然zip命令能够压缩文件和文件夹到单个文件，但是还不是最标准的归档工具，目前标准的归档工具是tar命令。</p><ol><li><p>压缩命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zcvf 压缩文件名.tar.gz 被压缩文件名 <span class="comment">#可先切换到当前目录下。压缩文件名和被压缩文件名都可加入路径。</span></span><br></pre></td></tr></table></figure></li><li><p>解压缩命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf 压缩文件名.tar.gz <span class="comment">#解压缩后的文件只能放在当前的目录。</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--文本管理类命令</title>
      <link href="/2016/01/27/Linux-%E6%96%87%E6%9C%AC%E7%AE%A1%E7%90%86%E7%B1%BB%E5%91%BD%E4%BB%A4/"/>
      <url>/2016/01/27/Linux-%E6%96%87%E6%9C%AC%E7%AE%A1%E7%90%86%E7%B1%BB%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h2 id="文件信息"><a href="#文件信息" class="headerlink" title="文件信息"></a><strong>文件信息</strong></h2><h3 id="文本统计信息"><a href="#文本统计信息" class="headerlink" title="文本统计信息"></a><strong>文本统计信息</strong></h3><p>ls命令可以查看，以及批量查看文件的某些信息，但是文件的状态信息还是无法查看。stat,可以查看文件的状态信息。</p><a id="more"></a><p><code>stat</code></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160317185329.png" alt="stat"></p><ul><li>访问：access</li><li>修改：modify（修改，指的是修改了文件的内容）</li><li>改变：change，metadata(元数据)（改变，指的是改变了文件的属性，或者说元数据）</li></ul><h3 id="文本查看命令"><a href="#文本查看命令" class="headerlink" title="文本查看命令"></a><strong>文本查看命令</strong></h3><p><code>cat</code>、<code>tac</code>、<code>more</code>、<code>less</code>、<code>head</code>、<code>tail</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat  <span class="comment">#链接并显示,一次显示整个文件</span></span><br><span class="line">tac  <span class="comment">#和cat相反，倒着显示</span></span><br></pre></td></tr></table></figure><blockquote><p>cat fileName : 一次显示所有文件内容<br>cat &gt; fileName : 从键盘创建一个文件（ctrl+c，保存代码）<br>cat f1 f2 &gt; fileNmae : 合并文件内容（技巧）<br>cat -n：在显示的时候给每一个行编号<br>cat -E：显示每一行的行结束符有，linux的文本行结束符为“$”，和windows有区别。(如果想翻屏，就shift+PaUp/PaDn）</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">more  <span class="comment">#分屏翻页（支持向后翻，不支持向前翻），常常配合管道命令使用</span></span><br><span class="line">less  <span class="comment">#和more相似，可前后翻。eg：ps -ef|less，（#使用q退出）</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">head  <span class="comment">#查看文件前n行（默认10行）</span></span><br><span class="line">tail  <span class="comment">#查看文件后n行（默认10行）</span></span><br></pre></td></tr></table></figure><blockquote><p>tail -n num fileName : 查看文件前num行。<br>tail -f：查看文件尾部，不退出，等待文件追加内容。常用于查看日志！</p></blockquote><h2 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a><strong>文本处理</strong></h2><h3 id="文本处理-1"><a href="#文本处理-1" class="headerlink" title="文本处理"></a><strong>文本处理</strong></h3><p><code>cut</code>、 <code>join</code>、<code>sed</code>、<code>awk</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut ：剪切命令，一般配合管道命令使用，</span><br></pre></td></tr></table></figure><blockquote><p>-d：字节，指定字段分隔符（默认为一个空格）。<br>-c：字符，<br>-f：区域，指定要显示的字段</p></blockquote><p>eg.</p><ul><li>-f 1：显示第一个字段</li><li>-f 1,3：显示第一个和第三个字段（离散表示法）</li><li>-f 1-3：显示一到三的字段（连续表示法）<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160316160346.png" alt=""></li></ul><h3 id="文本排序"><a href="#文本排序" class="headerlink" title="文本排序"></a><strong>文本排序</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort：（默认字母升序）</span><br></pre></td></tr></table></figure><blockquote><p>-n 排序数字<br>-r 逆向排序<br>-t  ：以什么为分隔符<br>-k    :从哪个字段开始<br>-u：排序后相同的行只显示一次<br>-f：忽略字符大小写</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uniq：报告重复行（相邻并相同才算做向同行）</span><br></pre></td></tr></table></figure><blockquote><p>-d：只显示重复行<br>-D：显示所有重复行<br>-c：把所有行取出来，并显示次数</p></blockquote><h3 id="文本统计"><a href="#文本统计" class="headerlink" title="文本统计"></a><strong>文本统计</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wc(word count)</span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F42190026-98ac-43aa-a690-f9122f44df3f.png" alt=""></p><p>分别为：行 单词数 字节/字符数</p><blockquote><p>-l：行<br>-w：单次数<br>-c：字节<br>-m：字符<br>-L：最长的一段包含了多少字符</p></blockquote><p>eg.</p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160316161803.png" alt=""></p><h3 id="字符处理"><a href="#字符处理" class="headerlink" title="字符处理"></a><strong>字符处理</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tr  <span class="comment">#转换或删除字符，可以实现set的基本功能，替换，删除，去重</span></span><br></pre></td></tr></table></figure><blockquote><p>tr [OPTION] SET1 [SET2]</p></blockquote><p>eg.</p><p><code>tr &#39;a-z&#39; &#39;A-Z&#39; &lt; /etc/passwd</code>  #把passwd中所有信息转成大写。<br><code>tr -d &#39;ab&#39; &lt; fileName</code>        #把文件中包含a和b的删除掉。</p>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--软件安装之JDK</title>
      <link href="/2016/01/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BJDK/"/>
      <url>/2016/01/22/Linux-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B9%8BJDK/</url>
      <content type="html"><![CDATA[<p>　　JDK（<code>jre+开发工具包</code>），即JDK包含了jre（<code>java虚拟机+核心类库</code>），jre主要是用来运行程序的，而jdk可以运行程序又可以用来开发。作为一个后端程序员，或者说使用一个运行在JVM虚拟机之上的语言和环境，对于jdk的安装是不可避免的，虽然比较简单，但也不要去忽略它。</p><a id="more"></a><h3 id="移除自带虚拟机"><a href="#移除自带虚拟机" class="headerlink" title="移除自带虚拟机"></a>移除自带虚拟机</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. java -version <span class="comment">#检查是否已经安装jdk(Ubuntu自带openjdk)。</span></span><br><span class="line">2. rpm -qa|grep gcj <span class="comment">#查看具体的信息,主要获取具体名称和版本，提供给卸载使用。</span></span><br><span class="line">3. rpm -e --nodeps java-xxxx.x86_64 <span class="comment">#卸载jdk。</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160321174156.png" alt=""></p><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><p>我们这里使用tar.gz和rpm两种安装方式，选择一种即可，推荐使用tar.gz方式。下载后上传：</p><blockquote><p>rpm　下载地址：<a href="http://pan.baidu.com/s/1eRoWe90" title="rpm_jdk1.7_64位" target="_blank" rel="noopener">jdk-7u67-linux-x64.rpm</a><br>tar.gz下载地址：<a href="http://pan.baidu.com/s/1o7fSmLk" title="tar.gz_64位_jdk1.7" target="_blank" rel="noopener">jdk-7u67-linux-x64.tar.gz</a></p></blockquote><h4 id="rpm安装"><a href="#rpm安装" class="headerlink" title="rpm安装"></a>rpm安装</h4><p>rpm安装，下载上传相应的rpm文件，然后执行安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jdk-7u67-linux-x64.rpm <span class="comment">#安装jdk,默认安装目录为/usr/java</span></span><br></pre></td></tr></table></figure><h4 id="tar-gz安装"><a href="#tar-gz安装" class="headerlink" title="tar.gz安装"></a>tar.gz安装</h4><p><a href="http://blog.xiaoxiaomo.com/2016/03/17/Linux-%E5%8E%8B%E7%BC%A9%E5%8F%8A%E5%BD%92%E6%A1%A3" title="Linux--压缩及归档">解压缩.tar.gz</a>,把解压后的文件夹推荐放到/usr/local下面。（当然任意目录下都可以）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-7u67-linux-x64.tar.gz <span class="comment">#解压jdk，会在当前目录下（自己改名或移动）</span></span><br></pre></td></tr></table></figure><h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><ul><li>第一种： 修改<code>/etc/profile</code>文件(开发环境推荐)</li></ul><p>很方便所有用户都能使用，但存在一定安全性。 </p><blockquote><p>/etc/profile #在profile文件末尾添加如下配置，<a href="http://blog.xiaoxiaomo.com/2016/03/18/Linux-%E5%B8%B8%E7%94%A8VI-VIM%E5%91%BD%E4%BB%A4" title="Linux--常见VI/VIM命令">具体修改操作</a>：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.7</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$&#123;JAVA_HOME&#125;</span>/lib:<span class="variable">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>【注意】：</p><blockquote><ol><li>你要将 /usr/local/jdk1.7改为你的jdk安装目录 </li><li>linux下用冒号“:”来分隔路径 </li><li>等号左右不能有空格。</li><li>CLASSPATH中当前目录“.”不能丢</li></ol></blockquote><ul><li>第二种： 修改<code>个人主目录/.bash_profile</code>文件（生产环境推荐）</li></ul><p>这种方法更为安全，个人主目录配置了的用户才能使用<br>添加如上配置即可（略）。</p><ul><li>第三种： 直接在<code>shell下设置变量</code>（不推荐，适合临时使用）</li></ul><p>只对该shell有效。只需在shell终端执行如上命令即可（略）。</p><h3 id="重新加载"><a href="#重新加载" class="headerlink" title="重新加载"></a>重新加载</h3><p>重新加载配置，使用source命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java -version <span class="comment">#或下面命令</span></span><br><span class="line">javac -version <span class="comment">#显示版本信息。</span></span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux--用户和组管理</title>
      <link href="/2016/01/18/Linux-%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%E7%AE%A1%E7%90%86/"/>
      <url>/2016/01/18/Linux-%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>　　在Linux系统中，用户信息及密码，组信息及其密码，都保存在不同的文件中，</p><ol><li>用户信息（<code>/etc/passwd</code>），</li><li>用户密码（<code>/etc/shadow</code>），</li><li>用户组帐号（<code>/etc/group</code>），</li><li>用户组密码（<code>/etc/gshadow</code>）。</li></ol><p>用户和组是多对多的关系，即一个用户可以属于多个组，一个组也可以包含多个用户。</p><a id="more"></a><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><ol><li><p><strong>/etc/passwd</strong><br><code>/etc/passwd</code>：保存了所有用户信息，密码使用了x表示(不是明文，加密了的)。<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155129.png" alt="/etc/passwd"></p><blockquote><p>root:x:0:0:root:/root:/bin/bash<br>表示：<strong>用户帐号</strong>|<strong>用户密码</strong>|<strong>用户ID</strong>|<strong>用户组ID</strong>|<strong>用户名全称</strong>|<strong>用户主目录</strong>|<strong>用户所使用的shell</strong>。<br>该文件默认就会初始化很多用户，当shell等于/sbin/nologin时就表示该用户不能登陆。</p></blockquote></li><li><p><strong>/etc/shadow</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155130.png" alt=""><br>第二位为用户密码，使用了MD5加密算法，超级用户才拥有该文件读权限。</p></li><li><p><strong>/etc/group</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155131.png" alt=""><br>分别表示：用户组名称 x 用户组ID 用户组成员列表 </p></li><li><p><strong>/etc/gshadow</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155132.png" alt=""></p></li></ol><h2 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h2><ol><li><p>添加用户 useradd [option] userName<br>添加用户<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160314155133.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; -d dir ：#指定目录，默认目录/home/userName</span><br><span class="line">&gt; -n ： #不为用户创建私有用户组</span><br><span class="line">&gt; -g groupName : #指定用户组，该用户组必须存在,eg：useradd -g blogger xiaoxiaomo</span><br><span class="line">&gt; -G groupName1,groupName2 ： #指定多个组</span><br><span class="line">&gt; -p passWord ： #指定用户密码，eg：usreadd -p 123456 xiaoxiaomo</span><br></pre></td></tr></table></figure></li><li><p>修改用户 usermod [option] userName</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; usermod -l newUserName userName #修改用户名。</span><br><span class="line">&gt; usermod -d 原目录 新目录名称 #修改用户目录，eg：usermod -d /home/xiaoxiaomo momo。</span><br><span class="line">&gt; usermod -L userName #锁定用户，锁定后用户密码前会有感叹号，解锁使用-U，可用-S查看状态。</span><br><span class="line">&gt; usermod -g 新组 用户 #修改用户组</span><br><span class="line">&gt; usermod -G 组 用户 #给用户添加组</span><br></pre></td></tr></table></figure></li><li><p>设置密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; passwd [userName] #带参数修改某用户密码（一般root用户才有权限），不带参数修改自己的密码。</span><br><span class="line">&gt; passwd -l userName #锁定用户密码，解锁使用-u。</span><br><span class="line">&gt; passwd -d userName #删除用户密码。</span><br></pre></td></tr></table></figure></li><li><p>删除用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; userdel userName   #删除用户保留文件夹</span><br><span class="line">&gt; userdel -r userName #删除用户不保留文件夹</span><br></pre></td></tr></table></figure></li></ol><h2 id="用户组管理"><a href="#用户组管理" class="headerlink" title="用户组管理"></a>用户组管理</h2><ol><li><p>添加组</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; groupadd [-r] groupName #创建用户组，带-r,会创建系统组GID&lt;500,不带-r,GID&gt;=500。</span><br><span class="line">&gt; groupmod -n newGroupName groupName #修改组名称。</span><br><span class="line">&gt; groupmod -g newGroupId groupId #修改组GID，不可与已有Id重复。</span><br></pre></td></tr></table></figure></li><li><p>删除组</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; groupdel groupName #注：删除组是应先删除用户，被删除的组不能是某个账户的私有用户组。</span><br></pre></td></tr></table></figure></li><li><p>用户和组</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; gpasswd -a userName groupName #添加用户到某个组（root用户和改组管理员又该权限）。</span><br><span class="line">&gt; gpasswd -d userName groupName #把某个用户从组中删除（root用户和改组管理员又该权限）。</span><br><span class="line">&gt; gpasswd -A userName groupName #设置userName为组管理员。</span><br><span class="line">&gt; groups userName #查看用户所属组</span><br></pre></td></tr></table></figure></li></ol><h2 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h2><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><ul><li>chmod [option] 文件或目录<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> chmod 777 文件目录 <span class="comment">#授权rwxrwxrwx。</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> chmod u=rwx,g=rwx,o=rwx <span class="comment">#等同上面的授权。</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> chmod o-x,g+w 文件 <span class="comment">#文件去除其他组用户执行的权限，增加组写的权限。</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> chmod a+w  <span class="comment">#给所有用户添加自读权限。</span></span></span><br></pre></td></tr></table></figure></li></ul><h3 id="修改所属"><a href="#修改所属" class="headerlink" title="修改所属"></a>修改所属</h3><ol><li><p>改变文件/目录所属者(用户)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown xiaoxiaomo 文件/目录  #改变文件/目录的所有者为xiaoxiaomo</span><br><span class="line">chown ‐R root 文件/目录  #改变文件/目录以及子目录文件的所有者为root</span><br></pre></td></tr></table></figure></li><li><p>改变文件/目录所属者（组）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chgrp root 文件/目录：改变文件/目录所属的组为root</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>VMware--克隆虚拟机后网络问题</title>
      <link href="/2016/01/15/VMware-%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%8E%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98/"/>
      <url>/2016/01/15/VMware-%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%8E%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="1-【问题】"><a href="#1-【问题】" class="headerlink" title="1. 【问题】"></a>1. 【问题】</h2><blockquote><p>使用VMware克隆功能后，会发现网卡有问题<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F9f23d0d7-d158-4302-b4f0-ed2f3a507edd.png" alt="重启网卡失败"></p></blockquote><a id="more"></a><h2 id="2-【解决】"><a href="#2-【解决】" class="headerlink" title="2. 【解决】"></a>2. 【解决】</h2><blockquote><p>由于网络配置中的网卡MAC地址还是之前虚拟机的，需要去复制出该虚拟机新生成的MAC地址到网络配置中</p></blockquote><ul><li><strong>具体步骤</strong></li></ul><blockquote><p>需要去 <strong>/etc/udev/rules.d/70-persistent-net.rules</strong> 复制出eth1（一般是最后一个网卡信息）的MAC地址到 <strong>/etc/sysconfig/network-script/eth0</strong> 。</p><p>①、修改eth0为：eth1（一般是最后一个）<br>②、修改HWADDR为：01:0c:29:43:21:3c（此网卡是作者电脑例子）<br>③、其中无用的eth0可以删除（保留最后一个就行）</p></blockquote><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F06295951-0670-4a7a-b633-a9f35a0166c3.png" alt="到/etc/udev/rules.d/70-persistent-net.rules目录"></p><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F8ab829c9-afb6-41a7-875d-5d3dae6bd05c.png" alt="复制ech1的网卡地址"></p><h2 id="3-【使用】"><a href="#3-【使用】" class="headerlink" title="3. 【使用】"></a>3. 【使用】</h2><blockquote><p><strong>重启服务即可：service network restart</strong></p></blockquote>]]></content>
      
      <categories>
          
          <category> 异常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 虚拟机 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>VMware--网络配置</title>
      <link href="/2016/01/15/VMware-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"/>
      <url>/2016/01/15/VMware-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>　　本篇博客主要讲解VMvare网络配置的三种方式<strong>Host-only</strong>、<strong>桥接</strong>、<strong>NAT连接</strong>的区别，以及用途。然后着重讲解一下常用的两种配置，<code>Bridge模式</code>和<code>自定义模式</code>。（<strong>PS</strong>：由于博主刚搭建博客，前期基础部分的博客都是来源于博主<a href="http://www.wiz.cn/" target="_blank" rel="noopener">为知笔记</a>上的整理）！</p><a id="more"></a><h2 id="三种网络连接模式"><a href="#三种网络连接模式" class="headerlink" title="三种网络连接模式"></a><strong>三种网络连接模式</strong></h2><ul><li><strong>Host-only连接方式</strong></li></ul><blockquote><p> <code>相当于新建了一个由所有虚机与宿主主机所构成的局域网</code>，但该局域网与宿主主机本身所处的现有局域网是相互独立的，如果不做额外路由设置，这两个局域网之间不会连通，因此新建的局域网可以认为是一个单独从属于当前宿主主机的私有网络.只能进行虚拟机和主机之间的网络通信。</p></blockquote><ul><li><strong>Bridge（桥接）连接方式</strong></li></ul><blockquote><p><code>让虚机具有与宿主机不同的各自独立IP地址</code>，但与宿主机保持在同一网段，最终结果是所有虚机都加入宿主主机所在的局域网，<code>这与在该局域网中添加入其他宿主主机在效果上没什么区别</code>。</p></blockquote><ul><li><strong>NAT连接方式</strong></li></ul><blockquote><p>虽然从表面现象看，虚机无自己的IP地址，而是共享宿主主机的IP地址，使得虚拟局域网内的虚机在对外访问时，<code>完全“冒用”宿主主机的IP地址，这样从外部网络来看，只能看到宿主主机，完全看不到新建的虚拟局域网</code>。</p></blockquote><!-- more --><h2 id="常见连接模式"><a href="#常见连接模式" class="headerlink" title="常见连接模式"></a><strong>常见连接模式</strong></h2><h3 id="Bridge模式"><a href="#Bridge模式" class="headerlink" title="Bridge模式"></a><strong>Bridge模式</strong></h3><ul><li>①、<strong>设置为桥接</strong></li></ul><p><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160324085430.jpg" alt="选择桥接"></p><ul><li>②、<strong>修改网卡地址</strong></li></ul><blockquote><p>①、<strong>ONBOOT</strong>          #修改为yes(表示一直生效，不然下次启动，就会无效)<br>②、<strong>BOOTPROTO</strong>      #删除或者修改为static（删除后默认static）<br>③、<strong>设置IPADDR</strong>      #设置为192.168.1.*（注：修改为本机网卡同段落IP地址，不要配置ip冲突）<br>④、<strong>设置NETMASK</strong>     #225.225.225.0<br>⑤、<strong>设置GATEWAY</strong>     #192,168.1.1(本机相同网关)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">HWADDR=00:0c:29:e7:78:24</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">UUID=09d41225-6440-4b5a-a9fd-819ab2738bc7</span><br><span class="line">ONBOOT=yes</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.1.76</span><br><span class="line">NETEMASK=225.225.225.0</span><br><span class="line">GATEWAY=192.168.1.1</span><br></pre></td></tr></table></figure></p></blockquote><ul><li><p>③、<strong>重启网络</strong>：<code>service network restart</code>。</p></li><li><p>④、ping 本机网关、本机ip、baiduIP(域名一般是无法解析的)<br>如果域名无法解析：修改<code>/etc/resolv.conf</code>文件，加上如下信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver 8.8.4.4</span><br></pre></td></tr></table></figure></li></ul><h3 id="NET模式"><a href="#NET模式" class="headerlink" title="NET模式"></a><strong>NET模式</strong></h3><ul><li><p><strong>如果使用net模式。修改信息和上面类似。只是注意下网关，配置信息如下：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">HWADDR=00:0c:29:e7:78:24</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">UUID=09d41225-6440-4b5a-a9fd-819ab2738bc7</span><br><span class="line">ONBOOT=yes</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.33.76  #静态ip</span><br><span class="line">NETEMASK=225.225.225.0</span><br><span class="line">GATEWAY=192.168.33.2  ##注意网关</span><br></pre></td></tr></table></figure></li><li><p><strong>虚拟网卡VMvare8设置</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160524154015.jpg" alt="windows 虚拟网卡VMvare8设置"></p></li><li><p><strong>在虚拟机中设置net网关和网段</strong><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160524154355.jpg" alt="虚拟机中 设置net网关和网段"></p></li></ul><h3 id="自定义模式"><a href="#自定义模式" class="headerlink" title="自定义模式"></a><strong>自定义模式</strong></h3><ul><li><p>①、通过虚拟网卡，然后修改虚拟网卡VMnet1<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160524153231.jpg" alt="选择，自定义模式"><br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F55c77f0e-3d67-45f6-8da8-a1c22d731d35.png" alt="设置ip"></p></li><li><p>②、只需要添加IP地址和子网掩码。 登录虚拟机，修改网卡ip地址</p></li></ul><blockquote><p>①、<strong>ONBOOT</strong>     #修改为yes(表示一直生效，不然下次启动，就会无效)<br>②、<strong>BOOTPROTO</strong>  #删除或者修改为static（删除后默认static）<br>③、<strong>设置IPADDR</strong>  #设置为192.168.8.*（注：修改为虚拟网卡同段落IP地址）<br>④、<strong>设置NETMASK</strong> #225.225.225.0<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fe0792daa-ed88-4f62-bbef-beddb98e6bc2.png" alt="设置后信息如下"></p></blockquote><ul><li><p>③、<strong>重启网络</strong>：<code>service network restart</code>。</p></li><li><p>附件<br><img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160313174016.png" alt="为知笔记截图"></p></li></ul>]]></content>
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 虚拟机 </tag>
            
        </tags>
      
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <link href="/404.html"/>
      <url>/404.html</url>
      <content type="html"><![CDATA[<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 TRANSITIONAL//EN"><html> <head> <meta http-equiv="content-type" content="text/html; charset=utf-8">  <title>404</title>  <style>body{background-color:#ccc;}  .content{text-align:center;margin-top:100px;}  </style> </head> <body> <div class="content"> <script type="text/javascript" src="http://www.qq.com/404/search_children.js" charset="utf-8" homepageurl="http://blog.xiaoxiaomo.com" homepagename="回到我的主页"></script>  </div> </body></html>]]></content>
    </entry>
    
    <entry>
      <title>关于我/留言板</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<ul><li>　　　想要得到你就要学会付出，要付出还要坚持；如果你真的觉得很难，那你就放弃，如果你放弃了就不要抱怨。</li></ul><p>　</p><hr><p>　</p><h1 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h1><blockquote><ol><li>本博客主要以<strong>Hadoop/Spark</strong>、<strong>机器学习</strong>、<strong>人工智能</strong>相关技术为主</li><li>当然无聊的时候也会 <strong>写写随笔</strong>、<strong>游记</strong>(●’◡’●)</li><li>博客会持续更新，理念：“<code>尽量精简，尽量易懂</code>”</li></ol></blockquote><h1 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h1><blockquote><ol><li>开源爱好者，乐于分享</li><li>追求相对完美</li><li>相信：存在即合理</li><li>相信：态度是做好一件事情的基础</li><li>相信：学习是一件很重要的事情</li><li>热爱生活，喜欢阅读、运动和旅游</li><li>一生追逐，爱与自由</li></ol></blockquote><h1 id="留言板"><a href="#留言板" class="headerlink" title="留言板"></a>留言板</h1><blockquote><ol><li>可在下方留言</li><li>不断成长和迭代的途中，希望能得到大家宝贵的建议</li><li>邮箱：<a href="mailto:jason.tangxd@gmail.com" target="_blank" rel="noopener">jason.tangxd@gmail.com</a></li></ol></blockquote><p>　<br><code>微信打赏</code> 扫一扫 (●’◡’●)<br>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2Fweixin02.jpg?imageMogr2/thumbnail/238x238" alt="微信二维码"></p><p><code>加个微信，相互学习讨论</code> 扫一扫 (●’◡’●)<br>　　<img src="https://img.xiaoxiaomo.com/blog%2Fimg%2F20160406211054.png" alt="微信二维码">　</p>]]></content>
    </entry>
    
    <entry>
      <title>相册</title>
      <link href="/photo/index.html"/>
      <url>/photo/index.html</url>
      <content type="html"><![CDATA[<p><link type="text/css" href="/fancybox/jquery.fancybox.css" rel="stylesheet"></p><p><link type="text/css" href="/css/style.css" rel="stylesheet"></p><script type="text/javascript" src="/js/jquery.min.js"></script><script src="/js/jquery.lazyload.js"></script><script src="/fancybox/jquery.fancybox.js"></script><script src="/js/photo.js"></script><script>    jQuery_lazyload=$.noConflict(true);</script><p><div class="instagram" style="margin-bottom:"><section class="archives album"><ul class="img-box-ul" style="list-style:none;"></ul></section></div></p><p><div>&nbsp;</div></p><p><link type="text/css" rel="stylesheet" href="/css/lrtk.css"></p><script src="/js/jquery.imgbox.pack.js"></script>]]></content>
    </entry>
    
    <entry>
      <title></title>
      <link href="/photo/output.json"/>
      <url>/photo/output.json</url>
      <content type="html"><![CDATA[["-50fbc8b434201d30.jpg","1234567100.jpg","1234567101.jpg","1234567890.jpg","1234567891.jpg","1234567892.jpg","1234567893.jpg","1234567894.jpg","1234567895.jpg","1234567896.jpg","1234567898.jpg","1234567899.jpg","1234567900.jpg","2012-10-01-703.jpg","2013-10-04_02-50-28_960.jpg","GEDC1515.JPG","GEDC2741.JPG","IMG_20150617_140931.jpg","IMG_20150618_203115.jpg","IMG_20150829_171005.jpg","IMG_20151001_173008.jpg","IMG_20151031_102502.jpg","IMG_20160228_132258.jpg","IMG_20160228_141929.jpg","IMG_20160228_161825.jpg","IMG_20160228_161830.jpg","IMG_20160501_104928.jpg","IMG_20160501_105429.jpg","IMG_20160501_105713.jpg","IMG_20160501_110110.jpg","IMG_20160501_115723.jpg","IMG_20160501_120251.jpg","IMG_20160501_120637.jpg","IMG_20160501_120950.jpg","IMG_20160501_120955.jpg","IMG_20160501_121006.jpg","IMG_20160501_121224.jpg","IMG_20160501_121400.jpg","IMG_20160501_122501.jpg","IMG_20160501_135817.jpg","IMG_20160501_141608.jpg","IMG_20160501_170605.jpg"]]]></content>
    </entry>
    
    <entry>
      <title></title>
      <link href="/photo/photo.js"/>
      <url>/photo/photo.js</url>
      <content type="html"><![CDATA[const fs = require("fs");// 相册相对路径const path = "../../node_modules/photo_album/";var qiniu = require("qiniu");//需要填写你的 Access Key 和 Secret Keyqiniu.conf.ACCESS_KEY = 'L1__K2wfsgkd07pf6LCPLEL_daimtShrBYxN8dUG';qiniu.conf.SECRET_KEY = 'iJjmQUPSDp50Nky_tPrLxb5KTMoxf_fwRxj1elIi';//要上传的空间bucket = 'photos';//构建上传策略函数function uptoken(bucket, key) {  var putPolicy = new qiniu.rs.PutPolicy(bucket+":"+key);  return putPolicy.token();}//构造上传函数function uploadFile(uptoken, key, localFile) {    var extra = new qiniu.io.PutExtra();    qiniu.io.putFile(uptoken, key, localFile, extra, function(err, ret) {      if(!err) {        // 上传成功， 处理返回值        console.log('upload success : ',ret.hash, ret.key);      } else {        // 上传失败， 处理返回代码        console.log(err);      }  });}//读取文件后缀名称，并转化成小写function getFilenameSuffix(file_name) {  if(file_name=='.DS_Store'){    return '.DS_Store';  }    if (file_name == null || file_name.length == 0)        return null;    var result = /\.[^\.]+/.exec(file_name);    return result == null ? null : (result + "").toLowerCase();}//获取文件名后缀名String.prototype.extension = function(){    var ext = null;    var name = this.toLowerCase();    var i = name.lastIndexOf(".");    if(i > -1){    var ext = name.substring(i);    }    return ext;}//判断Array中是否包含某个值Array.prototype.contain = function(obj){    for(var i=0; i]]></content>
    </entry>
    
    <entry>
      <title></title>
      <link href="/photo/tool.js"/>
      <url>/photo/tool.js</url>
      <content type="html"><![CDATA["use strict";const fs = require("fs");const path = "../../photos";fs.readdir(path, function (err, files) {    if (err) {        return;    }    let arr = [];    (function iterator(index) {        if (index == files.length) {            fs.writeFile("output.json", JSON.stringify(arr, null, "\t"));            return;        }        fs.stat(path + "/" + files[index], function (err, stats) {            if (err) {                return;            }            if (stats.isFile()) {                arr.push(files[index]);            }            iterator(index + 1);        })    }(0));});]]></content>
    </entry>
    
    <entry>
      <title>search</title>
      <link href="/search/index.html"/>
      <url>/search/index.html</url>
      <content type="html"><![CDATA[<p><div id="container" class="page"><br>  <div id="st-results-container" class="st-search-container" style="width:80%">正在加载搜索结果，请稍等。</div><br>  <style>.st-result-text {<br>  background: #fafafa;<br>  display: block;<br>  border-left: 0.5em solid #ccc;<br>  -webkit-transition: border-left 0.45s;<br>  -moz-transition: border-left 0.45s;<br>  -o-transition: border-left 0.45s;<br>  -ms-transition: border-left 0.45s;<br>  transition: border-left 0.45s;<br>  padding: 0.5em;<br>}<br>@media only screen and (min-width: 768px) {<br>  .st-result-text {<br>    padding: 1em;<br>  }<br>}<br>.st-result-text:hover {<br>  border-left: 0.5em solid #ea6753;<br>}<br>.st-result-text h3 a{<br>  color: #2ca6cb;<br>  line-height: 1.5;<br>  font-size: 22px;<br>}<br>.st-snippet em {<br>  font-weight: bold;<br>  color: #ea6753;<br>}</style></div></p><script type="text/javascript">  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');  _st('install','A-M5aWjch5SsKqsbodXz','2.0.0');</script>]]></content>
    </entry>
    
    <entry>
      <title>读书</title>
      <link href="/reading/index.html"/>
      <url>/reading/index.html</url>
      <content type="html"><![CDATA[]]></content>
    </entry>
    
    <entry>
      <title>云标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      <content type="html"><![CDATA[]]></content>
    </entry>
    
  
</search>
